{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889b02e6-e845-484b-bf6a-e1eed6bd266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a copy of slurm_train.py from anurag/slurm_onebutton\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "import cv2\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import detectron2.data.transforms as T\n",
    "import shutil\n",
    "from setuptools.namespaces import flatten\n",
    "\n",
    "import random\n",
    "import torch \n",
    "import base64\n",
    "import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "coco_yaml = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "lvis_yaml = \"LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n",
    "lvis_yaml2 = \"LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml\"\n",
    "pano_yaml = \"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"\n",
    "\n",
    "jsons_root = '/checkpoint/apratik/finals/jsons/active_vision/'\n",
    "img_dir_test = '/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb'\n",
    "test_jsons = ['frlapt1_20n0.json', 'frlapt1_20n1.json', 'frlapt1_20n2.json']\n",
    "test_jsons = [os.path.join(jsons_root, x) for x in test_jsons]\n",
    "\n",
    "# val_json = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json'\n",
    "# val_json = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json'\n",
    "# img_dir_val = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb'\n",
    "# img_dir_val = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb'\n",
    "\n",
    "## Detectron2 Setup\n",
    "\n",
    "# from copy_paste import CopyPaste\n",
    "# import albumentations as A\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "#     @classmethod\n",
    "#     def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "#         if output_folder is None:\n",
    "#             output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "#         return COCOEvaluator(dataset_name, output_dir=output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        mapper = DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "            T.ResizeShortestEdge(short_edge_length=cfg.INPUT.MIN_SIZE_TRAIN, max_size=1333, sample_style='choice'),\n",
    "            T.RandomFlip(prob=0.5),\n",
    "            T.RandomCrop(\"absolute\", (640, 640)),\n",
    "            T.RandomBrightness(0.9, 1.1)\n",
    "        ])\n",
    "        return build_detection_train_loader(cfg, mapper=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d30a90e-0131-4f70-8339-d7c6d28625d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)\n",
    "        \n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "                     \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            self.cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee15745e-d902-40a0-b2c9-0ee1f9fa2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOTrain:\n",
    "    def __init__(self, lr, w, maxiters, seed):\n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.merge_from_file(model_zoo.get_config_file(coco_yaml))\n",
    "        self.cfg.SOLVER.BASE_LR = lr  # pick a good LR\n",
    "        self.cfg.SOLVER.MAX_ITER = maxiters\n",
    "        self.cfg.SOLVER.WARMUP_ITERS = w\n",
    "        self.seed = seed\n",
    "        \n",
    "    def reset(self, train_json, img_dir_train, dataset_name):\n",
    "        DatasetCatalog.clear()\n",
    "        MetadataCatalog.clear()\n",
    "        self.train_data = dataset_name +  \"_train\"\n",
    "        self.dataset_name = dataset_name\n",
    "        self.train_json = train_json\n",
    "        register_coco_instances(self.train_data, {}, train_json, img_dir_train)\n",
    "        self.results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "        self.val_results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def vis(self):\n",
    "        dataset_dicts = DatasetCatalog.get(self.train_data)\n",
    "        for d in random.sample(dataset_dicts, 2):\n",
    "            img = cv2.imread(d[\"file_name\"])\n",
    "            visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(self.train_data), scale=0.5)\n",
    "            vis = visualizer.draw_dataset_dict(d)\n",
    "            img = vis.get_image()\n",
    "            plt.figure(figsize=(12,8))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "#     ['chair', 'door', 'table', 'indoor-plant', 'cushion', 'sofa'] != ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "\n",
    "            \n",
    "    def train(self, val_json, img_dir_val):\n",
    "        cfg = self.cfg\n",
    "        print(f'SOLVER PARAMS {cfg.SOLVER.MAX_ITER, cfg.SOLVER.WARMUP_ITERS, cfg.SOLVER.BASE_LR}')\n",
    "        cfg.DATASETS.TRAIN = (self.train_data,)\n",
    "        \n",
    "        self.val_data = self.dataset_name + \"_val\" + str(self.seed)\n",
    "        self.val_json = val_json\n",
    "        cfg.DATASETS.TEST = (self.val_data,)\n",
    "        register_coco_instances(self.val_data, {}, val_json, img_dir_val)\n",
    "        MetadataCatalog.get(self.val_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        \n",
    "        cfg.TEST.EVAL_PERIOD = 100\n",
    "        cfg.DATALOADER.NUM_WORKERS = 2\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(coco_yaml)  # Let training initialize from model zoo\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "        \n",
    "        cfg.SOLVER.GAMMA=0.75\n",
    "        cfg.SOLVER.STEPS=tuple([100*(i+1) for i in range(100) if 100*(i+1) < cfg.SOLVER.MAX_ITER])\n",
    "        \n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "        MetadataCatalog.get(self.train_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.train_data)}')\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(self.train_data).get(\"thing_classes\"))  \n",
    "        cfg.OUTPUT_DIR = os.path.join('output_aug_1108', str(cfg.SOLVER.MAX_ITER), self.dataset_name + str(self.seed))\n",
    "        print(f\"recreating {cfg.OUTPUT_DIR}\")\n",
    "        # if os.path.isdir(cfg.OUTPUT_DIR):\n",
    "        #     shutil.rmtree(cfg.OUTPUT_DIR)\n",
    "        print(cfg.OUTPUT_DIR)\n",
    "        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "        self.trainer = MyTrainer(cfg) #DefaultTrainer(cfg)  #Trainer(cfg)\n",
    "        self.trainer.resume_or_load(resume=False)\n",
    "        self.trainer.train()\n",
    "        \n",
    "    def run_val(self, dataset_name, val_json, img_dir_val):\n",
    "#         self.val_data = dataset_name + \"_val\" + str(self.seed)\n",
    "#         self.val_json = val_json\n",
    "#         self.cfg.DATASETS.TEST = (self.val_data,)\n",
    "#         register_coco_instances(self.val_data, {}, val_json, img_dir_val)\n",
    "#         MetadataCatalog.get(self.val_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "#         print(f'classes {MetadataCatalog.get(self.val_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.val_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.val_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.val_results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.val_results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "\n",
    "    def run_test(self, dataset_name, test_json, img_dir_test):\n",
    "        self.test_data = dataset_name + \"_test\" + str(self.seed)\n",
    "        self.test_json = test_json\n",
    "        self.cfg.DATASETS.TEST = (self.test_data,)\n",
    "        register_coco_instances(self.test_data, {}, test_json, img_dir_test)\n",
    "        MetadataCatalog.get(self.test_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.test_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.test_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.test_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "        \n",
    "    def run_train(self, train_json, img_dir_train, dataset_name, val_json, img_dir_val):\n",
    "        self.reset(train_json, img_dir_train, dataset_name)\n",
    "        # self.vis()\n",
    "        self.train(val_json, img_dir_val)\n",
    "\n",
    "\n",
    "# maxiters = [500, 800]\n",
    "# lrs = [0.0001, 0.0005, 0.001, 0.002, 0.005]\n",
    "# warmups = [100, 200]\n",
    "lrs = [0.004]\n",
    "maxiters = [2000]\n",
    "warmups = [200]\n",
    "\n",
    "def write_summary_to_file(filename, results, header_str):\n",
    "    if isinstance(results['bbox']['AP50'][0], list):\n",
    "        results['bbox']['AP50'] = list(flatten(results['bbox']['AP50']))\n",
    "        results['segm']['AP50'] = list(flatten(results['segm']['AP50']))\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(header_str)\n",
    "        f.write(f\"\\nbbox AP50 {sum(results['bbox']['AP50'])/len(results['bbox']['AP50'])}\")\n",
    "        f.write(f\"\\nsegm AP50 {sum(results['segm']['AP50'])/len(results['segm']['AP50'])}\")\n",
    "        f.write(f'\\nall results {results}')\n",
    "\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "def run_training(img_dir_train, n, traj, x, gt, p, train_json, val_json):\n",
    "    results_dir = os.path.join('results1021_sanity1105_7', str(traj), x, str(gt), str(p))\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "#     train_json = os.path.join(out_dir, tr_json)\n",
    "#     val_json = os.path.join(out_dir, val_json)\n",
    "    for lr in lrs:\n",
    "        for warmup in warmups:\n",
    "            for maxiter in maxiters:\n",
    "                results = {\n",
    "                    \"bbox\": {\n",
    "                        \"AP50\": []\n",
    "                    },\n",
    "                    \"segm\": {\n",
    "                        \"AP50\": []\n",
    "                    }\n",
    "                }\n",
    "                for i in range(n):\n",
    "                    c = COCOTrain(lr, warmup, maxiter, i)\n",
    "                    dataset_name = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(7))\n",
    "                    print(f'dataset_name {dataset_name}')\n",
    "                    c.run_train(train_json, img_dir_train, dataset_name, val_json, img_dir_train)\n",
    "                    res_eval = c.run_val(dataset_name, val_json, img_dir_train)\n",
    "                    with open(os.path.join(results_dir, \"validation_results.txt\"), \"a\") as f:\n",
    "                        f.write(f'val_json {val_json}\\n')\n",
    "                        f.write(f'lr {lr} warmup {warmup} maxiter {maxiter}\\n')\n",
    "                        f.write(json.dumps(res_eval) + '\\n')\n",
    "#                     for yix in range(len(test_jsons)):\n",
    "#                         r = c.run_test(dataset_name + str(yix), test_jsons[yix], img_dir_test)\n",
    "#                         with open(os.path.join(results_dir, \"all_results.txt\"), \"a\") as f:\n",
    "#                             f.write(json.dumps(r) + '\\n')\n",
    "#                     print(f'all results {c.results}')\n",
    "#                     results['bbox']['AP50'].append(c.results['bbox']['AP50'])\n",
    "#                     results['segm']['AP50'].append(c.results['segm']['AP50'])\n",
    "#                     write_summary_to_file(os.path.join(results_dir, str(n) + '_granular.txt'), c.results, f'\\ntrain_json {train_json}')\n",
    "                \n",
    "#                 itername = str(lr) + ' ' + str(warmup) + ' ' + str(maxiter) + ' ' + str(n)\n",
    "#                 write_summary_to_file(os.path.join(results_dir, itername + '_results_averaged.txt'), results, f'\\ntrain_json {train_json}, average over {n} runs')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47185a2c-ad5d-4952-923d-088337c6693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name 4Y2CHMY\n",
      "SOLVER PARAMS (2000, 200, 0.004)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json', name='4Y2CHMY_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug_1108/2000/4Y2CHMY0\n",
      "output_aug_1108/2000/4Y2CHMY0\n",
      "\u001b[32m[11/05 13:46:47 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "262 262\n",
      "\u001b[32m[11/05 13:46:47 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 13:46:47 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 45 images left.\n",
      "\u001b[32m[11/05 13:46:47 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 69           |  cushion   | 54           |    door    | 51           |\n",
      "| indoor-plant | 18           |    sofa    | 18           |   table    | 52           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 262          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[11/05 13:46:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[11/05 13:46:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/05 13:46:47 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 13:46:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[11/05 13:46:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "59 59\n",
      "\u001b[32m[11/05 13:46:47 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json\n",
      "\u001b[32m[11/05 13:46:47 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 12           |  cushion   | 12           |    door    | 14           |\n",
      "| indoor-plant | 6            |    sofa    | 4            |   table    | 11           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 59           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[11/05 13:46:47 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 13:46:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/05 13:46:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/apratik/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/structures/masks.py:348: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/private/home/apratik/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/structures/masks.py:348: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/private/home/apratik/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/05 13:47:21 d2.utils.events]: \u001b[0m eta: 0:55:07  iter: 19  total_loss: 3.714  loss_cls: 1.66  loss_box_reg: 0.8675  loss_mask: 0.6853  loss_rpn_cls: 0.2204  loss_rpn_loc: 0.2684  time: 1.6745  data_time: 0.1803  lr: 0.00021737  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:47:54 d2.utils.events]: \u001b[0m eta: 0:54:20  iter: 39  total_loss: 2.4  loss_cls: 0.7447  loss_box_reg: 0.8172  loss_mask: 0.6073  loss_rpn_cls: 0.04241  loss_rpn_loc: 0.1774  time: 1.6676  data_time: 0.1622  lr: 0.00044197  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:48:28 d2.utils.events]: \u001b[0m eta: 0:53:56  iter: 59  total_loss: 1.989  loss_cls: 0.513  loss_box_reg: 0.7922  loss_mask: 0.4834  loss_rpn_cls: 0.02402  loss_rpn_loc: 0.1394  time: 1.6740  data_time: 0.1705  lr: 0.00066657  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:49:02 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 79  total_loss: 1.579  loss_cls: 0.3855  loss_box_reg: 0.6969  loss_mask: 0.3531  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.1052  time: 1.6758  data_time: 0.1680  lr: 0.00089117  max_mem: 11155M\n",
      "59 59\n",
      "\u001b[32m[11/05 13:49:35 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json\n",
      "\u001b[32m[11/05 13:49:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 13:49:35 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 13:49:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 13:49:35 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 13:49:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.707684 (0.141537 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.064471 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/4Y2CHMY0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.759\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.512\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.562\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.404\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 47.611 | 75.853 | 51.203 | 32.894 | 61.685 | 74.156 |\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 72.368 | cushion    | 45.380 | door       | 44.907 |\n",
      "| indoor-plant | 44.950 | sofa       | 64.323 | table      | 13.739 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.588\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.319 | 56.712 | 24.464 | 15.138 | 58.772 | 73.357 |\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 53.600 | cushion    | 25.854 | door       | 48.587 |\n",
      "| indoor-plant | 32.192 | sofa       | 27.679 | table      | 0.000  |\n",
      "\u001b[32m[11/05 13:49:37 d2.engine.defaults]: \u001b[0mEvaluation results for 4Y2CHMY_val0 in csv format:\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.testing]: \u001b[0mcopypaste: 47.6113,75.8532,51.2027,32.8942,61.6854,74.1559\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:49:37 d2.evaluation.testing]: \u001b[0mcopypaste: 31.3186,56.7120,24.4639,15.1384,58.7720,73.3573\n",
      "\u001b[32m[11/05 13:49:38 d2.utils.events]: \u001b[0m eta: 0:53:06  iter: 99  total_loss: 1.223  loss_cls: 0.2462  loss_box_reg: 0.5434  loss_mask: 0.283  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.1012  validation_loss: 1.173  time: 1.6779  data_time: 0.1763  lr: 0.0011158  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:50:11 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 119  total_loss: 0.9791  loss_cls: 0.1901  loss_box_reg: 0.448  loss_mask: 0.2439  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.09521  validation_loss: 1.173  time: 1.6776  data_time: 0.1679  lr: 0.0013404  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:50:45 d2.utils.events]: \u001b[0m eta: 0:51:55  iter: 139  total_loss: 0.8437  loss_cls: 0.1497  loss_box_reg: 0.359  loss_mask: 0.2181  loss_rpn_cls: 0.008432  loss_rpn_loc: 0.08219  validation_loss: 1.173  time: 1.6773  data_time: 0.1608  lr: 0.001565  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:51:18 d2.utils.events]: \u001b[0m eta: 0:51:21  iter: 159  total_loss: 0.6997  loss_cls: 0.1226  loss_box_reg: 0.2929  loss_mask: 0.1938  loss_rpn_cls: 0.006911  loss_rpn_loc: 0.08206  validation_loss: 1.173  time: 1.6758  data_time: 0.1658  lr: 0.0017896  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:51:52 d2.utils.events]: \u001b[0m eta: 0:50:52  iter: 179  total_loss: 0.6438  loss_cls: 0.1199  loss_box_reg: 0.2601  loss_mask: 0.1747  loss_rpn_cls: 0.005217  loss_rpn_loc: 0.08608  validation_loss: 1.173  time: 1.6778  data_time: 0.1744  lr: 0.0020142  max_mem: 11155M\n",
      "59 59\n",
      "\u001b[32m[11/05 13:52:25 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json\n",
      "\u001b[32m[11/05 13:52:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 13:52:25 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 13:52:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 13:52:25 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 13:52:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.414135 (0.082827 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.058601 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/4Y2CHMY0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.829\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.502\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.820\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.505\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.709\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.528\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.840\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.757\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 67.417 | 87.128 | 82.936 | 50.193 | 82.026 | 74.426 |\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 68.702 | cushion    | 71.507 | door       | 59.635 |\n",
      "| indoor-plant | 56.716 | sofa       | 91.287 | table      | 56.655 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.714\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.406\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.654\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.702\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 40.861 | 71.430 | 40.646 | 19.864 | 65.425 | 76.848 |\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 60.706 | cushion    | 51.253 | door       | 59.248 |\n",
      "| indoor-plant | 25.611 | sofa       | 47.690 | table      | 0.660  |\n",
      "\u001b[32m[11/05 13:52:26 d2.engine.defaults]: \u001b[0mEvaluation results for 4Y2CHMY_val0 in csv format:\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.testing]: \u001b[0mcopypaste: 67.4170,87.1283,82.9364,50.1926,82.0263,74.4257\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:52:26 d2.evaluation.testing]: \u001b[0mcopypaste: 40.8614,71.4296,40.6458,19.8637,65.4251,76.8482\n",
      "\u001b[32m[11/05 13:52:27 d2.utils.events]: \u001b[0m eta: 0:50:16  iter: 199  total_loss: 0.6055  loss_cls: 0.1099  loss_box_reg: 0.245  loss_mask: 0.162  loss_rpn_cls: 0.004579  loss_rpn_loc: 0.0769  validation_loss: 0.9948  time: 1.6771  data_time: 0.1631  lr: 0.0022388  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:53:01 d2.utils.events]: \u001b[0m eta: 0:49:45  iter: 219  total_loss: 0.5452  loss_cls: 0.1075  loss_box_reg: 0.2119  loss_mask: 0.156  loss_rpn_cls: 0.003868  loss_rpn_loc: 0.06711  validation_loss: 0.9948  time: 1.6770  data_time: 0.1676  lr: 0.00225  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:53:35 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 239  total_loss: 0.496  loss_cls: 0.09549  loss_box_reg: 0.1927  loss_mask: 0.146  loss_rpn_cls: 0.003537  loss_rpn_loc: 0.06728  validation_loss: 0.9948  time: 1.6785  data_time: 0.1694  lr: 0.00225  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:54:08 d2.utils.events]: \u001b[0m eta: 0:48:39  iter: 259  total_loss: 0.4766  loss_cls: 0.09124  loss_box_reg: 0.1788  loss_mask: 0.1403  loss_rpn_cls: 0.002928  loss_rpn_loc: 0.06296  validation_loss: 0.9948  time: 1.6784  data_time: 0.1683  lr: 0.00225  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:54:42 d2.utils.events]: \u001b[0m eta: 0:48:06  iter: 279  total_loss: 0.4655  loss_cls: 0.08196  loss_box_reg: 0.1741  loss_mask: 0.1398  loss_rpn_cls: 0.002887  loss_rpn_loc: 0.06291  validation_loss: 0.9948  time: 1.6790  data_time: 0.1714  lr: 0.00225  max_mem: 11155M\n",
      "59 59\n",
      "\u001b[32m[11/05 13:55:16 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json\n",
      "\u001b[32m[11/05 13:55:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 13:55:16 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 13:55:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 13:55:16 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 13:55:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 13:55:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.385932 (0.077186 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:55:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.056516 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/4Y2CHMY0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.849\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.811\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.556\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.835\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.795\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.532\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.741\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.575\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.858\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.807\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 70.932 | 84.930 | 81.056 | 55.562 | 83.477 | 79.545 |\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 75.588 | cushion    | 77.723 | door       | 57.683 |\n",
      "| indoor-plant | 55.314 | sofa       | 96.906 | table      | 62.377 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.727\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.662\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.816\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.496\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.709\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.372 | 72.717 | 37.414 | 21.830 | 66.236 | 81.609 |\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 63.112 | cushion    | 53.881 | door       | 58.333 |\n",
      "| indoor-plant | 20.941 | sofa       | 57.756 | table      | 12.211 |\n",
      "\u001b[32m[11/05 13:55:17 d2.engine.defaults]: \u001b[0mEvaluation results for 4Y2CHMY_val0 in csv format:\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.testing]: \u001b[0mcopypaste: 70.9318,84.9301,81.0561,55.5621,83.4772,79.5446\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:55:17 d2.evaluation.testing]: \u001b[0mcopypaste: 44.3723,72.7173,37.4143,21.8300,66.2363,81.6089\n",
      "\u001b[32m[11/05 13:55:17 d2.utils.events]: \u001b[0m eta: 0:47:32  iter: 299  total_loss: 0.4251  loss_cls: 0.07435  loss_box_reg: 0.1606  loss_mask: 0.1302  loss_rpn_cls: 0.002511  loss_rpn_loc: 0.05423  validation_loss: 0.8164  time: 1.6788  data_time: 0.1654  lr: 0.00225  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:55:51 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 319  total_loss: 0.4149  loss_cls: 0.07442  loss_box_reg: 0.154  loss_mask: 0.1295  loss_rpn_cls: 0.00244  loss_rpn_loc: 0.05326  validation_loss: 0.8164  time: 1.6784  data_time: 0.1660  lr: 0.0016875  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:56:25 d2.utils.events]: \u001b[0m eta: 0:46:26  iter: 339  total_loss: 0.4003  loss_cls: 0.07251  loss_box_reg: 0.1468  loss_mask: 0.1334  loss_rpn_cls: 0.002656  loss_rpn_loc: 0.05451  validation_loss: 0.8164  time: 1.6792  data_time: 0.1728  lr: 0.0016875  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:56:58 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 359  total_loss: 0.3928  loss_cls: 0.06914  loss_box_reg: 0.1409  loss_mask: 0.1305  loss_rpn_cls: 0.002864  loss_rpn_loc: 0.05347  validation_loss: 0.8164  time: 1.6790  data_time: 0.1688  lr: 0.0016875  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:57:32 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 379  total_loss: 0.3836  loss_cls: 0.06548  loss_box_reg: 0.1435  loss_mask: 0.1257  loss_rpn_cls: 0.002574  loss_rpn_loc: 0.06167  validation_loss: 0.8164  time: 1.6791  data_time: 0.1629  lr: 0.0016875  max_mem: 11155M\n",
      "59 59\n",
      "\u001b[32m[11/05 13:58:05 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json\n",
      "\u001b[32m[11/05 13:58:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 13:58:05 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 13:58:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 13:58:05 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 13:58:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.381233 (0.076247 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.054768 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/4Y2CHMY0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.701\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.856\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.811\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.515\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.823\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.534\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.728\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.728\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.525\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.848\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 70.066 | 85.599 | 81.143 | 51.544 | 82.345 | 80.502 |\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 75.765 | cushion    | 79.106 | door       | 55.713 |\n",
      "| indoor-plant | 53.911 | sofa       | 95.644 | table      | 60.255 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.727\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.680\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.830\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.722\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 46.149 | 72.717 | 43.299 | 22.366 | 67.974 | 83.036 |\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 60.859 | cushion    | 55.276 | door       | 57.391 |\n",
      "| indoor-plant | 25.891 | sofa       | 66.436 | table      | 11.040 |\n",
      "\u001b[32m[11/05 13:58:06 d2.engine.defaults]: \u001b[0mEvaluation results for 4Y2CHMY_val0 in csv format:\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.testing]: \u001b[0mcopypaste: 70.0656,85.5986,81.1431,51.5440,82.3452,80.5017\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 13:58:06 d2.evaluation.testing]: \u001b[0mcopypaste: 46.1487,72.7173,43.2991,22.3657,67.9743,83.0363\n",
      "\u001b[32m[11/05 13:58:07 d2.utils.events]: \u001b[0m eta: 0:44:46  iter: 399  total_loss: 0.3754  loss_cls: 0.06458  loss_box_reg: 0.1354  loss_mask: 0.1224  loss_rpn_cls: 0.001976  loss_rpn_loc: 0.04941  validation_loss: 0.7907  time: 1.6790  data_time: 0.1656  lr: 0.0016875  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:58:41 d2.utils.events]: \u001b[0m eta: 0:44:13  iter: 419  total_loss: 0.3718  loss_cls: 0.06381  loss_box_reg: 0.132  loss_mask: 0.1201  loss_rpn_cls: 0.002417  loss_rpn_loc: 0.05292  validation_loss: 0.7907  time: 1.6792  data_time: 0.1703  lr: 0.0012656  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:59:15 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 439  total_loss: 0.3631  loss_cls: 0.0607  loss_box_reg: 0.1336  loss_mask: 0.1185  loss_rpn_cls: 0.00252  loss_rpn_loc: 0.047  validation_loss: 0.7907  time: 1.6793  data_time: 0.1669  lr: 0.0012656  max_mem: 11155M\n",
      "\u001b[32m[11/05 13:59:48 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 459  total_loss: 0.3656  loss_cls: 0.06114  loss_box_reg: 0.1289  loss_mask: 0.117  loss_rpn_cls: 0.002186  loss_rpn_loc: 0.05593  validation_loss: 0.7907  time: 1.6792  data_time: 0.1644  lr: 0.0012656  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:00:22 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 479  total_loss: 0.3628  loss_cls: 0.05869  loss_box_reg: 0.1314  loss_mask: 0.1175  loss_rpn_cls: 0.002541  loss_rpn_loc: 0.05571  validation_loss: 0.7907  time: 1.6792  data_time: 0.1643  lr: 0.0012656  max_mem: 11155M\n",
      "59 59\n",
      "\u001b[32m[11/05 14:00:55 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json\n",
      "\u001b[32m[11/05 14:00:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 14:00:55 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 14:00:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 14:00:55 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 14:00:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.367642 (0.073528 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.054581 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/4Y2CHMY0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.875\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.819\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.601\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.826\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.747\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.747\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.611\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.855\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 71.731 | 87.475 | 81.881 | 60.135 | 82.621 | 82.119 |\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 80.233 | cushion    | 78.017 | door       | 59.923 |\n",
      "| indoor-plant | 53.630 | sofa       | 96.287 | table      | 62.295 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.725\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.673\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.732\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 45.463 | 72.497 | 42.053 | 23.019 | 67.311 | 83.168 |\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 60.570 | cushion    | 55.506 | door       | 58.970 |\n",
      "| indoor-plant | 23.465 | sofa       | 62.079 | table      | 12.185 |\n",
      "\u001b[32m[11/05 14:00:56 d2.engine.defaults]: \u001b[0mEvaluation results for 4Y2CHMY_val0 in csv format:\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.testing]: \u001b[0mcopypaste: 71.7309,87.4752,81.8812,60.1350,82.6208,82.1188\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 14:00:56 d2.evaluation.testing]: \u001b[0mcopypaste: 45.4626,72.4972,42.0528,23.0195,67.3109,83.1683\n",
      "\u001b[32m[11/05 14:00:57 d2.utils.events]: \u001b[0m eta: 0:41:59  iter: 499  total_loss: 0.3392  loss_cls: 0.05631  loss_box_reg: 0.1175  loss_mask: 0.1152  loss_rpn_cls: 0.00223  loss_rpn_loc: 0.04569  validation_loss: 0.8164  time: 1.6795  data_time: 0.1703  lr: 0.0012656  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:01:31 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 519  total_loss: 0.3384  loss_cls: 0.05308  loss_box_reg: 0.1158  loss_mask: 0.1137  loss_rpn_cls: 0.001928  loss_rpn_loc: 0.04649  validation_loss: 0.8164  time: 1.6799  data_time: 0.1663  lr: 0.00094922  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:02:04 d2.utils.events]: \u001b[0m eta: 0:40:52  iter: 539  total_loss: 0.335  loss_cls: 0.05702  loss_box_reg: 0.1155  loss_mask: 0.1131  loss_rpn_cls: 0.00221  loss_rpn_loc: 0.04613  validation_loss: 0.8164  time: 1.6795  data_time: 0.1693  lr: 0.00094922  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:02:38 d2.utils.events]: \u001b[0m eta: 0:40:19  iter: 559  total_loss: 0.3276  loss_cls: 0.05344  loss_box_reg: 0.1124  loss_mask: 0.1135  loss_rpn_cls: 0.001575  loss_rpn_loc: 0.04013  validation_loss: 0.8164  time: 1.6799  data_time: 0.1696  lr: 0.00094922  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:03:12 d2.utils.events]: \u001b[0m eta: 0:39:45  iter: 579  total_loss: 0.3187  loss_cls: 0.05344  loss_box_reg: 0.1083  loss_mask: 0.1085  loss_rpn_cls: 0.001801  loss_rpn_loc: 0.04622  validation_loss: 0.8164  time: 1.6798  data_time: 0.1645  lr: 0.00094922  max_mem: 11155M\n",
      "59 59\n",
      "\u001b[32m[11/05 14:03:46 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json\n",
      "\u001b[32m[11/05 14:03:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 14:03:46 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 14:03:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 14:03:46 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 14:03:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.386425 (0.077285 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.058708 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/4Y2CHMY0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.856\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.813\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.566\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.832\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.542\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.743\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.575\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.860\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.829\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 71.730 | 85.599 | 81.259 | 56.613 | 83.192 | 80.917 |\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP      | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:--------|:-----------|:-------|\n",
      "| chair        | 77.056 | cushion    | 81.122  | door       | 57.924 |\n",
      "| indoor-plant | 53.630 | sofa       | 100.000 | table      | 60.648 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.447\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.689\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.830\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.519\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.737\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 46.934 | 72.882 | 44.736 | 23.079 | 68.935 | 83.036 |\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 60.207 | cushion    | 54.368 | door       | 58.515 |\n",
      "| indoor-plant | 23.465 | sofa       | 70.198 | table      | 14.851 |\n",
      "\u001b[32m[11/05 14:03:47 d2.engine.defaults]: \u001b[0mEvaluation results for 4Y2CHMY_val0 in csv format:\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.testing]: \u001b[0mcopypaste: 71.7300,85.5986,81.2586,56.6129,83.1917,80.9175\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 14:03:47 d2.evaluation.testing]: \u001b[0mcopypaste: 46.9342,72.8823,44.7363,23.0795,68.9347,83.0363\n",
      "\u001b[32m[11/05 14:03:48 d2.utils.events]: \u001b[0m eta: 0:39:12  iter: 599  total_loss: 0.3223  loss_cls: 0.05249  loss_box_reg: 0.1128  loss_mask: 0.1121  loss_rpn_cls: 0.001947  loss_rpn_loc: 0.0428  validation_loss: 0.8024  time: 1.6805  data_time: 0.1744  lr: 0.00094922  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:04:21 d2.utils.events]: \u001b[0m eta: 0:38:39  iter: 619  total_loss: 0.3128  loss_cls: 0.05274  loss_box_reg: 0.109  loss_mask: 0.111  loss_rpn_cls: 0.002095  loss_rpn_loc: 0.04267  validation_loss: 0.8024  time: 1.6806  data_time: 0.1700  lr: 0.00071191  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:04:55 d2.utils.events]: \u001b[0m eta: 0:38:05  iter: 639  total_loss: 0.3011  loss_cls: 0.05246  loss_box_reg: 0.1074  loss_mask: 0.107  loss_rpn_cls: 0.001994  loss_rpn_loc: 0.03926  validation_loss: 0.8024  time: 1.6807  data_time: 0.1689  lr: 0.00071191  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:05:29 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 659  total_loss: 0.3157  loss_cls: 0.04923  loss_box_reg: 0.1093  loss_mask: 0.1133  loss_rpn_cls: 0.001605  loss_rpn_loc: 0.04851  validation_loss: 0.8024  time: 1.6809  data_time: 0.1740  lr: 0.00071191  max_mem: 11155M\n",
      "\u001b[32m[11/05 14:06:03 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 679  total_loss: 0.3116  loss_cls: 0.05243  loss_box_reg: 0.1057  loss_mask: 0.1067  loss_rpn_cls: 0.00169  loss_rpn_loc: 0.04075  validation_loss: 0.8024  time: 1.6813  data_time: 0.1710  lr: 0.00071191  max_mem: 11155M\n"
     ]
    }
   ],
   "source": [
    "# have a bunch of json\n",
    "# /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json\n",
    "# '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/seg/coco_gt_0.json'\n",
    "\n",
    "# train_jsons = [f'coco_gt_{p}.json' for p in [0,2,4,6,8]]\n",
    "\n",
    "data_path = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019'\n",
    "job_dir = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11'\n",
    "\n",
    "\n",
    "p0_train = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_0train.json'\n",
    "p4_train = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json'\n",
    "pr_val = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json'\n",
    "\n",
    "gt = 5\n",
    "x = 'default'\n",
    "traj = 1\n",
    "# for traj in range(1, 4):\n",
    "traj_path = os.path.join(data_path, str(traj), x)\n",
    "\n",
    "# run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 0, p0_train, pr_val)\n",
    "run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 4, p4_train, pr_val) \n",
    "\n",
    "# gt = 5\n",
    "# x = 'default'\n",
    "# for traj in range(1, 4):\n",
    "#     traj_path = os.path.join(data_path, str(traj), x)\n",
    "#     # first train p0\n",
    "#     val_json = os.path.join(data_path, str(traj), f'default/seg/coco_gt{gt}_{p}val.json')\n",
    "    \n",
    "#     for p in range(2,10,2):\n",
    "#         f = os.path.join(job_dir, str(traj), 'default', f'pred_label_gt{gt}p{p}')\n",
    "#         val_json = os.path.join(data_path, str(traj), f'default/seg/coco_gt{gt}_{p}val.json')\n",
    "        \n",
    "#         train_json = os.path.join(f, f'coco_train.json')\n",
    "#         train_json_baseline = os.path.join(data_path, str(traj), f'default/seg/coco_gt{gt}_0train.json')\n",
    "        \n",
    "#         if not os.path.isfile(train_json_baseline):\n",
    "#             print(f\"Baseline train json {data_path, train_json_baseline} not found!! {p, traj, f}\")\n",
    "            \n",
    "#         run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 0, train_json_baseline, val_json)\n",
    "        \n",
    "#         if not os.path.isfile(train_json) or not os.path.isfile(val_json):\n",
    "#             print('train/val json missing...')\n",
    "#             continue\n",
    "#         run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, p, train_json, val_json)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c31b8a-c490-480d-8ee1-21f44ce55404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _runner([1,2,3,4], 5, [2,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc838dac-4db0-4a76-bb13-9b7536e2a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loco",
   "language": "python",
   "name": "loco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
