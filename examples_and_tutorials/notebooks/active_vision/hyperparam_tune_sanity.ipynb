{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167bde65-e878-4de0-909f-7ee608f9947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a copy of slurm_train.py from anurag/slurm_onebutton\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "import cv2\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import detectron2.data.transforms as T\n",
    "import shutil\n",
    "from setuptools.namespaces import flatten\n",
    "\n",
    "import random\n",
    "import torch \n",
    "import base64\n",
    "import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "coco_yaml = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "lvis_yaml = \"LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n",
    "lvis_yaml2 = \"LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml\"\n",
    "pano_yaml = \"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"\n",
    "\n",
    "jsons_root = '/checkpoint/apratik/finals/jsons/active_vision/'\n",
    "img_dir_test = '/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb'\n",
    "test_jsons = ['frlapt1_20n0.json', 'frlapt1_20n1.json', 'frlapt1_20n2.json']\n",
    "test_jsons = [os.path.join(jsons_root, x) for x in test_jsons]\n",
    "\n",
    "# val_json = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json'\n",
    "val_json = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json'\n",
    "# img_dir_val = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb'\n",
    "img_dir_val = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb'\n",
    "\n",
    "## Detectron2 Setup\n",
    "\n",
    "# from copy_paste import CopyPaste\n",
    "# import albumentations as A\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "#     @classmethod\n",
    "#     def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "#         if output_folder is None:\n",
    "#             output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "#         return COCOEvaluator(dataset_name, output_dir=output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        mapper = DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "            T.ResizeShortestEdge(short_edge_length=cfg.INPUT.MIN_SIZE_TRAIN, max_size=1333, sample_style='choice'),\n",
    "            T.RandomFlip(prob=0.5),\n",
    "            T.RandomCrop(\"absolute\", (640, 640)),\n",
    "            T.RandomBrightness(0.9, 1.1)\n",
    "        ])\n",
    "        return build_detection_train_loader(cfg, mapper=mapper)\n",
    "\n",
    "class COCOTrain:\n",
    "    def __init__(self, lr, w, maxiters, seed):\n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.merge_from_file(model_zoo.get_config_file(coco_yaml))\n",
    "        self.cfg.SOLVER.BASE_LR = lr  # pick a good LR\n",
    "        self.cfg.SOLVER.MAX_ITER = maxiters\n",
    "        self.cfg.SOLVER.WARMUP_ITERS = w\n",
    "        self.seed = seed\n",
    "        \n",
    "    def reset(self, train_json, img_dir_train, dataset_name):\n",
    "        DatasetCatalog.clear()\n",
    "        MetadataCatalog.clear()\n",
    "        self.train_data = dataset_name +  \"_train\"\n",
    "        self.dataset_name = dataset_name\n",
    "        self.train_json = train_json\n",
    "        register_coco_instances(self.train_data, {}, train_json, img_dir_train)\n",
    "        self.results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "        self.val_results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def vis(self):\n",
    "        dataset_dicts = DatasetCatalog.get(self.train_data)\n",
    "        for d in random.sample(dataset_dicts, 2):\n",
    "            img = cv2.imread(d[\"file_name\"])\n",
    "            visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(self.train_data), scale=0.5)\n",
    "            vis = visualizer.draw_dataset_dict(d)\n",
    "            img = vis.get_image()\n",
    "            plt.figure(figsize=(12,8))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            \n",
    "    def train(self):\n",
    "        cfg = self.cfg\n",
    "        print(f'SOLVER PARAMS {cfg.SOLVER.MAX_ITER, cfg.SOLVER.WARMUP_ITERS, cfg.SOLVER.BASE_LR}')\n",
    "        cfg.DATASETS.TRAIN = (self.train_data,)\n",
    "        cfg.DATASETS.TEST = ()\n",
    "        cfg.DATALOADER.NUM_WORKERS = 2\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(coco_yaml)  # Let training initialize from model zoo\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "        MetadataCatalog.get(self.train_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.train_data)}')\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(self.train_data).get(\"thing_classes\"))  \n",
    "        cfg.OUTPUT_DIR = os.path.join('output_aug', str(cfg.SOLVER.MAX_ITER), self.dataset_name + str(self.seed))\n",
    "        print(f\"recreating {cfg.OUTPUT_DIR}\")\n",
    "        # if os.path.isdir(cfg.OUTPUT_DIR):\n",
    "        #     shutil.rmtree(cfg.OUTPUT_DIR)\n",
    "        print(cfg.OUTPUT_DIR)\n",
    "        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "        self.trainer = Trainer(cfg) #DefaultTrainer(cfg) \n",
    "        self.trainer.resume_or_load(resume=False)\n",
    "        self.trainer.train()\n",
    "        \n",
    "    def run_val(self, dataset_name, val_json, img_dir_val):\n",
    "        self.val_data = dataset_name + \"_val\" + str(self.seed)\n",
    "        self.val_json = val_json\n",
    "        self.cfg.DATASETS.TEST = (self.val_data,)\n",
    "        register_coco_instances(self.val_data, {}, val_json, img_dir_val)\n",
    "        MetadataCatalog.get(self.val_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.val_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.val_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.val_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.val_results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.val_results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "\n",
    "    def run_test(self, dataset_name, test_json, img_dir_test):\n",
    "        self.test_data = dataset_name + \"_test\" + str(self.seed)\n",
    "        self.test_json = test_json\n",
    "        self.cfg.DATASETS.TEST = (self.test_data,)\n",
    "        register_coco_instances(self.test_data, {}, test_json, img_dir_test)\n",
    "        MetadataCatalog.get(self.test_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.test_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.test_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.test_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "        \n",
    "    def run_train(self, train_json, img_dir_train, dataset_name):\n",
    "        self.reset(train_json, img_dir_train, dataset_name)\n",
    "        # self.vis()\n",
    "        self.train()\n",
    "\n",
    "\n",
    "# maxiters = [500, 800]\n",
    "# lrs = [0.0001, 0.0005, 0.001, 0.002, 0.005]\n",
    "# warmups = [100, 200]\n",
    "lrs = [0.001, 0.0001]\n",
    "maxiters = [500, 800]\n",
    "warmups = [200]\n",
    "\n",
    "def write_summary_to_file(filename, results, header_str):\n",
    "    if isinstance(results['bbox']['AP50'][0], list):\n",
    "        results['bbox']['AP50'] = list(flatten(results['bbox']['AP50']))\n",
    "        results['segm']['AP50'] = list(flatten(results['segm']['AP50']))\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(header_str)\n",
    "        f.write(f\"\\nbbox AP50 {sum(results['bbox']['AP50'])/len(results['bbox']['AP50'])}\")\n",
    "        f.write(f\"\\nsegm AP50 {sum(results['segm']['AP50'])/len(results['segm']['AP50'])}\")\n",
    "        f.write(f'\\nall results {results}')\n",
    "\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "def run_training(out_dir, img_dir_train, n, traj, x, gt, p, tr_json):\n",
    "    results_dir = os.path.join('results1021_sanity2', str(traj), x, str(gt), str(p))\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    train_json = os.path.join(out_dir, tr_json)\n",
    "    for lr in lrs:\n",
    "        for warmup in warmups:\n",
    "            for maxiter in maxiters:\n",
    "                results = {\n",
    "                    \"bbox\": {\n",
    "                        \"AP50\": []\n",
    "                    },\n",
    "                    \"segm\": {\n",
    "                        \"AP50\": []\n",
    "                    }\n",
    "                }\n",
    "                for i in range(n):\n",
    "                    c = COCOTrain(lr, warmup, maxiter, i)\n",
    "                    dataset_name = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(7))\n",
    "                    print(f'dataset_name {dataset_name}')\n",
    "                    c.run_train(train_json, img_dir_train, dataset_name)\n",
    "                    res_eval = c.run_val(dataset_name, val_json, img_dir_val)\n",
    "                    with open(os.path.join(results_dir, \"validation_results.txt\"), \"a\") as f:\n",
    "                        f.write(f'lr {lr} warmup {warmup} maxiter {maxiter}\\n')\n",
    "                        f.write(json.dumps(res_eval) + '\\n')\n",
    "                    for yix in range(len(test_jsons)):\n",
    "                        r = c.run_test(dataset_name + str(yix), test_jsons[yix], img_dir_test)\n",
    "                        with open(os.path.join(results_dir, \"all_results.txt\"), \"a\") as f:\n",
    "                            f.write(json.dumps(r) + '\\n')\n",
    "                    print(f'all results {c.results}')\n",
    "                    results['bbox']['AP50'].append(c.results['bbox']['AP50'])\n",
    "                    results['segm']['AP50'].append(c.results['segm']['AP50'])\n",
    "                    write_summary_to_file(os.path.join(results_dir, str(n) + '_granular.txt'), c.results, f'\\ntrain_json {train_json}')\n",
    "                \n",
    "                itername = str(lr) + ' ' + str(warmup) + ' ' + str(maxiter) + ' ' + str(n)\n",
    "                write_summary_to_file(os.path.join(results_dir, itername + '_results_averaged.txt'), results, f'\\ntrain_json {train_json}, average over {n} runs')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed79e3a-2333-45d2-9c83-235962fef130",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019'\n",
    "# job_folder = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17'\n",
    "job_folder = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37'\n",
    "import glob\n",
    "\n",
    "def _runner(trajs, gt, ps):\n",
    "    for traj in trajs:\n",
    "        for p in ps:\n",
    "            for x in ['default']:\n",
    "                traj_path = os.path.join(data_path, str(traj), x)\n",
    "                if os.path.isdir(traj_path):\n",
    "                    outdir = os.path.join(job_folder, str(traj), x, f'pred_label_gt{gt}p{p}')\n",
    "                    if len(glob.glob1(outdir,\"*.npy\")) > 0:\n",
    "                        run_training(outdir, os.path.join(traj_path, 'rgb'), 1, traj, x, gt, p)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47185a2c-ad5d-4952-923d-088337c6693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name 060J9CV\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json', name='060J9CV_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/060J9CV0\n",
      "output_aug/500/060J9CV0\n",
      "\u001b[32m[10/25 13:48:17 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/25 13:48:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "19 19\n",
      "\u001b[32m[10/25 13:48:17 d2.data.datasets.coco]: \u001b[0mLoaded 5 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json\n",
      "\u001b[32m[10/25 13:48:17 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5 images left.\n",
      "\u001b[32m[10/25 13:48:17 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 3            |  cushion   | 5            |    door    | 5            |\n",
      "| indoor-plant | 1            |    sofa    | 2            |   table    | 3            |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 19           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/25 13:48:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/25 13:48:17 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:48:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/25 13:48:17 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:48:18 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/apratik/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/structures/masks.py:348: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/private/home/apratik/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/structures/masks.py:348: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  item = item.nonzero().squeeze(1).cpu().numpy().tolist()\n",
      "/private/home/apratik/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:48:22 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 19  total_loss: 3.319  loss_cls: 1.832  loss_box_reg: 0.6239  loss_mask: 0.689  loss_rpn_cls: 0.08345  loss_rpn_loc: 0.02084  time: 0.1741  data_time: 0.0159  lr: 9.5905e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:25 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 39  total_loss: 2.072  loss_cls: 0.6481  loss_box_reg: 0.6618  loss_mask: 0.6692  loss_rpn_cls: 0.02597  loss_rpn_loc: 0.02788  time: 0.1743  data_time: 0.0029  lr: 0.0001958  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:29 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 59  total_loss: 1.954  loss_cls: 0.5849  loss_box_reg: 0.774  loss_mask: 0.598  loss_rpn_cls: 0.02229  loss_rpn_loc: 0.02744  time: 0.1743  data_time: 0.0030  lr: 0.00029571  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:32 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 79  total_loss: 1.566  loss_cls: 0.4208  loss_box_reg: 0.6982  loss_mask: 0.5083  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.02492  time: 0.1743  data_time: 0.0031  lr: 0.0003956  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:36 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 99  total_loss: 1.339  loss_cls: 0.2992  loss_box_reg: 0.5829  loss_mask: 0.355  loss_rpn_cls: 0.02173  loss_rpn_loc: 0.02429  time: 0.1741  data_time: 0.0029  lr: 0.00049551  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:39 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 119  total_loss: 0.9883  loss_cls: 0.2198  loss_box_reg: 0.5309  loss_mask: 0.1955  loss_rpn_cls: 0.006189  loss_rpn_loc: 0.01942  time: 0.1743  data_time: 0.0031  lr: 0.00059541  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:43 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 139  total_loss: 0.9298  loss_cls: 0.1744  loss_box_reg: 0.4443  loss_mask: 0.1751  loss_rpn_cls: 0.00433  loss_rpn_loc: 0.01957  time: 0.1745  data_time: 0.0030  lr: 0.00069531  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:47 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 159  total_loss: 0.9088  loss_cls: 0.1008  loss_box_reg: 0.3905  loss_mask: 0.143  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.02637  time: 0.1749  data_time: 0.0030  lr: 0.00079521  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:50 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 179  total_loss: 0.5876  loss_cls: 0.09048  loss_box_reg: 0.3214  loss_mask: 0.1282  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.02286  time: 0.1756  data_time: 0.0031  lr: 0.0008951  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:54 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 199  total_loss: 0.5355  loss_cls: 0.102  loss_box_reg: 0.2791  loss_mask: 0.1225  loss_rpn_cls: 0.003985  loss_rpn_loc: 0.02087  time: 0.1762  data_time: 0.0031  lr: 0.000995  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:48:57 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 219  total_loss: 0.4729  loss_cls: 0.07747  loss_box_reg: 0.2308  loss_mask: 0.1046  loss_rpn_cls: 0.002162  loss_rpn_loc: 0.01575  time: 0.1760  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:01 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 239  total_loss: 0.3744  loss_cls: 0.07304  loss_box_reg: 0.1875  loss_mask: 0.1045  loss_rpn_cls: 0.00247  loss_rpn_loc: 0.02056  time: 0.1762  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:04 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 259  total_loss: 0.4214  loss_cls: 0.09758  loss_box_reg: 0.1995  loss_mask: 0.09035  loss_rpn_cls: 0.006516  loss_rpn_loc: 0.01526  time: 0.1765  data_time: 0.0030  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:08 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 279  total_loss: 0.495  loss_cls: 0.06115  loss_box_reg: 0.1977  loss_mask: 0.1071  loss_rpn_cls: 0.005551  loss_rpn_loc: 0.01851  time: 0.1764  data_time: 0.0029  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:12 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 299  total_loss: 0.3801  loss_cls: 0.06715  loss_box_reg: 0.1941  loss_mask: 0.08924  loss_rpn_cls: 0.003791  loss_rpn_loc: 0.0136  time: 0.1766  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:15 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 319  total_loss: 0.4104  loss_cls: 0.07053  loss_box_reg: 0.1964  loss_mask: 0.08288  loss_rpn_cls: 0.002541  loss_rpn_loc: 0.02419  time: 0.1768  data_time: 0.0030  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:19 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 339  total_loss: 0.3598  loss_cls: 0.05675  loss_box_reg: 0.1929  loss_mask: 0.08071  loss_rpn_cls: 0.002961  loss_rpn_loc: 0.01997  time: 0.1769  data_time: 0.0029  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:22 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 359  total_loss: 0.3529  loss_cls: 0.05239  loss_box_reg: 0.1657  loss_mask: 0.0844  loss_rpn_cls: 0.004565  loss_rpn_loc: 0.0133  time: 0.1771  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:26 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 379  total_loss: 0.3682  loss_cls: 0.05076  loss_box_reg: 0.1637  loss_mask: 0.08331  loss_rpn_cls: 0.001662  loss_rpn_loc: 0.01087  time: 0.1773  data_time: 0.0029  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:30 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 399  total_loss: 0.4193  loss_cls: 0.06354  loss_box_reg: 0.1787  loss_mask: 0.0824  loss_rpn_cls: 0.005264  loss_rpn_loc: 0.01125  time: 0.1776  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:33 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 419  total_loss: 0.4085  loss_cls: 0.06233  loss_box_reg: 0.195  loss_mask: 0.08871  loss_rpn_cls: 0.002232  loss_rpn_loc: 0.01736  time: 0.1779  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:37 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 439  total_loss: 0.2967  loss_cls: 0.04834  loss_box_reg: 0.1547  loss_mask: 0.06319  loss_rpn_cls: 0.001002  loss_rpn_loc: 0.01081  time: 0.1781  data_time: 0.0030  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:41 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.265  loss_cls: 0.04413  loss_box_reg: 0.1404  loss_mask: 0.06286  loss_rpn_cls: 0.0009056  loss_rpn_loc: 0.01051  time: 0.1783  data_time: 0.0030  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:44 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.2919  loss_cls: 0.0478  loss_box_reg: 0.1404  loss_mask: 0.07787  loss_rpn_cls: 0.001251  loss_rpn_loc: 0.009042  time: 0.1785  data_time: 0.0030  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.3175  loss_cls: 0.05618  loss_box_reg: 0.1264  loss_mask: 0.07184  loss_rpn_cls: 0.001904  loss_rpn_loc: 0.007549  time: 0.1787  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:49:49 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:29 (0.1787 s / it)\n",
      "\u001b[32m[10/25 13:49:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:30 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='060J9CV_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/25 13:49:49 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/25 13:49:49 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 28           |  cushion   | 37           |    door    | 43           |\n",
      "| indoor-plant | 9            |    sofa    | 12           |   table    | 31           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 160          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/25 13:49:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:49:49 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:49:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/25 13:49:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/25 13:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0566 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.059807 (0.066445 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.056436 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/060J9CV0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.546\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.785\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.625\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.517\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.532\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.544\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 54.619 | 78.473 | 62.538 | 51.749 | 54.472 | 53.213 |\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 62.147 | cushion    | 58.887 | door       | 38.089 |\n",
      "| indoor-plant | 66.238 | sofa       | 80.957 | table      | 21.396 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.628\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.467\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.837\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 38.090 | 62.785 | 32.946 | 31.205 | 36.614 | 61.075 |\n",
      "\u001b[32m[10/25 13:49:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 36.704 | cushion    | 39.706 | door       | 49.348 |\n",
      "| indoor-plant | 43.097 | sofa       | 59.683 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='060J9CV0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/25 13:49:51 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/25 13:49:52 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 416          |  cushion   | 251          |    door    | 264          |\n",
      "| indoor-plant | 259          |    sofa    | 87           |   table    | 555          |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 1832         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/25 13:49:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:49:52 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:49:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/25 13:49:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.0576 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/25 13:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 108/355. 0.0573 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/25 13:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 183/355. 0.0569 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/25 13:50:10 d2.evaluation.evaluator]: \u001b[0mInference done 248/355. 0.0571 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/25 13:50:15 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.0574 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/25 13:50:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.362528 (0.075322 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:50:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057386 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/060J9CV0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.233 | 30.858 | 19.012 | 9.180 | 19.904 | 20.134 |\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.039 | cushion    | 32.095 | door       | 1.177 |\n",
      "| indoor-plant | 24.095 | sofa       | 34.795 | table      | 1.199 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.753 | 27.348 | 17.291 | 8.765 | 20.936 | 18.303 |\n",
      "\u001b[32m[10/25 13:50:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.958  | cushion    | 39.008 | door       | 0.741 |\n",
      "| indoor-plant | 21.157 | sofa       | 29.651 | table      | 0.003 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='060J9CV1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/25 13:50:20 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/25 13:50:20 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 395          |  cushion   | 247          |    door    | 275          |\n",
      "| indoor-plant | 255          |    sofa    | 87           |   table    | 549          |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 1808         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/25 13:50:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:50:20 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:50:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/25 13:50:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:50:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0592 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/25 13:50:26 d2.evaluation.evaluator]: \u001b[0mInference done 77/355. 0.0573 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/25 13:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 150/355. 0.0569 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/25 13:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 219/355. 0.0567 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/25 13:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.0568 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/25 13:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.0569 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.957063 (0.077020 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.056982 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/060J9CV0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/25 13:50:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.371\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.442 | 32.461 | 20.283 | 9.901 | 21.331 | 19.863 |\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.563 | cushion    | 32.962 | door       | 0.960 |\n",
      "| indoor-plant | 23.973 | sofa       | 40.105 | table      | 1.087 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.883 | 28.267 | 18.869 | 9.406 | 22.559 | 18.193 |\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.380 | cushion    | 39.438 | door       | 0.630 |\n",
      "| indoor-plant | 21.434 | sofa       | 35.414 | table      | 0.003 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='060J9CV2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/25 13:50:48 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/25 13:50:48 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 438          |  cushion   | 282          |    door    | 301          |\n",
      "| indoor-plant | 254          |    sofa    | 103          |   table    | 594          |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 1972         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/25 13:50:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:50:48 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:50:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/25 13:50:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 29/355. 0.0596 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/25 13:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 100/355. 0.0583 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/25 13:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 175/355. 0.0580 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/25 13:51:06 d2.evaluation.evaluator]: \u001b[0mInference done 236/355. 0.0585 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/25 13:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.0590 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.133136 (0.077523 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059129 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/060J9CV0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.000 | 32.208 | 19.593 | 9.142 | 20.197 | 20.824 |\n",
      "\u001b[32m[10/25 13:51:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.533 | cushion    | 32.572 | door       | 0.956 |\n",
      "| indoor-plant | 24.630 | sofa       | 39.064 | table      | 1.244 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:51:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:51:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/25 13:51:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:51:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      "\u001b[32m[10/25 13:51:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.479 | 28.643 | 17.896 | 9.037 | 21.641 | 19.331 |\n",
      "\u001b[32m[10/25 13:51:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.497  | cushion    | 39.889 | door       | 0.767 |\n",
      "| indoor-plant | 22.097 | sofa       | 32.625 | table      | 0.001 |\n",
      "all results {'bbox': {'AP50': [30.8581689599754, 32.460739917203504, 32.20766683555437]}, 'segm': {'AP50': [27.348368233447435, 28.26728461567759, 28.643123114808063]}}\n",
      "dataset_name QE2RF2B\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json', name='QE2RF2B_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/QE2RF2B0\n",
      "output_aug/800/QE2RF2B0\n",
      "\u001b[32m[10/25 13:51:18 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/25 13:51:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "19 19\n",
      "\u001b[32m[10/25 13:51:18 d2.data.datasets.coco]: \u001b[0mLoaded 5 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json\n",
      "\u001b[32m[10/25 13:51:18 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5 images left.\n",
      "\u001b[32m[10/25 13:51:18 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/25 13:51:18 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:51:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/25 13:51:18 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:51:18 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/25 13:51:22 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 19  total_loss: 3.16  loss_cls: 1.832  loss_box_reg: 0.6864  loss_mask: 0.6932  loss_rpn_cls: 0.08462  loss_rpn_loc: 0.03259  time: 0.1798  data_time: 0.0141  lr: 9.5905e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:25 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 39  total_loss: 2.088  loss_cls: 0.6967  loss_box_reg: 0.7003  loss_mask: 0.666  loss_rpn_cls: 0.03153  loss_rpn_loc: 0.01657  time: 0.1795  data_time: 0.0034  lr: 0.00019581  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:29 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 59  total_loss: 1.864  loss_cls: 0.5098  loss_box_reg: 0.6527  loss_mask: 0.6002  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.02256  time: 0.1783  data_time: 0.0032  lr: 0.00029571  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:33 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 79  total_loss: 1.602  loss_cls: 0.3761  loss_box_reg: 0.6564  loss_mask: 0.4898  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.03086  time: 0.1784  data_time: 0.0032  lr: 0.00039561  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:36 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 99  total_loss: 1.439  loss_cls: 0.2985  loss_box_reg: 0.6041  loss_mask: 0.3853  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.02632  time: 0.1788  data_time: 0.0032  lr: 0.00049551  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:40 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 119  total_loss: 1.159  loss_cls: 0.2323  loss_box_reg: 0.568  loss_mask: 0.236  loss_rpn_cls: 0.00752  loss_rpn_loc: 0.03307  time: 0.1796  data_time: 0.0033  lr: 0.00059541  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:43 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 139  total_loss: 0.8889  loss_cls: 0.1821  loss_box_reg: 0.5108  loss_mask: 0.2008  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.03701  time: 0.1800  data_time: 0.0032  lr: 0.00069531  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:47 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 159  total_loss: 0.7894  loss_cls: 0.1256  loss_box_reg: 0.3285  loss_mask: 0.1414  loss_rpn_cls: 0.03025  loss_rpn_loc: 0.02399  time: 0.1800  data_time: 0.0032  lr: 0.00079521  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:51 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 179  total_loss: 0.5599  loss_cls: 0.1155  loss_box_reg: 0.3215  loss_mask: 0.1105  loss_rpn_cls: 0.006212  loss_rpn_loc: 0.02082  time: 0.1805  data_time: 0.0032  lr: 0.00089511  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:54 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 199  total_loss: 0.4023  loss_cls: 0.07395  loss_box_reg: 0.2079  loss_mask: 0.09827  loss_rpn_cls: 0.005147  loss_rpn_loc: 0.01942  time: 0.1806  data_time: 0.0033  lr: 0.000995  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:51:58 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 219  total_loss: 0.4467  loss_cls: 0.08692  loss_box_reg: 0.2608  loss_mask: 0.1124  loss_rpn_cls: 0.004936  loss_rpn_loc: 0.01777  time: 0.1807  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:02 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 239  total_loss: 0.4179  loss_cls: 0.07448  loss_box_reg: 0.2112  loss_mask: 0.08902  loss_rpn_cls: 0.001428  loss_rpn_loc: 0.01123  time: 0.1806  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:05 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 259  total_loss: 0.5175  loss_cls: 0.0589  loss_box_reg: 0.2156  loss_mask: 0.09237  loss_rpn_cls: 0.001452  loss_rpn_loc: 0.02094  time: 0.1806  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:09 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 279  total_loss: 0.4324  loss_cls: 0.06554  loss_box_reg: 0.1954  loss_mask: 0.07748  loss_rpn_cls: 0.005806  loss_rpn_loc: 0.02086  time: 0.1808  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:13 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 299  total_loss: 0.4341  loss_cls: 0.07719  loss_box_reg: 0.2018  loss_mask: 0.1192  loss_rpn_cls: 0.004465  loss_rpn_loc: 0.0165  time: 0.1810  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:16 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 319  total_loss: 0.4973  loss_cls: 0.06995  loss_box_reg: 0.1912  loss_mask: 0.1185  loss_rpn_cls: 0.007662  loss_rpn_loc: 0.03175  time: 0.1811  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:20 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 339  total_loss: 0.3581  loss_cls: 0.04992  loss_box_reg: 0.1582  loss_mask: 0.07767  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.02124  time: 0.1809  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:23 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 359  total_loss: 0.3419  loss_cls: 0.04292  loss_box_reg: 0.174  loss_mask: 0.07862  loss_rpn_cls: 0.002802  loss_rpn_loc: 0.01469  time: 0.1809  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:27 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 379  total_loss: 0.262  loss_cls: 0.03502  loss_box_reg: 0.1261  loss_mask: 0.08001  loss_rpn_cls: 0.002426  loss_rpn_loc: 0.01317  time: 0.1809  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:31 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 399  total_loss: 0.2331  loss_cls: 0.04044  loss_box_reg: 0.1298  loss_mask: 0.08013  loss_rpn_cls: 0.002197  loss_rpn_loc: 0.01281  time: 0.1808  data_time: 0.0034  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:34 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 419  total_loss: 0.2531  loss_cls: 0.04922  loss_box_reg: 0.1272  loss_mask: 0.05898  loss_rpn_cls: 0.001634  loss_rpn_loc: 0.01156  time: 0.1808  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:38 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 439  total_loss: 0.3007  loss_cls: 0.04975  loss_box_reg: 0.1558  loss_mask: 0.08172  loss_rpn_cls: 0.001196  loss_rpn_loc: 0.0151  time: 0.1808  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:42 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 459  total_loss: 0.287  loss_cls: 0.05595  loss_box_reg: 0.139  loss_mask: 0.062  loss_rpn_cls: 0.0009772  loss_rpn_loc: 0.01767  time: 0.1809  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:45 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 479  total_loss: 0.3039  loss_cls: 0.03974  loss_box_reg: 0.1207  loss_mask: 0.0644  loss_rpn_cls: 0.0009214  loss_rpn_loc: 0.01214  time: 0.1809  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:49 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 499  total_loss: 0.2172  loss_cls: 0.03505  loss_box_reg: 0.1177  loss_mask: 0.07115  loss_rpn_cls: 0.00106  loss_rpn_loc: 0.01295  time: 0.1809  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:53 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 519  total_loss: 0.2854  loss_cls: 0.04767  loss_box_reg: 0.1348  loss_mask: 0.06328  loss_rpn_cls: 0.002024  loss_rpn_loc: 0.01299  time: 0.1810  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:52:56 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 539  total_loss: 0.3025  loss_cls: 0.03613  loss_box_reg: 0.1379  loss_mask: 0.06865  loss_rpn_cls: 0.0007571  loss_rpn_loc: 0.01511  time: 0.1809  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:00 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 559  total_loss: 0.3201  loss_cls: 0.04557  loss_box_reg: 0.1339  loss_mask: 0.06214  loss_rpn_cls: 0.0007624  loss_rpn_loc: 0.03459  time: 0.1809  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:03 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 579  total_loss: 0.3007  loss_cls: 0.04661  loss_box_reg: 0.1192  loss_mask: 0.07299  loss_rpn_cls: 0.0008654  loss_rpn_loc: 0.009502  time: 0.1809  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:07 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 599  total_loss: 0.2611  loss_cls: 0.03426  loss_box_reg: 0.1184  loss_mask: 0.06508  loss_rpn_cls: 0.0007593  loss_rpn_loc: 0.012  time: 0.1810  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:11 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 619  total_loss: 0.2124  loss_cls: 0.02893  loss_box_reg: 0.1175  loss_mask: 0.05718  loss_rpn_cls: 0.0006022  loss_rpn_loc: 0.0101  time: 0.1811  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:14 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 639  total_loss: 0.2345  loss_cls: 0.03667  loss_box_reg: 0.116  loss_mask: 0.05958  loss_rpn_cls: 0.001074  loss_rpn_loc: 0.01484  time: 0.1811  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:18 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 659  total_loss: 0.315  loss_cls: 0.04811  loss_box_reg: 0.1283  loss_mask: 0.07557  loss_rpn_cls: 0.001587  loss_rpn_loc: 0.01936  time: 0.1811  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:22 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 679  total_loss: 0.2921  loss_cls: 0.04792  loss_box_reg: 0.1083  loss_mask: 0.07196  loss_rpn_cls: 0.0006004  loss_rpn_loc: 0.01435  time: 0.1811  data_time: 0.0032  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:25 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 699  total_loss: 0.2296  loss_cls: 0.03697  loss_box_reg: 0.1158  loss_mask: 0.06419  loss_rpn_cls: 0.0005363  loss_rpn_loc: 0.009401  time: 0.1811  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:29 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 719  total_loss: 0.2684  loss_cls: 0.03165  loss_box_reg: 0.1171  loss_mask: 0.06588  loss_rpn_cls: 0.000593  loss_rpn_loc: 0.01278  time: 0.1812  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:33 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 739  total_loss: 0.2704  loss_cls: 0.05011  loss_box_reg: 0.1114  loss_mask: 0.05404  loss_rpn_cls: 0.001177  loss_rpn_loc: 0.01518  time: 0.1812  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:36 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.2182  loss_cls: 0.0387  loss_box_reg: 0.1068  loss_mask: 0.05567  loss_rpn_cls: 0.0003836  loss_rpn_loc: 0.01138  time: 0.1812  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:40 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.2084  loss_cls: 0.03873  loss_box_reg: 0.09163  loss_mask: 0.05244  loss_rpn_cls: 0.0006648  loss_rpn_loc: 0.008442  time: 0.1812  data_time: 0.0033  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:44 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.2986  loss_cls: 0.04788  loss_box_reg: 0.1208  loss_mask: 0.06112  loss_rpn_cls: 0.0008656  loss_rpn_loc: 0.01036  time: 0.1811  data_time: 0.0031  lr: 0.001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:53:44 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:24 (0.1811 s / it)\n",
      "\u001b[32m[10/25 13:53:44 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:25 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='QE2RF2B_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/25 13:53:44 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/25 13:53:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:53:44 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:53:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/25 13:53:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/25 13:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0558 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.986664 (0.064086 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.055114 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QE2RF2B0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.779\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.693\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.553\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.584\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.833\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 58.401 | 77.860 | 69.291 | 55.258 | 56.653 | 60.339 |\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 63.264 | cushion    | 66.275 | door       | 41.647 |\n",
      "| indoor-plant | 70.371 | sofa       | 85.315 | table      | 23.536 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.679\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.620\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 40.633 | 67.862 | 40.054 | 34.457 | 37.181 | 62.046 |\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 35.192 | cushion    | 47.303 | door       | 50.247 |\n",
      "| indoor-plant | 45.470 | sofa       | 62.500 | table      | 3.084  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='QE2RF2B0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/25 13:53:47 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/25 13:53:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:53:47 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:53:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/25 13:53:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 42/355. 0.0565 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/25 13:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.0563 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/25 13:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 194/355. 0.0562 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/25 13:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 262/355. 0.0564 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/25 13:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 328/355. 0.0566 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/25 13:54:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.079577 (0.071656 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:54:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.056838 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:54:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:54:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QE2RF2B0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.429 | 29.574 | 17.616 | 10.096 | 17.402 | 20.811 |\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.234 | cushion    | 38.579 | door       | 0.595 |\n",
      "| indoor-plant | 16.799 | sofa       | 34.009 | table      | 2.358 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.716 | 26.332 | 15.853 | 9.072 | 15.846 | 18.519 |\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.576  | cushion    | 37.681 | door       | 0.376 |\n",
      "| indoor-plant | 17.376 | sofa       | 31.270 | table      | 0.016 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='QE2RF2B1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/25 13:54:13 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/25 13:54:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:54:13 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:54:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/25 13:54:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 23/355. 0.0563 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/25 13:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 97/355. 0.0565 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/25 13:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 173/355. 0.0562 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/25 13:54:30 d2.evaluation.evaluator]: \u001b[0mInference done 241/355. 0.0562 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/25 13:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 305/355. 0.0563 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.291079 (0.072260 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.056408 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QE2RF2B0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/25 13:54:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.412 | 29.804 | 18.208 | 11.185 | 18.255 | 18.412 |\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.370 | cushion    | 37.662 | door       | 0.468 |\n",
      "| indoor-plant | 15.832 | sofa       | 34.967 | table      | 2.175 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.936 | 25.687 | 16.343 | 9.920 | 16.935 | 17.107 |\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.844  | cushion    | 38.091 | door       | 0.423 |\n",
      "| indoor-plant | 16.978 | sofa       | 32.262 | table      | 0.019 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='QE2RF2B2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/25 13:54:40 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/25 13:54:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:54:40 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:54:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/25 13:54:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0584 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/25 13:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.0566 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/25 13:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 160/355. 0.0561 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/25 13:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 231/355. 0.0561 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/25 13:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.0565 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.355985 (0.072446 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.056622 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QE2RF2B0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.12 seconds.\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.582 | 30.657 | 18.391 | 10.575 | 16.929 | 20.268 |\n",
      "\u001b[32m[10/25 13:55:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.162 | cushion    | 38.967 | door       | 0.642 |\n",
      "| indoor-plant | 17.567 | sofa       | 33.587 | table      | 2.566 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:55:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:55:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/25 13:55:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:55:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
      "\u001b[32m[10/25 13:55:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.352 | 26.887 | 16.256 | 9.617 | 15.777 | 18.342 |\n",
      "\u001b[32m[10/25 13:55:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.770  | cushion    | 38.768 | door       | 0.587 |\n",
      "| indoor-plant | 17.934 | sofa       | 33.040 | table      | 0.015 |\n",
      "all results {'bbox': {'AP50': [29.573617281359454, 29.803645186642736, 30.656545614608117]}, 'segm': {'AP50': [26.331617507514466, 25.68732363839047, 26.88737804112534]}}\n",
      "dataset_name MJZMHZG\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json', name='MJZMHZG_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/MJZMHZG0\n",
      "output_aug/500/MJZMHZG0\n",
      "\u001b[32m[10/25 13:55:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/25 13:55:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "19 19\n",
      "\u001b[32m[10/25 13:55:08 d2.data.datasets.coco]: \u001b[0mLoaded 5 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json\n",
      "\u001b[32m[10/25 13:55:08 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5 images left.\n",
      "\u001b[32m[10/25 13:55:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/25 13:55:08 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:55:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/25 13:55:08 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:55:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/25 13:55:12 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 19  total_loss: 3.352  loss_cls: 1.828  loss_box_reg: 0.6923  loss_mask: 0.6918  loss_rpn_cls: 0.1331  loss_rpn_loc: 0.03657  time: 0.1805  data_time: 0.0116  lr: 9.5905e-06  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:15 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 39  total_loss: 3.068  loss_cls: 1.553  loss_box_reg: 0.6382  loss_mask: 0.6879  loss_rpn_cls: 0.103  loss_rpn_loc: 0.02618  time: 0.1800  data_time: 0.0032  lr: 1.958e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:19 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 59  total_loss: 2.569  loss_cls: 1.072  loss_box_reg: 0.6742  loss_mask: 0.6771  loss_rpn_cls: 0.07397  loss_rpn_loc: 0.03083  time: 0.1796  data_time: 0.0032  lr: 2.9571e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:22 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 79  total_loss: 2.283  loss_cls: 0.806  loss_box_reg: 0.7487  loss_mask: 0.6641  loss_rpn_cls: 0.05108  loss_rpn_loc: 0.02313  time: 0.1797  data_time: 0.0031  lr: 3.9561e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:26 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 99  total_loss: 2.179  loss_cls: 0.6523  loss_box_reg: 0.6949  loss_mask: 0.6563  loss_rpn_cls: 0.04346  loss_rpn_loc: 0.05518  time: 0.1798  data_time: 0.0031  lr: 4.955e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:30 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 119  total_loss: 1.967  loss_cls: 0.5839  loss_box_reg: 0.6398  loss_mask: 0.6416  loss_rpn_cls: 0.02131  loss_rpn_loc: 0.03657  time: 0.1797  data_time: 0.0032  lr: 5.954e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:33 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 139  total_loss: 1.836  loss_cls: 0.5445  loss_box_reg: 0.6446  loss_mask: 0.6053  loss_rpn_cls: 0.01827  loss_rpn_loc: 0.02535  time: 0.1795  data_time: 0.0031  lr: 6.9531e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:37 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 159  total_loss: 1.761  loss_cls: 0.4843  loss_box_reg: 0.644  loss_mask: 0.5854  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.02522  time: 0.1796  data_time: 0.0031  lr: 7.952e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:40 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 179  total_loss: 1.773  loss_cls: 0.4748  loss_box_reg: 0.66  loss_mask: 0.5574  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.03059  time: 0.1795  data_time: 0.0031  lr: 8.951e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:44 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 199  total_loss: 1.671  loss_cls: 0.4234  loss_box_reg: 0.6558  loss_mask: 0.5054  loss_rpn_cls: 0.01665  loss_rpn_loc: 0.04403  time: 0.1795  data_time: 0.0031  lr: 9.9501e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:48 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 219  total_loss: 1.605  loss_cls: 0.4214  loss_box_reg: 0.6211  loss_mask: 0.4814  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.02287  time: 0.1795  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:51 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 239  total_loss: 1.514  loss_cls: 0.3436  loss_box_reg: 0.6587  loss_mask: 0.4341  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.02286  time: 0.1800  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:55 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 259  total_loss: 1.366  loss_cls: 0.3339  loss_box_reg: 0.6026  loss_mask: 0.3677  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.0246  time: 0.1802  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:55:59 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 279  total_loss: 1.307  loss_cls: 0.3166  loss_box_reg: 0.644  loss_mask: 0.3508  loss_rpn_cls: 0.00987  loss_rpn_loc: 0.0244  time: 0.1803  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:02 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 299  total_loss: 1.321  loss_cls: 0.3191  loss_box_reg: 0.5769  loss_mask: 0.3053  loss_rpn_cls: 0.01024  loss_rpn_loc: 0.021  time: 0.1802  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:06 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 319  total_loss: 1.039  loss_cls: 0.1989  loss_box_reg: 0.6059  loss_mask: 0.2395  loss_rpn_cls: 0.009866  loss_rpn_loc: 0.01753  time: 0.1803  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:09 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 339  total_loss: 1.137  loss_cls: 0.2215  loss_box_reg: 0.5665  loss_mask: 0.221  loss_rpn_cls: 0.006652  loss_rpn_loc: 0.0245  time: 0.1804  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:13 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 359  total_loss: 0.9918  loss_cls: 0.204  loss_box_reg: 0.4778  loss_mask: 0.2307  loss_rpn_cls: 0.009931  loss_rpn_loc: 0.01426  time: 0.1804  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:17 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 379  total_loss: 0.9946  loss_cls: 0.2119  loss_box_reg: 0.5016  loss_mask: 0.1981  loss_rpn_cls: 0.008668  loss_rpn_loc: 0.02229  time: 0.1804  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:20 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 399  total_loss: 0.8142  loss_cls: 0.1637  loss_box_reg: 0.3973  loss_mask: 0.1729  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.03884  time: 0.1805  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:24 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 419  total_loss: 1.013  loss_cls: 0.216  loss_box_reg: 0.4234  loss_mask: 0.1944  loss_rpn_cls: 0.00569  loss_rpn_loc: 0.01766  time: 0.1807  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:28 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 439  total_loss: 0.9025  loss_cls: 0.1764  loss_box_reg: 0.4201  loss_mask: 0.1662  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.02291  time: 0.1808  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:31 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.7652  loss_cls: 0.1419  loss_box_reg: 0.3438  loss_mask: 0.1581  loss_rpn_cls: 0.007984  loss_rpn_loc: 0.02089  time: 0.1809  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:35 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.8068  loss_cls: 0.1842  loss_box_reg: 0.3344  loss_mask: 0.1696  loss_rpn_cls: 0.00595  loss_rpn_loc: 0.03358  time: 0.1810  data_time: 0.0030  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:39 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.6011  loss_cls: 0.1231  loss_box_reg: 0.3312  loss_mask: 0.1434  loss_rpn_cls: 0.006188  loss_rpn_loc: 0.01518  time: 0.1810  data_time: 0.0030  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:56:39 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:30 (0.1810 s / it)\n",
      "\u001b[32m[10/25 13:56:39 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:31 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='MJZMHZG_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/25 13:56:40 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/25 13:56:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:56:40 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:56:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/25 13:56:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/25 13:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0549 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.505906 (0.080836 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.059021 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MJZMHZG0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.596\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.186 | 59.614 | 32.728 | 34.638 | 34.126 | 22.670 |\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 36.280 | cushion    | 39.884 | door       | 19.927 |\n",
      "| indoor-plant | 37.113 | sofa       | 53.513 | table      | 0.396  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.532\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.801\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.246 | 53.151 | 13.114 | 19.746 | 21.967 | 42.972 |\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.942 | cushion    | 33.103 | door       | 26.905 |\n",
      "| indoor-plant | 15.496 | sofa       | 32.030 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='MJZMHZG0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/25 13:56:43 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/25 13:56:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:56:43 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:56:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/25 13:56:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 23/355. 0.0642 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/25 13:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 77/355. 0.0612 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/25 13:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.0603 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/25 13:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 204/355. 0.0592 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/25 13:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 248/355. 0.0601 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/25 13:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 297/355. 0.0604 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/25 13:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 347/355. 0.0606 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.148729 (0.094711 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060723 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MJZMHZG0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.046\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 8.730 | 18.754 | 6.056  | 4.615 | 12.185 | 6.504 |\n",
      "\u001b[32m[10/25 13:57:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.269 | cushion    | 15.259 | door       | 1.686 |\n",
      "| indoor-plant | 13.098 | sofa       | 10.056 | table      | 0.009 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:57:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:57:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/25 13:57:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:57:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
      "\u001b[32m[10/25 13:57:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 8.181 | 16.379 | 6.990  | 4.775 | 12.475 | 11.536 |\n",
      "\u001b[32m[10/25 13:57:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.069 | cushion    | 17.280 | door       | 0.484 |\n",
      "| indoor-plant | 9.468 | sofa       | 14.785 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='MJZMHZG1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/25 13:57:18 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/25 13:57:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:57:18 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:57:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/25 13:57:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 20/355. 0.0631 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/25 13:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 74/355. 0.0607 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/25 13:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.0598 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/25 13:57:36 d2.evaluation.evaluator]: \u001b[0mInference done 201/355. 0.0593 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/25 13:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.0602 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/25 13:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.0606 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/25 13:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 345/355. 0.0606 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/25 13:57:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.083173 (0.094523 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:57:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060755 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:57:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:57:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MJZMHZG0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:57:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:57:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:57:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/25 13:57:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:57:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
      "\u001b[32m[10/25 13:57:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 8.745 | 18.721 | 6.242  | 5.119 | 11.419 | 6.971 |\n",
      "\u001b[32m[10/25 13:57:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.221 | cushion    | 15.898 | door       | 1.395 |\n",
      "| indoor-plant | 11.638 | sofa       | 10.310 | table      | 0.009 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:57:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:57:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/25 13:57:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:57:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      "\u001b[32m[10/25 13:57:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 8.236 | 16.351 | 6.951  | 4.391 | 11.794 | 12.027 |\n",
      "\u001b[32m[10/25 13:57:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.501 | cushion    | 18.285 | door       | 0.495 |\n",
      "| indoor-plant | 9.223 | sofa       | 13.910 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='MJZMHZG2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/25 13:57:54 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/25 13:57:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 13:57:54 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:57:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/25 13:57:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 13:57:56 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0652 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/25 13:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 69/355. 0.0608 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/25 13:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.0593 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/25 13:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.0590 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/25 13:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.0598 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/25 13:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.0607 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/25 13:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 340/355. 0.0607 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/25 13:58:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.467166 (0.095620 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:58:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060953 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 13:58:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 13:58:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MJZMHZG0/coco_instances_results.json\n",
      "\u001b[32m[10/25 13:58:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:58:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 13:58:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/25 13:58:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:58:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      "\u001b[32m[10/25 13:58:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 8.402 | 18.416 | 5.856  | 4.995 | 10.434 | 7.020 |\n",
      "\u001b[32m[10/25 13:58:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.099 | cushion    | 14.035 | door       | 1.608 |\n",
      "| indoor-plant | 12.290 | sofa       | 10.377 | table      | 0.003 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 13:58:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 13:58:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/25 13:58:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 13:58:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
      "\u001b[32m[10/25 13:58:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 7.888 | 16.165 | 6.347  | 4.022 | 10.707 | 10.744 |\n",
      "\u001b[32m[10/25 13:58:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 6.871 | cushion    | 16.130 | door       | 0.720 |\n",
      "| indoor-plant | 9.468 | sofa       | 14.136 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [18.754004072074, 18.720958301390763, 18.41637879348804]}, 'segm': {'AP50': [16.378919566472412, 16.351202881559896, 16.165022351420056]}}\n",
      "dataset_name 6GG6B63\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json', name='6GG6B63_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/6GG6B630\n",
      "output_aug/800/6GG6B630\n",
      "\u001b[32m[10/25 13:58:30 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/25 13:58:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "19 19\n",
      "\u001b[32m[10/25 13:58:30 d2.data.datasets.coco]: \u001b[0mLoaded 5 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json\n",
      "\u001b[32m[10/25 13:58:30 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5 images left.\n",
      "\u001b[32m[10/25 13:58:30 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/25 13:58:30 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 13:58:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/25 13:58:30 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/25 13:58:31 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/25 13:58:34 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 19  total_loss: 3.624  loss_cls: 2.046  loss_box_reg: 0.6844  loss_mask: 0.6922  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.03555  time: 0.1772  data_time: 0.0121  lr: 9.5905e-06  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:58:38 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 39  total_loss: 3.259  loss_cls: 1.735  loss_box_reg: 0.633  loss_mask: 0.6885  loss_rpn_cls: 0.07373  loss_rpn_loc: 0.02492  time: 0.1784  data_time: 0.0031  lr: 1.958e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:58:42 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 59  total_loss: 2.657  loss_cls: 1.18  loss_box_reg: 0.6986  loss_mask: 0.6793  loss_rpn_cls: 0.0587  loss_rpn_loc: 0.02386  time: 0.1783  data_time: 0.0031  lr: 2.9571e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:58:45 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 79  total_loss: 2.367  loss_cls: 0.798  loss_box_reg: 0.7137  loss_mask: 0.6641  loss_rpn_cls: 0.06856  loss_rpn_loc: 0.02579  time: 0.1785  data_time: 0.0031  lr: 3.9561e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:58:49 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 99  total_loss: 2.075  loss_cls: 0.657  loss_box_reg: 0.6727  loss_mask: 0.6533  loss_rpn_cls: 0.04003  loss_rpn_loc: 0.02985  time: 0.1787  data_time: 0.0031  lr: 4.955e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:58:52 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 119  total_loss: 2.041  loss_cls: 0.6274  loss_box_reg: 0.7101  loss_mask: 0.6206  loss_rpn_cls: 0.02633  loss_rpn_loc: 0.02916  time: 0.1786  data_time: 0.0031  lr: 5.954e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:58:56 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 139  total_loss: 1.859  loss_cls: 0.5434  loss_box_reg: 0.6094  loss_mask: 0.6082  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.02818  time: 0.1788  data_time: 0.0031  lr: 6.9531e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:00 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 159  total_loss: 1.762  loss_cls: 0.4838  loss_box_reg: 0.6527  loss_mask: 0.5824  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.01582  time: 0.1789  data_time: 0.0032  lr: 7.9521e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:03 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 179  total_loss: 1.685  loss_cls: 0.4471  loss_box_reg: 0.652  loss_mask: 0.5422  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.03011  time: 0.1790  data_time: 0.0032  lr: 8.9511e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:07 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 199  total_loss: 1.663  loss_cls: 0.4344  loss_box_reg: 0.6388  loss_mask: 0.5007  loss_rpn_cls: 0.007373  loss_rpn_loc: 0.02412  time: 0.1792  data_time: 0.0032  lr: 9.9501e-05  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:10 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 219  total_loss: 1.692  loss_cls: 0.4399  loss_box_reg: 0.6812  loss_mask: 0.4934  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.02421  time: 0.1792  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:14 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 239  total_loss: 1.436  loss_cls: 0.3561  loss_box_reg: 0.6584  loss_mask: 0.4231  loss_rpn_cls: 0.009835  loss_rpn_loc: 0.0222  time: 0.1792  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:18 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 259  total_loss: 1.343  loss_cls: 0.295  loss_box_reg: 0.5945  loss_mask: 0.3719  loss_rpn_cls: 0.00821  loss_rpn_loc: 0.01788  time: 0.1792  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:21 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 279  total_loss: 1.292  loss_cls: 0.2916  loss_box_reg: 0.6082  loss_mask: 0.3142  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.01694  time: 0.1794  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:25 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 299  total_loss: 1.302  loss_cls: 0.2984  loss_box_reg: 0.6169  loss_mask: 0.2639  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.02031  time: 0.1795  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:28 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 319  total_loss: 1.216  loss_cls: 0.2805  loss_box_reg: 0.6006  loss_mask: 0.2718  loss_rpn_cls: 0.0214  loss_rpn_loc: 0.026  time: 0.1796  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:32 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 339  total_loss: 1.135  loss_cls: 0.1889  loss_box_reg: 0.5128  loss_mask: 0.2352  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.03343  time: 0.1797  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:36 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 359  total_loss: 1.206  loss_cls: 0.224  loss_box_reg: 0.4962  loss_mask: 0.2119  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.02276  time: 0.1797  data_time: 0.0033  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:39 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 379  total_loss: 1.103  loss_cls: 0.2415  loss_box_reg: 0.469  loss_mask: 0.2036  loss_rpn_cls: 0.009332  loss_rpn_loc: 0.02815  time: 0.1798  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:43 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 399  total_loss: 0.953  loss_cls: 0.2183  loss_box_reg: 0.5016  loss_mask: 0.1886  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.02526  time: 0.1799  data_time: 0.0033  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:47 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 419  total_loss: 0.9415  loss_cls: 0.2084  loss_box_reg: 0.5156  loss_mask: 0.1848  loss_rpn_cls: 0.006953  loss_rpn_loc: 0.02166  time: 0.1802  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:50 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 439  total_loss: 0.8693  loss_cls: 0.1754  loss_box_reg: 0.4637  loss_mask: 0.1867  loss_rpn_cls: 0.003918  loss_rpn_loc: 0.02199  time: 0.1802  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:54 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 459  total_loss: 0.7797  loss_cls: 0.1262  loss_box_reg: 0.3705  loss_mask: 0.1621  loss_rpn_cls: 0.005569  loss_rpn_loc: 0.02096  time: 0.1805  data_time: 0.0030  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 13:59:58 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 479  total_loss: 0.8912  loss_cls: 0.1149  loss_box_reg: 0.3134  loss_mask: 0.1558  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.0272  time: 0.1806  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:01 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 499  total_loss: 0.8668  loss_cls: 0.1747  loss_box_reg: 0.3924  loss_mask: 0.1661  loss_rpn_cls: 0.007203  loss_rpn_loc: 0.02472  time: 0.1807  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:05 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 519  total_loss: 0.7335  loss_cls: 0.1295  loss_box_reg: 0.3484  loss_mask: 0.156  loss_rpn_cls: 0.005946  loss_rpn_loc: 0.02314  time: 0.1808  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:09 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 539  total_loss: 0.4616  loss_cls: 0.09461  loss_box_reg: 0.2234  loss_mask: 0.1365  loss_rpn_cls: 0.006594  loss_rpn_loc: 0.02608  time: 0.1810  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:12 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 559  total_loss: 0.6238  loss_cls: 0.1137  loss_box_reg: 0.3056  loss_mask: 0.1329  loss_rpn_cls: 0.005651  loss_rpn_loc: 0.01731  time: 0.1811  data_time: 0.0032  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:16 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 579  total_loss: 0.6207  loss_cls: 0.09431  loss_box_reg: 0.3215  loss_mask: 0.1399  loss_rpn_cls: 0.006683  loss_rpn_loc: 0.02229  time: 0.1811  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:20 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 599  total_loss: 0.5154  loss_cls: 0.09462  loss_box_reg: 0.2658  loss_mask: 0.1314  loss_rpn_cls: 0.01049  loss_rpn_loc: 0.01738  time: 0.1813  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:24 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 619  total_loss: 0.5507  loss_cls: 0.09778  loss_box_reg: 0.2799  loss_mask: 0.1547  loss_rpn_cls: 0.004374  loss_rpn_loc: 0.01393  time: 0.1813  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:27 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 639  total_loss: 0.566  loss_cls: 0.1143  loss_box_reg: 0.3047  loss_mask: 0.1283  loss_rpn_cls: 0.003908  loss_rpn_loc: 0.01952  time: 0.1814  data_time: 0.0030  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:31 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 659  total_loss: 0.5316  loss_cls: 0.08915  loss_box_reg: 0.1635  loss_mask: 0.1283  loss_rpn_cls: 0.005763  loss_rpn_loc: 0.0145  time: 0.1815  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:35 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 679  total_loss: 0.4058  loss_cls: 0.07506  loss_box_reg: 0.2127  loss_mask: 0.1191  loss_rpn_cls: 0.002775  loss_rpn_loc: 0.01201  time: 0.1815  data_time: 0.0029  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:38 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 699  total_loss: 0.6193  loss_cls: 0.1092  loss_box_reg: 0.2671  loss_mask: 0.1282  loss_rpn_cls: 0.002559  loss_rpn_loc: 0.02209  time: 0.1816  data_time: 0.0030  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:42 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 719  total_loss: 0.3824  loss_cls: 0.07547  loss_box_reg: 0.2005  loss_mask: 0.1185  loss_rpn_cls: 0.006743  loss_rpn_loc: 0.009165  time: 0.1816  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:46 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 739  total_loss: 0.3475  loss_cls: 0.06806  loss_box_reg: 0.1605  loss_mask: 0.09579  loss_rpn_cls: 0.004124  loss_rpn_loc: 0.01039  time: 0.1817  data_time: 0.0030  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:49 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.5213  loss_cls: 0.09288  loss_box_reg: 0.2631  loss_mask: 0.1127  loss_rpn_cls: 0.003964  loss_rpn_loc: 0.01894  time: 0.1818  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:53 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.4017  loss_cls: 0.0866  loss_box_reg: 0.2051  loss_mask: 0.1084  loss_rpn_cls: 0.001263  loss_rpn_loc: 0.01418  time: 0.1819  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.338  loss_cls: 0.06866  loss_box_reg: 0.1859  loss_mask: 0.09488  loss_rpn_cls: 0.003401  loss_rpn_loc: 0.01188  time: 0.1820  data_time: 0.0031  lr: 0.0001  max_mem: 1609M\n",
      "\u001b[32m[10/25 14:00:58 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:25 (0.1820 s / it)\n",
      "\u001b[32m[10/25 14:00:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:26 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='6GG6B63_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/25 14:00:58 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/25 14:00:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 14:00:58 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 14:00:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/25 14:00:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/25 14:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0572 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.346610 (0.075697 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057616 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6GG6B630/coco_instances_results.json\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.680\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.506\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.442\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.411\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.528\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.562\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.527 | 67.983 | 50.609 | 44.163 | 48.121 | 39.814 |\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 51.729 | cushion    | 53.275 | door       | 28.222 |\n",
      "| indoor-plant | 47.913 | sofa       | 81.855 | table      | 4.167  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.312 | 61.031 | 23.020 | 26.233 | 27.632 | 47.871 |\n",
      "\u001b[32m[10/25 14:01:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 33.251 | cushion    | 41.220 | door       | 38.636 |\n",
      "| indoor-plant | 29.347 | sofa       | 33.420 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='6GG6B630_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/25 14:01:01 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/25 14:01:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 14:01:01 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 14:01:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/25 14:01:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 14:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 28/355. 0.0607 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/25 14:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.0587 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/25 14:01:13 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.0581 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/25 14:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.0580 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/25 14:01:24 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.0583 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/25 14:01:29 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.0586 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.681689 (0.084805 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058938 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6GG6B630/coco_instances_results.json\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.415 | 26.211 | 13.340 | 7.704 | 19.743 | 14.830 |\n",
      "\u001b[32m[10/25 14:01:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.451 | cushion    | 24.005 | door       | 1.326 |\n",
      "| indoor-plant | 16.630 | sofa       | 25.763 | table      | 0.316 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:01:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 14:01:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/25 14:01:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:01:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\n",
      "\u001b[32m[10/25 14:01:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.432 | 23.042 | 12.872 | 6.781 | 21.152 | 18.330 |\n",
      "\u001b[32m[10/25 14:01:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.814  | cushion    | 28.715 | door       | 0.506 |\n",
      "| indoor-plant | 15.709 | sofa       | 25.846 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='6GG6B631_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/25 14:01:32 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/25 14:01:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 14:01:32 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 14:01:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/25 14:01:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 14:01:34 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0609 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/25 14:01:39 d2.evaluation.evaluator]: \u001b[0mInference done 78/355. 0.0580 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/25 14:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 146/355. 0.0577 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/25 14:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 214/355. 0.0577 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/25 14:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.0582 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/25 14:01:59 d2.evaluation.evaluator]: \u001b[0mInference done 327/355. 0.0585 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.803358 (0.082295 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058827 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6GG6B630/coco_instances_results.json\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.790 | 26.543 | 13.103 | 7.378 | 18.657 | 14.548 |\n",
      "\u001b[32m[10/25 14:02:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 20.658 | cushion    | 25.223 | door       | 1.174 |\n",
      "| indoor-plant | 16.546 | sofa       | 24.785 | table      | 0.355 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:02:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 14:02:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/25 14:02:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:02:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      "\u001b[32m[10/25 14:02:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.815 | 23.338 | 13.496 | 6.255 | 19.832 | 17.529 |\n",
      "\u001b[32m[10/25 14:02:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.817 | cushion    | 30.134 | door       | 0.612 |\n",
      "| indoor-plant | 15.655 | sofa       | 25.671 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='6GG6B632_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/25 14:02:03 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/25 14:02:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/25 14:02:03 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/25 14:02:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/25 14:02:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/25 14:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0648 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/25 14:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 73/355. 0.0585 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/25 14:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 143/355. 0.0576 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/25 14:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 207/355. 0.0578 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/25 14:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 264/355. 0.0582 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/25 14:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.0587 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.825373 (0.085215 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058910 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6GG6B630/coco_instances_results.json\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.266 | 26.082 | 12.964 | 7.195 | 17.766 | 16.741 |\n",
      "\u001b[32m[10/25 14:02:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.024 | cushion    | 23.547 | door       | 1.356 |\n",
      "| indoor-plant | 17.307 | sofa       | 24.931 | table      | 0.434 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/25 14:02:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/25 14:02:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/25 14:02:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/25 14:02:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      "\u001b[32m[10/25 14:02:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.301 | 23.025 | 12.625 | 5.930 | 18.821 | 18.980 |\n",
      "\u001b[32m[10/25 14:02:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.545  | cushion    | 28.023 | door       | 0.664 |\n",
      "| indoor-plant | 15.945 | sofa       | 25.630 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [26.211227402176267, 26.543492087159425, 26.0815523503682]}, 'segm': {'AP50': [23.042306344470244, 23.33821602500331, 23.024927306798322]}}\n"
     ]
    }
   ],
   "source": [
    "# have a bunch of json\n",
    "# /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json\n",
    "# '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/seg/coco_gt_0.json'\n",
    "\n",
    "train_jsons = [f'coco_gt_{p}.json' for p in [0,2,4,6,8]]\n",
    "\n",
    "data_path = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019'\n",
    "job_folder = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37'\n",
    "\n",
    "gt = 5\n",
    "traj = '1'\n",
    "x = 'default'\n",
    "traj_path = os.path.join(data_path, str(traj), x)\n",
    "\n",
    "train_json = f'coco_gt_0.json'\n",
    "out_dir = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/'\n",
    "# os.path.join(job_folder, traj, x, 'seg')\n",
    "# out_dir = os.path.join(job_folder, traj, x, 'seg')\n",
    "run_training(out_dir, os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 0, train_json)\n",
    "\n",
    "\n",
    "# for p in [2,4,6,8]:\n",
    "#     train_json = f'coco_gt_{p}.json'\n",
    "#     out_dir = os.path.join(job_folder, traj, x, f'pred_label_gt{gt}p{p}')\n",
    "#     run_training(out_dir, os.path.join(traj_path, 'rgb'), 1, traj, x, gt, p, train_json)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c31b8a-c490-480d-8ee1-21f44ce55404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name HDM5R2N\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json', name='HDM5R2N_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/HDM5R2N0\n",
      "output_aug/500/HDM5R2N0\n",
      "\u001b[32m[10/21 11:10:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:10:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "90 90\n",
      "\u001b[32m[10/21 11:10:19 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 11:10:19 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 11:10:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:10:19 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:10:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:10:19 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:10:19 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:10:23 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 19  total_loss: 3.083  loss_cls: 1.651  loss_box_reg: 0.6183  loss_mask: 0.6927  loss_rpn_cls: 0.08876  loss_rpn_loc: 0.02216  time: 0.1881  data_time: 0.0173  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:27 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 39  total_loss: 2.136  loss_cls: 0.6881  loss_box_reg: 0.7142  loss_mask: 0.6604  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.03367  time: 0.1918  data_time: 0.0042  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:31 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 59  total_loss: 1.923  loss_cls: 0.5116  loss_box_reg: 0.7  loss_mask: 0.6121  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.0408  time: 0.1918  data_time: 0.0040  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:35 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 79  total_loss: 1.674  loss_cls: 0.3987  loss_box_reg: 0.6406  loss_mask: 0.5093  loss_rpn_cls: 0.02592  loss_rpn_loc: 0.03311  time: 0.1915  data_time: 0.0041  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:39 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 99  total_loss: 1.323  loss_cls: 0.2685  loss_box_reg: 0.624  loss_mask: 0.4074  loss_rpn_cls: 0.01939  loss_rpn_loc: 0.02721  time: 0.1916  data_time: 0.0040  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:43 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 119  total_loss: 1.232  loss_cls: 0.2261  loss_box_reg: 0.5469  loss_mask: 0.2766  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.02351  time: 0.1925  data_time: 0.0040  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:47 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 1.149  loss_cls: 0.2351  loss_box_reg: 0.495  loss_mask: 0.2747  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.02643  time: 0.1929  data_time: 0.0040  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:51 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 159  total_loss: 0.8653  loss_cls: 0.1443  loss_box_reg: 0.4142  loss_mask: 0.2573  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.02162  time: 0.1930  data_time: 0.0040  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:55 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 179  total_loss: 1.01  loss_cls: 0.1406  loss_box_reg: 0.3665  loss_mask: 0.2685  loss_rpn_cls: 0.009519  loss_rpn_loc: 0.02914  time: 0.1932  data_time: 0.0040  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:10:58 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 199  total_loss: 0.8086  loss_cls: 0.1162  loss_box_reg: 0.33  loss_mask: 0.2454  loss_rpn_cls: 0.007551  loss_rpn_loc: 0.01569  time: 0.1930  data_time: 0.0039  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:02 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 219  total_loss: 0.7796  loss_cls: 0.12  loss_box_reg: 0.3618  loss_mask: 0.2327  loss_rpn_cls: 0.00852  loss_rpn_loc: 0.02259  time: 0.1930  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:06 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 0.6471  loss_cls: 0.1017  loss_box_reg: 0.2979  loss_mask: 0.197  loss_rpn_cls: 0.005044  loss_rpn_loc: 0.02521  time: 0.1929  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:10 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 0.6927  loss_cls: 0.1219  loss_box_reg: 0.3278  loss_mask: 0.2006  loss_rpn_cls: 0.003642  loss_rpn_loc: 0.01822  time: 0.1927  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:14 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 0.5376  loss_cls: 0.07785  loss_box_reg: 0.2039  loss_mask: 0.1701  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.01768  time: 0.1927  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:18 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 299  total_loss: 0.5459  loss_cls: 0.09757  loss_box_reg: 0.2439  loss_mask: 0.1834  loss_rpn_cls: 0.004902  loss_rpn_loc: 0.0209  time: 0.1925  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:21 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 319  total_loss: 0.5569  loss_cls: 0.08404  loss_box_reg: 0.2386  loss_mask: 0.1878  loss_rpn_cls: 0.004882  loss_rpn_loc: 0.03176  time: 0.1924  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:25 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 339  total_loss: 0.5584  loss_cls: 0.08246  loss_box_reg: 0.2194  loss_mask: 0.1492  loss_rpn_cls: 0.003388  loss_rpn_loc: 0.02299  time: 0.1926  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:29 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 359  total_loss: 0.5193  loss_cls: 0.08216  loss_box_reg: 0.2222  loss_mask: 0.1464  loss_rpn_cls: 0.002538  loss_rpn_loc: 0.01657  time: 0.1927  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:33 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.5357  loss_cls: 0.08048  loss_box_reg: 0.202  loss_mask: 0.1611  loss_rpn_cls: 0.004884  loss_rpn_loc: 0.01372  time: 0.1926  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:37 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.5282  loss_cls: 0.0688  loss_box_reg: 0.2384  loss_mask: 0.1655  loss_rpn_cls: 0.003159  loss_rpn_loc: 0.01957  time: 0.1928  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:41 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.4045  loss_cls: 0.06726  loss_box_reg: 0.1812  loss_mask: 0.1372  loss_rpn_cls: 0.00355  loss_rpn_loc: 0.01002  time: 0.1929  data_time: 0.0038  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:45 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.5269  loss_cls: 0.07502  loss_box_reg: 0.2449  loss_mask: 0.1738  loss_rpn_cls: 0.003935  loss_rpn_loc: 0.02156  time: 0.1931  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:49 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.4643  loss_cls: 0.07092  loss_box_reg: 0.1722  loss_mask: 0.1473  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.01647  time: 0.1931  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:53 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.4726  loss_cls: 0.06912  loss_box_reg: 0.1736  loss_mask: 0.123  loss_rpn_cls: 0.005281  loss_rpn_loc: 0.01691  time: 0.1931  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.4649  loss_cls: 0.06536  loss_box_reg: 0.1994  loss_mask: 0.1521  loss_rpn_cls: 0.005116  loss_rpn_loc: 0.02028  time: 0.1931  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:11:58 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:36 (0.1931 s / it)\n",
      "\u001b[32m[10/21 11:11:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='HDM5R2N_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:11:58 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:11:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:11:58 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:11:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:11:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:11:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0564 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.405195 (0.077587 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.058062 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/HDM5R2N0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:12:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.744\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.557\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.482\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.450\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.542\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 46.627 | 74.394 | 55.666 | 48.218 | 44.983 | 51.878 |\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 43.996 | cushion    | 40.424 | door       | 37.039 |\n",
      "| indoor-plant | 64.282 | sofa       | 69.532 | table      | 24.491 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.823 | 68.285 | 22.145 | 24.477 | 30.645 | 60.960 |\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 31.566 | cushion    | 39.007 | door       | 55.672 |\n",
      "| indoor-plant | 26.068 | sofa       | 38.629 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='HDM5R2N0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:12:01 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:12:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:12:01 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:12:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:12:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 29/355. 0.0591 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 11:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.0586 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 11:12:14 d2.evaluation.evaluator]: \u001b[0mInference done 164/355. 0.0585 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.0585 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 282/355. 0.0586 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 11:12:29 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.0587 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.233688 (0.083525 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058859 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/HDM5R2N0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.250 | 36.225 | 14.416 | 8.290 | 18.042 | 13.804 |\n",
      "\u001b[32m[10/21 11:12:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.404 | cushion    | 34.532 | door       | 2.197 |\n",
      "| indoor-plant | 18.495 | sofa       | 40.213 | table      | 0.660 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:12:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:12:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 11:12:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:12:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      "\u001b[32m[10/21 11:12:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.241 | 33.377 | 19.869 | 8.495 | 17.519 | 13.766 |\n",
      "\u001b[32m[10/21 11:12:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.747 | cushion    | 45.538 | door       | 1.425 |\n",
      "| indoor-plant | 7.762 | sofa       | 39.978 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='HDM5R2N1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:12:32 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:12:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:12:32 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:12:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:12:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:12:34 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0595 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 11:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 78/355. 0.0581 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 11:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 144/355. 0.0582 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 11:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.0582 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.0586 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 326/355. 0.0587 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:13:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.708657 (0.082025 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:13:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058759 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/HDM5R2N0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.450 | 37.278 | 13.824 | 8.948 | 19.499 | 12.948 |\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.526 | cushion    | 35.912 | door       | 2.040 |\n",
      "| indoor-plant | 17.124 | sofa       | 40.604 | table      | 0.496 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:13:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:13:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 11:13:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:13:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      "\u001b[32m[10/21 11:13:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.475 | 34.614 | 19.711 | 9.126 | 19.247 | 13.157 |\n",
      "\u001b[32m[10/21 11:13:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.105 | cushion    | 46.603 | door       | 1.786 |\n",
      "| indoor-plant | 6.840 | sofa       | 40.518 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='HDM5R2N2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:13:03 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:13:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:13:03 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:13:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:13:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0609 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 11:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 76/355. 0.0588 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 11:13:14 d2.evaluation.evaluator]: \u001b[0mInference done 146/355. 0.0586 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 11:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.0586 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 11:13:24 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.0587 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:13:29 d2.evaluation.evaluator]: \u001b[0mInference done 328/355. 0.0589 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.248540 (0.080710 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058907 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/HDM5R2N0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.055 | 36.062 | 14.010 | 8.908 | 17.841 | 13.505 |\n",
      "\u001b[32m[10/21 11:13:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.896 | cushion    | 35.558 | door       | 2.410 |\n",
      "| indoor-plant | 16.773 | sofa       | 40.107 | table      | 0.587 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:13:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:13:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 11:13:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:13:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "\u001b[32m[10/21 11:13:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.323 | 33.436 | 20.555 | 8.901 | 17.878 | 13.662 |\n",
      "\u001b[32m[10/21 11:13:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.910 | cushion    | 45.540 | door       | 2.117 |\n",
      "| indoor-plant | 6.794 | sofa       | 40.578 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [36.224911377231905, 37.278284727557555, 36.06167091424253]}, 'segm': {'AP50': [33.37748684323583, 34.61352830913768, 33.435600170745886]}}\n",
      "dataset_name BBFATCV\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json', name='BBFATCV_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/BBFATCV0\n",
      "output_aug/800/BBFATCV0\n",
      "\u001b[32m[10/21 11:13:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:13:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "90 90\n",
      "\u001b[32m[10/21 11:13:34 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 11:13:34 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 11:13:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:13:34 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:13:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:13:34 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:13:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:13:38 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 19  total_loss: 2.989  loss_cls: 1.585  loss_box_reg: 0.589  loss_mask: 0.6875  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.027  time: 0.1953  data_time: 0.0173  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:13:42 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 39  total_loss: 2.104  loss_cls: 0.6667  loss_box_reg: 0.6571  loss_mask: 0.6581  loss_rpn_cls: 0.03702  loss_rpn_loc: 0.0232  time: 0.1926  data_time: 0.0039  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:13:46 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 59  total_loss: 1.832  loss_cls: 0.481  loss_box_reg: 0.5982  loss_mask: 0.6075  loss_rpn_cls: 0.02845  loss_rpn_loc: 0.02947  time: 0.1921  data_time: 0.0042  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:13:50 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 79  total_loss: 1.518  loss_cls: 0.3668  loss_box_reg: 0.6195  loss_mask: 0.5203  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.02375  time: 0.1919  data_time: 0.0040  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:13:54 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 99  total_loss: 1.357  loss_cls: 0.2514  loss_box_reg: 0.644  loss_mask: 0.4057  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.02525  time: 0.1915  data_time: 0.0039  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:13:58 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 119  total_loss: 1.059  loss_cls: 0.1776  loss_box_reg: 0.4884  loss_mask: 0.2792  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.03004  time: 0.1917  data_time: 0.0040  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:02 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 139  total_loss: 1.094  loss_cls: 0.1991  loss_box_reg: 0.4402  loss_mask: 0.2478  loss_rpn_cls: 0.008868  loss_rpn_loc: 0.02528  time: 0.1918  data_time: 0.0038  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:05 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 159  total_loss: 0.9297  loss_cls: 0.1586  loss_box_reg: 0.4414  loss_mask: 0.2429  loss_rpn_cls: 0.005817  loss_rpn_loc: 0.02199  time: 0.1923  data_time: 0.0040  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:09 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 179  total_loss: 0.8168  loss_cls: 0.14  loss_box_reg: 0.3794  loss_mask: 0.1851  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.01471  time: 0.1926  data_time: 0.0039  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:13 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 199  total_loss: 0.671  loss_cls: 0.1306  loss_box_reg: 0.3284  loss_mask: 0.223  loss_rpn_cls: 0.008128  loss_rpn_loc: 0.01964  time: 0.1928  data_time: 0.0039  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:17 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 219  total_loss: 0.7443  loss_cls: 0.1146  loss_box_reg: 0.3226  loss_mask: 0.1919  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.0213  time: 0.1930  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:21 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 239  total_loss: 0.7371  loss_cls: 0.1299  loss_box_reg: 0.3541  loss_mask: 0.2064  loss_rpn_cls: 0.007586  loss_rpn_loc: 0.02939  time: 0.1933  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:25 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 259  total_loss: 0.6309  loss_cls: 0.0981  loss_box_reg: 0.2524  loss_mask: 0.1828  loss_rpn_cls: 0.003281  loss_rpn_loc: 0.01722  time: 0.1932  data_time: 0.0037  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:29 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 279  total_loss: 0.6004  loss_cls: 0.1033  loss_box_reg: 0.2653  loss_mask: 0.1767  loss_rpn_cls: 0.006733  loss_rpn_loc: 0.02071  time: 0.1934  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:33 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 299  total_loss: 0.5498  loss_cls: 0.06123  loss_box_reg: 0.1877  loss_mask: 0.1318  loss_rpn_cls: 0.001949  loss_rpn_loc: 0.02041  time: 0.1936  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:37 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 319  total_loss: 0.5489  loss_cls: 0.09877  loss_box_reg: 0.239  loss_mask: 0.1794  loss_rpn_cls: 0.007999  loss_rpn_loc: 0.0221  time: 0.1935  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:41 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 339  total_loss: 0.5292  loss_cls: 0.1046  loss_box_reg: 0.2309  loss_mask: 0.1713  loss_rpn_cls: 0.001073  loss_rpn_loc: 0.01873  time: 0.1935  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:44 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 359  total_loss: 0.4883  loss_cls: 0.07606  loss_box_reg: 0.23  loss_mask: 0.1417  loss_rpn_cls: 0.00422  loss_rpn_loc: 0.01911  time: 0.1934  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:48 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 0.5173  loss_cls: 0.08118  loss_box_reg: 0.2429  loss_mask: 0.163  loss_rpn_cls: 0.004333  loss_rpn_loc: 0.01608  time: 0.1935  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:52 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 399  total_loss: 0.5318  loss_cls: 0.08178  loss_box_reg: 0.2053  loss_mask: 0.156  loss_rpn_cls: 0.002029  loss_rpn_loc: 0.0134  time: 0.1936  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:14:56 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 419  total_loss: 0.3504  loss_cls: 0.04851  loss_box_reg: 0.1695  loss_mask: 0.1509  loss_rpn_cls: 0.0008041  loss_rpn_loc: 0.01545  time: 0.1935  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:00 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 439  total_loss: 0.4464  loss_cls: 0.07172  loss_box_reg: 0.1902  loss_mask: 0.1405  loss_rpn_cls: 0.001386  loss_rpn_loc: 0.01521  time: 0.1935  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:04 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 459  total_loss: 0.4497  loss_cls: 0.06284  loss_box_reg: 0.1893  loss_mask: 0.1651  loss_rpn_cls: 0.001264  loss_rpn_loc: 0.0121  time: 0.1935  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:08 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 0.4235  loss_cls: 0.05722  loss_box_reg: 0.2027  loss_mask: 0.1282  loss_rpn_cls: 0.001041  loss_rpn_loc: 0.0144  time: 0.1935  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:12 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 0.4361  loss_cls: 0.05326  loss_box_reg: 0.1723  loss_mask: 0.1589  loss_rpn_cls: 0.003159  loss_rpn_loc: 0.02057  time: 0.1935  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:15 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 0.4203  loss_cls: 0.06122  loss_box_reg: 0.1756  loss_mask: 0.137  loss_rpn_cls: 0.001783  loss_rpn_loc: 0.01468  time: 0.1934  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:19 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 0.4572  loss_cls: 0.06892  loss_box_reg: 0.1803  loss_mask: 0.1337  loss_rpn_cls: 0.001164  loss_rpn_loc: 0.01769  time: 0.1934  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:23 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 0.4745  loss_cls: 0.07502  loss_box_reg: 0.2096  loss_mask: 0.1448  loss_rpn_cls: 0.001584  loss_rpn_loc: 0.01503  time: 0.1935  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:27 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 0.4459  loss_cls: 0.05262  loss_box_reg: 0.1646  loss_mask: 0.1601  loss_rpn_cls: 0.002546  loss_rpn_loc: 0.01716  time: 0.1935  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:31 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 599  total_loss: 0.3024  loss_cls: 0.0503  loss_box_reg: 0.1358  loss_mask: 0.117  loss_rpn_cls: 0.0008794  loss_rpn_loc: 0.01439  time: 0.1936  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:35 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 619  total_loss: 0.4034  loss_cls: 0.05232  loss_box_reg: 0.1341  loss_mask: 0.1429  loss_rpn_cls: 0.002748  loss_rpn_loc: 0.01452  time: 0.1935  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:39 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 639  total_loss: 0.3906  loss_cls: 0.04454  loss_box_reg: 0.1627  loss_mask: 0.1362  loss_rpn_cls: 0.003394  loss_rpn_loc: 0.007434  time: 0.1934  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:43 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.4132  loss_cls: 0.04958  loss_box_reg: 0.1765  loss_mask: 0.1503  loss_rpn_cls: 0.001778  loss_rpn_loc: 0.01129  time: 0.1934  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:46 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.3674  loss_cls: 0.04369  loss_box_reg: 0.1685  loss_mask: 0.1159  loss_rpn_cls: 0.002117  loss_rpn_loc: 0.01191  time: 0.1934  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:50 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.3705  loss_cls: 0.04552  loss_box_reg: 0.1453  loss_mask: 0.1168  loss_rpn_cls: 0.001156  loss_rpn_loc: 0.01152  time: 0.1934  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:54 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.381  loss_cls: 0.05061  loss_box_reg: 0.1427  loss_mask: 0.1299  loss_rpn_cls: 0.002374  loss_rpn_loc: 0.01347  time: 0.1933  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:15:58 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.4097  loss_cls: 0.0505  loss_box_reg: 0.1558  loss_mask: 0.1404  loss_rpn_cls: 0.001907  loss_rpn_loc: 0.01728  time: 0.1932  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:16:02 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.3778  loss_cls: 0.04786  loss_box_reg: 0.1408  loss_mask: 0.1389  loss_rpn_cls: 0.008024  loss_rpn_loc: 0.01595  time: 0.1931  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:16:06 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.4051  loss_cls: 0.05715  loss_box_reg: 0.1362  loss_mask: 0.137  loss_rpn_cls: 0.005456  loss_rpn_loc: 0.01513  time: 0.1931  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:16:10 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.3347  loss_cls: 0.04539  loss_box_reg: 0.1252  loss_mask: 0.1117  loss_rpn_cls: 0.0009139  loss_rpn_loc: 0.01285  time: 0.1931  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:16:10 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:34 (0.1931 s / it)\n",
      "\u001b[32m[10/21 11:16:10 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:35 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='BBFATCV_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:16:10 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:16:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:16:11 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:16:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:16:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:16:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0588 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.146916 (0.069255 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.056881 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BBFATCV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.457\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.448\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.497\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.555\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.723\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 45.677 | 72.887 | 44.839 | 49.713 | 43.731 | 42.710 |\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 39.444 | cushion    | 50.127 | door       | 27.361 |\n",
      "| indoor-plant | 63.294 | sofa       | 74.645 | table      | 19.191 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.620\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.307 | 62.004 | 26.503 | 27.323 | 30.484 | 44.689 |\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 24.744 | cushion    | 41.719 | door       | 34.149 |\n",
      "| indoor-plant | 32.616 | sofa       | 54.417 | table      | 0.198  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='BBFATCV0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:16:13 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:16:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:16:13 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:16:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:16:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:16:16 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.0582 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 109/355. 0.0575 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 184/355. 0.0572 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.0575 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:16:36 d2.evaluation.evaluator]: \u001b[0mInference done 305/355. 0.0578 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.819372 (0.076627 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058116 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BBFATCV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 22.677 | 38.434 | 22.218 | 8.319 | 22.567 | 20.879 |\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.346 | cushion    | 34.794 | door       | 0.401 |\n",
      "| indoor-plant | 29.953 | sofa       | 53.019 | table      | 0.551 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:16:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:16:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 11:16:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:16:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      "\u001b[32m[10/21 11:16:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.321 | 36.283 | 22.126 | 8.849 | 22.176 | 17.906 |\n",
      "\u001b[32m[10/21 11:16:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.533 | cushion    | 45.493 | door       | 0.331 |\n",
      "| indoor-plant | 19.562 | sofa       | 49.009 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='BBFATCV1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:16:42 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:16:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:16:42 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:16:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:16:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0587 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 11:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 79/355. 0.0579 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 11:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 152/355. 0.0578 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 223/355. 0.0578 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.0578 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 352/355. 0.0579 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:17:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.925546 (0.074073 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:17:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057954 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BBFATCV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.401\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 22.918 | 40.074 | 21.249 | 9.373 | 24.013 | 18.986 |\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 19.847 | cushion    | 34.975 | door       | 0.439 |\n",
      "| indoor-plant | 29.478 | sofa       | 52.223 | table      | 0.544 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.616 | 37.686 | 22.485 | 8.849 | 24.370 | 16.719 |\n",
      "\u001b[32m[10/21 11:17:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.284 | cushion    | 45.133 | door       | 0.382 |\n",
      "| indoor-plant | 19.133 | sofa       | 49.766 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='BBFATCV2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:17:10 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:17:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:17:10 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:17:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:17:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 43/355. 0.0577 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 113/355. 0.0576 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:17:23 d2.evaluation.evaluator]: \u001b[0mInference done 188/355. 0.0574 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:17:28 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.0577 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:17:33 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.0579 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.821660 (0.076633 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057906 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BBFATCV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 22.776 | 39.696 | 21.099 | 8.744 | 22.641 | 22.138 |\n",
      "\u001b[32m[10/21 11:17:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.570 | cushion    | 35.188 | door       | 0.519 |\n",
      "| indoor-plant | 30.899 | sofa       | 51.798 | table      | 0.682 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:17:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:17:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 11:17:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:17:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.253\n",
      "\u001b[32m[10/21 11:17:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.565 | 37.722 | 21.971 | 8.699 | 23.252 | 19.107 |\n",
      "\u001b[32m[10/21 11:17:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.201 | cushion    | 44.574 | door       | 0.517 |\n",
      "| indoor-plant | 20.284 | sofa       | 49.813 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [38.43378744861658, 40.0744137215372, 39.696194511716484]}, 'segm': {'AP50': [36.28255854117174, 37.68603091413099, 37.722202883958616]}}\n",
      "dataset_name S63Z57D\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json', name='S63Z57D_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/S63Z57D0\n",
      "output_aug/500/S63Z57D0\n",
      "\u001b[32m[10/21 11:17:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:17:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "90 90\n",
      "\u001b[32m[10/21 11:17:39 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 11:17:39 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 11:17:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:17:39 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:17:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:17:39 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:17:39 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:17:44 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.699  loss_cls: 2.154  loss_box_reg: 0.6555  loss_mask: 0.6943  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.03164  time: 0.1930  data_time: 0.0163  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:17:47 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 39  total_loss: 3.355  loss_cls: 1.844  loss_box_reg: 0.6524  loss_mask: 0.6928  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.02911  time: 0.1926  data_time: 0.0042  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:17:51 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 59  total_loss: 2.878  loss_cls: 1.254  loss_box_reg: 0.7899  loss_mask: 0.6853  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.03188  time: 0.1929  data_time: 0.0041  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:17:55 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 79  total_loss: 2.283  loss_cls: 0.8166  loss_box_reg: 0.6908  loss_mask: 0.6773  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.03326  time: 0.1920  data_time: 0.0039  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:17:59 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 99  total_loss: 2.124  loss_cls: 0.6655  loss_box_reg: 0.6907  loss_mask: 0.6659  loss_rpn_cls: 0.02589  loss_rpn_loc: 0.02344  time: 0.1920  data_time: 0.0041  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:03 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 119  total_loss: 1.95  loss_cls: 0.5979  loss_box_reg: 0.6529  loss_mask: 0.6496  loss_rpn_cls: 0.02169  loss_rpn_loc: 0.03017  time: 0.1918  data_time: 0.0039  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:07 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 2.037  loss_cls: 0.5875  loss_box_reg: 0.7411  loss_mask: 0.6295  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.03209  time: 0.1922  data_time: 0.0040  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:11 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 159  total_loss: 1.843  loss_cls: 0.5041  loss_box_reg: 0.6312  loss_mask: 0.5999  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.0299  time: 0.1923  data_time: 0.0042  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:14 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 179  total_loss: 1.831  loss_cls: 0.5061  loss_box_reg: 0.6477  loss_mask: 0.5826  loss_rpn_cls: 0.02792  loss_rpn_loc: 0.04672  time: 0.1927  data_time: 0.0040  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:18 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 1.882  loss_cls: 0.4622  loss_box_reg: 0.6929  loss_mask: 0.576  loss_rpn_cls: 0.02361  loss_rpn_loc: 0.02761  time: 0.1929  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:22 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 1.721  loss_cls: 0.4207  loss_box_reg: 0.6309  loss_mask: 0.5342  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.03669  time: 0.1928  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:26 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 1.466  loss_cls: 0.3034  loss_box_reg: 0.5515  loss_mask: 0.4993  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.01961  time: 0.1930  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:30 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 1.564  loss_cls: 0.3397  loss_box_reg: 0.6332  loss_mask: 0.4314  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.03613  time: 0.1929  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:34 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 1.362  loss_cls: 0.3012  loss_box_reg: 0.5929  loss_mask: 0.4085  loss_rpn_cls: 0.02044  loss_rpn_loc: 0.01934  time: 0.1929  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:38 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 299  total_loss: 1.41  loss_cls: 0.3099  loss_box_reg: 0.5953  loss_mask: 0.3677  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.02632  time: 0.1931  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:42 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 319  total_loss: 1.327  loss_cls: 0.2604  loss_box_reg: 0.6001  loss_mask: 0.3419  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.02712  time: 0.1931  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:45 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.149  loss_cls: 0.2182  loss_box_reg: 0.5583  loss_mask: 0.3043  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.03117  time: 0.1930  data_time: 0.0037  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:49 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.253  loss_cls: 0.2228  loss_box_reg: 0.5317  loss_mask: 0.29  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.02416  time: 0.1931  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:53 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.182  loss_cls: 0.2652  loss_box_reg: 0.5586  loss_mask: 0.3258  loss_rpn_cls: 0.009817  loss_rpn_loc: 0.0259  time: 0.1931  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:18:57 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.149  loss_cls: 0.2101  loss_box_reg: 0.5053  loss_mask: 0.2579  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.02302  time: 0.1933  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:19:01 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.036  loss_cls: 0.1648  loss_box_reg: 0.4665  loss_mask: 0.2408  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.0161  time: 0.1935  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:19:05 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.062  loss_cls: 0.2202  loss_box_reg: 0.4984  loss_mask: 0.2861  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.02103  time: 0.1937  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:19:09 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.034  loss_cls: 0.1827  loss_box_reg: 0.4991  loss_mask: 0.2716  loss_rpn_cls: 0.004924  loss_rpn_loc: 0.01783  time: 0.1939  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:19:13 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.044  loss_cls: 0.1954  loss_box_reg: 0.4769  loss_mask: 0.278  loss_rpn_cls: 0.006852  loss_rpn_loc: 0.02043  time: 0.1939  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:19:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.8636  loss_cls: 0.1709  loss_box_reg: 0.3921  loss_mask: 0.2695  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.02065  time: 0.1941  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:19:18 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:36 (0.1941 s / it)\n",
      "\u001b[32m[10/21 11:19:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='S63Z57D_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:19:18 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:19:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:19:18 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:19:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:19:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:19:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0596 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:19:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.847503 (0.091855 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:19:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.060520 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:19:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:19:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/S63Z57D0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.648\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.411\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.886 | 64.752 | 26.346 | 33.134 | 33.863 | 31.405 |\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 35.746 | cushion    | 32.566 | door       | 29.298 |\n",
      "| indoor-plant | 41.724 | sofa       | 44.945 | table      | 1.040  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.418\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.833 | 41.844 | 10.563 | 13.407 | 14.078 | 44.055 |\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.446 | cushion    | 27.039 | door       | 29.973 |\n",
      "| indoor-plant | 0.000  | sofa       | 18.543 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='S63Z57D0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:19:22 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:19:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:19:22 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:19:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:19:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0684 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 11:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 62/355. 0.0639 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 11:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.0619 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 11:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.0613 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.0616 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 11:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 266/355. 0.0620 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 305/355. 0.0625 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 11:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 347/355. 0.0628 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:20:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.998065 (0.108566 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:20:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.062903 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:20:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:20:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/S63Z57D0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:20:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:20:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:20:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 11:20:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:20:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.295\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "\u001b[32m[10/21 11:20:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.695 | 29.510 | 5.081  | 6.523 | 12.142 | 8.911 |\n",
      "\u001b[32m[10/21 11:20:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.812 | cushion    | 18.456 | door       | 1.480 |\n",
      "| indoor-plant | 11.714 | sofa       | 24.691 | table      | 0.015 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:20:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:20:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 11:20:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:20:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      "\u001b[32m[10/21 11:20:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 10.903 | 22.496 | 8.041  | 6.812 | 10.701 | 10.393 |\n",
      "\u001b[32m[10/21 11:20:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.274 | cushion    | 26.772 | door       | 0.540 |\n",
      "| indoor-plant | 0.711 | sofa       | 29.122 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='S63Z57D1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:20:03 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:20:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:20:03 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:20:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:20:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0677 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 11:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 54/355. 0.0637 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 11:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 109/355. 0.0619 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 11:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 161/355. 0.0616 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 11:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.0617 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 249/355. 0.0622 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.0625 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 326/355. 0.0627 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 11:20:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.084589 (0.114527 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:20:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.062817 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/S63Z57D0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.980 | 30.968 | 5.152  | 7.025 | 12.067 | 8.874 |\n",
      "\u001b[32m[10/21 11:20:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.652 | cushion    | 20.853 | door       | 1.405 |\n",
      "| indoor-plant | 11.417 | sofa       | 23.538 | table      | 0.015 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:20:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:20:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 11:20:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:20:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.240\n",
      "\u001b[32m[10/21 11:20:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.396 | 23.824 | 7.873  | 5.619 | 11.031 | 10.090 |\n",
      "\u001b[32m[10/21 11:20:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.152 | cushion    | 29.629 | door       | 0.816 |\n",
      "| indoor-plant | 0.647 | sofa       | 28.131 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='S63Z57D2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:20:47 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:20:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:20:47 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:20:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:20:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0686 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 11:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 56/355. 0.0636 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 11:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 113/355. 0.0616 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 175/355. 0.0607 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 11:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 215/355. 0.0618 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.0621 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 300/355. 0.0626 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 11:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 345/355. 0.0628 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:21:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.825230 (0.108072 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:21:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.062947 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/S63Z57D0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.380 | 29.733 | 4.900  | 6.483 | 11.071 | 10.016 |\n",
      "\u001b[32m[10/21 11:21:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.842 | cushion    | 20.369 | door       | 1.470 |\n",
      "| indoor-plant | 11.829 | sofa       | 21.761 | table      | 0.007 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:21:27 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:21:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.56 seconds.\n",
      "\u001b[32m[10/21 11:21:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:21:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n",
      "\u001b[32m[10/21 11:21:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 10.685 | 22.409 | 7.705  | 4.979 | 10.428 | 10.811 |\n",
      "\u001b[32m[10/21 11:21:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.137 | cushion    | 27.784 | door       | 0.930 |\n",
      "| indoor-plant | 0.792 | sofa       | 26.467 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [29.509557906844403, 30.967755902466287, 29.73345360087557]}, 'segm': {'AP50': [22.495527448985726, 23.824226735182624, 22.40902430191057]}}\n",
      "dataset_name WRZ64XD\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json', name='WRZ64XD_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/WRZ64XD0\n",
      "output_aug/800/WRZ64XD0\n",
      "\u001b[32m[10/21 11:21:29 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:21:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "90 90\n",
      "\u001b[32m[10/21 11:21:29 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 11:21:29 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 11:21:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:21:29 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:21:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:21:29 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:21:29 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:21:33 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 19  total_loss: 3.532  loss_cls: 1.979  loss_box_reg: 0.6875  loss_mask: 0.6936  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.02557  time: 0.1925  data_time: 0.0173  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:21:37 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 39  total_loss: 3.083  loss_cls: 1.66  loss_box_reg: 0.6035  loss_mask: 0.6906  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.02418  time: 0.1927  data_time: 0.0040  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:21:41 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 59  total_loss: 2.751  loss_cls: 1.152  loss_box_reg: 0.6907  loss_mask: 0.6824  loss_rpn_cls: 0.08358  loss_rpn_loc: 0.03083  time: 0.1925  data_time: 0.0040  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:21:45 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 79  total_loss: 2.184  loss_cls: 0.7505  loss_box_reg: 0.6652  loss_mask: 0.6754  loss_rpn_cls: 0.106  loss_rpn_loc: 0.03723  time: 0.1927  data_time: 0.0041  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:21:49 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 99  total_loss: 2.142  loss_cls: 0.6633  loss_box_reg: 0.7037  loss_mask: 0.6639  loss_rpn_cls: 0.04047  loss_rpn_loc: 0.03203  time: 0.1927  data_time: 0.0039  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:21:53 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 119  total_loss: 1.998  loss_cls: 0.6247  loss_box_reg: 0.6938  loss_mask: 0.6357  loss_rpn_cls: 0.02828  loss_rpn_loc: 0.03056  time: 0.1930  data_time: 0.0041  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:21:56 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 139  total_loss: 1.887  loss_cls: 0.5577  loss_box_reg: 0.6583  loss_mask: 0.6174  loss_rpn_cls: 0.01845  loss_rpn_loc: 0.02549  time: 0.1927  data_time: 0.0040  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:00 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 159  total_loss: 1.936  loss_cls: 0.5124  loss_box_reg: 0.698  loss_mask: 0.6107  loss_rpn_cls: 0.021  loss_rpn_loc: 0.01894  time: 0.1926  data_time: 0.0039  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:04 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 179  total_loss: 1.775  loss_cls: 0.473  loss_box_reg: 0.6921  loss_mask: 0.5864  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.03396  time: 0.1928  data_time: 0.0041  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:08 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 199  total_loss: 1.768  loss_cls: 0.46  loss_box_reg: 0.6261  loss_mask: 0.5447  loss_rpn_cls: 0.02721  loss_rpn_loc: 0.03067  time: 0.1926  data_time: 0.0039  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:12 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 219  total_loss: 1.613  loss_cls: 0.3659  loss_box_reg: 0.626  loss_mask: 0.5336  loss_rpn_cls: 0.02871  loss_rpn_loc: 0.03289  time: 0.1926  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:16 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 239  total_loss: 1.351  loss_cls: 0.2951  loss_box_reg: 0.5791  loss_mask: 0.447  loss_rpn_cls: 0.01783  loss_rpn_loc: 0.02997  time: 0.1927  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:20 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 259  total_loss: 1.496  loss_cls: 0.3101  loss_box_reg: 0.5871  loss_mask: 0.4199  loss_rpn_cls: 0.01763  loss_rpn_loc: 0.02277  time: 0.1927  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:23 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 279  total_loss: 1.223  loss_cls: 0.2142  loss_box_reg: 0.6041  loss_mask: 0.3504  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.02151  time: 0.1928  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:27 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 299  total_loss: 1.298  loss_cls: 0.2403  loss_box_reg: 0.5801  loss_mask: 0.3733  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.03152  time: 0.1926  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:31 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 319  total_loss: 1.044  loss_cls: 0.1903  loss_box_reg: 0.553  loss_mask: 0.2687  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.02821  time: 0.1925  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:35 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 339  total_loss: 1.253  loss_cls: 0.2702  loss_box_reg: 0.5554  loss_mask: 0.3364  loss_rpn_cls: 0.009776  loss_rpn_loc: 0.02956  time: 0.1924  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:39 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 359  total_loss: 1.028  loss_cls: 0.2101  loss_box_reg: 0.5167  loss_mask: 0.2509  loss_rpn_cls: 0.01697  loss_rpn_loc: 0.01301  time: 0.1924  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:43 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 1.203  loss_cls: 0.2088  loss_box_reg: 0.5139  loss_mask: 0.2802  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.02032  time: 0.1925  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:47 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 399  total_loss: 1.048  loss_cls: 0.2019  loss_box_reg: 0.5022  loss_mask: 0.2754  loss_rpn_cls: 0.01555  loss_rpn_loc: 0.02903  time: 0.1927  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:51 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 419  total_loss: 1.051  loss_cls: 0.2015  loss_box_reg: 0.4881  loss_mask: 0.3117  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.02005  time: 0.1929  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:55 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 439  total_loss: 1.024  loss_cls: 0.2389  loss_box_reg: 0.4692  loss_mask: 0.2746  loss_rpn_cls: 0.009873  loss_rpn_loc: 0.03039  time: 0.1931  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:22:58 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 459  total_loss: 0.9185  loss_cls: 0.1685  loss_box_reg: 0.4272  loss_mask: 0.2333  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.02829  time: 0.1932  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:02 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 479  total_loss: 1.023  loss_cls: 0.1456  loss_box_reg: 0.4803  loss_mask: 0.2234  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.01925  time: 0.1934  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:06 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.042  loss_cls: 0.1926  loss_box_reg: 0.4789  loss_mask: 0.2811  loss_rpn_cls: 0.009522  loss_rpn_loc: 0.02884  time: 0.1936  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:10 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 0.8944  loss_cls: 0.1607  loss_box_reg: 0.3827  loss_mask: 0.2539  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.02847  time: 0.1936  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:14 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 0.8762  loss_cls: 0.1511  loss_box_reg: 0.3993  loss_mask: 0.222  loss_rpn_cls: 0.008139  loss_rpn_loc: 0.02334  time: 0.1937  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:18 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 0.8223  loss_cls: 0.1352  loss_box_reg: 0.3835  loss_mask: 0.2228  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.02131  time: 0.1938  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:22 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 0.9317  loss_cls: 0.2054  loss_box_reg: 0.4249  loss_mask: 0.2664  loss_rpn_cls: 0.007964  loss_rpn_loc: 0.02417  time: 0.1939  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:26 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 599  total_loss: 0.7751  loss_cls: 0.1473  loss_box_reg: 0.3577  loss_mask: 0.2282  loss_rpn_cls: 0.005663  loss_rpn_loc: 0.01748  time: 0.1939  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:30 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.8173  loss_cls: 0.156  loss_box_reg: 0.3715  loss_mask: 0.2459  loss_rpn_cls: 0.005003  loss_rpn_loc: 0.01361  time: 0.1941  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:34 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.657  loss_cls: 0.1016  loss_box_reg: 0.3248  loss_mask: 0.1981  loss_rpn_cls: 0.007543  loss_rpn_loc: 0.02222  time: 0.1941  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:38 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.7004  loss_cls: 0.1125  loss_box_reg: 0.3316  loss_mask: 0.1839  loss_rpn_cls: 0.004214  loss_rpn_loc: 0.01333  time: 0.1942  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:42 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.7375  loss_cls: 0.1252  loss_box_reg: 0.3279  loss_mask: 0.2152  loss_rpn_cls: 0.003594  loss_rpn_loc: 0.01615  time: 0.1943  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:46 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.7233  loss_cls: 0.1003  loss_box_reg: 0.2811  loss_mask: 0.1524  loss_rpn_cls: 0.009683  loss_rpn_loc: 0.02097  time: 0.1943  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:50 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.7706  loss_cls: 0.1272  loss_box_reg: 0.3541  loss_mask: 0.2171  loss_rpn_cls: 0.004394  loss_rpn_loc: 0.01306  time: 0.1944  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:54 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.6946  loss_cls: 0.1162  loss_box_reg: 0.2633  loss_mask: 0.1671  loss_rpn_cls: 0.009322  loss_rpn_loc: 0.01893  time: 0.1944  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:23:57 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.7099  loss_cls: 0.1328  loss_box_reg: 0.3281  loss_mask: 0.1847  loss_rpn_cls: 0.008136  loss_rpn_loc: 0.02379  time: 0.1944  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:24:01 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.6388  loss_cls: 0.1045  loss_box_reg: 0.3059  loss_mask: 0.1873  loss_rpn_cls: 0.006497  loss_rpn_loc: 0.02004  time: 0.1945  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:24:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5934  loss_cls: 0.1252  loss_box_reg: 0.2708  loss_mask: 0.1881  loss_rpn_cls: 0.006328  loss_rpn_loc: 0.01495  time: 0.1945  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:24:06 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:35 (0.1946 s / it)\n",
      "\u001b[32m[10/21 11:24:06 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:36 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='WRZ64XD_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:24:06 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:24:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:24:06 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:24:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:24:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0580 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.645130 (0.085327 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.060296 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WRZ64XD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.700\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.424\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.450\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.539\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.552\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 39.837 | 69.990 | 42.450 | 44.972 | 39.270 | 44.367 |\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 42.676 | cushion    | 48.743 | door       | 26.135 |\n",
      "| indoor-plant | 54.119 | sofa       | 55.853 | table      | 11.498 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.354 | 54.117 | 15.799 | 20.379 | 17.519 | 49.968 |\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.503 | cushion    | 38.888 | door       | 29.820 |\n",
      "| indoor-plant | 12.419 | sofa       | 21.496 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='WRZ64XD0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:24:10 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:24:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:24:10 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:24:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:24:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.0628 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 11:24:18 d2.evaluation.evaluator]: \u001b[0mInference done 84/355. 0.0598 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 11:24:23 d2.evaluation.evaluator]: \u001b[0mInference done 151/355. 0.0595 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 11:24:28 d2.evaluation.evaluator]: \u001b[0mInference done 217/355. 0.0593 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.0597 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:24:38 d2.evaluation.evaluator]: \u001b[0mInference done 320/355. 0.0599 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:24:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:30.665024 (0.087614 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:24:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060159 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:24:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:24:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WRZ64XD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 12.964 | 27.019 | 9.622  | 7.066 | 16.328 | 9.919 |\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.077 | cushion    | 30.580 | door       | 1.011 |\n",
      "| indoor-plant | 13.045 | sofa       | 14.446 | table      | 0.624 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:24:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:24:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 11:24:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:24:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.266\n",
      "\u001b[32m[10/21 11:24:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.836 | 25.488 | 10.918 | 6.461 | 18.508 | 11.950 |\n",
      "\u001b[32m[10/21 11:24:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.116 | cushion    | 35.977 | door       | 0.344 |\n",
      "| indoor-plant | 11.284 | sofa       | 19.297 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='WRZ64XD1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:24:43 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:24:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:24:43 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:24:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:24:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0619 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 11:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 72/355. 0.0595 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 11:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.0589 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 206/355. 0.0589 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.0593 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 302/355. 0.0595 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 351/355. 0.0597 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:25:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:31.488823 (0.089968 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:25:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059788 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:25:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:25:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WRZ64XD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:25:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:25:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:25:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 11:25:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:25:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.249\n",
      "\u001b[32m[10/21 11:25:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.796 | 28.961 | 10.643 | 8.047 | 16.430 | 10.206 |\n",
      "\u001b[32m[10/21 11:25:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.289 | cushion    | 32.516 | door       | 1.063 |\n",
      "| indoor-plant | 12.269 | sofa       | 15.058 | table      | 0.580 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:25:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:25:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 11:25:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:25:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
      "\u001b[32m[10/21 11:25:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.853 | 27.148 | 11.529 | 7.197 | 18.773 | 12.235 |\n",
      "\u001b[32m[10/21 11:25:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.937 | cushion    | 38.414 | door       | 0.714 |\n",
      "| indoor-plant | 11.005 | sofa       | 21.047 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='WRZ64XD2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:25:17 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:25:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:25:17 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:25:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:25:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.0624 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 11:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.0597 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 11:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 147/355. 0.0593 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 205/355. 0.0594 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 11:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.0597 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 302/355. 0.0600 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 351/355. 0.0602 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.896227 (0.093989 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060242 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WRZ64XD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.176 | 27.783 | 9.729  | 7.581 | 15.211 | 12.248 |\n",
      "\u001b[32m[10/21 11:25:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.677 | cushion    | 30.360 | door       | 1.088 |\n",
      "| indoor-plant | 12.932 | sofa       | 15.337 | table      | 0.663 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:25:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:25:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 11:25:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:25:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
      "\u001b[32m[10/21 11:25:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.315 | 26.086 | 11.373 | 6.656 | 17.819 | 13.133 |\n",
      "\u001b[32m[10/21 11:25:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.227 | cushion    | 35.726 | door       | 0.618 |\n",
      "| indoor-plant | 11.152 | sofa       | 21.167 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [27.01909353457613, 28.960600115195945, 27.78325211091387]}, 'segm': {'AP50': [25.488094371116766, 27.147655226543925, 26.08636484199855]}}\n",
      "dataset_name N33L4KG\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json', name='N33L4KG_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/N33L4KG0\n",
      "output_aug/500/N33L4KG0\n",
      "\u001b[32m[10/21 11:25:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:25:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "154 154\n",
      "\u001b[32m[10/21 11:25:53 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 11:25:53 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 39 images left.\n",
      "\u001b[32m[10/21 11:25:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:25:53 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:25:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:25:53 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:25:53 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:25:58 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.528  loss_cls: 1.94  loss_box_reg: 0.7174  loss_mask: 0.6929  loss_rpn_cls: 0.2054  loss_rpn_loc: 0.04055  time: 0.1946  data_time: 0.0172  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:02 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 39  total_loss: 2.203  loss_cls: 0.7908  loss_box_reg: 0.6768  loss_mask: 0.6655  loss_rpn_cls: 0.0492  loss_rpn_loc: 0.0304  time: 0.1951  data_time: 0.0045  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:06 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 59  total_loss: 1.877  loss_cls: 0.5137  loss_box_reg: 0.72  loss_mask: 0.6415  loss_rpn_cls: 0.04886  loss_rpn_loc: 0.02718  time: 0.1955  data_time: 0.0040  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:09 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 79  total_loss: 1.629  loss_cls: 0.4077  loss_box_reg: 0.6349  loss_mask: 0.544  loss_rpn_cls: 0.03142  loss_rpn_loc: 0.03654  time: 0.1948  data_time: 0.0041  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:13 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 99  total_loss: 1.63  loss_cls: 0.3819  loss_box_reg: 0.619  loss_mask: 0.4565  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.03013  time: 0.1946  data_time: 0.0041  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:17 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 119  total_loss: 1.306  loss_cls: 0.2888  loss_box_reg: 0.5796  loss_mask: 0.3625  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.0277  time: 0.1945  data_time: 0.0041  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:21 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 139  total_loss: 1.097  loss_cls: 0.2128  loss_box_reg: 0.5793  loss_mask: 0.3139  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.0259  time: 0.1952  data_time: 0.0041  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:25 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 1.016  loss_cls: 0.184  loss_box_reg: 0.6004  loss_mask: 0.2897  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.02852  time: 0.1954  data_time: 0.0041  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:29 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 1.015  loss_cls: 0.1567  loss_box_reg: 0.4736  loss_mask: 0.2667  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.02274  time: 0.1952  data_time: 0.0039  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:33 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 0.6803  loss_cls: 0.1247  loss_box_reg: 0.3435  loss_mask: 0.2221  loss_rpn_cls: 0.007016  loss_rpn_loc: 0.02663  time: 0.1953  data_time: 0.0040  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:37 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 0.7386  loss_cls: 0.1228  loss_box_reg: 0.3292  loss_mask: 0.1884  loss_rpn_cls: 0.004029  loss_rpn_loc: 0.01846  time: 0.1953  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:41 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 0.7443  loss_cls: 0.1295  loss_box_reg: 0.3331  loss_mask: 0.2169  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.02482  time: 0.1953  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:45 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 0.7035  loss_cls: 0.1096  loss_box_reg: 0.2963  loss_mask: 0.2185  loss_rpn_cls: 0.008749  loss_rpn_loc: 0.01921  time: 0.1952  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:49 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 0.5472  loss_cls: 0.09279  loss_box_reg: 0.2375  loss_mask: 0.1692  loss_rpn_cls: 0.006027  loss_rpn_loc: 0.02571  time: 0.1952  data_time: 0.0047  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:52 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 299  total_loss: 0.5737  loss_cls: 0.0894  loss_box_reg: 0.252  loss_mask: 0.1877  loss_rpn_cls: 0.005836  loss_rpn_loc: 0.03268  time: 0.1949  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:26:56 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.5116  loss_cls: 0.08622  loss_box_reg: 0.2317  loss_mask: 0.1637  loss_rpn_cls: 0.004035  loss_rpn_loc: 0.01396  time: 0.1951  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:00 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.6194  loss_cls: 0.09961  loss_box_reg: 0.2747  loss_mask: 0.1743  loss_rpn_cls: 0.00636  loss_rpn_loc: 0.01959  time: 0.1949  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:04 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.5793  loss_cls: 0.08347  loss_box_reg: 0.2332  loss_mask: 0.1436  loss_rpn_cls: 0.005343  loss_rpn_loc: 0.02428  time: 0.1949  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:08 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.5894  loss_cls: 0.1108  loss_box_reg: 0.2383  loss_mask: 0.1804  loss_rpn_cls: 0.002768  loss_rpn_loc: 0.02264  time: 0.1950  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:12 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.5518  loss_cls: 0.07637  loss_box_reg: 0.2191  loss_mask: 0.1734  loss_rpn_cls: 0.004458  loss_rpn_loc: 0.02271  time: 0.1950  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:16 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.4817  loss_cls: 0.06474  loss_box_reg: 0.2008  loss_mask: 0.1329  loss_rpn_cls: 0.003076  loss_rpn_loc: 0.01933  time: 0.1949  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:20 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.5406  loss_cls: 0.07201  loss_box_reg: 0.2256  loss_mask: 0.1755  loss_rpn_cls: 0.011  loss_rpn_loc: 0.01698  time: 0.1949  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:24 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.4761  loss_cls: 0.07172  loss_box_reg: 0.2111  loss_mask: 0.167  loss_rpn_cls: 0.005131  loss_rpn_loc: 0.01614  time: 0.1949  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:28 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.4481  loss_cls: 0.06712  loss_box_reg: 0.2008  loss_mask: 0.1301  loss_rpn_cls: 0.006893  loss_rpn_loc: 0.01657  time: 0.1949  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:32 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.454  loss_cls: 0.07715  loss_box_reg: 0.1913  loss_mask: 0.1511  loss_rpn_cls: 0.003385  loss_rpn_loc: 0.01399  time: 0.1948  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:27:32 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:37 (0.1949 s / it)\n",
      "\u001b[32m[10/21 11:27:32 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='N33L4KG_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:27:32 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:27:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:27:33 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:27:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:27:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0587 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.496772 (0.080541 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.059702 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/N33L4KG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.706\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.417\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.463\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.528\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.527\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 39.724 | 70.610 | 41.743 | 46.318 | 40.496 | 38.295 |\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 34.218 | cushion    | 49.655 | door       | 19.170 |\n",
      "| indoor-plant | 69.349 | sofa       | 44.319 | table      | 21.634 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.590\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.898 | 58.986 | 15.955 | 24.753 | 29.833 | 36.704 |\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.337 | cushion    | 37.013 | door       | 27.712 |\n",
      "| indoor-plant | 31.552 | sofa       | 38.773 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='N33L4KG0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:27:36 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:27:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:27:36 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:27:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:27:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 23/355. 0.0619 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 11:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 80/355. 0.0603 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 11:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 139/355. 0.0600 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 201/355. 0.0599 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.0601 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 302/355. 0.0605 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.0608 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:28:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.402687 (0.092579 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:28:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060828 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:28:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:28:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/N33L4KG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:28:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:28:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:28:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 11:28:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:28:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.404\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      "\u001b[32m[10/21 11:28:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.307 | 40.377 | 15.165 | 7.327 | 20.893 | 18.883 |\n",
      "\u001b[32m[10/21 11:28:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.026 | cushion    | 28.837 | door       | 2.649 |\n",
      "| indoor-plant | 29.858 | sofa       | 37.274 | table      | 0.196 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:28:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:28:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 11:28:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:28:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "\u001b[32m[10/21 11:28:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.945 | 39.401 | 18.131 | 8.523 | 22.678 | 18.534 |\n",
      "\u001b[32m[10/21 11:28:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.193 | cushion    | 42.914 | door       | 2.241 |\n",
      "| indoor-plant | 19.173 | sofa       | 39.148 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='N33L4KG1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:28:11 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:28:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:28:11 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:28:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:28:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 23/355. 0.0628 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 11:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 75/355. 0.0611 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 11:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.0607 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 11:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 186/355. 0.0605 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 11:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 236/355. 0.0607 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 284/355. 0.0608 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 331/355. 0.0610 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:28:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.134721 (0.100385 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:28:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061149 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:28:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:28:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/N33L4KG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:28:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:28:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:28:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 11:28:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:28:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.424\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
      "\u001b[32m[10/21 11:28:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.239 | 42.352 | 15.275 | 7.858 | 22.509 | 15.732 |\n",
      "\u001b[32m[10/21 11:28:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.456 | cushion    | 31.215 | door       | 3.092 |\n",
      "| indoor-plant | 28.443 | sofa       | 39.938 | table      | 0.291 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:28:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:28:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 11:28:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:28:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n",
      "\u001b[32m[10/21 11:28:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.632 | 41.074 | 19.944 | 8.756 | 24.712 | 15.730 |\n",
      "\u001b[32m[10/21 11:28:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.915 | cushion    | 45.083 | door       | 2.513 |\n",
      "| indoor-plant | 17.324 | sofa       | 41.960 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='N33L4KG2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:28:49 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:28:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:28:49 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:28:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:28:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0637 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 11:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 63/355. 0.0615 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 11:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 119/355. 0.0607 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 11:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.0600 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 11:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 229/355. 0.0603 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 278/355. 0.0606 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.0609 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 11:29:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.744547 (0.099270 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:29:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061135 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/N33L4KG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.355 | 42.251 | 16.289 | 7.445 | 21.548 | 19.857 |\n",
      "\u001b[32m[10/21 11:29:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.974 | cushion    | 30.143 | door       | 3.160 |\n",
      "| indoor-plant | 30.324 | sofa       | 40.269 | table      | 0.261 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:29:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:29:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "\u001b[32m[10/21 11:29:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:29:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.417\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "\u001b[32m[10/21 11:29:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.108 | 41.660 | 20.244 | 8.944 | 23.887 | 19.591 |\n",
      "\u001b[32m[10/21 11:29:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.466 | cushion    | 44.432 | door       | 3.150 |\n",
      "| indoor-plant | 18.906 | sofa       | 42.692 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [40.37701919507876, 42.352423558607725, 42.25058551744084]}, 'segm': {'AP50': [39.40105253035981, 41.074478908779305, 41.65986792388009]}}\n",
      "dataset_name H2A1JG5\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json', name='H2A1JG5_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/H2A1JG50\n",
      "output_aug/800/H2A1JG50\n",
      "\u001b[32m[10/21 11:29:27 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:29:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "154 154\n",
      "\u001b[32m[10/21 11:29:27 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 11:29:27 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 39 images left.\n",
      "\u001b[32m[10/21 11:29:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:29:27 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:29:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:29:27 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:29:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:29:31 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 19  total_loss: 3.286  loss_cls: 1.744  loss_box_reg: 0.6324  loss_mask: 0.6907  loss_rpn_cls: 0.1384  loss_rpn_loc: 0.02973  time: 0.1914  data_time: 0.0159  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:29:35 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 39  total_loss: 2.138  loss_cls: 0.7536  loss_box_reg: 0.6637  loss_mask: 0.675  loss_rpn_cls: 0.05328  loss_rpn_loc: 0.03425  time: 0.1922  data_time: 0.0041  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:29:39 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 59  total_loss: 1.907  loss_cls: 0.5282  loss_box_reg: 0.6465  loss_mask: 0.6197  loss_rpn_cls: 0.04101  loss_rpn_loc: 0.02841  time: 0.1922  data_time: 0.0041  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:29:43 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 79  total_loss: 1.751  loss_cls: 0.4276  loss_box_reg: 0.68  loss_mask: 0.5583  loss_rpn_cls: 0.02957  loss_rpn_loc: 0.02983  time: 0.1923  data_time: 0.0045  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:29:47 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 99  total_loss: 1.321  loss_cls: 0.2865  loss_box_reg: 0.5793  loss_mask: 0.4412  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.02843  time: 0.1925  data_time: 0.0040  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:29:51 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 119  total_loss: 1.347  loss_cls: 0.3069  loss_box_reg: 0.5706  loss_mask: 0.344  loss_rpn_cls: 0.0108  loss_rpn_loc: 0.03062  time: 0.1927  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:29:55 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 139  total_loss: 1.134  loss_cls: 0.2545  loss_box_reg: 0.5557  loss_mask: 0.3098  loss_rpn_cls: 0.01579  loss_rpn_loc: 0.02719  time: 0.1925  data_time: 0.0040  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:29:59 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 159  total_loss: 0.9167  loss_cls: 0.1406  loss_box_reg: 0.4074  loss_mask: 0.2373  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.018  time: 0.1926  data_time: 0.0041  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:02 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 179  total_loss: 0.9609  loss_cls: 0.185  loss_box_reg: 0.4963  loss_mask: 0.2574  loss_rpn_cls: 0.008655  loss_rpn_loc: 0.02234  time: 0.1928  data_time: 0.0040  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:06 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 199  total_loss: 0.7659  loss_cls: 0.1147  loss_box_reg: 0.3174  loss_mask: 0.2023  loss_rpn_cls: 0.008095  loss_rpn_loc: 0.03206  time: 0.1929  data_time: 0.0040  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:10 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 219  total_loss: 0.7623  loss_cls: 0.1344  loss_box_reg: 0.3578  loss_mask: 0.2281  loss_rpn_cls: 0.007795  loss_rpn_loc: 0.01977  time: 0.1930  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:14 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 239  total_loss: 0.7026  loss_cls: 0.105  loss_box_reg: 0.3252  loss_mask: 0.2214  loss_rpn_cls: 0.007439  loss_rpn_loc: 0.02211  time: 0.1931  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:18 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 259  total_loss: 0.7009  loss_cls: 0.1318  loss_box_reg: 0.2981  loss_mask: 0.1847  loss_rpn_cls: 0.0081  loss_rpn_loc: 0.0223  time: 0.1933  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:22 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 279  total_loss: 0.6589  loss_cls: 0.1307  loss_box_reg: 0.2937  loss_mask: 0.2094  loss_rpn_cls: 0.007247  loss_rpn_loc: 0.02002  time: 0.1936  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:26 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 299  total_loss: 0.6678  loss_cls: 0.1054  loss_box_reg: 0.3042  loss_mask: 0.2124  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.02016  time: 0.1938  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:30 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 319  total_loss: 0.6054  loss_cls: 0.08824  loss_box_reg: 0.2696  loss_mask: 0.1885  loss_rpn_cls: 0.003843  loss_rpn_loc: 0.02552  time: 0.1938  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:34 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 339  total_loss: 0.6215  loss_cls: 0.1018  loss_box_reg: 0.2658  loss_mask: 0.2034  loss_rpn_cls: 0.006583  loss_rpn_loc: 0.02784  time: 0.1939  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:38 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 359  total_loss: 0.4834  loss_cls: 0.07775  loss_box_reg: 0.1837  loss_mask: 0.175  loss_rpn_cls: 0.003074  loss_rpn_loc: 0.01219  time: 0.1937  data_time: 0.0038  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:41 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 0.5255  loss_cls: 0.0895  loss_box_reg: 0.251  loss_mask: 0.1649  loss_rpn_cls: 0.004123  loss_rpn_loc: 0.01645  time: 0.1938  data_time: 0.0038  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:45 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 399  total_loss: 0.4508  loss_cls: 0.0738  loss_box_reg: 0.1963  loss_mask: 0.1473  loss_rpn_cls: 0.001582  loss_rpn_loc: 0.01705  time: 0.1938  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:49 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 419  total_loss: 0.4849  loss_cls: 0.08479  loss_box_reg: 0.2127  loss_mask: 0.1599  loss_rpn_cls: 0.002371  loss_rpn_loc: 0.01962  time: 0.1939  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:53 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 439  total_loss: 0.4935  loss_cls: 0.0718  loss_box_reg: 0.2372  loss_mask: 0.1564  loss_rpn_cls: 0.001438  loss_rpn_loc: 0.009917  time: 0.1939  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:30:57 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 0.5119  loss_cls: 0.07848  loss_box_reg: 0.2179  loss_mask: 0.1705  loss_rpn_cls: 0.001347  loss_rpn_loc: 0.01645  time: 0.1939  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:01 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 0.4751  loss_cls: 0.07827  loss_box_reg: 0.1985  loss_mask: 0.157  loss_rpn_cls: 0.007278  loss_rpn_loc: 0.01783  time: 0.1940  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:05 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 0.4301  loss_cls: 0.05718  loss_box_reg: 0.1735  loss_mask: 0.1482  loss_rpn_cls: 0.002489  loss_rpn_loc: 0.0134  time: 0.1939  data_time: 0.0038  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:09 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 0.4764  loss_cls: 0.0619  loss_box_reg: 0.178  loss_mask: 0.1207  loss_rpn_cls: 0.004724  loss_rpn_loc: 0.01658  time: 0.1938  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:13 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 0.4112  loss_cls: 0.05651  loss_box_reg: 0.1777  loss_mask: 0.139  loss_rpn_cls: 0.003775  loss_rpn_loc: 0.0131  time: 0.1938  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:17 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 0.3757  loss_cls: 0.0487  loss_box_reg: 0.162  loss_mask: 0.1271  loss_rpn_cls: 0.002279  loss_rpn_loc: 0.01554  time: 0.1939  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:20 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 0.4129  loss_cls: 0.06015  loss_box_reg: 0.1948  loss_mask: 0.1462  loss_rpn_cls: 0.002039  loss_rpn_loc: 0.01236  time: 0.1939  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:24 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 599  total_loss: 0.4327  loss_cls: 0.05337  loss_box_reg: 0.1706  loss_mask: 0.1183  loss_rpn_cls: 0.004592  loss_rpn_loc: 0.01592  time: 0.1939  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:28 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.3959  loss_cls: 0.05802  loss_box_reg: 0.1731  loss_mask: 0.1299  loss_rpn_cls: 0.006048  loss_rpn_loc: 0.01014  time: 0.1939  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:32 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.4201  loss_cls: 0.06603  loss_box_reg: 0.1691  loss_mask: 0.1408  loss_rpn_cls: 0.001644  loss_rpn_loc: 0.01117  time: 0.1941  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:36 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.3783  loss_cls: 0.05134  loss_box_reg: 0.1587  loss_mask: 0.1165  loss_rpn_cls: 0.001093  loss_rpn_loc: 0.01072  time: 0.1940  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:40 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.4039  loss_cls: 0.05713  loss_box_reg: 0.1829  loss_mask: 0.1256  loss_rpn_cls: 0.001359  loss_rpn_loc: 0.01416  time: 0.1941  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:44 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.4003  loss_cls: 0.06065  loss_box_reg: 0.1819  loss_mask: 0.1468  loss_rpn_cls: 0.001559  loss_rpn_loc: 0.0203  time: 0.1942  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:48 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.3784  loss_cls: 0.05194  loss_box_reg: 0.1662  loss_mask: 0.1314  loss_rpn_cls: 0.001484  loss_rpn_loc: 0.0149  time: 0.1943  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:52 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.4006  loss_cls: 0.05943  loss_box_reg: 0.1702  loss_mask: 0.1342  loss_rpn_cls: 0.001545  loss_rpn_loc: 0.01653  time: 0.1943  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:31:56 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.3527  loss_cls: 0.05701  loss_box_reg: 0.1474  loss_mask: 0.1417  loss_rpn_cls: 0.002779  loss_rpn_loc: 0.01747  time: 0.1943  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:32:00 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.3847  loss_cls: 0.05441  loss_box_reg: 0.1731  loss_mask: 0.1292  loss_rpn_cls: 0.0009593  loss_rpn_loc: 0.01535  time: 0.1944  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:32:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.3267  loss_cls: 0.0439  loss_box_reg: 0.149  loss_mask: 0.1176  loss_rpn_cls: 0.002551  loss_rpn_loc: 0.009799  time: 0.1944  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:32:05 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:35 (0.1944 s / it)\n",
      "\u001b[32m[10/21 11:32:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:36 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='H2A1JG5_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:32:05 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:32:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:32:05 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:32:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:32:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:32:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0576 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.218748 (0.071573 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057515 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H2A1JG50/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.622\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.404\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.468\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 37.833 | 62.202 | 40.402 | 44.264 | 34.819 | 21.319 |\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.937 | cushion    | 55.500 | door       | 22.413 |\n",
      "| indoor-plant | 53.020 | sofa       | 49.279 | table      | 20.847 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.291 | 43.265 | 18.529 | 20.479 | 22.681 | 14.775 |\n",
      "\u001b[32m[10/21 11:32:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 18.350 | cushion    | 44.546 | door       | 27.963 |\n",
      "| indoor-plant | 12.277 | sofa       | 30.164 | table      | 0.444  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='H2A1JG50_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:32:07 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:32:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:32:08 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:32:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:32:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 35/355. 0.0586 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 11:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0572 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 11:32:21 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.0572 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:32:26 d2.evaluation.evaluator]: \u001b[0mInference done 239/355. 0.0574 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:32:31 d2.evaluation.evaluator]: \u001b[0mInference done 299/355. 0.0574 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:32:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.163951 (0.077611 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:32:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057456 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:32:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:32:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H2A1JG50/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:32:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:32:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.532 | 38.654 | 18.308 | 7.573 | 21.930 | 19.067 |\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.042 | cushion    | 32.771 | door       | 1.044 |\n",
      "| indoor-plant | 27.625 | sofa       | 48.048 | table      | 0.661 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.368\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.244 | 36.777 | 17.917 | 8.902 | 18.678 | 15.105 |\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.524 | cushion    | 38.430 | door       | 0.973 |\n",
      "| indoor-plant | 13.361 | sofa       | 46.173 | table      | 0.003 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='H2A1JG51_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:32:36 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:32:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:32:36 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:32:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:32:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0584 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 11:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 77/355. 0.0579 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 11:32:47 d2.evaluation.evaluator]: \u001b[0mInference done 149/355. 0.0576 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 11:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 219/355. 0.0575 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 283/355. 0.0576 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 11:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 347/355. 0.0577 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:33:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.470149 (0.075629 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:33:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057753 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H2A1JG50/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.399\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.864 | 39.875 | 17.617 | 7.870 | 23.303 | 16.800 |\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.727 | cushion    | 33.456 | door       | 2.053 |\n",
      "| indoor-plant | 26.799 | sofa       | 47.660 | table      | 0.490 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
      "\u001b[32m[10/21 11:33:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.630 | 38.449 | 18.950 | 8.568 | 20.763 | 14.956 |\n",
      "\u001b[32m[10/21 11:33:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.200 | cushion    | 38.135 | door       | 2.525 |\n",
      "| indoor-plant | 12.680 | sofa       | 47.233 | table      | 0.006 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='H2A1JG52_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:33:05 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:33:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:33:05 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:33:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:33:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.0583 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 11:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 107/355. 0.0579 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 11:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 181/355. 0.0577 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 11:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.0578 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 301/355. 0.0579 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.964161 (0.077040 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057864 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H2A1JG50/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 11:33:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.482 | 39.395 | 17.918 | 7.447 | 21.367 | 18.783 |\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.856 | cushion    | 32.984 | door       | 1.416 |\n",
      "| indoor-plant | 28.292 | sofa       | 46.839 | table      | 0.508 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.320 | 37.738 | 18.124 | 8.359 | 19.007 | 15.975 |\n",
      "\u001b[32m[10/21 11:33:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.599 | cushion    | 38.223 | door       | 1.642 |\n",
      "| indoor-plant | 13.374 | sofa       | 46.082 | table      | 0.001 |\n",
      "all results {'bbox': {'AP50': [38.65424965638765, 39.8748146268351, 39.39538077018864]}, 'segm': {'AP50': [36.776971223983686, 38.448573690047404, 37.7377043872515]}}\n",
      "dataset_name 6Q3DH7L\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json', name='6Q3DH7L_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/6Q3DH7L0\n",
      "output_aug/500/6Q3DH7L0\n",
      "\u001b[32m[10/21 11:33:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:33:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "154 154\n",
      "\u001b[32m[10/21 11:33:34 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 11:33:34 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 39 images left.\n",
      "\u001b[32m[10/21 11:33:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:33:34 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:33:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:33:34 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:33:35 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:33:39 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.302  loss_cls: 1.788  loss_box_reg: 0.6134  loss_mask: 0.6939  loss_rpn_cls: 0.1377  loss_rpn_loc: 0.03439  time: 0.1931  data_time: 0.0171  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:33:43 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 39  total_loss: 3.005  loss_cls: 1.523  loss_box_reg: 0.6414  loss_mask: 0.6918  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.02889  time: 0.1912  data_time: 0.0039  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:33:46 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 59  total_loss: 2.503  loss_cls: 1.048  loss_box_reg: 0.5755  loss_mask: 0.688  loss_rpn_cls: 0.09918  loss_rpn_loc: 0.02769  time: 0.1909  data_time: 0.0040  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:33:50 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 79  total_loss: 2.251  loss_cls: 0.7713  loss_box_reg: 0.6304  loss_mask: 0.6813  loss_rpn_cls: 0.07856  loss_rpn_loc: 0.04559  time: 0.1912  data_time: 0.0041  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:33:54 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 99  total_loss: 2.173  loss_cls: 0.6822  loss_box_reg: 0.6883  loss_mask: 0.6685  loss_rpn_cls: 0.06734  loss_rpn_loc: 0.04198  time: 0.1913  data_time: 0.0040  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:33:58 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 119  total_loss: 2.089  loss_cls: 0.6642  loss_box_reg: 0.6882  loss_mask: 0.655  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.03739  time: 0.1919  data_time: 0.0041  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:02 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 1.904  loss_cls: 0.5453  loss_box_reg: 0.614  loss_mask: 0.6404  loss_rpn_cls: 0.05256  loss_rpn_loc: 0.03836  time: 0.1922  data_time: 0.0042  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:06 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 159  total_loss: 1.982  loss_cls: 0.5749  loss_box_reg: 0.6757  loss_mask: 0.6206  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.02661  time: 0.1924  data_time: 0.0040  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:10 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 179  total_loss: 1.944  loss_cls: 0.5436  loss_box_reg: 0.6931  loss_mask: 0.6217  loss_rpn_cls: 0.0215  loss_rpn_loc: 0.03852  time: 0.1925  data_time: 0.0041  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:14 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 199  total_loss: 1.765  loss_cls: 0.4748  loss_box_reg: 0.6085  loss_mask: 0.591  loss_rpn_cls: 0.02151  loss_rpn_loc: 0.02634  time: 0.1925  data_time: 0.0040  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:17 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 219  total_loss: 1.708  loss_cls: 0.4232  loss_box_reg: 0.6968  loss_mask: 0.5325  loss_rpn_cls: 0.0275  loss_rpn_loc: 0.02901  time: 0.1928  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:21 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 239  total_loss: 1.567  loss_cls: 0.372  loss_box_reg: 0.5824  loss_mask: 0.5298  loss_rpn_cls: 0.01896  loss_rpn_loc: 0.02964  time: 0.1927  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:25 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 1.536  loss_cls: 0.3856  loss_box_reg: 0.6057  loss_mask: 0.4694  loss_rpn_cls: 0.02376  loss_rpn_loc: 0.02902  time: 0.1927  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:29 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 1.463  loss_cls: 0.314  loss_box_reg: 0.6983  loss_mask: 0.4341  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.02118  time: 0.1927  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:33 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 299  total_loss: 1.286  loss_cls: 0.237  loss_box_reg: 0.5857  loss_mask: 0.3927  loss_rpn_cls: 0.02302  loss_rpn_loc: 0.02442  time: 0.1927  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:37 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 319  total_loss: 1.563  loss_cls: 0.385  loss_box_reg: 0.699  loss_mask: 0.4055  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.02955  time: 0.1929  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:41 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 339  total_loss: 1.134  loss_cls: 0.2215  loss_box_reg: 0.5229  loss_mask: 0.3357  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.01634  time: 0.1927  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:45 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 359  total_loss: 1.315  loss_cls: 0.2317  loss_box_reg: 0.643  loss_mask: 0.3266  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.02397  time: 0.1929  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:48 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.089  loss_cls: 0.1915  loss_box_reg: 0.5824  loss_mask: 0.3176  loss_rpn_cls: 0.009915  loss_rpn_loc: 0.02217  time: 0.1930  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:52 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.158  loss_cls: 0.2587  loss_box_reg: 0.5432  loss_mask: 0.3396  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.0253  time: 0.1931  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:34:56 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.15  loss_cls: 0.187  loss_box_reg: 0.5496  loss_mask: 0.2876  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.02145  time: 0.1933  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:35:00 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.174  loss_cls: 0.2188  loss_box_reg: 0.5081  loss_mask: 0.32  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.02402  time: 0.1934  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:35:04 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.9696  loss_cls: 0.1835  loss_box_reg: 0.4593  loss_mask: 0.2534  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.02412  time: 0.1934  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:35:08 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.09  loss_cls: 0.1935  loss_box_reg: 0.5112  loss_mask: 0.2998  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.02487  time: 0.1935  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:35:13 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.9668  loss_cls: 0.1591  loss_box_reg: 0.4969  loss_mask: 0.287  loss_rpn_cls: 0.008946  loss_rpn_loc: 0.02837  time: 0.1936  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:35:13 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:36 (0.1937 s / it)\n",
      "\u001b[32m[10/21 11:35:13 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='6Q3DH7L_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:35:13 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:35:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:35:13 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:35:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:35:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0591 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.078208 (0.099297 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.061670 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6Q3DH7L0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.622\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.856 | 62.223 | 24.776 | 35.784 | 31.173 | 36.320 |\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 35.999 | cushion    | 39.298 | door       | 26.910 |\n",
      "| indoor-plant | 41.719 | sofa       | 39.974 | table      | 1.238  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.792 | 42.299 | 11.537 | 15.786 | 13.491 | 47.155 |\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 20.564 | cushion    | 34.777 | door       | 29.269 |\n",
      "| indoor-plant | 0.000  | sofa       | 22.140 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='6Q3DH7L0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:35:17 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:35:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:35:17 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:35:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:35:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0684 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 11:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 54/355. 0.0660 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 11:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0640 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 11:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 154/355. 0.0632 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 11:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 208/355. 0.0626 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 11:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 246/355. 0.0633 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.0636 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 326/355. 0.0640 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.517677 (0.115765 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064094 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6Q3DH7L0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.297\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 15.719 | 34.855 | 9.130  | 9.346 | 18.209 | 9.456 |\n",
      "\u001b[32m[10/21 11:35:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.566 | cushion    | 32.147 | door       | 2.071 |\n",
      "| indoor-plant | 20.398 | sofa       | 17.123 | table      | 0.007 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.30s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:36:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:36:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 11:36:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:36:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
      "\u001b[32m[10/21 11:36:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.662 | 26.710 | 11.184 | 8.910 | 14.981 | 11.341 |\n",
      "\u001b[32m[10/21 11:36:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.709 | cushion    | 43.046 | door       | 0.774 |\n",
      "| indoor-plant | 1.759  | sofa       | 22.683 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='6Q3DH7L1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:36:01 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:36:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:36:01 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:36:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:36:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0689 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 11:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.0659 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 11:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0636 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 11:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 155/355. 0.0631 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 11:36:23 d2.evaluation.evaluator]: \u001b[0mInference done 207/355. 0.0628 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 11:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.0635 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 11:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 282/355. 0.0638 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 316/355. 0.0642 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:36:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.339892 (0.118114 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:36:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064153 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6Q3DH7L0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.356\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 16.021 | 35.613 | 9.355  | 8.951 | 17.757 | 9.307 |\n",
      "\u001b[32m[10/21 11:36:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 23.170 | cushion    | 32.814 | door       | 2.125 |\n",
      "| indoor-plant | 19.558 | sofa       | 18.459 | table      | 0.003 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:36:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:36:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 11:36:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:36:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.268\n",
      "\u001b[32m[10/21 11:36:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.989 | 27.590 | 10.647 | 7.728 | 15.028 | 10.960 |\n",
      "\u001b[32m[10/21 11:36:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.125 | cushion    | 42.915 | door       | 1.091 |\n",
      "| indoor-plant | 1.727  | sofa       | 24.075 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='6Q3DH7L2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:36:46 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:36:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:36:46 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:36:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:36:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0685 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 11:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 48/355. 0.0666 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 11:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 96/355. 0.0638 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 11:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 145/355. 0.0630 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.0624 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.0632 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.0635 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 11:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 303/355. 0.0640 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 343/355. 0.0640 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:37:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.344078 (0.123840 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:37:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064208 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6Q3DH7L0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.721 | 34.617 | 9.446  | 8.443 | 16.997 | 11.648 |\n",
      "\u001b[32m[10/21 11:37:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.724 | cushion    | 31.625 | door       | 2.834 |\n",
      "| indoor-plant | 21.102 | sofa       | 17.034 | table      | 0.006 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:37:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:37:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "\u001b[32m[10/21 11:37:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:37:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.10 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.290\n",
      "\u001b[32m[10/21 11:37:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.620 | 26.609 | 11.051 | 7.331 | 14.313 | 12.528 |\n",
      "\u001b[32m[10/21 11:37:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.255 | cushion    | 41.334 | door       | 1.370 |\n",
      "| indoor-plant | 1.783  | sofa       | 23.979 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [34.85517598221063, 35.613396699500775, 34.617074068718026]}, 'segm': {'AP50': [26.710389185623885, 27.5903845331059, 26.60865926635359]}}\n",
      "dataset_name ZGQ85MA\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json', name='ZGQ85MA_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/ZGQ85MA0\n",
      "output_aug/800/ZGQ85MA0\n",
      "\u001b[32m[10/21 11:37:34 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:37:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "154 154\n",
      "\u001b[32m[10/21 11:37:34 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 11:37:34 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 39 images left.\n",
      "\u001b[32m[10/21 11:37:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:37:34 d2.data.common]: \u001b[0mSerializing 39 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:37:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:37:34 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:37:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:37:39 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 19  total_loss: 3.449  loss_cls: 1.953  loss_box_reg: 0.6248  loss_mask: 0.6911  loss_rpn_cls: 0.1924  loss_rpn_loc: 0.03417  time: 0.1937  data_time: 0.0227  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:37:43 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 39  total_loss: 3.155  loss_cls: 1.645  loss_box_reg: 0.6185  loss_mask: 0.6892  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.03805  time: 0.1942  data_time: 0.0040  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:37:46 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 59  total_loss: 2.657  loss_cls: 1.106  loss_box_reg: 0.5719  loss_mask: 0.6844  loss_rpn_cls: 0.09998  loss_rpn_loc: 0.03139  time: 0.1936  data_time: 0.0041  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:37:50 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 79  total_loss: 2.208  loss_cls: 0.7089  loss_box_reg: 0.5628  loss_mask: 0.6759  loss_rpn_cls: 0.1606  loss_rpn_loc: 0.04184  time: 0.1935  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:37:54 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 99  total_loss: 2.111  loss_cls: 0.6573  loss_box_reg: 0.6784  loss_mask: 0.67  loss_rpn_cls: 0.06193  loss_rpn_loc: 0.04665  time: 0.1932  data_time: 0.0041  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:37:58 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 119  total_loss: 2.106  loss_cls: 0.6399  loss_box_reg: 0.747  loss_mask: 0.6437  loss_rpn_cls: 0.03328  loss_rpn_loc: 0.03842  time: 0.1931  data_time: 0.0040  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:02 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 139  total_loss: 1.973  loss_cls: 0.5861  loss_box_reg: 0.6966  loss_mask: 0.6413  loss_rpn_cls: 0.04887  loss_rpn_loc: 0.04467  time: 0.1931  data_time: 0.0040  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:06 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 159  total_loss: 1.92  loss_cls: 0.5445  loss_box_reg: 0.6585  loss_mask: 0.6266  loss_rpn_cls: 0.02728  loss_rpn_loc: 0.03474  time: 0.1930  data_time: 0.0040  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:10 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 179  total_loss: 1.814  loss_cls: 0.4884  loss_box_reg: 0.6259  loss_mask: 0.6115  loss_rpn_cls: 0.03595  loss_rpn_loc: 0.04198  time: 0.1930  data_time: 0.0042  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:14 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 199  total_loss: 1.812  loss_cls: 0.4794  loss_box_reg: 0.7682  loss_mask: 0.5932  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.02918  time: 0.1935  data_time: 0.0042  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:17 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 219  total_loss: 1.61  loss_cls: 0.394  loss_box_reg: 0.6247  loss_mask: 0.5225  loss_rpn_cls: 0.02135  loss_rpn_loc: 0.0255  time: 0.1933  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:21 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 239  total_loss: 1.533  loss_cls: 0.3965  loss_box_reg: 0.6283  loss_mask: 0.4904  loss_rpn_cls: 0.01737  loss_rpn_loc: 0.02721  time: 0.1934  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:25 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 259  total_loss: 1.466  loss_cls: 0.3586  loss_box_reg: 0.5564  loss_mask: 0.4793  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.02546  time: 0.1934  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:29 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 279  total_loss: 1.52  loss_cls: 0.3303  loss_box_reg: 0.5817  loss_mask: 0.4422  loss_rpn_cls: 0.02296  loss_rpn_loc: 0.02897  time: 0.1935  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:33 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 299  total_loss: 1.389  loss_cls: 0.2487  loss_box_reg: 0.5969  loss_mask: 0.3732  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.02681  time: 0.1933  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:37 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 319  total_loss: 1.459  loss_cls: 0.3296  loss_box_reg: 0.7014  loss_mask: 0.4009  loss_rpn_cls: 0.01925  loss_rpn_loc: 0.03909  time: 0.1934  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:41 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 339  total_loss: 1.361  loss_cls: 0.2907  loss_box_reg: 0.6055  loss_mask: 0.3557  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01687  time: 0.1934  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:45 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 359  total_loss: 1.292  loss_cls: 0.2745  loss_box_reg: 0.5732  loss_mask: 0.3585  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.02857  time: 0.1937  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:49 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 1.121  loss_cls: 0.2161  loss_box_reg: 0.5309  loss_mask: 0.3304  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.02614  time: 0.1935  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:52 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 399  total_loss: 1.058  loss_cls: 0.1792  loss_box_reg: 0.5295  loss_mask: 0.2901  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.02578  time: 0.1936  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:38:56 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 419  total_loss: 1.166  loss_cls: 0.1927  loss_box_reg: 0.5056  loss_mask: 0.271  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.02405  time: 0.1936  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:00 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 439  total_loss: 1.148  loss_cls: 0.2422  loss_box_reg: 0.5539  loss_mask: 0.3051  loss_rpn_cls: 0.009135  loss_rpn_loc: 0.02202  time: 0.1937  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:04 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 459  total_loss: 1.142  loss_cls: 0.1968  loss_box_reg: 0.5274  loss_mask: 0.3119  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.02778  time: 0.1940  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:08 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 0.8085  loss_cls: 0.1245  loss_box_reg: 0.4628  loss_mask: 0.2478  loss_rpn_cls: 0.004029  loss_rpn_loc: 0.01673  time: 0.1940  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:12 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.063  loss_cls: 0.1833  loss_box_reg: 0.4774  loss_mask: 0.2962  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.02768  time: 0.1940  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:16 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 0.9914  loss_cls: 0.1684  loss_box_reg: 0.4903  loss_mask: 0.2649  loss_rpn_cls: 0.009914  loss_rpn_loc: 0.01925  time: 0.1943  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:20 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 1.047  loss_cls: 0.1559  loss_box_reg: 0.4547  loss_mask: 0.2678  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.02817  time: 0.1943  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:24 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 0.9568  loss_cls: 0.1614  loss_box_reg: 0.4731  loss_mask: 0.2741  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.02434  time: 0.1944  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:28 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 0.7932  loss_cls: 0.1338  loss_box_reg: 0.3906  loss_mask: 0.226  loss_rpn_cls: 0.008117  loss_rpn_loc: 0.0228  time: 0.1946  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:32 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 599  total_loss: 0.8986  loss_cls: 0.1681  loss_box_reg: 0.4035  loss_mask: 0.2647  loss_rpn_cls: 0.00882  loss_rpn_loc: 0.01711  time: 0.1946  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:36 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.874  loss_cls: 0.1409  loss_box_reg: 0.4254  loss_mask: 0.2409  loss_rpn_cls: 0.008272  loss_rpn_loc: 0.02113  time: 0.1947  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:40 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.9458  loss_cls: 0.1707  loss_box_reg: 0.4154  loss_mask: 0.2746  loss_rpn_cls: 0.009  loss_rpn_loc: 0.02478  time: 0.1947  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:44 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.687  loss_cls: 0.099  loss_box_reg: 0.3001  loss_mask: 0.2112  loss_rpn_cls: 0.009505  loss_rpn_loc: 0.01614  time: 0.1947  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:48 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.7499  loss_cls: 0.1491  loss_box_reg: 0.3379  loss_mask: 0.2379  loss_rpn_cls: 0.004982  loss_rpn_loc: 0.01509  time: 0.1948  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:52 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.8846  loss_cls: 0.1501  loss_box_reg: 0.4138  loss_mask: 0.2346  loss_rpn_cls: 0.005576  loss_rpn_loc: 0.02464  time: 0.1949  data_time: 0.0046  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:39:56 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.7121  loss_cls: 0.1179  loss_box_reg: 0.3348  loss_mask: 0.2224  loss_rpn_cls: 0.006224  loss_rpn_loc: 0.01831  time: 0.1950  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:40:00 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.7354  loss_cls: 0.1294  loss_box_reg: 0.3077  loss_mask: 0.2267  loss_rpn_cls: 0.008653  loss_rpn_loc: 0.01683  time: 0.1951  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:40:04 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.7543  loss_cls: 0.1375  loss_box_reg: 0.329  loss_mask: 0.217  loss_rpn_cls: 0.007301  loss_rpn_loc: 0.02018  time: 0.1952  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:40:07 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.7579  loss_cls: 0.1265  loss_box_reg: 0.3398  loss_mask: 0.2284  loss_rpn_cls: 0.006621  loss_rpn_loc: 0.01924  time: 0.1952  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:40:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.6969  loss_cls: 0.1122  loss_box_reg: 0.3229  loss_mask: 0.2074  loss_rpn_cls: 0.003426  loss_rpn_loc: 0.01523  time: 0.1953  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:40:12 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:35 (0.1953 s / it)\n",
      "\u001b[32m[10/21 11:40:12 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='ZGQ85MA_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:40:12 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:40:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:40:12 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:40:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:40:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0593 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.718308 (0.087687 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.060529 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/ZGQ85MA0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.517\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 37.318 | 68.955 | 36.667 | 40.989 | 39.625 | 44.482 |\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 31.893 | cushion    | 30.443 | door       | 24.719 |\n",
      "| indoor-plant | 59.857 | sofa       | 66.037 | table      | 10.960 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.512\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.643\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.855 | 51.199 | 11.201 | 19.072 | 17.398 | 47.435 |\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 19.929 | cushion    | 35.047 | door       | 23.805 |\n",
      "| indoor-plant | 11.485 | sofa       | 28.864 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='ZGQ85MA0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:40:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:40:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:40:16 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:40:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:40:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 20/355. 0.0633 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 11:40:24 d2.evaluation.evaluator]: \u001b[0mInference done 73/355. 0.0603 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 11:40:29 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.0591 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:40:34 d2.evaluation.evaluator]: \u001b[0mInference done 204/355. 0.0588 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 11:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.0593 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 297/355. 0.0595 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 11:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 343/355. 0.0597 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.720631 (0.096345 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059949 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/ZGQ85MA0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.325\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.455 | 34.392 | 8.728  | 8.173 | 17.090 | 10.996 |\n",
      "\u001b[32m[10/21 11:40:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.907 | cushion    | 21.828 | door       | 1.253 |\n",
      "| indoor-plant | 22.209 | sofa       | 28.015 | table      | 0.517 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:40:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:40:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 11:40:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:40:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.266\n",
      "\u001b[32m[10/21 11:40:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.506 | 31.486 | 12.127 | 8.031 | 19.475 | 13.112 |\n",
      "\u001b[32m[10/21 11:40:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.048 | cushion    | 31.788 | door       | 0.422 |\n",
      "| indoor-plant | 15.444 | sofa       | 34.336 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='ZGQ85MA1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:40:52 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:40:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:40:52 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:40:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:40:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0630 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 11:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 72/355. 0.0597 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.0593 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 11:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 205/355. 0.0591 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 256/355. 0.0595 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 310/355. 0.0596 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 11:41:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:30.235047 (0.086386 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:41:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059723 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:41:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:41:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/ZGQ85MA0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:41:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.447 | 35.228 | 10.534 | 7.455 | 18.789 | 11.788 |\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.530 | cushion    | 22.416 | door       | 1.310 |\n",
      "| indoor-plant | 23.010 | sofa       | 29.828 | table      | 0.590 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 11:41:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:41:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      "\u001b[32m[10/21 11:41:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.351 | 32.312 | 13.596 | 6.462 | 20.844 | 12.922 |\n",
      "\u001b[32m[10/21 11:41:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.370 | cushion    | 33.233 | door       | 0.787 |\n",
      "| indoor-plant | 16.254 | sofa       | 35.463 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='ZGQ85MA2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:41:25 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:41:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:41:25 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:41:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:41:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0648 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 11:41:31 d2.evaluation.evaluator]: \u001b[0mInference done 67/355. 0.0603 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 11:41:36 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.0592 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 11:41:41 d2.evaluation.evaluator]: \u001b[0mInference done 197/355. 0.0590 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 246/355. 0.0594 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:41:51 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.0599 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 11:41:56 d2.evaluation.evaluator]: \u001b[0mInference done 339/355. 0.0600 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:41:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.065681 (0.094473 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:41:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060205 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/ZGQ85MA0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.574 | 33.532 | 9.761  | 6.929 | 16.714 | 14.595 |\n",
      "\u001b[32m[10/21 11:41:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.435 | cushion    | 19.683 | door       | 1.320 |\n",
      "| indoor-plant | 23.384 | sofa       | 30.004 | table      | 0.621 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:42:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:42:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "\u001b[32m[10/21 11:42:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:42:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
      "\u001b[32m[10/21 11:42:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.408 | 31.139 | 12.527 | 5.680 | 19.158 | 15.324 |\n",
      "\u001b[32m[10/21 11:42:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.447 | cushion    | 29.320 | door       | 0.785 |\n",
      "| indoor-plant | 16.368 | sofa       | 34.526 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [34.392415064919916, 35.228071573406794, 33.5321869539675]}, 'segm': {'AP50': [31.486181112777885, 32.312261798042, 31.13898923382379]}}\n",
      "dataset_name KCVH06R\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json', name='KCVH06R_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/KCVH06R0\n",
      "output_aug/500/KCVH06R0\n",
      "\u001b[32m[10/21 11:42:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:42:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "219 219\n",
      "\u001b[32m[10/21 11:42:01 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 11:42:01 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 55 images left.\n",
      "\u001b[32m[10/21 11:42:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:42:01 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:42:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:42:01 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:42:01 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:42:06 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 19  total_loss: 3.536  loss_cls: 1.929  loss_box_reg: 0.6501  loss_mask: 0.6905  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.04662  time: 0.1937  data_time: 0.0176  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:09 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 39  total_loss: 2.166  loss_cls: 0.7134  loss_box_reg: 0.6192  loss_mask: 0.679  loss_rpn_cls: 0.07364  loss_rpn_loc: 0.0334  time: 0.1933  data_time: 0.0043  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:13 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 59  total_loss: 2.027  loss_cls: 0.5678  loss_box_reg: 0.7239  loss_mask: 0.629  loss_rpn_cls: 0.03134  loss_rpn_loc: 0.03357  time: 0.1943  data_time: 0.0043  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:17 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 79  total_loss: 1.729  loss_cls: 0.42  loss_box_reg: 0.5971  loss_mask: 0.5763  loss_rpn_cls: 0.02507  loss_rpn_loc: 0.03756  time: 0.1925  data_time: 0.0039  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:21 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 99  total_loss: 1.334  loss_cls: 0.2542  loss_box_reg: 0.6499  loss_mask: 0.4546  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.02595  time: 0.1925  data_time: 0.0042  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:25 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 119  total_loss: 1.166  loss_cls: 0.1987  loss_box_reg: 0.5459  loss_mask: 0.3521  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.02804  time: 0.1929  data_time: 0.0041  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:29 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 1.284  loss_cls: 0.261  loss_box_reg: 0.6346  loss_mask: 0.3333  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.03395  time: 0.1931  data_time: 0.0041  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:33 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 159  total_loss: 0.8518  loss_cls: 0.1497  loss_box_reg: 0.4099  loss_mask: 0.2493  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.01783  time: 0.1932  data_time: 0.0041  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:37 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 179  total_loss: 1.07  loss_cls: 0.1718  loss_box_reg: 0.5024  loss_mask: 0.3242  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.03305  time: 0.1937  data_time: 0.0042  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:41 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 0.9439  loss_cls: 0.168  loss_box_reg: 0.4547  loss_mask: 0.2677  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.02299  time: 0.1942  data_time: 0.0043  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:45 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 0.8635  loss_cls: 0.1506  loss_box_reg: 0.3625  loss_mask: 0.2368  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.03536  time: 0.1944  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:48 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 0.8035  loss_cls: 0.123  loss_box_reg: 0.3564  loss_mask: 0.2385  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.02396  time: 0.1944  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:52 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 0.7738  loss_cls: 0.1523  loss_box_reg: 0.352  loss_mask: 0.2486  loss_rpn_cls: 0.009589  loss_rpn_loc: 0.02291  time: 0.1947  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:42:56 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 0.673  loss_cls: 0.105  loss_box_reg: 0.3072  loss_mask: 0.2035  loss_rpn_cls: 0.006348  loss_rpn_loc: 0.01475  time: 0.1947  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:00 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 299  total_loss: 0.5702  loss_cls: 0.0884  loss_box_reg: 0.2645  loss_mask: 0.1745  loss_rpn_cls: 0.006602  loss_rpn_loc: 0.01464  time: 0.1948  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:04 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 319  total_loss: 0.5966  loss_cls: 0.09751  loss_box_reg: 0.2465  loss_mask: 0.1851  loss_rpn_cls: 0.007108  loss_rpn_loc: 0.02615  time: 0.1949  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:08 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.589  loss_cls: 0.107  loss_box_reg: 0.2397  loss_mask: 0.1882  loss_rpn_cls: 0.003252  loss_rpn_loc: 0.02677  time: 0.1950  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:12 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.5473  loss_cls: 0.08592  loss_box_reg: 0.2254  loss_mask: 0.1938  loss_rpn_cls: 0.005056  loss_rpn_loc: 0.0322  time: 0.1948  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:16 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.6119  loss_cls: 0.09023  loss_box_reg: 0.2443  loss_mask: 0.1745  loss_rpn_cls: 0.00761  loss_rpn_loc: 0.0435  time: 0.1952  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:20 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.5425  loss_cls: 0.07878  loss_box_reg: 0.251  loss_mask: 0.1455  loss_rpn_cls: 0.003467  loss_rpn_loc: 0.01509  time: 0.1953  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:24 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.5536  loss_cls: 0.07505  loss_box_reg: 0.245  loss_mask: 0.1893  loss_rpn_cls: 0.006897  loss_rpn_loc: 0.02025  time: 0.1956  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:28 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.5635  loss_cls: 0.07584  loss_box_reg: 0.2774  loss_mask: 0.1675  loss_rpn_cls: 0.007193  loss_rpn_loc: 0.02006  time: 0.1955  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:32 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.4509  loss_cls: 0.07847  loss_box_reg: 0.2206  loss_mask: 0.1483  loss_rpn_cls: 0.004187  loss_rpn_loc: 0.01335  time: 0.1956  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:36 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.4915  loss_cls: 0.06916  loss_box_reg: 0.1997  loss_mask: 0.1708  loss_rpn_cls: 0.007209  loss_rpn_loc: 0.02827  time: 0.1956  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:41 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.503  loss_cls: 0.06904  loss_box_reg: 0.209  loss_mask: 0.1495  loss_rpn_cls: 0.003946  loss_rpn_loc: 0.0258  time: 0.1956  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:43:41 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:37 (0.1956 s / it)\n",
      "\u001b[32m[10/21 11:43:41 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='KCVH06R_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:43:41 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:43:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:43:41 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:43:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:43:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:43:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0565 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:43:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.220502 (0.071629 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:43:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.056759 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:43:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:43:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KCVH06R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:43:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:43:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.388\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 37.250 | 61.040 | 38.772 | 43.336 | 34.250 | 34.963 |\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 27.173 | cushion    | 51.017 | door       | 15.754 |\n",
      "| indoor-plant | 51.634 | sofa       | 57.096 | table      | 20.825 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.417\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.556\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.503 | 41.673 | 18.018 | 20.330 | 26.009 | 39.422 |\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 21.002 | cushion    | 41.923 | door       | 20.780 |\n",
      "| indoor-plant | 16.460 | sofa       | 34.851 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='KCVH06R0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:43:44 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:43:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:43:44 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:43:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:43:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:43:47 d2.evaluation.evaluator]: \u001b[0mInference done 34/355. 0.0587 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 11:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 103/355. 0.0584 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 170/355. 0.0581 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 233/355. 0.0582 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.0582 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 349/355. 0.0585 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.171048 (0.080489 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058523 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KCVH06R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.403 | 33.537 | 18.412 | 7.889 | 17.842 | 17.193 |\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.103  | cushion    | 22.875 | door       | 1.466 |\n",
      "| indoor-plant | 30.611 | sofa       | 47.202 | table      | 0.160 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:44:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:44:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 11:44:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:44:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.232\n",
      "\u001b[32m[10/21 11:44:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.512 | 34.111 | 19.408 | 8.516 | 17.860 | 17.890 |\n",
      "\u001b[32m[10/21 11:44:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.502  | cushion    | 30.963 | door       | 1.664 |\n",
      "| indoor-plant | 19.396 | sofa       | 49.548 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='KCVH06R1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:44:14 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:44:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:44:14 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:44:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:44:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 35/355. 0.0623 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 11:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0595 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.0589 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:44:32 d2.evaluation.evaluator]: \u001b[0mInference done 239/355. 0.0589 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:44:37 d2.evaluation.evaluator]: \u001b[0mInference done 302/355. 0.0588 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:44:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.862196 (0.076749 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:44:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058885 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KCVH06R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:44:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.673 | 33.511 | 19.405 | 6.683 | 19.282 | 15.168 |\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.208  | cushion    | 24.276 | door       | 1.281 |\n",
      "| indoor-plant | 31.060 | sofa       | 45.916 | table      | 0.295 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 11:44:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:44:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      "\u001b[32m[10/21 11:44:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.407 | 34.276 | 18.801 | 7.914 | 19.265 | 15.837 |\n",
      "\u001b[32m[10/21 11:44:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.865  | cushion    | 31.194 | door       | 1.366 |\n",
      "| indoor-plant | 19.622 | sofa       | 48.394 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='KCVH06R2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:44:43 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:44:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:44:43 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:44:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:44:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0600 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 11:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 76/355. 0.0587 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 11:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 145/355. 0.0584 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 11:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.0585 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 273/355. 0.0586 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 331/355. 0.0587 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:45:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.916426 (0.079761 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:45:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058719 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:45:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:45:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KCVH06R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:45:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:45:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.522 | 33.469 | 19.114 | 6.755 | 17.817 | 17.811 |\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.433  | cushion    | 22.207 | door       | 1.357 |\n",
      "| indoor-plant | 32.393 | sofa       | 46.408 | table      | 0.334 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.411 | 33.907 | 19.017 | 7.551 | 17.949 | 18.715 |\n",
      "\u001b[32m[10/21 11:45:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.536  | cushion    | 28.957 | door       | 1.879 |\n",
      "| indoor-plant | 20.475 | sofa       | 49.616 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [33.537495572374496, 33.51104919219399, 33.46911723630859]}, 'segm': {'AP50': [34.110694067351446, 34.27630951844971, 33.907181142828065]}}\n",
      "dataset_name KFJ1D5Q\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json', name='KFJ1D5Q_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/KFJ1D5Q0\n",
      "output_aug/800/KFJ1D5Q0\n",
      "\u001b[32m[10/21 11:45:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:45:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "219 219\n",
      "\u001b[32m[10/21 11:45:13 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 11:45:13 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 55 images left.\n",
      "\u001b[32m[10/21 11:45:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:45:13 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:45:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:45:13 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:45:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:45:18 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 19  total_loss: 3.272  loss_cls: 1.791  loss_box_reg: 0.5627  loss_mask: 0.6919  loss_rpn_cls: 0.1861  loss_rpn_loc: 0.0305  time: 0.1909  data_time: 0.0178  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:22 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 39  total_loss: 2.133  loss_cls: 0.6527  loss_box_reg: 0.6231  loss_mask: 0.6762  loss_rpn_cls: 0.04583  loss_rpn_loc: 0.03577  time: 0.1921  data_time: 0.0043  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:25 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 59  total_loss: 1.941  loss_cls: 0.5236  loss_box_reg: 0.6618  loss_mask: 0.6442  loss_rpn_cls: 0.05387  loss_rpn_loc: 0.03686  time: 0.1932  data_time: 0.0043  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:29 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 79  total_loss: 1.723  loss_cls: 0.3897  loss_box_reg: 0.7487  loss_mask: 0.5837  loss_rpn_cls: 0.02122  loss_rpn_loc: 0.03245  time: 0.1926  data_time: 0.0041  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:33 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 99  total_loss: 1.584  loss_cls: 0.3517  loss_box_reg: 0.6114  loss_mask: 0.5076  loss_rpn_cls: 0.0214  loss_rpn_loc: 0.04278  time: 0.1922  data_time: 0.0041  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:37 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 119  total_loss: 1.435  loss_cls: 0.3019  loss_box_reg: 0.6559  loss_mask: 0.4205  loss_rpn_cls: 0.02779  loss_rpn_loc: 0.03266  time: 0.1929  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:41 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 1.163  loss_cls: 0.1958  loss_box_reg: 0.5528  loss_mask: 0.3272  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.03188  time: 0.1936  data_time: 0.0041  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:45 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 159  total_loss: 1.145  loss_cls: 0.2142  loss_box_reg: 0.5587  loss_mask: 0.3247  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.02752  time: 0.1939  data_time: 0.0042  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:49 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 179  total_loss: 0.9668  loss_cls: 0.1748  loss_box_reg: 0.4856  loss_mask: 0.2648  loss_rpn_cls: 0.008864  loss_rpn_loc: 0.02094  time: 0.1944  data_time: 0.0042  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:53 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 199  total_loss: 0.8729  loss_cls: 0.1258  loss_box_reg: 0.4404  loss_mask: 0.2362  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.02081  time: 0.1947  data_time: 0.0043  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:45:57 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 219  total_loss: 0.8487  loss_cls: 0.1483  loss_box_reg: 0.4147  loss_mask: 0.2374  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.02762  time: 0.1949  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:01 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 239  total_loss: 0.8103  loss_cls: 0.1368  loss_box_reg: 0.3838  loss_mask: 0.2369  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.02528  time: 0.1949  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:05 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 259  total_loss: 0.645  loss_cls: 0.09583  loss_box_reg: 0.2799  loss_mask: 0.208  loss_rpn_cls: 0.00725  loss_rpn_loc: 0.02916  time: 0.1949  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:09 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 279  total_loss: 0.7126  loss_cls: 0.102  loss_box_reg: 0.304  loss_mask: 0.1878  loss_rpn_cls: 0.007472  loss_rpn_loc: 0.02784  time: 0.1951  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:12 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 299  total_loss: 0.6058  loss_cls: 0.07417  loss_box_reg: 0.2762  loss_mask: 0.1954  loss_rpn_cls: 0.005363  loss_rpn_loc: 0.02015  time: 0.1948  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:16 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 319  total_loss: 0.6226  loss_cls: 0.0995  loss_box_reg: 0.2786  loss_mask: 0.1953  loss_rpn_cls: 0.008057  loss_rpn_loc: 0.02467  time: 0.1950  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:20 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 339  total_loss: 0.5787  loss_cls: 0.09672  loss_box_reg: 0.261  loss_mask: 0.1784  loss_rpn_cls: 0.004123  loss_rpn_loc: 0.01829  time: 0.1949  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:24 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 359  total_loss: 0.6325  loss_cls: 0.09293  loss_box_reg: 0.2841  loss_mask: 0.1946  loss_rpn_cls: 0.004198  loss_rpn_loc: 0.01473  time: 0.1950  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:28 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 0.5237  loss_cls: 0.07462  loss_box_reg: 0.2555  loss_mask: 0.1791  loss_rpn_cls: 0.00507  loss_rpn_loc: 0.01699  time: 0.1949  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:32 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 0.6042  loss_cls: 0.07556  loss_box_reg: 0.2866  loss_mask: 0.1771  loss_rpn_cls: 0.007664  loss_rpn_loc: 0.02109  time: 0.1951  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:36 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 419  total_loss: 0.5994  loss_cls: 0.09447  loss_box_reg: 0.281  loss_mask: 0.1805  loss_rpn_cls: 0.005776  loss_rpn_loc: 0.01975  time: 0.1952  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:40 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 439  total_loss: 0.488  loss_cls: 0.07787  loss_box_reg: 0.2089  loss_mask: 0.1767  loss_rpn_cls: 0.001604  loss_rpn_loc: 0.01402  time: 0.1950  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:44 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 0.4988  loss_cls: 0.07534  loss_box_reg: 0.2014  loss_mask: 0.1621  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.01522  time: 0.1951  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:48 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 0.4812  loss_cls: 0.06214  loss_box_reg: 0.2159  loss_mask: 0.159  loss_rpn_cls: 0.006247  loss_rpn_loc: 0.01559  time: 0.1951  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:52 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 0.4995  loss_cls: 0.07834  loss_box_reg: 0.2169  loss_mask: 0.1474  loss_rpn_cls: 0.001762  loss_rpn_loc: 0.01686  time: 0.1951  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:46:56 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 0.4213  loss_cls: 0.05688  loss_box_reg: 0.1903  loss_mask: 0.1309  loss_rpn_cls: 0.002141  loss_rpn_loc: 0.01491  time: 0.1952  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:00 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 0.4764  loss_cls: 0.06558  loss_box_reg: 0.2103  loss_mask: 0.1532  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.01863  time: 0.1953  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:04 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 0.409  loss_cls: 0.0593  loss_box_reg: 0.1842  loss_mask: 0.1481  loss_rpn_cls: 0.00563  loss_rpn_loc: 0.0146  time: 0.1953  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:07 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 0.4869  loss_cls: 0.06107  loss_box_reg: 0.1798  loss_mask: 0.1627  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.03457  time: 0.1953  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:11 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.4426  loss_cls: 0.06249  loss_box_reg: 0.1972  loss_mask: 0.1405  loss_rpn_cls: 0.00613  loss_rpn_loc: 0.02188  time: 0.1953  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:15 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.3969  loss_cls: 0.05482  loss_box_reg: 0.178  loss_mask: 0.1578  loss_rpn_cls: 0.001993  loss_rpn_loc: 0.01567  time: 0.1954  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:19 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.4404  loss_cls: 0.06935  loss_box_reg: 0.2003  loss_mask: 0.1369  loss_rpn_cls: 0.002064  loss_rpn_loc: 0.01404  time: 0.1954  data_time: 0.0044  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:23 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.4391  loss_cls: 0.06374  loss_box_reg: 0.2018  loss_mask: 0.139  loss_rpn_cls: 0.003425  loss_rpn_loc: 0.02059  time: 0.1954  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:27 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.3566  loss_cls: 0.04648  loss_box_reg: 0.1556  loss_mask: 0.1379  loss_rpn_cls: 0.002693  loss_rpn_loc: 0.01371  time: 0.1954  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:31 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.3493  loss_cls: 0.05777  loss_box_reg: 0.1626  loss_mask: 0.1311  loss_rpn_cls: 0.003942  loss_rpn_loc: 0.01784  time: 0.1954  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:35 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.4537  loss_cls: 0.06721  loss_box_reg: 0.1792  loss_mask: 0.1506  loss_rpn_cls: 0.003217  loss_rpn_loc: 0.01853  time: 0.1954  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:39 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.3464  loss_cls: 0.05203  loss_box_reg: 0.1298  loss_mask: 0.118  loss_rpn_cls: 0.002133  loss_rpn_loc: 0.0109  time: 0.1954  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:43 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.411  loss_cls: 0.05839  loss_box_reg: 0.1791  loss_mask: 0.1383  loss_rpn_cls: 0.002661  loss_rpn_loc: 0.02045  time: 0.1954  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:47 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.3806  loss_cls: 0.0489  loss_box_reg: 0.1687  loss_mask: 0.1233  loss_rpn_cls: 0.002078  loss_rpn_loc: 0.01153  time: 0.1954  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4765  loss_cls: 0.06257  loss_box_reg: 0.1995  loss_mask: 0.1501  loss_rpn_cls: 0.005335  loss_rpn_loc: 0.01897  time: 0.1954  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:47:52 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:35 (0.1955 s / it)\n",
      "\u001b[32m[10/21 11:47:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='KFJ1D5Q_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:47:52 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:47:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:47:52 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:47:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:47:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0586 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.164836 (0.069833 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057607 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/KFJ1D5Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.557\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 31.502 | 55.709 | 35.432 | 39.435 | 31.583 | 8.553 |\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.680 | cushion    | 46.340 | door       | 20.394 |\n",
      "| indoor-plant | 49.530 | sofa       | 29.397 | table      | 17.671 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 18.980 | 37.068 | 15.291 | 17.556 | 24.880 | 8.715 |\n",
      "\u001b[32m[10/21 11:47:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 14.984 | cushion    | 37.734 | door       | 25.743 |\n",
      "| indoor-plant | 17.822 | sofa       | 17.599 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='KFJ1D5Q0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:47:55 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:47:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:47:55 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:47:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:47:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 36/355. 0.0581 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:48:03 d2.evaluation.evaluator]: \u001b[0mInference done 110/355. 0.0578 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 185/355. 0.0578 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.0577 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 319/355. 0.0579 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:48:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.242503 (0.072121 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:48:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057924 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/KFJ1D5Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.081 | 35.489 | 18.250 | 6.651 | 20.581 | 17.489 |\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.943 | cushion    | 23.763 | door       | 1.176 |\n",
      "| indoor-plant | 32.895 | sofa       | 45.384 | table      | 0.323 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.280 | 35.800 | 19.242 | 7.267 | 19.398 | 16.176 |\n",
      "\u001b[32m[10/21 11:48:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.955  | cushion    | 34.260 | door       | 2.035 |\n",
      "| indoor-plant | 19.806 | sofa       | 43.623 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='KFJ1D5Q1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:48:22 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:48:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:48:22 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:48:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:48:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0601 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 11:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.0578 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 156/355. 0.0577 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 227/355. 0.0578 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 291/355. 0.0578 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.535193 (0.072958 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057795 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/KFJ1D5Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.362 | 37.753 | 18.878 | 7.646 | 23.180 | 15.414 |\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.638 | cushion    | 25.979 | door       | 1.700 |\n",
      "| indoor-plant | 31.989 | sofa       | 48.616 | table      | 0.252 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:48:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:48:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 11:48:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:48:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      "\u001b[32m[10/21 11:48:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.788 | 38.083 | 20.769 | 8.085 | 22.679 | 15.806 |\n",
      "\u001b[32m[10/21 11:48:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.343 | cushion    | 35.941 | door       | 2.833 |\n",
      "| indoor-plant | 20.333 | sofa       | 48.276 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='KFJ1D5Q2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:48:49 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:48:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:48:49 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:48:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:48:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0591 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 11:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 82/355. 0.0579 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.0576 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.0575 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.0577 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:49:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.111371 (0.071747 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:49:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057702 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/KFJ1D5Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.370\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.770 | 36.964 | 19.327 | 6.965 | 20.662 | 17.803 |\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.741 | cushion    | 23.848 | door       | 1.553 |\n",
      "| indoor-plant | 34.148 | sofa       | 47.995 | table      | 0.332 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:49:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
      "\u001b[32m[10/21 11:49:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.973 | 37.615 | 19.468 | 8.052 | 19.732 | 16.948 |\n",
      "\u001b[32m[10/21 11:49:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.063 | cushion    | 33.633 | door       | 2.838 |\n",
      "| indoor-plant | 20.958 | sofa       | 46.348 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [35.48908462631204, 37.75342459916949, 36.96398811233704]}, 'segm': {'AP50': [35.799723899709484, 38.0834010168354, 37.61473166289141]}}\n",
      "dataset_name DNTSJFR\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json', name='DNTSJFR_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/DNTSJFR0\n",
      "output_aug/500/DNTSJFR0\n",
      "\u001b[32m[10/21 11:49:17 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:49:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "219 219\n",
      "\u001b[32m[10/21 11:49:17 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 11:49:17 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 55 images left.\n",
      "\u001b[32m[10/21 11:49:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:49:17 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:49:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:49:17 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:49:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:49:21 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 19  total_loss: 3.282  loss_cls: 1.877  loss_box_reg: 0.551  loss_mask: 0.6926  loss_rpn_cls: 0.1345  loss_rpn_loc: 0.03282  time: 0.1920  data_time: 0.0178  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:25 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 39  total_loss: 3.061  loss_cls: 1.574  loss_box_reg: 0.5587  loss_mask: 0.6913  loss_rpn_cls: 0.1664  loss_rpn_loc: 0.03836  time: 0.1929  data_time: 0.0040  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:29 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 59  total_loss: 2.503  loss_cls: 1.061  loss_box_reg: 0.5465  loss_mask: 0.6866  loss_rpn_cls: 0.1417  loss_rpn_loc: 0.03302  time: 0.1920  data_time: 0.0041  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:33 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 79  total_loss: 2.339  loss_cls: 0.7778  loss_box_reg: 0.6725  loss_mask: 0.6804  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.04232  time: 0.1925  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:36 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 99  total_loss: 2.272  loss_cls: 0.7593  loss_box_reg: 0.7456  loss_mask: 0.6739  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.04182  time: 0.1931  data_time: 0.0040  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:40 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 119  total_loss: 1.973  loss_cls: 0.5935  loss_box_reg: 0.5869  loss_mask: 0.6613  loss_rpn_cls: 0.05432  loss_rpn_loc: 0.03288  time: 0.1931  data_time: 0.0043  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:44 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 2.024  loss_cls: 0.5897  loss_box_reg: 0.6476  loss_mask: 0.6501  loss_rpn_cls: 0.02587  loss_rpn_loc: 0.03408  time: 0.1932  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:48 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 159  total_loss: 1.976  loss_cls: 0.5436  loss_box_reg: 0.6447  loss_mask: 0.6453  loss_rpn_cls: 0.02936  loss_rpn_loc: 0.03415  time: 0.1933  data_time: 0.0040  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:52 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 179  total_loss: 1.98  loss_cls: 0.5651  loss_box_reg: 0.724  loss_mask: 0.6  loss_rpn_cls: 0.02814  loss_rpn_loc: 0.03664  time: 0.1936  data_time: 0.0042  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:49:56 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 199  total_loss: 1.771  loss_cls: 0.4698  loss_box_reg: 0.6241  loss_mask: 0.604  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.03596  time: 0.1936  data_time: 0.0043  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:00 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 1.828  loss_cls: 0.4619  loss_box_reg: 0.7008  loss_mask: 0.5613  loss_rpn_cls: 0.02575  loss_rpn_loc: 0.02695  time: 0.1938  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:04 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 1.736  loss_cls: 0.4031  loss_box_reg: 0.624  loss_mask: 0.5831  loss_rpn_cls: 0.02521  loss_rpn_loc: 0.03614  time: 0.1938  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:08 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 1.583  loss_cls: 0.3717  loss_box_reg: 0.5982  loss_mask: 0.4917  loss_rpn_cls: 0.01978  loss_rpn_loc: 0.02773  time: 0.1939  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:12 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 1.508  loss_cls: 0.3174  loss_box_reg: 0.5986  loss_mask: 0.4711  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.03112  time: 0.1941  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:16 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 299  total_loss: 1.585  loss_cls: 0.3278  loss_box_reg: 0.6981  loss_mask: 0.4601  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.03696  time: 0.1943  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:19 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 319  total_loss: 1.51  loss_cls: 0.2671  loss_box_reg: 0.6125  loss_mask: 0.4093  loss_rpn_cls: 0.01636  loss_rpn_loc: 0.02051  time: 0.1943  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:23 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.385  loss_cls: 0.2832  loss_box_reg: 0.6198  loss_mask: 0.4007  loss_rpn_cls: 0.02056  loss_rpn_loc: 0.03475  time: 0.1943  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:27 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.245  loss_cls: 0.2285  loss_box_reg: 0.6064  loss_mask: 0.3772  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.01539  time: 0.1945  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:31 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.369  loss_cls: 0.3156  loss_box_reg: 0.6062  loss_mask: 0.359  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.02197  time: 0.1944  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:35 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.214  loss_cls: 0.2038  loss_box_reg: 0.5848  loss_mask: 0.3276  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.03745  time: 0.1945  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:39 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.273  loss_cls: 0.2829  loss_box_reg: 0.5784  loss_mask: 0.3577  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.02679  time: 0.1944  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:43 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.186  loss_cls: 0.1791  loss_box_reg: 0.5675  loss_mask: 0.3075  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.02534  time: 0.1946  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:47 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.205  loss_cls: 0.1956  loss_box_reg: 0.5573  loss_mask: 0.2877  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.03993  time: 0.1946  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:51 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.205  loss_cls: 0.2148  loss_box_reg: 0.5652  loss_mask: 0.3228  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.03078  time: 0.1948  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:56 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.182  loss_cls: 0.1665  loss_box_reg: 0.569  loss_mask: 0.2912  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.02743  time: 0.1949  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:50:56 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:37 (0.1949 s / it)\n",
      "\u001b[32m[10/21 11:50:56 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='DNTSJFR_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:50:56 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:50:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:50:56 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:50:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:50:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0589 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.968821 (0.095768 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.061700 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/DNTSJFR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:50:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.557\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.580 | 55.665 | 20.829 | 32.979 | 22.225 | 25.178 |\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.061 | cushion    | 40.798 | door       | 19.434 |\n",
      "| indoor-plant | 34.179 | sofa       | 32.610 | table      | 0.396  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 14.217 | 35.885 | 9.648  | 14.842 | 11.356 | 38.886 |\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 16.229 | cushion    | 30.275 | door       | 23.655 |\n",
      "| indoor-plant | 0.000  | sofa       | 15.141 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='DNTSJFR0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:51:00 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:51:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:51:00 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:51:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:51:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0678 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 11:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 63/355. 0.0637 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 11:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 122/355. 0.0616 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 11:51:17 d2.evaluation.evaluator]: \u001b[0mInference done 175/355. 0.0615 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 225/355. 0.0618 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 11:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.0622 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:51:32 d2.evaluation.evaluator]: \u001b[0mInference done 310/355. 0.0626 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.0628 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:51:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.149260 (0.106141 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:51:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.062828 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:51:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:51:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/DNTSJFR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:51:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:51:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:51:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 11:51:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:51:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
      "\u001b[32m[10/21 11:51:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 11.842 | 25.644 | 8.354  | 10.147 | 14.522 | 7.396 |\n",
      "\u001b[32m[10/21 11:51:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.680 | cushion    | 33.110 | door       | 2.531 |\n",
      "| indoor-plant | 13.018 | sofa       | 10.672 | table      | 0.041 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:51:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:51:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/21 11:51:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:51:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
      "\u001b[32m[10/21 11:51:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 10.695 | 19.905 | 10.431 | 9.523 | 14.561 | 8.364 |\n",
      "\u001b[32m[10/21 11:51:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.580 | cushion    | 41.077 | door       | 1.184 |\n",
      "| indoor-plant | 1.208 | sofa       | 12.121 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='DNTSJFR1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:51:40 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:51:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:51:40 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:51:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:51:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:51:43 d2.evaluation.evaluator]: \u001b[0mInference done 16/355. 0.0668 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 11:51:48 d2.evaluation.evaluator]: \u001b[0mInference done 61/355. 0.0631 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 11:51:53 d2.evaluation.evaluator]: \u001b[0mInference done 118/355. 0.0613 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:51:58 d2.evaluation.evaluator]: \u001b[0mInference done 167/355. 0.0612 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 215/355. 0.0614 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.0619 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 11:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.0623 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.0625 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.591971 (0.113120 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.062549 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/DNTSJFR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.736 | 26.250 | 7.767  | 8.120 | 13.653 | 8.572 |\n",
      "\u001b[32m[10/21 11:52:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.919 | cushion    | 32.574 | door       | 2.738 |\n",
      "| indoor-plant | 12.104 | sofa       | 11.015 | table      | 0.067 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:52:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:52:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 11:52:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:52:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
      "\u001b[32m[10/21 11:52:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 10.777 | 20.601 | 10.394 | 7.422 | 14.084 | 9.648 |\n",
      "\u001b[32m[10/21 11:52:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.411 | cushion    | 40.910 | door       | 1.630 |\n",
      "| indoor-plant | 1.271 | sofa       | 12.441 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='DNTSJFR2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:52:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:52:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:52:23 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:52:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:52:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:52:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0681 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 11:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 56/355. 0.0645 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 11:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 113/355. 0.0623 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 11:52:40 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.0614 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.0620 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 11:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 249/355. 0.0624 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 11:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.0627 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 11:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 325/355. 0.0630 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 11:53:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.988312 (0.114252 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:53:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.063512 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:53:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:53:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/DNTSJFR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:53:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:53:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:53:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 11:53:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:53:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      "\u001b[32m[10/21 11:53:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.528 | 25.353 | 7.764  | 7.594 | 13.584 | 9.752 |\n",
      "\u001b[32m[10/21 11:53:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.823 | cushion    | 30.375 | door       | 2.541 |\n",
      "| indoor-plant | 13.971 | sofa       | 11.443 | table      | 0.014 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:53:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:53:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 11:53:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:53:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      "\u001b[32m[10/21 11:53:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 10.493 | 19.856 | 10.210 | 6.939 | 14.215 | 10.311 |\n",
      "\u001b[32m[10/21 11:53:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.110 | cushion    | 38.697 | door       | 1.677 |\n",
      "| indoor-plant | 1.327 | sofa       | 13.148 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [25.644121556244148, 26.250236275497862, 25.352529820229208]}, 'segm': {'AP50': [19.904549276853785, 20.600816814151067, 19.85618110853466]}}\n",
      "dataset_name 0LUQDAU\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json', name='0LUQDAU_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/0LUQDAU0\n",
      "output_aug/800/0LUQDAU0\n",
      "\u001b[32m[10/21 11:53:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:53:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "219 219\n",
      "\u001b[32m[10/21 11:53:07 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 11:53:07 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 55 images left.\n",
      "\u001b[32m[10/21 11:53:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:53:07 d2.data.common]: \u001b[0mSerializing 55 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:53:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:53:07 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:53:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:53:12 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 19  total_loss: 3.437  loss_cls: 1.939  loss_box_reg: 0.6129  loss_mask: 0.693  loss_rpn_cls: 0.1686  loss_rpn_loc: 0.0318  time: 0.1897  data_time: 0.0175  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:15 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 39  total_loss: 3.217  loss_cls: 1.631  loss_box_reg: 0.6024  loss_mask: 0.6918  loss_rpn_cls: 0.1285  loss_rpn_loc: 0.03155  time: 0.1897  data_time: 0.0042  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:19 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 59  total_loss: 2.549  loss_cls: 1.168  loss_box_reg: 0.6068  loss_mask: 0.689  loss_rpn_cls: 0.121  loss_rpn_loc: 0.03763  time: 0.1914  data_time: 0.0043  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:23 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 79  total_loss: 2.261  loss_cls: 0.7971  loss_box_reg: 0.6445  loss_mask: 0.6835  loss_rpn_cls: 0.06799  loss_rpn_loc: 0.04812  time: 0.1918  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:27 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 99  total_loss: 2.076  loss_cls: 0.6712  loss_box_reg: 0.6043  loss_mask: 0.6731  loss_rpn_cls: 0.05942  loss_rpn_loc: 0.03719  time: 0.1913  data_time: 0.0040  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:31 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 119  total_loss: 2.022  loss_cls: 0.6407  loss_box_reg: 0.6568  loss_mask: 0.6656  loss_rpn_cls: 0.03501  loss_rpn_loc: 0.02295  time: 0.1912  data_time: 0.0038  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:35 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 139  total_loss: 2.003  loss_cls: 0.5726  loss_box_reg: 0.6303  loss_mask: 0.6428  loss_rpn_cls: 0.04124  loss_rpn_loc: 0.04077  time: 0.1911  data_time: 0.0040  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:39 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 159  total_loss: 2.108  loss_cls: 0.5646  loss_box_reg: 0.7272  loss_mask: 0.6463  loss_rpn_cls: 0.02363  loss_rpn_loc: 0.03221  time: 0.1917  data_time: 0.0041  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:42 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 179  total_loss: 1.88  loss_cls: 0.4895  loss_box_reg: 0.6563  loss_mask: 0.6196  loss_rpn_cls: 0.03679  loss_rpn_loc: 0.02869  time: 0.1918  data_time: 0.0041  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:46 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 199  total_loss: 1.799  loss_cls: 0.4552  loss_box_reg: 0.5939  loss_mask: 0.5993  loss_rpn_cls: 0.02533  loss_rpn_loc: 0.03262  time: 0.1922  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:50 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 219  total_loss: 1.958  loss_cls: 0.4539  loss_box_reg: 0.7262  loss_mask: 0.5808  loss_rpn_cls: 0.03896  loss_rpn_loc: 0.03525  time: 0.1925  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:54 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 239  total_loss: 1.706  loss_cls: 0.3607  loss_box_reg: 0.6502  loss_mask: 0.522  loss_rpn_cls: 0.03326  loss_rpn_loc: 0.03631  time: 0.1926  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:53:58 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 259  total_loss: 1.468  loss_cls: 0.2963  loss_box_reg: 0.6425  loss_mask: 0.5039  loss_rpn_cls: 0.02235  loss_rpn_loc: 0.0264  time: 0.1927  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:02 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 279  total_loss: 1.64  loss_cls: 0.3752  loss_box_reg: 0.6464  loss_mask: 0.5299  loss_rpn_cls: 0.02038  loss_rpn_loc: 0.0359  time: 0.1930  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:06 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 299  total_loss: 1.573  loss_cls: 0.349  loss_box_reg: 0.6394  loss_mask: 0.4838  loss_rpn_cls: 0.02924  loss_rpn_loc: 0.03536  time: 0.1932  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:10 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 319  total_loss: 1.468  loss_cls: 0.3346  loss_box_reg: 0.6324  loss_mask: 0.4327  loss_rpn_cls: 0.03867  loss_rpn_loc: 0.02868  time: 0.1932  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:14 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 339  total_loss: 1.418  loss_cls: 0.2948  loss_box_reg: 0.6486  loss_mask: 0.3912  loss_rpn_cls: 0.01832  loss_rpn_loc: 0.02997  time: 0.1933  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:18 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 359  total_loss: 1.374  loss_cls: 0.2862  loss_box_reg: 0.6145  loss_mask: 0.3491  loss_rpn_cls: 0.02529  loss_rpn_loc: 0.02994  time: 0.1934  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:22 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 1.392  loss_cls: 0.3123  loss_box_reg: 0.6537  loss_mask: 0.3699  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.02542  time: 0.1936  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:26 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 399  total_loss: 1.323  loss_cls: 0.2869  loss_box_reg: 0.5947  loss_mask: 0.336  loss_rpn_cls: 0.01958  loss_rpn_loc: 0.03077  time: 0.1938  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:29 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 419  total_loss: 1.119  loss_cls: 0.1585  loss_box_reg: 0.5628  loss_mask: 0.3081  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.02074  time: 0.1938  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:33 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 439  total_loss: 1.208  loss_cls: 0.241  loss_box_reg: 0.6021  loss_mask: 0.3224  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.01883  time: 0.1939  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:37 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 459  total_loss: 1.238  loss_cls: 0.2127  loss_box_reg: 0.6045  loss_mask: 0.3224  loss_rpn_cls: 0.02035  loss_rpn_loc: 0.02505  time: 0.1941  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:41 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 479  total_loss: 1.105  loss_cls: 0.196  loss_box_reg: 0.4729  loss_mask: 0.3022  loss_rpn_cls: 0.02565  loss_rpn_loc: 0.0323  time: 0.1942  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:45 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.157  loss_cls: 0.2135  loss_box_reg: 0.555  loss_mask: 0.3078  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.04718  time: 0.1944  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:49 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 1.025  loss_cls: 0.1374  loss_box_reg: 0.4898  loss_mask: 0.2687  loss_rpn_cls: 0.01851  loss_rpn_loc: 0.03031  time: 0.1945  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:53 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 1.123  loss_cls: 0.2139  loss_box_reg: 0.5435  loss_mask: 0.2769  loss_rpn_cls: 0.009593  loss_rpn_loc: 0.02342  time: 0.1946  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:54:57 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 0.938  loss_cls: 0.1799  loss_box_reg: 0.4513  loss_mask: 0.2663  loss_rpn_cls: 0.009726  loss_rpn_loc: 0.0221  time: 0.1947  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:01 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 0.9212  loss_cls: 0.1932  loss_box_reg: 0.3814  loss_mask: 0.2727  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.02587  time: 0.1948  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:05 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 599  total_loss: 0.8871  loss_cls: 0.1773  loss_box_reg: 0.458  loss_mask: 0.2571  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.02448  time: 0.1949  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:09 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.932  loss_cls: 0.1475  loss_box_reg: 0.4528  loss_mask: 0.271  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.0245  time: 0.1950  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:13 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.8256  loss_cls: 0.1334  loss_box_reg: 0.4249  loss_mask: 0.2433  loss_rpn_cls: 0.007906  loss_rpn_loc: 0.01385  time: 0.1951  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:17 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.8933  loss_cls: 0.177  loss_box_reg: 0.4789  loss_mask: 0.246  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.01838  time: 0.1953  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:21 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.8727  loss_cls: 0.143  loss_box_reg: 0.4247  loss_mask: 0.2646  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.02172  time: 0.1953  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:25 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.9067  loss_cls: 0.1686  loss_box_reg: 0.4346  loss_mask: 0.2583  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.01633  time: 0.1953  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:29 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.823  loss_cls: 0.1483  loss_box_reg: 0.3794  loss_mask: 0.2303  loss_rpn_cls: 0.006892  loss_rpn_loc: 0.01931  time: 0.1953  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:33 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.8656  loss_cls: 0.162  loss_box_reg: 0.4338  loss_mask: 0.2495  loss_rpn_cls: 0.006584  loss_rpn_loc: 0.0218  time: 0.1953  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:37 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.7833  loss_cls: 0.1404  loss_box_reg: 0.3478  loss_mask: 0.2493  loss_rpn_cls: 0.006623  loss_rpn_loc: 0.01696  time: 0.1954  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:41 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.7741  loss_cls: 0.09828  loss_box_reg: 0.3177  loss_mask: 0.2162  loss_rpn_cls: 0.006855  loss_rpn_loc: 0.01717  time: 0.1955  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:46 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.7973  loss_cls: 0.1487  loss_box_reg: 0.3378  loss_mask: 0.251  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.02825  time: 0.1956  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:55:46 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:36 (0.1956 s / it)\n",
      "\u001b[32m[10/21 11:55:46 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='0LUQDAU_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:55:46 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:55:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:55:46 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:55:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:55:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:55:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0573 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.650698 (0.085506 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.060259 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0LUQDAU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.352\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 33.333 | 60.806 | 35.155 | 42.072 | 32.163 | 18.735 |\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.645 | cushion    | 43.962 | door       | 17.015 |\n",
      "| indoor-plant | 51.227 | sofa       | 52.746 | table      | 9.406  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.431\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.624 | 43.061 | 12.830 | 17.687 | 19.095 | 22.740 |\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 12.983 | cushion    | 38.681 | door       | 15.800 |\n",
      "| indoor-plant | 12.277 | sofa       | 26.005 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='0LUQDAU0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:55:49 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:55:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:55:49 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:55:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:55:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.0623 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 11:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.0595 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 11:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 147/355. 0.0591 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 11:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 210/355. 0.0590 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 11:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.0599 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 11:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 309/355. 0.0601 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:31.655587 (0.090445 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060226 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0LUQDAU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.102 | 32.686 | 7.545  | 7.490 | 16.605 | 11.342 |\n",
      "\u001b[32m[10/21 11:56:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.744 | cushion    | 25.400 | door       | 2.613 |\n",
      "| indoor-plant | 17.998 | sofa       | 24.822 | table      | 0.035 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:56:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:56:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 11:56:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:56:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n",
      "\u001b[32m[10/21 11:56:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.760 | 31.834 | 13.091 | 8.890 | 20.050 | 13.553 |\n",
      "\u001b[32m[10/21 11:56:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.804  | cushion    | 39.793 | door       | 1.526 |\n",
      "| indoor-plant | 13.019 | sofa       | 30.419 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='0LUQDAU1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:56:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:56:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:56:23 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:56:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:56:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0622 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 11:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 66/355. 0.0599 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 11:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.0588 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 11:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 192/355. 0.0588 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 235/355. 0.0596 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 11:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 286/355. 0.0597 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.0598 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.206786 (0.094877 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:56:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059913 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:56:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:56:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0LUQDAU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 14.158 | 32.885 | 7.276  | 7.321 | 16.937 | 9.807 |\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.532 | cushion    | 26.398 | door       | 2.950 |\n",
      "| indoor-plant | 17.457 | sofa       | 23.592 | table      | 0.022 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:56:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:56:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 11:56:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:56:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
      "\u001b[32m[10/21 11:56:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.717 | 31.617 | 12.282 | 8.340 | 20.569 | 12.129 |\n",
      "\u001b[32m[10/21 11:56:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.936  | cushion    | 40.220 | door       | 2.195 |\n",
      "| indoor-plant | 13.081 | sofa       | 28.872 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='0LUQDAU2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 11:56:59 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 11:56:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:56:59 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:56:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 11:56:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0640 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 11:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 68/355. 0.0603 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 11:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 133/355. 0.0597 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 11:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.0597 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 11:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 248/355. 0.0600 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 11:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 298/355. 0.0603 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 354/355. 0.0603 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:31.208916 (0.089168 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060347 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0LUQDAU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:57:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.082 | 31.948 | 7.757  | 6.367 | 16.281 | 11.914 |\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.483 | cushion    | 24.284 | door       | 2.777 |\n",
      "| indoor-plant | 18.977 | sofa       | 24.946 | table      | 0.028 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.529 | 31.289 | 13.251 | 7.577 | 20.104 | 14.119 |\n",
      "\u001b[32m[10/21 11:57:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.211 | cushion    | 37.806 | door       | 2.045 |\n",
      "| indoor-plant | 13.972 | sofa       | 29.138 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [32.6856762256778, 32.885129274612765, 31.947940747812897]}, 'segm': {'AP50': [31.834495852295213, 31.6165498431007, 31.288659002006742]}}\n",
      "dataset_name ZXLFOM5\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json', name='ZXLFOM5_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/ZXLFOM50\n",
      "output_aug/500/ZXLFOM50\n",
      "\u001b[32m[10/21 11:57:33 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 11:57:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "282 282\n",
      "\u001b[32m[10/21 11:57:33 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 11:57:33 d2.data.build]: \u001b[0mRemoved 7 images with no usable annotations. 71 images left.\n",
      "\u001b[32m[10/21 11:57:33 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 42           |  cushion   | 78           |    door    | 73           |\n",
      "| indoor-plant | 17           |    sofa    | 27           |   table    | 45           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 282          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 11:57:33 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 11:57:33 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:57:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.12 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 11:57:33 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 11:57:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 11:57:38 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.52  loss_cls: 1.859  loss_box_reg: 0.6169  loss_mask: 0.6934  loss_rpn_cls: 0.2518  loss_rpn_loc: 0.04826  time: 0.1948  data_time: 0.0162  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:57:42 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 39  total_loss: 2.006  loss_cls: 0.7266  loss_box_reg: 0.5764  loss_mask: 0.6805  loss_rpn_cls: 0.03619  loss_rpn_loc: 0.03203  time: 0.1943  data_time: 0.0042  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:57:46 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 59  total_loss: 1.945  loss_cls: 0.5742  loss_box_reg: 0.6467  loss_mask: 0.6644  loss_rpn_cls: 0.04628  loss_rpn_loc: 0.03233  time: 0.1942  data_time: 0.0044  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:57:50 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 79  total_loss: 1.899  loss_cls: 0.4699  loss_box_reg: 0.6863  loss_mask: 0.6007  loss_rpn_cls: 0.02696  loss_rpn_loc: 0.03529  time: 0.1944  data_time: 0.0042  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:57:53 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 99  total_loss: 1.764  loss_cls: 0.426  loss_box_reg: 0.6822  loss_mask: 0.5195  loss_rpn_cls: 0.03013  loss_rpn_loc: 0.04332  time: 0.1939  data_time: 0.0041  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:57:57 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 119  total_loss: 1.501  loss_cls: 0.3145  loss_box_reg: 0.6614  loss_mask: 0.3845  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.02824  time: 0.1945  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:01 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 1.224  loss_cls: 0.2158  loss_box_reg: 0.5763  loss_mask: 0.3411  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.0353  time: 0.1948  data_time: 0.0041  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:05 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 1.172  loss_cls: 0.2045  loss_box_reg: 0.5703  loss_mask: 0.3314  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.03142  time: 0.1954  data_time: 0.0040  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:09 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 1.11  loss_cls: 0.1964  loss_box_reg: 0.4596  loss_mask: 0.3107  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.02695  time: 0.1956  data_time: 0.0041  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:13 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 0.9697  loss_cls: 0.1616  loss_box_reg: 0.4345  loss_mask: 0.2877  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.02241  time: 0.1959  data_time: 0.0043  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:17 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 0.8917  loss_cls: 0.1667  loss_box_reg: 0.3238  loss_mask: 0.2587  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.02926  time: 0.1958  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:21 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 0.7685  loss_cls: 0.1332  loss_box_reg: 0.3546  loss_mask: 0.2264  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.01633  time: 0.1958  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:25 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 0.8547  loss_cls: 0.1425  loss_box_reg: 0.3729  loss_mask: 0.2508  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.03037  time: 0.1958  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:29 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 0.6418  loss_cls: 0.08298  loss_box_reg: 0.2404  loss_mask: 0.174  loss_rpn_cls: 0.008119  loss_rpn_loc: 0.0289  time: 0.1956  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:33 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 0.771  loss_cls: 0.1451  loss_box_reg: 0.3377  loss_mask: 0.2158  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.04423  time: 0.1958  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:37 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.5863  loss_cls: 0.08283  loss_box_reg: 0.2455  loss_mask: 0.1792  loss_rpn_cls: 0.009736  loss_rpn_loc: 0.02323  time: 0.1955  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:41 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.6594  loss_cls: 0.09163  loss_box_reg: 0.2901  loss_mask: 0.1583  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.02702  time: 0.1956  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:45 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.6673  loss_cls: 0.1211  loss_box_reg: 0.337  loss_mask: 0.2133  loss_rpn_cls: 0.008138  loss_rpn_loc: 0.02294  time: 0.1957  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:49 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.5724  loss_cls: 0.08588  loss_box_reg: 0.2482  loss_mask: 0.1684  loss_rpn_cls: 0.009028  loss_rpn_loc: 0.01888  time: 0.1958  data_time: 0.0044  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:52 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.5672  loss_cls: 0.08025  loss_box_reg: 0.2332  loss_mask: 0.1961  loss_rpn_cls: 0.005122  loss_rpn_loc: 0.02715  time: 0.1956  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:58:56 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.529  loss_cls: 0.07294  loss_box_reg: 0.2267  loss_mask: 0.1711  loss_rpn_cls: 0.007743  loss_rpn_loc: 0.02612  time: 0.1956  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:59:00 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.5919  loss_cls: 0.08957  loss_box_reg: 0.2459  loss_mask: 0.1788  loss_rpn_cls: 0.005841  loss_rpn_loc: 0.02306  time: 0.1958  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:59:04 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.5369  loss_cls: 0.08687  loss_box_reg: 0.2309  loss_mask: 0.1704  loss_rpn_cls: 0.002565  loss_rpn_loc: 0.01723  time: 0.1957  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:59:08 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.5  loss_cls: 0.07724  loss_box_reg: 0.2281  loss_mask: 0.1729  loss_rpn_cls: 0.005507  loss_rpn_loc: 0.01576  time: 0.1957  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:59:13 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5263  loss_cls: 0.07907  loss_box_reg: 0.2294  loss_mask: 0.1673  loss_rpn_cls: 0.002112  loss_rpn_loc: 0.01485  time: 0.1956  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 11:59:13 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:37 (0.1956 s / it)\n",
      "\u001b[32m[10/21 11:59:13 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='ZXLFOM5_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 11:59:13 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 11:59:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:59:13 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:59:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 11:59:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 11:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0588 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.328704 (0.075119 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.058529 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ZXLFOM50/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.571\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.476\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.516\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.464\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 34.569 | 57.050 | 35.420 | 43.722 | 35.893 | 9.139 |\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 30.633 | cushion    | 51.736 | door       | 14.380 |\n",
      "| indoor-plant | 57.583 | sofa       | 30.397 | table      | 22.685 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.418\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 20.091 | 41.834 | 13.909 | 19.583 | 29.220 | 5.597 |\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 24.531 | cushion    | 33.718 | door       | 18.490 |\n",
      "| indoor-plant | 20.908 | sofa       | 22.900 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='ZXLFOM50_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 11:59:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 11:59:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:59:16 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:59:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 11:59:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:59:19 d2.evaluation.evaluator]: \u001b[0mInference done 31/355. 0.0600 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 11:59:24 d2.evaluation.evaluator]: \u001b[0mInference done 98/355. 0.0582 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 11:59:29 d2.evaluation.evaluator]: \u001b[0mInference done 162/355. 0.0582 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 11:59:34 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.0583 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 11:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 277/355. 0.0586 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 11:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.0594 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 11:59:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:30.573855 (0.087354 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:59:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059469 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 11:59:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 11:59:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ZXLFOM50/coco_instances_results.json\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.916 | 33.998 | 10.104 | 6.040 | 15.768 | 13.491 |\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.284 | cushion    | 17.572 | door       | 3.809 |\n",
      "| indoor-plant | 23.879 | sofa       | 32.644 | table      | 0.310 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 11:59:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 11:59:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 11:59:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 11:59:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
      "\u001b[32m[10/21 11:59:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.295 | 31.025 | 14.126 | 6.779 | 16.035 | 15.639 |\n",
      "\u001b[32m[10/21 11:59:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.067 | cushion    | 20.145 | door       | 3.746 |\n",
      "| indoor-plant | 20.925 | sofa       | 35.886 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='ZXLFOM51_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 11:59:49 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 11:59:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 11:59:49 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 11:59:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 11:59:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 11:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0612 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 11:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 73/355. 0.0590 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 12:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 141/355. 0.0584 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.0581 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.0585 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 317/355. 0.0589 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:29.068207 (0.083052 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058828 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ZXLFOM50/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.368\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.012 | 36.773 | 11.144 | 5.787 | 18.242 | 12.064 |\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.740 | cushion    | 17.780 | door       | 5.257 |\n",
      "| indoor-plant | 23.817 | sofa       | 36.136 | table      | 0.345 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:00:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:00:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 12:00:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:00:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      "\u001b[32m[10/21 12:00:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.846 | 32.848 | 14.039 | 5.878 | 18.673 | 14.098 |\n",
      "\u001b[32m[10/21 12:00:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.420 | cushion    | 18.960 | door       | 4.667 |\n",
      "| indoor-plant | 21.556 | sofa       | 38.474 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='ZXLFOM52_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:00:20 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:00:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:00:20 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:00:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:00:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0619 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 12:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 73/355. 0.0593 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 12:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 139/355. 0.0595 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 204/355. 0.0590 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 255/355. 0.0592 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 303/355. 0.0595 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:30.442941 (0.086980 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059604 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ZXLFOM50/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 12:00:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.422 | 35.355 | 11.119 | 5.477 | 16.364 | 14.615 |\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.759 | cushion    | 16.396 | door       | 4.311 |\n",
      "| indoor-plant | 24.893 | sofa       | 35.773 | table      | 0.402 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.776 | 32.783 | 14.641 | 5.803 | 16.483 | 15.679 |\n",
      "\u001b[32m[10/21 12:00:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.832 | cushion    | 19.110 | door       | 4.162 |\n",
      "| indoor-plant | 21.872 | sofa       | 38.681 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [33.99849007057645, 36.773216235893855, 35.35458157864434]}, 'segm': {'AP50': [31.024546355135037, 32.847708620180114, 32.78311224252334]}}\n",
      "dataset_name BDZUO20\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json', name='BDZUO20_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/BDZUO200\n",
      "output_aug/800/BDZUO200\n",
      "\u001b[32m[10/21 12:00:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:00:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "282 282\n",
      "\u001b[32m[10/21 12:00:53 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 12:00:53 d2.data.build]: \u001b[0mRemoved 7 images with no usable annotations. 71 images left.\n",
      "\u001b[32m[10/21 12:00:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:00:53 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:00:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.12 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:00:53 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:00:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:00:58 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 19  total_loss: 3.442  loss_cls: 1.88  loss_box_reg: 0.592  loss_mask: 0.6922  loss_rpn_cls: 0.1763  loss_rpn_loc: 0.04202  time: 0.1940  data_time: 0.0169  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:02 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 39  total_loss: 2.263  loss_cls: 0.712  loss_box_reg: 0.6354  loss_mask: 0.6827  loss_rpn_cls: 0.05376  loss_rpn_loc: 0.03735  time: 0.1937  data_time: 0.0041  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:06 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 59  total_loss: 1.965  loss_cls: 0.5636  loss_box_reg: 0.6491  loss_mask: 0.654  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.03971  time: 0.1930  data_time: 0.0042  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:09 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 79  total_loss: 1.817  loss_cls: 0.5085  loss_box_reg: 0.6199  loss_mask: 0.5816  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.03788  time: 0.1932  data_time: 0.0042  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:13 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 99  total_loss: 1.677  loss_cls: 0.3938  loss_box_reg: 0.7097  loss_mask: 0.5037  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.03517  time: 0.1936  data_time: 0.0042  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:17 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 119  total_loss: 1.132  loss_cls: 0.1872  loss_box_reg: 0.5031  loss_mask: 0.4014  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.0301  time: 0.1930  data_time: 0.0038  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:21 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 1.465  loss_cls: 0.2679  loss_box_reg: 0.6269  loss_mask: 0.3498  loss_rpn_cls: 0.03044  loss_rpn_loc: 0.04944  time: 0.1936  data_time: 0.0042  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:25 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 159  total_loss: 1.034  loss_cls: 0.1994  loss_box_reg: 0.5401  loss_mask: 0.2825  loss_rpn_cls: 0.007015  loss_rpn_loc: 0.02253  time: 0.1938  data_time: 0.0042  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:29 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 179  total_loss: 0.9757  loss_cls: 0.1761  loss_box_reg: 0.4947  loss_mask: 0.2771  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.03506  time: 0.1942  data_time: 0.0041  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:33 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 199  total_loss: 0.8229  loss_cls: 0.1247  loss_box_reg: 0.4384  loss_mask: 0.2564  loss_rpn_cls: 0.006193  loss_rpn_loc: 0.01441  time: 0.1944  data_time: 0.0042  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:37 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 219  total_loss: 1.027  loss_cls: 0.1689  loss_box_reg: 0.4434  loss_mask: 0.2797  loss_rpn_cls: 0.008521  loss_rpn_loc: 0.0337  time: 0.1946  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:41 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 239  total_loss: 0.8531  loss_cls: 0.1553  loss_box_reg: 0.3895  loss_mask: 0.2392  loss_rpn_cls: 0.009939  loss_rpn_loc: 0.02835  time: 0.1951  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:45 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 259  total_loss: 0.7145  loss_cls: 0.1077  loss_box_reg: 0.3213  loss_mask: 0.1804  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.02768  time: 0.1951  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:49 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 279  total_loss: 0.7884  loss_cls: 0.1492  loss_box_reg: 0.3717  loss_mask: 0.2221  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.0226  time: 0.1952  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:53 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 299  total_loss: 0.6614  loss_cls: 0.1029  loss_box_reg: 0.291  loss_mask: 0.2164  loss_rpn_cls: 0.005011  loss_rpn_loc: 0.01812  time: 0.1952  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:01:57 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 319  total_loss: 0.6375  loss_cls: 0.112  loss_box_reg: 0.2729  loss_mask: 0.1974  loss_rpn_cls: 0.00853  loss_rpn_loc: 0.0241  time: 0.1953  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:01 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 339  total_loss: 0.6061  loss_cls: 0.08692  loss_box_reg: 0.287  loss_mask: 0.1879  loss_rpn_cls: 0.006774  loss_rpn_loc: 0.02835  time: 0.1953  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:04 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 359  total_loss: 0.5924  loss_cls: 0.09704  loss_box_reg: 0.2725  loss_mask: 0.1886  loss_rpn_cls: 0.005424  loss_rpn_loc: 0.02096  time: 0.1953  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:08 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 0.5852  loss_cls: 0.08887  loss_box_reg: 0.2215  loss_mask: 0.1736  loss_rpn_cls: 0.04017  loss_rpn_loc: 0.01944  time: 0.1951  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:12 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 0.6533  loss_cls: 0.1045  loss_box_reg: 0.2339  loss_mask: 0.2056  loss_rpn_cls: 0.02031  loss_rpn_loc: 0.0314  time: 0.1952  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:16 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 419  total_loss: 0.5843  loss_cls: 0.1048  loss_box_reg: 0.2481  loss_mask: 0.1831  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.02727  time: 0.1953  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:20 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 439  total_loss: 0.4733  loss_cls: 0.07024  loss_box_reg: 0.2036  loss_mask: 0.1744  loss_rpn_cls: 0.007105  loss_rpn_loc: 0.01592  time: 0.1952  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:24 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 0.5199  loss_cls: 0.08962  loss_box_reg: 0.2337  loss_mask: 0.1652  loss_rpn_cls: 0.00909  loss_rpn_loc: 0.01599  time: 0.1952  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:28 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 0.5082  loss_cls: 0.08881  loss_box_reg: 0.2478  loss_mask: 0.1814  loss_rpn_cls: 0.005546  loss_rpn_loc: 0.01666  time: 0.1954  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:32 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 0.5506  loss_cls: 0.08654  loss_box_reg: 0.2602  loss_mask: 0.1774  loss_rpn_cls: 0.003841  loss_rpn_loc: 0.023  time: 0.1954  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:36 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 0.5108  loss_cls: 0.08292  loss_box_reg: 0.2385  loss_mask: 0.1655  loss_rpn_cls: 0.003223  loss_rpn_loc: 0.01676  time: 0.1955  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:40 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 0.4859  loss_cls: 0.06026  loss_box_reg: 0.228  loss_mask: 0.1552  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.02083  time: 0.1956  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:44 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 0.4584  loss_cls: 0.07773  loss_box_reg: 0.2014  loss_mask: 0.1464  loss_rpn_cls: 0.006447  loss_rpn_loc: 0.01451  time: 0.1955  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:48 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.5208  loss_cls: 0.09212  loss_box_reg: 0.2251  loss_mask: 0.1809  loss_rpn_cls: 0.008694  loss_rpn_loc: 0.02516  time: 0.1956  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:52 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.4309  loss_cls: 0.06175  loss_box_reg: 0.2014  loss_mask: 0.1455  loss_rpn_cls: 0.005236  loss_rpn_loc: 0.01094  time: 0.1956  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:02:56 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.4235  loss_cls: 0.06398  loss_box_reg: 0.1852  loss_mask: 0.1685  loss_rpn_cls: 0.002545  loss_rpn_loc: 0.01952  time: 0.1956  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:00 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.4529  loss_cls: 0.06752  loss_box_reg: 0.1819  loss_mask: 0.1466  loss_rpn_cls: 0.004512  loss_rpn_loc: 0.02417  time: 0.1956  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:03 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.4208  loss_cls: 0.07138  loss_box_reg: 0.1692  loss_mask: 0.1608  loss_rpn_cls: 0.003807  loss_rpn_loc: 0.02022  time: 0.1957  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:07 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.4449  loss_cls: 0.06806  loss_box_reg: 0.1851  loss_mask: 0.1517  loss_rpn_cls: 0.003172  loss_rpn_loc: 0.01414  time: 0.1957  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:11 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.403  loss_cls: 0.05073  loss_box_reg: 0.2162  loss_mask: 0.1369  loss_rpn_cls: 0.002979  loss_rpn_loc: 0.01693  time: 0.1958  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:15 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.4486  loss_cls: 0.05829  loss_box_reg: 0.2041  loss_mask: 0.1525  loss_rpn_cls: 0.003186  loss_rpn_loc: 0.01528  time: 0.1959  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:19 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.4291  loss_cls: 0.0716  loss_box_reg: 0.1909  loss_mask: 0.13  loss_rpn_cls: 0.002885  loss_rpn_loc: 0.01376  time: 0.1960  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:23 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.4367  loss_cls: 0.06117  loss_box_reg: 0.1828  loss_mask: 0.1387  loss_rpn_cls: 0.004613  loss_rpn_loc: 0.01625  time: 0.1959  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:27 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.4463  loss_cls: 0.06241  loss_box_reg: 0.1868  loss_mask: 0.1411  loss_rpn_cls: 0.003554  loss_rpn_loc: 0.01383  time: 0.1959  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:32 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4954  loss_cls: 0.07475  loss_box_reg: 0.2251  loss_mask: 0.1559  loss_rpn_cls: 0.004142  loss_rpn_loc: 0.01552  time: 0.1959  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:03:32 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:36 (0.1959 s / it)\n",
      "\u001b[32m[10/21 12:03:32 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='BDZUO20_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:03:32 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:03:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:03:32 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:03:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:03:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0566 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.093147 (0.067521 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.056736 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BDZUO200/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.523\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.421\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 33.006 | 52.259 | 36.592 | 36.888 | 32.863 | 5.492 |\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.914 | cushion    | 51.390 | door       | 13.596 |\n",
      "| indoor-plant | 35.474 | sofa       | 51.033 | table      | 20.629 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 19.920 | 38.875 | 17.526 | 17.546 | 26.203 | 3.491 |\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 21.593 | cushion    | 42.052 | door       | 15.209 |\n",
      "| indoor-plant | 7.277  | sofa       | 33.388 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='BDZUO200_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:03:35 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:03:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:03:35 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:03:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:03:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 40/355. 0.0570 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 116/355. 0.0571 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 194/355. 0.0570 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.0573 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 324/355. 0.0578 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.120021 (0.071771 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057752 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BDZUO200/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.188 | 36.363 | 18.657 | 9.787 | 20.162 | 18.062 |\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.029 | cushion    | 27.508 | door       | 1.460 |\n",
      "| indoor-plant | 29.976 | sofa       | 51.867 | table      | 0.289 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:04:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:04:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 12:04:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:04:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195\n",
      "\u001b[32m[10/21 12:04:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.506 | 33.169 | 17.866 | 10.148 | 16.226 | 16.455 |\n",
      "\u001b[32m[10/21 12:04:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.784  | cushion    | 31.106 | door       | 1.618 |\n",
      "| indoor-plant | 13.363 | sofa       | 50.163 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='BDZUO201_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:04:02 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:04:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:04:02 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:04:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:04:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 19/355. 0.0581 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 89/355. 0.0591 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 12:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 164/355. 0.0582 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 231/355. 0.0582 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.0581 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:04:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.922164 (0.074063 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:04:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058114 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:04:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:04:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BDZUO200/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:04:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:04:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.232\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.232 | 37.944 | 19.607 | 7.745 | 22.674 | 17.416 |\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.417 | cushion    | 29.043 | door       | 1.675 |\n",
      "| indoor-plant | 29.121 | sofa       | 55.735 | table      | 0.399 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.351\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.992 | 35.075 | 18.919 | 7.459 | 19.051 | 16.201 |\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.094  | cushion    | 32.878 | door       | 1.575 |\n",
      "| indoor-plant | 12.739 | sofa       | 51.668 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='BDZUO202_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:04:29 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:04:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:04:29 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:04:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:04:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:04:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0577 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 12:04:35 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.0576 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 12:04:40 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.0572 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:04:45 d2.evaluation.evaluator]: \u001b[0mInference done 223/355. 0.0575 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:04:51 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.0575 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.evaluator]: \u001b[0mInference done 354/355. 0.0575 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.822440 (0.073778 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057514 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BDZUO200/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.375\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.048 | 37.542 | 18.772 | 7.726 | 21.378 | 18.502 |\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.518  | cushion    | 28.699 | door       | 1.675 |\n",
      "| indoor-plant | 30.825 | sofa       | 55.112 | table      | 0.460 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:04:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:04:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "\u001b[32m[10/21 12:04:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:04:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      "\u001b[32m[10/21 12:04:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.794 | 34.340 | 18.519 | 7.008 | 17.603 | 16.158 |\n",
      "\u001b[32m[10/21 12:04:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.415  | cushion    | 31.887 | door       | 1.871 |\n",
      "| indoor-plant | 13.694 | sofa       | 50.896 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [36.362563358839814, 37.94361717885528, 37.54161902605871]}, 'segm': {'AP50': [33.169355648571795, 35.07505023359127, 34.340147882626454]}}\n",
      "dataset_name SBHCOMN\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json', name='SBHCOMN_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/SBHCOMN0\n",
      "output_aug/500/SBHCOMN0\n",
      "\u001b[32m[10/21 12:04:58 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:04:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "282 282\n",
      "\u001b[32m[10/21 12:04:58 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 12:04:58 d2.data.build]: \u001b[0mRemoved 7 images with no usable annotations. 71 images left.\n",
      "\u001b[32m[10/21 12:04:58 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:04:58 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:04:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.12 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:04:58 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:04:58 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:05:02 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 19  total_loss: 3.243  loss_cls: 1.845  loss_box_reg: 0.5451  loss_mask: 0.6933  loss_rpn_cls: 0.1969  loss_rpn_loc: 0.03303  time: 0.1895  data_time: 0.0177  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:06 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 39  total_loss: 3.135  loss_cls: 1.574  loss_box_reg: 0.6457  loss_mask: 0.6918  loss_rpn_cls: 0.148  loss_rpn_loc: 0.03863  time: 0.1922  data_time: 0.0043  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:10 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 59  total_loss: 2.774  loss_cls: 1.13  loss_box_reg: 0.6563  loss_mask: 0.689  loss_rpn_cls: 0.2114  loss_rpn_loc: 0.04568  time: 0.1922  data_time: 0.0043  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:14 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 79  total_loss: 2.14  loss_cls: 0.7332  loss_box_reg: 0.5157  loss_mask: 0.6847  loss_rpn_cls: 0.05223  loss_rpn_loc: 0.03869  time: 0.1932  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:18 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 99  total_loss: 2.283  loss_cls: 0.746  loss_box_reg: 0.7596  loss_mask: 0.6743  loss_rpn_cls: 0.04167  loss_rpn_loc: 0.03826  time: 0.1932  data_time: 0.0039  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:22 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 119  total_loss: 2.063  loss_cls: 0.6146  loss_box_reg: 0.6134  loss_mask: 0.6668  loss_rpn_cls: 0.05136  loss_rpn_loc: 0.04961  time: 0.1937  data_time: 0.0042  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:25 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 1.916  loss_cls: 0.5774  loss_box_reg: 0.5923  loss_mask: 0.6573  loss_rpn_cls: 0.04279  loss_rpn_loc: 0.03398  time: 0.1936  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:29 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 159  total_loss: 1.923  loss_cls: 0.5052  loss_box_reg: 0.6738  loss_mask: 0.6475  loss_rpn_cls: 0.03842  loss_rpn_loc: 0.02349  time: 0.1937  data_time: 0.0041  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:33 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 179  total_loss: 1.849  loss_cls: 0.5014  loss_box_reg: 0.6115  loss_mask: 0.6392  loss_rpn_cls: 0.04215  loss_rpn_loc: 0.0341  time: 0.1936  data_time: 0.0042  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:37 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 199  total_loss: 1.887  loss_cls: 0.5466  loss_box_reg: 0.6609  loss_mask: 0.6105  loss_rpn_cls: 0.03287  loss_rpn_loc: 0.03753  time: 0.1935  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:41 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 1.731  loss_cls: 0.4342  loss_box_reg: 0.59  loss_mask: 0.5902  loss_rpn_cls: 0.02662  loss_rpn_loc: 0.03193  time: 0.1941  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:45 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 1.677  loss_cls: 0.3823  loss_box_reg: 0.6487  loss_mask: 0.5602  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.03135  time: 0.1941  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:49 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 1.666  loss_cls: 0.3394  loss_box_reg: 0.6027  loss_mask: 0.5405  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.02582  time: 0.1940  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:53 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 1.609  loss_cls: 0.3068  loss_box_reg: 0.6862  loss_mask: 0.5011  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.02994  time: 0.1940  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:05:57 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 299  total_loss: 1.585  loss_cls: 0.3005  loss_box_reg: 0.582  loss_mask: 0.4749  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.03542  time: 0.1940  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:00 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 319  total_loss: 1.359  loss_cls: 0.2655  loss_box_reg: 0.6043  loss_mask: 0.4782  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.03399  time: 0.1940  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:04 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.436  loss_cls: 0.3063  loss_box_reg: 0.6466  loss_mask: 0.4317  loss_rpn_cls: 0.02032  loss_rpn_loc: 0.02851  time: 0.1942  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:08 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.423  loss_cls: 0.2735  loss_box_reg: 0.6267  loss_mask: 0.3662  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.03762  time: 0.1944  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:12 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.465  loss_cls: 0.2871  loss_box_reg: 0.6593  loss_mask: 0.4078  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.03243  time: 0.1946  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:16 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.309  loss_cls: 0.268  loss_box_reg: 0.6168  loss_mask: 0.3598  loss_rpn_cls: 0.02554  loss_rpn_loc: 0.02893  time: 0.1946  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:20 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.265  loss_cls: 0.2499  loss_box_reg: 0.5735  loss_mask: 0.3431  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.0258  time: 0.1947  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:24 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.321  loss_cls: 0.3018  loss_box_reg: 0.6342  loss_mask: 0.3297  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.02366  time: 0.1947  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:28 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.136  loss_cls: 0.1978  loss_box_reg: 0.5659  loss_mask: 0.3117  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.035  time: 0.1947  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:32 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.178  loss_cls: 0.2224  loss_box_reg: 0.568  loss_mask: 0.3298  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.02149  time: 0.1947  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:37 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.087  loss_cls: 0.2204  loss_box_reg: 0.5708  loss_mask: 0.3036  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.02191  time: 0.1947  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:06:37 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:36 (0.1947 s / it)\n",
      "\u001b[32m[10/21 12:06:37 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='SBHCOMN_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:06:37 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:06:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:06:37 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:06:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:06:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0585 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.079703 (0.099345 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.062371 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SBHCOMN0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.227 | 56.067 | 14.597 | 31.224 | 25.862 | 17.716 |\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 23.575 | cushion    | 26.238 | door       | 22.502 |\n",
      "| indoor-plant | 31.855 | sofa       | 51.049 | table      | 2.145  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.390\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 14.631 | 39.048 | 9.116  | 12.436 | 11.350 | 39.784 |\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 13.167 | cushion    | 22.125 | door       | 32.357 |\n",
      "| indoor-plant | 0.000  | sofa       | 20.136 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='SBHCOMN0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:06:41 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:06:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:06:41 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:06:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:06:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 14/355. 0.0683 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 56/355. 0.0656 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 12:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 110/355. 0.0627 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.0626 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 12:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.0622 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 249/355. 0.0630 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.0632 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.0635 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:07:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.078588 (0.111653 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:07:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.063537 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:07:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:07:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SBHCOMN0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:07:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:07:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:07:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 12:07:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:07:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
      "\u001b[32m[10/21 12:07:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.773 | 30.209 | 7.437  | 9.766 | 14.098 | 12.285 |\n",
      "\u001b[32m[10/21 12:07:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.534 | cushion    | 27.247 | door       | 3.121 |\n",
      "| indoor-plant | 13.585 | sofa       | 19.956 | table      | 0.197 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:07:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:07:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 12:07:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:07:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n",
      "\u001b[32m[10/21 12:07:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.619 | 23.755 | 12.800 | 8.374 | 12.688 | 14.780 |\n",
      "\u001b[32m[10/21 12:07:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.224 | cushion    | 39.594 | door       | 2.456 |\n",
      "| indoor-plant | 0.893 | sofa       | 24.546 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='SBHCOMN1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:07:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:07:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:07:24 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:07:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:07:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:07:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0686 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:07:30 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.0657 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 12:07:35 d2.evaluation.evaluator]: \u001b[0mInference done 109/355. 0.0630 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 12:07:40 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.0628 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 12:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 208/355. 0.0627 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.0633 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.0636 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 12:08:01 d2.evaluation.evaluator]: \u001b[0mInference done 329/355. 0.0637 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:08:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.348070 (0.112423 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:08:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.063720 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:08:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:08:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SBHCOMN0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:08:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:08:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:08:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 12:08:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:08:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.063\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
      "\u001b[32m[10/21 12:08:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.888 | 30.657 | 6.342  | 8.131 | 13.387 | 12.096 |\n",
      "\u001b[32m[10/21 12:08:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.814 | cushion    | 27.755 | door       | 3.482 |\n",
      "| indoor-plant | 13.467 | sofa       | 18.603 | table      | 0.207 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:08:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:08:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/21 12:08:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:08:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
      "\u001b[32m[10/21 12:08:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.768 | 24.074 | 12.176 | 7.026 | 12.593 | 15.079 |\n",
      "\u001b[32m[10/21 12:08:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.570 | cushion    | 40.449 | door       | 3.550 |\n",
      "| indoor-plant | 0.895 | sofa       | 23.145 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='SBHCOMN2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:08:06 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:08:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:08:06 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:08:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:08:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:08:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0698 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:08:13 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.0660 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 12:08:18 d2.evaluation.evaluator]: \u001b[0mInference done 107/355. 0.0631 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.0627 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 12:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 203/355. 0.0629 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 241/355. 0.0634 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:08:38 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.0635 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 318/355. 0.0638 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:08:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.998704 (0.117139 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:08:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.063792 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:08:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:08:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SBHCOMN0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:08:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:08:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:08:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 12:08:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:08:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.076\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
      "\u001b[32m[10/21 12:08:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.649 | 30.167 | 7.593  | 7.009 | 13.222 | 13.807 |\n",
      "\u001b[32m[10/21 12:08:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.242 | cushion    | 26.897 | door       | 3.873 |\n",
      "| indoor-plant | 13.351 | sofa       | 20.321 | table      | 0.206 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.30s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:08:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:08:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "\u001b[32m[10/21 12:08:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:08:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
      "\u001b[32m[10/21 12:08:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.693 | 23.858 | 12.546 | 6.471 | 12.934 | 15.730 |\n",
      "\u001b[32m[10/21 12:08:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.712 | cushion    | 39.161 | door       | 3.467 |\n",
      "| indoor-plant | 0.979 | sofa       | 24.837 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [30.208948697434025, 30.65744966519087, 30.167356775450898]}, 'segm': {'AP50': [23.754788645420437, 24.07408791591755, 23.8583059586589]}}\n",
      "dataset_name IBR119R\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json', name='IBR119R_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/IBR119R0\n",
      "output_aug/800/IBR119R0\n",
      "\u001b[32m[10/21 12:08:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:08:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "282 282\n",
      "\u001b[32m[10/21 12:08:52 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 12:08:52 d2.data.build]: \u001b[0mRemoved 7 images with no usable annotations. 71 images left.\n",
      "\u001b[32m[10/21 12:08:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:08:52 d2.data.common]: \u001b[0mSerializing 71 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:08:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.12 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:08:52 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:08:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:08:56 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 19  total_loss: 3.46  loss_cls: 1.957  loss_box_reg: 0.5479  loss_mask: 0.694  loss_rpn_cls: 0.1913  loss_rpn_loc: 0.03472  time: 0.1903  data_time: 0.0171  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:00 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 39  total_loss: 3.23  loss_cls: 1.639  loss_box_reg: 0.5538  loss_mask: 0.6917  loss_rpn_cls: 0.3464  loss_rpn_loc: 0.05331  time: 0.1920  data_time: 0.0043  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:04 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 59  total_loss: 2.459  loss_cls: 1.112  loss_box_reg: 0.5853  loss_mask: 0.6891  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.03083  time: 0.1923  data_time: 0.0042  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:08 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 79  total_loss: 2.304  loss_cls: 0.833  loss_box_reg: 0.6843  loss_mask: 0.6879  loss_rpn_cls: 0.06174  loss_rpn_loc: 0.03728  time: 0.1930  data_time: 0.0043  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:11 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 99  total_loss: 2.137  loss_cls: 0.6958  loss_box_reg: 0.6638  loss_mask: 0.6753  loss_rpn_cls: 0.06465  loss_rpn_loc: 0.03556  time: 0.1929  data_time: 0.0042  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:15 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 119  total_loss: 2.035  loss_cls: 0.6221  loss_box_reg: 0.639  loss_mask: 0.6701  loss_rpn_cls: 0.047  loss_rpn_loc: 0.03213  time: 0.1930  data_time: 0.0042  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:19 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 139  total_loss: 1.997  loss_cls: 0.5812  loss_box_reg: 0.6906  loss_mask: 0.6547  loss_rpn_cls: 0.02382  loss_rpn_loc: 0.03509  time: 0.1928  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:23 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 159  total_loss: 2.002  loss_cls: 0.5625  loss_box_reg: 0.6452  loss_mask: 0.6403  loss_rpn_cls: 0.03823  loss_rpn_loc: 0.05533  time: 0.1927  data_time: 0.0041  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:27 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 179  total_loss: 1.928  loss_cls: 0.5076  loss_box_reg: 0.6593  loss_mask: 0.6213  loss_rpn_cls: 0.03105  loss_rpn_loc: 0.03011  time: 0.1930  data_time: 0.0043  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:31 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 199  total_loss: 1.945  loss_cls: 0.4602  loss_box_reg: 0.6764  loss_mask: 0.6101  loss_rpn_cls: 0.04115  loss_rpn_loc: 0.05184  time: 0.1931  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:35 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 219  total_loss: 1.778  loss_cls: 0.4266  loss_box_reg: 0.643  loss_mask: 0.5702  loss_rpn_cls: 0.03074  loss_rpn_loc: 0.03972  time: 0.1931  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:39 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 239  total_loss: 1.699  loss_cls: 0.3929  loss_box_reg: 0.6033  loss_mask: 0.5621  loss_rpn_cls: 0.03294  loss_rpn_loc: 0.035  time: 0.1930  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:42 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 259  total_loss: 1.561  loss_cls: 0.3019  loss_box_reg: 0.6419  loss_mask: 0.519  loss_rpn_cls: 0.03085  loss_rpn_loc: 0.03291  time: 0.1930  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:46 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 279  total_loss: 1.518  loss_cls: 0.3554  loss_box_reg: 0.6091  loss_mask: 0.5401  loss_rpn_cls: 0.02257  loss_rpn_loc: 0.02944  time: 0.1930  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:50 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 299  total_loss: 1.544  loss_cls: 0.2994  loss_box_reg: 0.6569  loss_mask: 0.4468  loss_rpn_cls: 0.02655  loss_rpn_loc: 0.03482  time: 0.1930  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:54 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 319  total_loss: 1.331  loss_cls: 0.2889  loss_box_reg: 0.6213  loss_mask: 0.4485  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.02529  time: 0.1931  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:09:58 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 339  total_loss: 1.386  loss_cls: 0.2982  loss_box_reg: 0.6175  loss_mask: 0.3878  loss_rpn_cls: 0.02226  loss_rpn_loc: 0.03163  time: 0.1933  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:02 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 359  total_loss: 1.349  loss_cls: 0.2561  loss_box_reg: 0.5927  loss_mask: 0.403  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.02911  time: 0.1932  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:06 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 1.359  loss_cls: 0.2783  loss_box_reg: 0.6148  loss_mask: 0.3788  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.03161  time: 0.1934  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:10 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 399  total_loss: 1.318  loss_cls: 0.2511  loss_box_reg: 0.6448  loss_mask: 0.3616  loss_rpn_cls: 0.0249  loss_rpn_loc: 0.02979  time: 0.1936  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:14 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 419  total_loss: 1.294  loss_cls: 0.2761  loss_box_reg: 0.6298  loss_mask: 0.3243  loss_rpn_cls: 0.02046  loss_rpn_loc: 0.02558  time: 0.1938  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:18 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 439  total_loss: 1.154  loss_cls: 0.1974  loss_box_reg: 0.5369  loss_mask: 0.3234  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.02481  time: 0.1940  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:22 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 1.234  loss_cls: 0.2459  loss_box_reg: 0.568  loss_mask: 0.3267  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.03455  time: 0.1941  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:26 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 1.211  loss_cls: 0.2195  loss_box_reg: 0.5974  loss_mask: 0.3293  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.02683  time: 0.1942  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:30 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.043  loss_cls: 0.1978  loss_box_reg: 0.5287  loss_mask: 0.3126  loss_rpn_cls: 0.007599  loss_rpn_loc: 0.02727  time: 0.1943  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:33 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 1.039  loss_cls: 0.1722  loss_box_reg: 0.5046  loss_mask: 0.2717  loss_rpn_cls: 0.01843  loss_rpn_loc: 0.03246  time: 0.1943  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:37 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 1.101  loss_cls: 0.2086  loss_box_reg: 0.544  loss_mask: 0.2928  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.02788  time: 0.1943  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:41 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 1.038  loss_cls: 0.1947  loss_box_reg: 0.4646  loss_mask: 0.2804  loss_rpn_cls: 0.007839  loss_rpn_loc: 0.02253  time: 0.1944  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:45 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 1.094  loss_cls: 0.1985  loss_box_reg: 0.5512  loss_mask: 0.3194  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.0288  time: 0.1946  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:49 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 599  total_loss: 0.9513  loss_cls: 0.1949  loss_box_reg: 0.4586  loss_mask: 0.2788  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.02123  time: 0.1946  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:53 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.9214  loss_cls: 0.1591  loss_box_reg: 0.3915  loss_mask: 0.2726  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.02423  time: 0.1948  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:10:57 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.9667  loss_cls: 0.1539  loss_box_reg: 0.3944  loss_mask: 0.2771  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.02393  time: 0.1950  data_time: 0.0044  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:01 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.9232  loss_cls: 0.1636  loss_box_reg: 0.3676  loss_mask: 0.27  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.02143  time: 0.1950  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:05 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 1.073  loss_cls: 0.2107  loss_box_reg: 0.4846  loss_mask: 0.2958  loss_rpn_cls: 0.02048  loss_rpn_loc: 0.03648  time: 0.1951  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:09 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.9124  loss_cls: 0.1588  loss_box_reg: 0.3979  loss_mask: 0.2671  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.02231  time: 0.1953  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:13 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.86  loss_cls: 0.1446  loss_box_reg: 0.3796  loss_mask: 0.2592  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.02738  time: 0.1954  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:17 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.9073  loss_cls: 0.1613  loss_box_reg: 0.3923  loss_mask: 0.2841  loss_rpn_cls: 0.007293  loss_rpn_loc: 0.02569  time: 0.1954  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:21 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 1  loss_cls: 0.2073  loss_box_reg: 0.4816  loss_mask: 0.2557  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.03416  time: 0.1955  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:25 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.8022  loss_cls: 0.1562  loss_box_reg: 0.3498  loss_mask: 0.2335  loss_rpn_cls: 0.007766  loss_rpn_loc: 0.0141  time: 0.1955  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:30 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.7541  loss_cls: 0.1302  loss_box_reg: 0.3601  loss_mask: 0.2289  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.02253  time: 0.1956  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:11:30 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:36 (0.1956 s / it)\n",
      "\u001b[32m[10/21 12:11:30 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:37 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='IBR119R_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:11:30 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:11:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:11:30 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:11:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:11:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:11:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0595 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.802076 (0.090390 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.061668 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IBR119R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.644\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.347\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.455\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.541\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.524\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.697\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 34.492 | 64.378 | 34.732 | 45.542 | 29.982 | 26.403 |\n",
      "\u001b[32m[10/21 12:11:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 31.816 | cushion    | 48.057 | door       | 20.079 |\n",
      "| indoor-plant | 55.556 | sofa       | 43.401 | table      | 8.044  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:11:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:11:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 12:11:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:11:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.419\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n",
      "\u001b[32m[10/21 12:11:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.587 | 41.913 | 14.025 | 18.230 | 17.465 | 29.885 |\n",
      "\u001b[32m[10/21 12:11:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 16.630 | cushion    | 39.341 | door       | 14.472 |\n",
      "| indoor-plant | 9.505  | sofa       | 19.574 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='IBR119R0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:11:34 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:11:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:11:34 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:11:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:11:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:11:36 d2.evaluation.evaluator]: \u001b[0mInference done 19/355. 0.0638 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 12:11:41 d2.evaluation.evaluator]: \u001b[0mInference done 78/355. 0.0603 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 12:11:46 d2.evaluation.evaluator]: \u001b[0mInference done 142/355. 0.0597 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 12:11:51 d2.evaluation.evaluator]: \u001b[0mInference done 202/355. 0.0595 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:11:56 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.0603 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:12:01 d2.evaluation.evaluator]: \u001b[0mInference done 298/355. 0.0605 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.0607 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.014613 (0.094327 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060811 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IBR119R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 16.091 | 34.772 | 10.561 | 8.742 | 20.461 | 9.208 |\n",
      "\u001b[32m[10/21 12:12:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.021 | cushion    | 29.527 | door       | 3.503 |\n",
      "| indoor-plant | 22.962 | sofa       | 18.499 | table      | 1.037 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:12:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:12:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 12:12:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:12:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
      "\u001b[32m[10/21 12:12:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.262 | 32.372 | 13.532 | 8.228 | 22.556 | 11.713 |\n",
      "\u001b[32m[10/21 12:12:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.590 | cushion    | 43.273 | door       | 2.223 |\n",
      "| indoor-plant | 15.150 | sofa       | 23.335 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='IBR119R1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:12:09 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:12:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:12:09 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:12:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:12:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0639 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 12:12:16 d2.evaluation.evaluator]: \u001b[0mInference done 64/355. 0.0605 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 12:12:21 d2.evaluation.evaluator]: \u001b[0mInference done 126/355. 0.0593 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 12:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 182/355. 0.0592 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.0600 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.0600 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 12:12:42 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.0605 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.604595 (0.098870 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060496 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IBR119R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 12:12:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:12:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n",
      "\u001b[32m[10/21 12:12:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 16.241 | 35.353 | 11.063 | 8.322 | 20.644 | 9.175 |\n",
      "\u001b[32m[10/21 12:12:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.691 | cushion    | 29.997 | door       | 3.987 |\n",
      "| indoor-plant | 22.653 | sofa       | 17.318 | table      | 0.801 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:12:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:12:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[10/21 12:12:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:12:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
      "\u001b[32m[10/21 12:12:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.397 | 32.957 | 13.139 | 8.207 | 22.395 | 10.625 |\n",
      "\u001b[32m[10/21 12:12:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.482 | cushion    | 43.629 | door       | 2.792 |\n",
      "| indoor-plant | 15.120 | sofa       | 22.357 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='IBR119R2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:12:47 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:12:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:12:47 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:12:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:12:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0657 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 12:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 65/355. 0.0608 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 12:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 129/355. 0.0595 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 12:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 189/355. 0.0600 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 235/355. 0.0606 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.0608 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:13:19 d2.evaluation.evaluator]: \u001b[0mInference done 337/355. 0.0609 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.003425 (0.094296 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061014 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IBR119R0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.301\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.969 | 34.813 | 10.222 | 8.161 | 19.154 | 11.274 |\n",
      "\u001b[32m[10/21 12:13:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 20.229 | cushion    | 27.931 | door       | 4.388 |\n",
      "| indoor-plant | 23.921 | sofa       | 18.512 | table      | 0.833 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:13:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:13:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "\u001b[32m[10/21 12:13:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:13:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.277\n",
      "\u001b[32m[10/21 12:13:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.007 | 32.520 | 13.004 | 7.443 | 21.702 | 13.214 |\n",
      "\u001b[32m[10/21 12:13:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.689 | cushion    | 40.373 | door       | 3.064 |\n",
      "| indoor-plant | 15.819 | sofa       | 23.095 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [34.77157067998528, 35.35285743379648, 34.81257237515992]}, 'segm': {'AP50': [32.37229535944229, 32.957486560698804, 32.519707118948396]}}\n",
      "dataset_name JPMSBWH\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json', name='JPMSBWH_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/JPMSBWH0\n",
      "output_aug/500/JPMSBWH0\n",
      "\u001b[32m[10/21 12:13:23 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:13:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "124 124\n",
      "\u001b[32m[10/21 12:13:23 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 12:13:23 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 12:13:23 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 14           |  cushion   | 29           |    door    | 37           |\n",
      "| indoor-plant | 16           |    sofa    | 13           |   table    | 15           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 124          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 12:13:23 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:13:23 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:13:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:13:23 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:13:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:13:28 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.39  loss_cls: 1.704  loss_box_reg: 0.603  loss_mask: 0.691  loss_rpn_cls: 0.1941  loss_rpn_loc: 0.2263  time: 0.1931  data_time: 0.0169  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:32 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 39  total_loss: 2.553  loss_cls: 0.8105  loss_box_reg: 0.7111  loss_mask: 0.6625  loss_rpn_cls: 0.08448  loss_rpn_loc: 0.07412  time: 0.1928  data_time: 0.0041  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:36 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 59  total_loss: 2.29  loss_cls: 0.6828  loss_box_reg: 0.8554  loss_mask: 0.6185  loss_rpn_cls: 0.05309  loss_rpn_loc: 0.1268  time: 0.1943  data_time: 0.0041  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:40 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 79  total_loss: 2.049  loss_cls: 0.5301  loss_box_reg: 0.8456  loss_mask: 0.5489  loss_rpn_cls: 0.05153  loss_rpn_loc: 0.1516  time: 0.1952  data_time: 0.0042  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:44 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 99  total_loss: 1.869  loss_cls: 0.4576  loss_box_reg: 0.8006  loss_mask: 0.4858  loss_rpn_cls: 0.0373  loss_rpn_loc: 0.1294  time: 0.1955  data_time: 0.0040  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:48 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 119  total_loss: 1.398  loss_cls: 0.2742  loss_box_reg: 0.6626  loss_mask: 0.3598  loss_rpn_cls: 0.01783  loss_rpn_loc: 0.07657  time: 0.1959  data_time: 0.0043  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:52 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 139  total_loss: 1.28  loss_cls: 0.2205  loss_box_reg: 0.5173  loss_mask: 0.3549  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.1138  time: 0.1963  data_time: 0.0041  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:55 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 1.217  loss_cls: 0.2262  loss_box_reg: 0.5277  loss_mask: 0.2795  loss_rpn_cls: 0.02617  loss_rpn_loc: 0.1222  time: 0.1965  data_time: 0.0040  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:13:59 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 1.082  loss_cls: 0.1843  loss_box_reg: 0.4306  loss_mask: 0.2816  loss_rpn_cls: 0.04754  loss_rpn_loc: 0.1112  time: 0.1965  data_time: 0.0041  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:03 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 0.9449  loss_cls: 0.1603  loss_box_reg: 0.4041  loss_mask: 0.2302  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.09692  time: 0.1968  data_time: 0.0042  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:07 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 219  total_loss: 0.9675  loss_cls: 0.1879  loss_box_reg: 0.3804  loss_mask: 0.218  loss_rpn_cls: 0.01583  loss_rpn_loc: 0.09321  time: 0.1970  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:11 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 0.8288  loss_cls: 0.1363  loss_box_reg: 0.3367  loss_mask: 0.1694  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.09758  time: 0.1973  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:15 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 0.7738  loss_cls: 0.1434  loss_box_reg: 0.3154  loss_mask: 0.2273  loss_rpn_cls: 0.009904  loss_rpn_loc: 0.08636  time: 0.1974  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:19 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 0.6269  loss_cls: 0.1099  loss_box_reg: 0.289  loss_mask: 0.1555  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.04978  time: 0.1975  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:23 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 0.675  loss_cls: 0.1116  loss_box_reg: 0.3198  loss_mask: 0.1667  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.03879  time: 0.1976  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:27 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.6427  loss_cls: 0.1023  loss_box_reg: 0.2481  loss_mask: 0.1589  loss_rpn_cls: 0.008037  loss_rpn_loc: 0.09206  time: 0.1977  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:31 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.7018  loss_cls: 0.1082  loss_box_reg: 0.3098  loss_mask: 0.1864  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.08785  time: 0.1978  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:35 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.6823  loss_cls: 0.103  loss_box_reg: 0.2682  loss_mask: 0.176  loss_rpn_cls: 0.008182  loss_rpn_loc: 0.07487  time: 0.1979  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:39 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.6353  loss_cls: 0.1184  loss_box_reg: 0.2463  loss_mask: 0.1498  loss_rpn_cls: 0.008833  loss_rpn_loc: 0.08109  time: 0.1980  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:43 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.6636  loss_cls: 0.1064  loss_box_reg: 0.2604  loss_mask: 0.1744  loss_rpn_cls: 0.008429  loss_rpn_loc: 0.1007  time: 0.1980  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:47 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.6333  loss_cls: 0.09029  loss_box_reg: 0.2323  loss_mask: 0.1709  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.08525  time: 0.1981  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:51 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.5993  loss_cls: 0.08681  loss_box_reg: 0.219  loss_mask: 0.1765  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.04011  time: 0.1981  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:55 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.5501  loss_cls: 0.09991  loss_box_reg: 0.2153  loss_mask: 0.1271  loss_rpn_cls: 0.008922  loss_rpn_loc: 0.09145  time: 0.1983  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:14:59 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.5937  loss_cls: 0.08171  loss_box_reg: 0.2291  loss_mask: 0.1627  loss_rpn_cls: 0.007071  loss_rpn_loc: 0.08381  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:15:04 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.549  loss_cls: 0.07932  loss_box_reg: 0.2399  loss_mask: 0.1428  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.07856  time: 0.1985  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:15:04 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:38 (0.1985 s / it)\n",
      "\u001b[32m[10/21 12:15:04 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:40 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='JPMSBWH_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:15:05 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:15:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:15:05 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:15:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:15:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0573 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.142830 (0.069124 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057696 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/JPMSBWH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.599\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.469\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 35.018 | 59.853 | 34.440 | 34.226 | 34.244 | 41.805 |\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.022 | cushion    | 47.324 | door       | 17.492 |\n",
      "| indoor-plant | 49.454 | sofa       | 64.778 | table      | 6.036  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.534\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.163 | 53.396 | 22.405 | 20.829 | 22.175 | 57.468 |\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 12.578 | cushion    | 29.650 | door       | 31.843 |\n",
      "| indoor-plant | 39.285 | sofa       | 50.462 | table      | 5.158  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='JPMSBWH0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:15:07 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:15:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:15:07 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:15:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:15:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 33/355. 0.0626 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 12:15:16 d2.evaluation.evaluator]: \u001b[0mInference done 99/355. 0.0596 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 12:15:21 d2.evaluation.evaluator]: \u001b[0mInference done 169/355. 0.0586 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 238/355. 0.0583 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 301/355. 0.0582 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:15:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.217615 (0.077765 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:15:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058252 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:15:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:15:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/JPMSBWH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:15:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:15:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.259 | 36.320 | 25.914 | 13.316 | 22.128 | 26.369 |\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.549  | cushion    | 67.568 | door       | 6.859 |\n",
      "| indoor-plant | 13.684 | sofa       | 52.044 | table      | 0.847 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.645 | 34.538 | 25.004 | 10.854 | 23.460 | 19.355 |\n",
      "\u001b[32m[10/21 12:15:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.095  | cushion    | 71.860 | door       | 6.115 |\n",
      "| indoor-plant | 13.319 | sofa       | 42.190 | table      | 0.290 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='JPMSBWH1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:15:36 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:15:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:15:36 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:15:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:15:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:15:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0577 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 12:15:43 d2.evaluation.evaluator]: \u001b[0mInference done 75/355. 0.0575 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:15:48 d2.evaluation.evaluator]: \u001b[0mInference done 146/355. 0.0573 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:15:53 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.0573 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:15:58 d2.evaluation.evaluator]: \u001b[0mInference done 279/355. 0.0575 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 341/355. 0.0576 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:16:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.066415 (0.077333 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:16:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057665 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:16:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:16:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/JPMSBWH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:16:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:16:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.788 | 35.837 | 25.181 | 12.418 | 22.229 | 26.976 |\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.139  | cushion    | 68.440 | door       | 6.669 |\n",
      "| indoor-plant | 12.589 | sofa       | 49.822 | table      | 1.069 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.745 | 33.870 | 26.116 | 11.153 | 22.836 | 20.674 |\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.240  | cushion    | 71.870 | door       | 7.183 |\n",
      "| indoor-plant | 12.314 | sofa       | 42.654 | table      | 0.207 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='JPMSBWH2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:16:05 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:16:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:16:05 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:16:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:16:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:16:08 d2.evaluation.evaluator]: \u001b[0mInference done 28/355. 0.0582 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 12:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 96/355. 0.0576 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 12:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 166/355. 0.0576 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 231/355. 0.0575 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.0577 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 355/355. 0.0577 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.227105 (0.077792 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:16:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057704 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:16:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:16:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/JPMSBWH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:16:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:16:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.428\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.034 | 35.711 | 24.781 | 12.153 | 21.407 | 25.546 |\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.568  | cushion    | 65.767 | door       | 7.935 |\n",
      "| indoor-plant | 11.863 | sofa       | 48.162 | table      | 0.905 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.916 | 34.181 | 24.917 | 10.551 | 22.659 | 20.244 |\n",
      "\u001b[32m[10/21 12:16:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.215  | cushion    | 69.548 | door       | 7.512 |\n",
      "| indoor-plant | 11.728 | sofa       | 40.212 | table      | 0.282 |\n",
      "all results {'bbox': {'AP50': [36.31951914735119, 35.83664230080302, 35.71136260136139]}, 'segm': {'AP50': [34.5375998568136, 33.87031781323139, 34.18096123014872]}}\n",
      "dataset_name YB777MZ\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json', name='YB777MZ_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/YB777MZ0\n",
      "output_aug/800/YB777MZ0\n",
      "\u001b[32m[10/21 12:16:35 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:16:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "124 124\n",
      "\u001b[32m[10/21 12:16:35 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 12:16:35 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 12:16:35 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:16:35 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:16:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:16:35 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:16:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:16:40 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 19  total_loss: 3.532  loss_cls: 1.655  loss_box_reg: 0.7262  loss_mask: 0.693  loss_rpn_cls: 0.2233  loss_rpn_loc: 0.1258  time: 0.1940  data_time: 0.0176  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:16:44 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 39  total_loss: 2.609  loss_cls: 0.8351  loss_box_reg: 0.8404  loss_mask: 0.6599  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.1501  time: 0.1944  data_time: 0.0042  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:16:48 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 59  total_loss: 2.371  loss_cls: 0.6424  loss_box_reg: 0.8443  loss_mask: 0.5979  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.0888  time: 0.1963  data_time: 0.0042  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:16:52 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 79  total_loss: 2.167  loss_cls: 0.5453  loss_box_reg: 0.847  loss_mask: 0.5703  loss_rpn_cls: 0.0567  loss_rpn_loc: 0.1473  time: 0.1978  data_time: 0.0042  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:16:56 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 99  total_loss: 1.601  loss_cls: 0.3543  loss_box_reg: 0.766  loss_mask: 0.4358  loss_rpn_cls: 0.03308  loss_rpn_loc: 0.1125  time: 0.1979  data_time: 0.0041  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:00 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 119  total_loss: 1.469  loss_cls: 0.2955  loss_box_reg: 0.6244  loss_mask: 0.3275  loss_rpn_cls: 0.02415  loss_rpn_loc: 0.09185  time: 0.1978  data_time: 0.0040  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:04 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 139  total_loss: 1.32  loss_cls: 0.2877  loss_box_reg: 0.5833  loss_mask: 0.332  loss_rpn_cls: 0.02035  loss_rpn_loc: 0.09421  time: 0.1984  data_time: 0.0044  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:08 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 159  total_loss: 1.162  loss_cls: 0.2144  loss_box_reg: 0.5196  loss_mask: 0.2974  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.07175  time: 0.1984  data_time: 0.0040  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:12 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 179  total_loss: 1.041  loss_cls: 0.188  loss_box_reg: 0.4196  loss_mask: 0.2564  loss_rpn_cls: 0.01904  loss_rpn_loc: 0.1054  time: 0.1981  data_time: 0.0041  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:16 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 199  total_loss: 0.8942  loss_cls: 0.1748  loss_box_reg: 0.3863  loss_mask: 0.2283  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.09406  time: 0.1981  data_time: 0.0041  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:20 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 219  total_loss: 0.8784  loss_cls: 0.1636  loss_box_reg: 0.374  loss_mask: 0.1998  loss_rpn_cls: 0.01572  loss_rpn_loc: 0.11  time: 0.1983  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:24 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 239  total_loss: 0.7829  loss_cls: 0.13  loss_box_reg: 0.3411  loss_mask: 0.1911  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.09696  time: 0.1983  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:28 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 259  total_loss: 0.7799  loss_cls: 0.1173  loss_box_reg: 0.3145  loss_mask: 0.2001  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.1086  time: 0.1984  data_time: 0.0044  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:32 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 279  total_loss: 0.6968  loss_cls: 0.0921  loss_box_reg: 0.2883  loss_mask: 0.1812  loss_rpn_cls: 0.007916  loss_rpn_loc: 0.05318  time: 0.1985  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:36 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 299  total_loss: 0.8457  loss_cls: 0.1183  loss_box_reg: 0.3604  loss_mask: 0.1949  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.09852  time: 0.1984  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:40 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 319  total_loss: 0.6904  loss_cls: 0.1221  loss_box_reg: 0.2663  loss_mask: 0.1884  loss_rpn_cls: 0.008823  loss_rpn_loc: 0.07983  time: 0.1985  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:44 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 339  total_loss: 0.6614  loss_cls: 0.1086  loss_box_reg: 0.2548  loss_mask: 0.1707  loss_rpn_cls: 0.009661  loss_rpn_loc: 0.08826  time: 0.1986  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:48 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 359  total_loss: 0.6422  loss_cls: 0.08924  loss_box_reg: 0.2656  loss_mask: 0.1778  loss_rpn_cls: 0.00998  loss_rpn_loc: 0.08034  time: 0.1986  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:51 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 379  total_loss: 0.6916  loss_cls: 0.09921  loss_box_reg: 0.2478  loss_mask: 0.1413  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.1166  time: 0.1985  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:55 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 0.6163  loss_cls: 0.1026  loss_box_reg: 0.2328  loss_mask: 0.1633  loss_rpn_cls: 0.009578  loss_rpn_loc: 0.08191  time: 0.1984  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:17:59 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 419  total_loss: 0.5428  loss_cls: 0.07652  loss_box_reg: 0.2266  loss_mask: 0.1253  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.08108  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:03 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 439  total_loss: 0.6421  loss_cls: 0.09703  loss_box_reg: 0.2344  loss_mask: 0.1527  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.09408  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:07 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 459  total_loss: 0.596  loss_cls: 0.08707  loss_box_reg: 0.2269  loss_mask: 0.1599  loss_rpn_cls: 0.008924  loss_rpn_loc: 0.0795  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:11 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 479  total_loss: 0.5714  loss_cls: 0.0833  loss_box_reg: 0.2088  loss_mask: 0.1638  loss_rpn_cls: 0.009441  loss_rpn_loc: 0.08509  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:15 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 499  total_loss: 0.5504  loss_cls: 0.08372  loss_box_reg: 0.217  loss_mask: 0.1302  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.08622  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:19 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 519  total_loss: 0.5331  loss_cls: 0.07186  loss_box_reg: 0.1948  loss_mask: 0.1619  loss_rpn_cls: 0.008232  loss_rpn_loc: 0.09267  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:23 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 0.5158  loss_cls: 0.06483  loss_box_reg: 0.2021  loss_mask: 0.1438  loss_rpn_cls: 0.008171  loss_rpn_loc: 0.09466  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:27 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 0.533  loss_cls: 0.08625  loss_box_reg: 0.2168  loss_mask: 0.1446  loss_rpn_cls: 0.01077  loss_rpn_loc: 0.06913  time: 0.1984  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:31 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.5266  loss_cls: 0.07743  loss_box_reg: 0.2065  loss_mask: 0.1326  loss_rpn_cls: 0.008055  loss_rpn_loc: 0.08108  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:35 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.5559  loss_cls: 0.09873  loss_box_reg: 0.2297  loss_mask: 0.1353  loss_rpn_cls: 0.005941  loss_rpn_loc: 0.08926  time: 0.1984  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:39 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.4339  loss_cls: 0.07456  loss_box_reg: 0.1994  loss_mask: 0.1249  loss_rpn_cls: 0.00377  loss_rpn_loc: 0.03655  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:43 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.5315  loss_cls: 0.08757  loss_box_reg: 0.1947  loss_mask: 0.1423  loss_rpn_cls: 0.008229  loss_rpn_loc: 0.06313  time: 0.1985  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:47 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.5325  loss_cls: 0.07865  loss_box_reg: 0.2046  loss_mask: 0.1341  loss_rpn_cls: 0.006093  loss_rpn_loc: 0.05658  time: 0.1985  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:51 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.4953  loss_cls: 0.07331  loss_box_reg: 0.1941  loss_mask: 0.136  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.06199  time: 0.1986  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:55 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.5681  loss_cls: 0.08351  loss_box_reg: 0.2115  loss_mask: 0.148  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.07114  time: 0.1986  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:18:59 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.5731  loss_cls: 0.1074  loss_box_reg: 0.2082  loss_mask: 0.1162  loss_rpn_cls: 0.02579  loss_rpn_loc: 0.06164  time: 0.1988  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:19:03 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.4767  loss_cls: 0.08155  loss_box_reg: 0.1905  loss_mask: 0.121  loss_rpn_cls: 0.008013  loss_rpn_loc: 0.04844  time: 0.1988  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:19:07 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.4949  loss_cls: 0.06678  loss_box_reg: 0.189  loss_mask: 0.14  loss_rpn_cls: 0.00539  loss_rpn_loc: 0.08415  time: 0.1988  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:19:11 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.4435  loss_cls: 0.0718  loss_box_reg: 0.1731  loss_mask: 0.1311  loss_rpn_cls: 0.008136  loss_rpn_loc: 0.07933  time: 0.1989  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:19:16 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4628  loss_cls: 0.07348  loss_box_reg: 0.1981  loss_mask: 0.1128  loss_rpn_cls: 0.004145  loss_rpn_loc: 0.04839  time: 0.1989  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:19:16 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:38 (0.1989 s / it)\n",
      "\u001b[32m[10/21 12:19:16 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:40 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='YB777MZ_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:19:16 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:19:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:19:16 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:19:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:19:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:19:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0568 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.141063 (0.069067 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057650 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/YB777MZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.611\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.351\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 34.832 | 61.115 | 35.482 | 35.054 | 35.016 | 44.491 |\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 30.535 | cushion    | 40.805 | door       | 12.105 |\n",
      "| indoor-plant | 55.006 | sofa       | 64.520 | table      | 6.021  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.12 seconds.\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.559\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.044 | 55.888 | 17.237 | 23.262 | 25.394 | 52.894 |\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 18.752 | cushion    | 28.223 | door       | 26.922 |\n",
      "| indoor-plant | 38.858 | sofa       | 51.130 | table      | 4.376  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='YB777MZ0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:19:19 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:19:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:19:19 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:19:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:19:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:19:22 d2.evaluation.evaluator]: \u001b[0mInference done 34/355. 0.0588 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 12:19:27 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0580 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 12:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 175/355. 0.0581 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:19:37 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.0580 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 306/355. 0.0582 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.491597 (0.075690 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058348 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/YB777MZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.388\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.333 | 39.731 | 27.025 | 13.639 | 21.913 | 23.743 |\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.618  | cushion    | 65.401 | door       | 9.547 |\n",
      "| indoor-plant | 17.732 | sofa       | 54.621 | table      | 0.077 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:19:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:19:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 12:19:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:19:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
      "\u001b[32m[10/21 12:19:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.375 | 37.207 | 21.990 | 11.402 | 22.282 | 16.066 |\n",
      "\u001b[32m[10/21 12:19:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.228  | cushion    | 71.685 | door       | 10.629 |\n",
      "| indoor-plant | 13.943 | sofa       | 34.737 | table      | 0.026  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='YB777MZ1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:19:48 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:19:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:19:48 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:19:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:19:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0580 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 12:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 78/355. 0.0586 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 12:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 149/355. 0.0583 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 220/355. 0.0583 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 283/355. 0.0585 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:20:14 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.0585 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:20:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.725432 (0.076358 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:20:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058567 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:20:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:20:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/YB777MZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:20:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.052 | 39.079 | 27.136 | 13.166 | 21.490 | 23.862 |\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.355  | cushion    | 67.252 | door       | 9.800 |\n",
      "| indoor-plant | 15.430 | sofa       | 53.354 | table      | 0.121 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.365\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.562 | 36.510 | 24.225 | 11.939 | 21.818 | 17.028 |\n",
      "\u001b[32m[10/21 12:20:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.071  | cushion    | 73.040 | door       | 11.110 |\n",
      "| indoor-plant | 12.235 | sofa       | 35.890 | table      | 0.025  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='YB777MZ2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:20:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:20:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:20:17 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:20:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:20:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:20:19 d2.evaluation.evaluator]: \u001b[0mInference done 30/355. 0.0584 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:20:24 d2.evaluation.evaluator]: \u001b[0mInference done 100/355. 0.0579 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 12:20:29 d2.evaluation.evaluator]: \u001b[0mInference done 173/355. 0.0578 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 240/355. 0.0581 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 301/355. 0.0583 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.720014 (0.076343 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058455 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/YB777MZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.398\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.869 | 39.713 | 26.699 | 12.559 | 21.398 | 23.399 |\n",
      "\u001b[32m[10/21 12:20:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.710  | cushion    | 67.513 | door       | 10.087 |\n",
      "| indoor-plant | 15.910 | sofa       | 51.937 | table      | 0.057  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:20:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:20:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/21 12:20:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:20:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
      "\u001b[32m[10/21 12:20:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.987 | 37.117 | 21.930 | 11.510 | 21.598 | 16.666 |\n",
      "\u001b[32m[10/21 12:20:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 2.961  | cushion    | 72.063 | door       | 10.816 |\n",
      "| indoor-plant | 12.936 | sofa       | 33.123 | table      | 0.025  |\n",
      "all results {'bbox': {'AP50': [39.73110862163882, 39.0794060763561, 39.71265368836146]}, 'segm': {'AP50': [37.20672209964883, 36.50999164411155, 37.11690839540475]}}\n",
      "dataset_name 9W4DX6H\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json', name='9W4DX6H_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/9W4DX6H0\n",
      "output_aug/500/9W4DX6H0\n",
      "\u001b[32m[10/21 12:20:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:20:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "124 124\n",
      "\u001b[32m[10/21 12:20:46 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 12:20:46 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 12:20:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:20:46 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:20:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:20:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:20:46 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:20:51 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 19  total_loss: 3.963  loss_cls: 1.878  loss_box_reg: 0.5557  loss_mask: 0.6928  loss_rpn_cls: 0.2692  loss_rpn_loc: 0.2072  time: 0.1971  data_time: 0.0168  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:20:55 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 39  total_loss: 3.584  loss_cls: 1.626  loss_box_reg: 0.8324  loss_mask: 0.6907  loss_rpn_cls: 0.2038  loss_rpn_loc: 0.1087  time: 0.1947  data_time: 0.0042  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:20:58 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 59  total_loss: 3.323  loss_cls: 1.172  loss_box_reg: 0.7532  loss_mask: 0.683  loss_rpn_cls: 0.2119  loss_rpn_loc: 0.2372  time: 0.1940  data_time: 0.0042  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:02 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 79  total_loss: 2.646  loss_cls: 0.8302  loss_box_reg: 0.7477  loss_mask: 0.6667  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.1648  time: 0.1936  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:06 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 99  total_loss: 2.483  loss_cls: 0.6982  loss_box_reg: 0.7746  loss_mask: 0.6526  loss_rpn_cls: 0.09977  loss_rpn_loc: 0.1971  time: 0.1946  data_time: 0.0043  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:10 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 119  total_loss: 2.409  loss_cls: 0.7457  loss_box_reg: 0.8394  loss_mask: 0.6363  loss_rpn_cls: 0.05803  loss_rpn_loc: 0.1805  time: 0.1953  data_time: 0.0042  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:14 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 139  total_loss: 2.289  loss_cls: 0.6495  loss_box_reg: 0.8497  loss_mask: 0.6124  loss_rpn_cls: 0.04965  loss_rpn_loc: 0.05465  time: 0.1956  data_time: 0.0042  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:18 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 2.286  loss_cls: 0.6529  loss_box_reg: 0.8791  loss_mask: 0.6062  loss_rpn_cls: 0.05676  loss_rpn_loc: 0.1549  time: 0.1955  data_time: 0.0040  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:22 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 2.136  loss_cls: 0.5529  loss_box_reg: 0.8462  loss_mask: 0.566  loss_rpn_cls: 0.0483  loss_rpn_loc: 0.1541  time: 0.1957  data_time: 0.0041  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:26 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 2.123  loss_cls: 0.5545  loss_box_reg: 0.8675  loss_mask: 0.5373  loss_rpn_cls: 0.05987  loss_rpn_loc: 0.1719  time: 0.1958  data_time: 0.0042  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:30 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 2.015  loss_cls: 0.505  loss_box_reg: 0.8231  loss_mask: 0.55  loss_rpn_cls: 0.04651  loss_rpn_loc: 0.1594  time: 0.1960  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:34 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 1.923  loss_cls: 0.4779  loss_box_reg: 0.8276  loss_mask: 0.5064  loss_rpn_cls: 0.03481  loss_rpn_loc: 0.1135  time: 0.1961  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:38 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 1.796  loss_cls: 0.4276  loss_box_reg: 0.7705  loss_mask: 0.4941  loss_rpn_cls: 0.04001  loss_rpn_loc: 0.1089  time: 0.1962  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:42 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 1.658  loss_cls: 0.3607  loss_box_reg: 0.7513  loss_mask: 0.4292  loss_rpn_cls: 0.0265  loss_rpn_loc: 0.1222  time: 0.1963  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:46 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 1.675  loss_cls: 0.3674  loss_box_reg: 0.7108  loss_mask: 0.4206  loss_rpn_cls: 0.02945  loss_rpn_loc: 0.1079  time: 0.1965  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:50 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 1.61  loss_cls: 0.3488  loss_box_reg: 0.7327  loss_mask: 0.4025  loss_rpn_cls: 0.0272  loss_rpn_loc: 0.07455  time: 0.1966  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:54 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.514  loss_cls: 0.3281  loss_box_reg: 0.6176  loss_mask: 0.4258  loss_rpn_cls: 0.02859  loss_rpn_loc: 0.06346  time: 0.1965  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:21:58 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.342  loss_cls: 0.2731  loss_box_reg: 0.6584  loss_mask: 0.3539  loss_rpn_cls: 0.01785  loss_rpn_loc: 0.06505  time: 0.1967  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:02 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.485  loss_cls: 0.2836  loss_box_reg: 0.6362  loss_mask: 0.3836  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.07777  time: 0.1968  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:06 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.43  loss_cls: 0.2831  loss_box_reg: 0.5714  loss_mask: 0.3561  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.09624  time: 0.1969  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:10 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.206  loss_cls: 0.2302  loss_box_reg: 0.512  loss_mask: 0.3268  loss_rpn_cls: 0.02887  loss_rpn_loc: 0.09827  time: 0.1972  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:14 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.206  loss_cls: 0.2231  loss_box_reg: 0.5299  loss_mask: 0.2907  loss_rpn_cls: 0.01722  loss_rpn_loc: 0.0967  time: 0.1972  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:18 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.174  loss_cls: 0.1984  loss_box_reg: 0.489  loss_mask: 0.334  loss_rpn_cls: 0.01831  loss_rpn_loc: 0.07922  time: 0.1973  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:22 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.141  loss_cls: 0.2132  loss_box_reg: 0.4651  loss_mask: 0.3027  loss_rpn_cls: 0.0229  loss_rpn_loc: 0.09013  time: 0.1974  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:27 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.056  loss_cls: 0.1927  loss_box_reg: 0.4706  loss_mask: 0.2942  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.1103  time: 0.1974  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:22:27 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:38 (0.1975 s / it)\n",
      "\u001b[32m[10/21 12:22:27 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='9W4DX6H_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:22:27 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:22:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:22:27 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:22:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:22:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:22:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0591 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.963159 (0.095586 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.061063 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/9W4DX6H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.574\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.575\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.443 | 57.402 | 25.095 | 22.931 | 39.401 | 39.543 |\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 27.509 | cushion    | 30.832 | door       | 15.258 |\n",
      "| indoor-plant | 39.913 | sofa       | 74.719 | table      | 0.424  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:22:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:22:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 12:22:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:22:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.524\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780\n",
      "\u001b[32m[10/21 12:22:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.237 | 52.361 | 14.349 | 15.855 | 21.820 | 67.518 |\n",
      "\u001b[32m[10/21 12:22:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 19.416 | cushion    | 22.989 | door       | 33.261 |\n",
      "| indoor-plant | 40.524 | sofa       | 23.126 | table      | 0.106  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='9W4DX6H0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:22:31 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:22:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:22:31 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:22:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:22:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0684 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 12:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 55/355. 0.0661 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 12:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 106/355. 0.0635 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 12:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 155/355. 0.0631 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 208/355. 0.0623 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.0631 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 283/355. 0.0633 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 318/355. 0.0638 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:23:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.902285 (0.119721 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:23:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064042 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:23:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:23:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/9W4DX6H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:23:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:23:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:23:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 12:23:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:23:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n",
      "\u001b[32m[10/21 12:23:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.235 | 32.387 | 17.062 | 11.030 | 18.977 | 20.733 |\n",
      "\u001b[32m[10/21 12:23:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 4.291 | cushion    | 45.322 | door       | 10.393 |\n",
      "| indoor-plant | 5.717 | sofa       | 43.654 | table      | 0.030  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:23:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:23:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "\u001b[32m[10/21 12:23:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:23:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
      "\u001b[32m[10/21 12:23:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.308 | 31.895 | 24.157 | 9.053 | 23.813 | 23.991 |\n",
      "\u001b[32m[10/21 12:23:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.656 | cushion    | 58.921 | door       | 13.663 |\n",
      "| indoor-plant | 5.634 | sofa       | 45.876 | table      | 0.099  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='9W4DX6H1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:23:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:23:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:23:16 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:23:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:23:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0690 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 12:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.0662 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 12:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 102/355. 0.0637 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 12:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 150/355. 0.0633 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 205/355. 0.0625 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.0631 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 284/355. 0.0635 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 12:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.0640 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 12:23:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.576344 (0.115932 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:23:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064045 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:23:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:23:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/9W4DX6H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:23:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:23:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:23:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 12:23:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:23:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.440\n",
      "\u001b[32m[10/21 12:23:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.175 | 31.163 | 16.550 | 8.017 | 18.455 | 17.552 |\n",
      "\u001b[32m[10/21 12:23:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.955 | cushion    | 42.118 | door       | 11.674 |\n",
      "| indoor-plant | 4.878 | sofa       | 40.415 | table      | 0.008  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:24:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:24:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.63 seconds.\n",
      "\u001b[32m[10/21 12:24:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:24:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
      "\u001b[32m[10/21 12:24:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.441 | 30.592 | 25.042 | 8.005 | 23.006 | 21.915 |\n",
      "\u001b[32m[10/21 12:24:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.600 | cushion    | 56.603 | door       | 14.355 |\n",
      "| indoor-plant | 4.395 | sofa       | 43.690 | table      | 0.002  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='9W4DX6H2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:24:01 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:24:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:24:01 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:24:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:24:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0687 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:24:08 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.0663 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 12:24:13 d2.evaluation.evaluator]: \u001b[0mInference done 102/355. 0.0639 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 12:24:18 d2.evaluation.evaluator]: \u001b[0mInference done 154/355. 0.0629 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 12:24:23 d2.evaluation.evaluator]: \u001b[0mInference done 203/355. 0.0626 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:24:28 d2.evaluation.evaluator]: \u001b[0mInference done 243/355. 0.0630 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.0636 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:24:38 d2.evaluation.evaluator]: \u001b[0mInference done 317/355. 0.0641 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.995618 (0.117130 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064303 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/9W4DX6H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.451\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.186 | 32.012 | 17.864 | 8.398 | 19.594 | 20.118 |\n",
      "\u001b[32m[10/21 12:24:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.518 | cushion    | 44.237 | door       | 12.560 |\n",
      "| indoor-plant | 5.731 | sofa       | 43.051 | table      | 0.020  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:24:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:24:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.68 seconds.\n",
      "\u001b[32m[10/21 12:24:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:24:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
      "\u001b[32m[10/21 12:24:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.148 | 31.539 | 25.094 | 8.422 | 23.920 | 23.478 |\n",
      "\u001b[32m[10/21 12:24:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.077 | cushion    | 57.345 | door       | 15.340 |\n",
      "| indoor-plant | 5.402 | sofa       | 45.711 | table      | 0.014  |\n",
      "all results {'bbox': {'AP50': [32.38726162872046, 31.163364283800117, 32.011705458784625]}, 'segm': {'AP50': [31.8950995295189, 30.591877678277807, 31.53877909367028]}}\n",
      "dataset_name HXJYYNR\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json', name='HXJYYNR_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/HXJYYNR0\n",
      "output_aug/800/HXJYYNR0\n",
      "\u001b[32m[10/21 12:24:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:24:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "124 124\n",
      "\u001b[32m[10/21 12:24:46 d2.data.datasets.coco]: \u001b[0mLoaded 24 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 12:24:46 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 23 images left.\n",
      "\u001b[32m[10/21 12:24:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:24:46 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:24:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:24:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:24:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:24:51 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 19  total_loss: 3.868  loss_cls: 2.035  loss_box_reg: 0.5656  loss_mask: 0.6948  loss_rpn_cls: 0.2464  loss_rpn_loc: 0.241  time: 0.1920  data_time: 0.0164  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:24:55 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 39  total_loss: 3.619  loss_cls: 1.749  loss_box_reg: 0.7688  loss_mask: 0.6921  loss_rpn_cls: 0.187  loss_rpn_loc: 0.1301  time: 0.1924  data_time: 0.0042  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:24:58 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 59  total_loss: 3.312  loss_cls: 1.323  loss_box_reg: 0.6395  loss_mask: 0.6853  loss_rpn_cls: 0.1787  loss_rpn_loc: 0.2379  time: 0.1918  data_time: 0.0041  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:02 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 79  total_loss: 2.899  loss_cls: 0.9115  loss_box_reg: 0.6144  loss_mask: 0.6758  loss_rpn_cls: 0.08601  loss_rpn_loc: 0.22  time: 0.1930  data_time: 0.0043  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:06 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 99  total_loss: 2.675  loss_cls: 0.8206  loss_box_reg: 0.9085  loss_mask: 0.656  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2085  time: 0.1939  data_time: 0.0043  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:10 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 119  total_loss: 2.505  loss_cls: 0.8023  loss_box_reg: 0.8488  loss_mask: 0.6516  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1459  time: 0.1942  data_time: 0.0042  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:14 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 2.448  loss_cls: 0.6588  loss_box_reg: 0.8017  loss_mask: 0.6142  loss_rpn_cls: 0.06064  loss_rpn_loc: 0.1796  time: 0.1945  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:18 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 159  total_loss: 2.281  loss_cls: 0.669  loss_box_reg: 0.8654  loss_mask: 0.6046  loss_rpn_cls: 0.05037  loss_rpn_loc: 0.1539  time: 0.1953  data_time: 0.0042  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:22 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 179  total_loss: 2.302  loss_cls: 0.6505  loss_box_reg: 0.8036  loss_mask: 0.5954  loss_rpn_cls: 0.04956  loss_rpn_loc: 0.1682  time: 0.1951  data_time: 0.0043  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:26 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 199  total_loss: 2.147  loss_cls: 0.5763  loss_box_reg: 0.8493  loss_mask: 0.5369  loss_rpn_cls: 0.04477  loss_rpn_loc: 0.08395  time: 0.1956  data_time: 0.0043  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:30 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 219  total_loss: 2.158  loss_cls: 0.5345  loss_box_reg: 0.782  loss_mask: 0.5261  loss_rpn_cls: 0.0467  loss_rpn_loc: 0.1779  time: 0.1958  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:34 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 239  total_loss: 2.01  loss_cls: 0.4968  loss_box_reg: 0.7912  loss_mask: 0.4954  loss_rpn_cls: 0.03603  loss_rpn_loc: 0.1226  time: 0.1960  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:38 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 259  total_loss: 1.811  loss_cls: 0.4443  loss_box_reg: 0.789  loss_mask: 0.4846  loss_rpn_cls: 0.04441  loss_rpn_loc: 0.1314  time: 0.1962  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:42 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 279  total_loss: 1.839  loss_cls: 0.4267  loss_box_reg: 0.79  loss_mask: 0.4895  loss_rpn_cls: 0.02637  loss_rpn_loc: 0.1307  time: 0.1962  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:46 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 299  total_loss: 1.678  loss_cls: 0.378  loss_box_reg: 0.7058  loss_mask: 0.409  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.1062  time: 0.1964  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:50 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 319  total_loss: 1.566  loss_cls: 0.3429  loss_box_reg: 0.695  loss_mask: 0.3945  loss_rpn_cls: 0.01953  loss_rpn_loc: 0.08596  time: 0.1964  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:54 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 339  total_loss: 1.61  loss_cls: 0.3595  loss_box_reg: 0.7046  loss_mask: 0.4085  loss_rpn_cls: 0.0254  loss_rpn_loc: 0.1258  time: 0.1964  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:25:58 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 359  total_loss: 1.46  loss_cls: 0.2969  loss_box_reg: 0.6531  loss_mask: 0.3435  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.09903  time: 0.1965  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:02 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 379  total_loss: 1.384  loss_cls: 0.2787  loss_box_reg: 0.6499  loss_mask: 0.3559  loss_rpn_cls: 0.02043  loss_rpn_loc: 0.09706  time: 0.1965  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:06 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 1.311  loss_cls: 0.2683  loss_box_reg: 0.6002  loss_mask: 0.3277  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.09978  time: 0.1968  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:10 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 419  total_loss: 1.187  loss_cls: 0.2545  loss_box_reg: 0.5573  loss_mask: 0.3063  loss_rpn_cls: 0.02454  loss_rpn_loc: 0.04782  time: 0.1969  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:14 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 439  total_loss: 1.219  loss_cls: 0.2589  loss_box_reg: 0.5393  loss_mask: 0.3344  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.1093  time: 0.1969  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:18 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 1.016  loss_cls: 0.1866  loss_box_reg: 0.4968  loss_mask: 0.2756  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.0915  time: 0.1971  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:22 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 1.107  loss_cls: 0.2314  loss_box_reg: 0.473  loss_mask: 0.3141  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.09043  time: 0.1972  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:26 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.141  loss_cls: 0.218  loss_box_reg: 0.4986  loss_mask: 0.3056  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.1042  time: 0.1974  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:30 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 1.056  loss_cls: 0.1777  loss_box_reg: 0.4527  loss_mask: 0.3012  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.1001  time: 0.1972  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:34 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 0.9616  loss_cls: 0.1944  loss_box_reg: 0.4414  loss_mask: 0.2373  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.03879  time: 0.1974  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:38 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 1.004  loss_cls: 0.1639  loss_box_reg: 0.4186  loss_mask: 0.2929  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.09124  time: 0.1974  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:42 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 1.046  loss_cls: 0.1707  loss_box_reg: 0.4588  loss_mask: 0.2903  loss_rpn_cls: 0.01945  loss_rpn_loc: 0.09866  time: 0.1975  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:46 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.9496  loss_cls: 0.1571  loss_box_reg: 0.4046  loss_mask: 0.2479  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.05434  time: 0.1975  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:50 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.977  loss_cls: 0.2115  loss_box_reg: 0.4136  loss_mask: 0.2725  loss_rpn_cls: 0.01669  loss_rpn_loc: 0.07031  time: 0.1976  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:54 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.9548  loss_cls: 0.1713  loss_box_reg: 0.3995  loss_mask: 0.2697  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.1009  time: 0.1976  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:26:58 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.8518  loss_cls: 0.1524  loss_box_reg: 0.3712  loss_mask: 0.2528  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.04877  time: 0.1976  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:02 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.8269  loss_cls: 0.1682  loss_box_reg: 0.3315  loss_mask: 0.2277  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.07996  time: 0.1976  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:06 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.9217  loss_cls: 0.1531  loss_box_reg: 0.3682  loss_mask: 0.2592  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.1016  time: 0.1977  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:10 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.8895  loss_cls: 0.1661  loss_box_reg: 0.3201  loss_mask: 0.2548  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.09976  time: 0.1977  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:14 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.7562  loss_cls: 0.1351  loss_box_reg: 0.2869  loss_mask: 0.1918  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.0717  time: 0.1978  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:18 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.8914  loss_cls: 0.1699  loss_box_reg: 0.3472  loss_mask: 0.2688  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.06338  time: 0.1978  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:22 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.7729  loss_cls: 0.1469  loss_box_reg: 0.3301  loss_mask: 0.2186  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.09087  time: 0.1978  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:27 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.7147  loss_cls: 0.1456  loss_box_reg: 0.2869  loss_mask: 0.2164  loss_rpn_cls: 0.009955  loss_rpn_loc: 0.09298  time: 0.1978  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:27:27 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:37 (0.1978 s / it)\n",
      "\u001b[32m[10/21 12:27:27 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='HXJYYNR_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:27:27 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:27:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:27:27 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:27:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:27:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0564 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.718471 (0.087693 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.059460 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/HXJYYNR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.639\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.616\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 35.672 | 63.944 | 35.463 | 36.030 | 35.072 | 37.871 |\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 23.062 | cushion    | 40.418 | door       | 16.665 |\n",
      "| indoor-plant | 55.494 | sofa       | 71.801 | table      | 6.590  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.608\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.531 | 54.143 | 11.358 | 17.021 | 19.288 | 60.844 |\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 14.323 | cushion    | 23.541 | door       | 32.125 |\n",
      "| indoor-plant | 41.875 | sofa       | 28.397 | table      | 0.927  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='HXJYYNR0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:27:30 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:27:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:27:30 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:27:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:27:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 17/355. 0.0662 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 12:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 60/355. 0.0639 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 12:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 113/355. 0.0619 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 166/355. 0.0612 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 12:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.0612 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 253/355. 0.0618 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.0622 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 12:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.0628 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 12:28:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.673391 (0.119067 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:28:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.063150 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:28:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:28:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/HXJYYNR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:28:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:28:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:28:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 12:28:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:28:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511\n",
      "\u001b[32m[10/21 12:28:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.098 | 38.151 | 26.258 | 11.836 | 25.071 | 22.713 |\n",
      "\u001b[32m[10/21 12:28:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.885  | cushion    | 61.681 | door       | 9.304 |\n",
      "| indoor-plant | 19.853 | sofa       | 44.951 | table      | 0.912 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:28:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:28:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 12:28:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:28:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
      "\u001b[32m[10/21 12:28:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.578 | 37.223 | 25.655 | 11.035 | 26.689 | 25.682 |\n",
      "\u001b[32m[10/21 12:28:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.026  | cushion    | 69.531 | door       | 12.215 |\n",
      "| indoor-plant | 17.357 | sofa       | 41.835 | table      | 0.505  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='HXJYYNR1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:28:15 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:28:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:28:15 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:28:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:28:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0655 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 12:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 55/355. 0.0652 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 12:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 110/355. 0.0627 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 12:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 165/355. 0.0617 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 12:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.0616 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 258/355. 0.0620 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 295/355. 0.0626 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.0629 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:28:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.891405 (0.111118 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:28:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.063220 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:28:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:28:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/HXJYYNR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:28:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:28:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:28:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 12:28:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:28:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
      "\u001b[32m[10/21 12:28:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.263 | 37.209 | 25.223 | 11.803 | 24.894 | 19.164 |\n",
      "\u001b[32m[10/21 12:28:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.285  | cushion    | 62.118 | door       | 9.467 |\n",
      "| indoor-plant | 19.607 | sofa       | 40.009 | table      | 1.093 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:28:57 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:28:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.59 seconds.\n",
      "\u001b[32m[10/21 12:28:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:28:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
      "\u001b[32m[10/21 12:28:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.896 | 36.184 | 25.891 | 11.083 | 26.177 | 23.423 |\n",
      "\u001b[32m[10/21 12:28:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.689  | cushion    | 69.099 | door       | 12.743 |\n",
      "| indoor-plant | 17.162 | sofa       | 38.351 | table      | 0.330  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='HXJYYNR2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:28:57 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:28:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:28:57 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:28:58 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:28:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:28:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0659 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 12:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.0637 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 12:29:09 d2.evaluation.evaluator]: \u001b[0mInference done 107/355. 0.0614 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 163/355. 0.0606 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 12:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 207/355. 0.0610 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.0615 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 279/355. 0.0626 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:29:35 d2.evaluation.evaluator]: \u001b[0mInference done 309/355. 0.0633 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.0637 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:29:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.783922 (0.125097 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:29:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.063820 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:29:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:29:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/HXJYYNR0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:29:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:29:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:29:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 12:29:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:29:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
      "\u001b[32m[10/21 12:29:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.016 | 39.220 | 27.125 | 11.561 | 26.273 | 22.460 |\n",
      "\u001b[32m[10/21 12:29:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.992  | cushion    | 61.806 | door       | 10.538 |\n",
      "| indoor-plant | 21.973 | sofa       | 47.930 | table      | 0.858  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.28s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:29:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:29:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "\u001b[32m[10/21 12:29:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:29:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442\n",
      "\u001b[32m[10/21 12:29:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.307 | 38.668 | 26.836 | 10.563 | 27.127 | 25.575 |\n",
      "\u001b[32m[10/21 12:29:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.522  | cushion    | 68.118 | door       | 13.987 |\n",
      "| indoor-plant | 19.005 | sofa       | 44.817 | table      | 0.391  |\n",
      "all results {'bbox': {'AP50': [38.151458514701545, 37.209251091775656, 39.21974158422521]}, 'segm': {'AP50': [37.22257399702881, 36.183908043058594, 38.66832510151906]}}\n",
      "dataset_name I56EGFF\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json', name='I56EGFF_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/I56EGFF0\n",
      "output_aug/500/I56EGFF0\n",
      "\u001b[32m[10/21 12:29:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:29:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "217 217\n",
      "\u001b[32m[10/21 12:29:46 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 12:29:46 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 40 images left.\n",
      "\u001b[32m[10/21 12:29:46 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 24           |  cushion   | 50           |    door    | 68           |\n",
      "| indoor-plant | 28           |    sofa    | 22           |   table    | 25           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 217          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 12:29:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:29:46 d2.data.common]: \u001b[0mSerializing 40 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:29:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:29:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:29:46 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:29:50 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 19  total_loss: 3.469  loss_cls: 1.625  loss_box_reg: 0.75  loss_mask: 0.6912  loss_rpn_cls: 0.2033  loss_rpn_loc: 0.1868  time: 0.1898  data_time: 0.0169  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:29:54 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 39  total_loss: 2.482  loss_cls: 0.7711  loss_box_reg: 0.7329  loss_mask: 0.6584  loss_rpn_cls: 0.07903  loss_rpn_loc: 0.1052  time: 0.1911  data_time: 0.0042  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:29:58 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 59  total_loss: 2.217  loss_cls: 0.5909  loss_box_reg: 0.7793  loss_mask: 0.6193  loss_rpn_cls: 0.08572  loss_rpn_loc: 0.1586  time: 0.1929  data_time: 0.0043  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:02 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 79  total_loss: 1.982  loss_cls: 0.465  loss_box_reg: 0.8017  loss_mask: 0.5426  loss_rpn_cls: 0.04902  loss_rpn_loc: 0.1411  time: 0.1940  data_time: 0.0043  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:06 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 99  total_loss: 1.718  loss_cls: 0.4022  loss_box_reg: 0.7539  loss_mask: 0.4451  loss_rpn_cls: 0.04316  loss_rpn_loc: 0.1295  time: 0.1953  data_time: 0.0042  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:10 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 119  total_loss: 1.474  loss_cls: 0.2897  loss_box_reg: 0.6334  loss_mask: 0.3844  loss_rpn_cls: 0.03558  loss_rpn_loc: 0.121  time: 0.1952  data_time: 0.0041  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:14 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 139  total_loss: 1.228  loss_cls: 0.2396  loss_box_reg: 0.5959  loss_mask: 0.3057  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.08595  time: 0.1956  data_time: 0.0042  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:17 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 1.107  loss_cls: 0.1968  loss_box_reg: 0.4484  loss_mask: 0.2987  loss_rpn_cls: 0.0255  loss_rpn_loc: 0.1288  time: 0.1955  data_time: 0.0041  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:21 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 1.061  loss_cls: 0.1516  loss_box_reg: 0.4273  loss_mask: 0.2584  loss_rpn_cls: 0.01994  loss_rpn_loc: 0.1117  time: 0.1958  data_time: 0.0039  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:25 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 0.936  loss_cls: 0.1601  loss_box_reg: 0.4325  loss_mask: 0.2097  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.1415  time: 0.1964  data_time: 0.0041  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:30 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 0.9082  loss_cls: 0.1619  loss_box_reg: 0.4169  loss_mask: 0.2105  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.1525  time: 0.1970  data_time: 0.0044  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:34 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 0.9552  loss_cls: 0.1499  loss_box_reg: 0.4046  loss_mask: 0.217  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.1069  time: 0.1971  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:37 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 0.7518  loss_cls: 0.1204  loss_box_reg: 0.3146  loss_mask: 0.1996  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.08989  time: 0.1973  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:41 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 0.7333  loss_cls: 0.1118  loss_box_reg: 0.3108  loss_mask: 0.2003  loss_rpn_cls: 0.008898  loss_rpn_loc: 0.102  time: 0.1973  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:45 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 0.6988  loss_cls: 0.1153  loss_box_reg: 0.3547  loss_mask: 0.1769  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.06839  time: 0.1973  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:49 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.6879  loss_cls: 0.1002  loss_box_reg: 0.2912  loss_mask: 0.1884  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.07425  time: 0.1974  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:53 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.7602  loss_cls: 0.1088  loss_box_reg: 0.2911  loss_mask: 0.1991  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.09223  time: 0.1974  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:30:57 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.6119  loss_cls: 0.08335  loss_box_reg: 0.2485  loss_mask: 0.1429  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.07678  time: 0.1975  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:01 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.7208  loss_cls: 0.1151  loss_box_reg: 0.2714  loss_mask: 0.1591  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.09769  time: 0.1975  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:05 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.6686  loss_cls: 0.09402  loss_box_reg: 0.2502  loss_mask: 0.1756  loss_rpn_cls: 0.008499  loss_rpn_loc: 0.1021  time: 0.1976  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:09 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.651  loss_cls: 0.09812  loss_box_reg: 0.2879  loss_mask: 0.172  loss_rpn_cls: 0.008173  loss_rpn_loc: 0.07641  time: 0.1976  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:13 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.6271  loss_cls: 0.08829  loss_box_reg: 0.2587  loss_mask: 0.1594  loss_rpn_cls: 0.007816  loss_rpn_loc: 0.06459  time: 0.1978  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:17 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.5387  loss_cls: 0.07757  loss_box_reg: 0.2179  loss_mask: 0.1538  loss_rpn_cls: 0.005343  loss_rpn_loc: 0.08011  time: 0.1979  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:21 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.6109  loss_cls: 0.09361  loss_box_reg: 0.2161  loss_mask: 0.167  loss_rpn_cls: 0.00568  loss_rpn_loc: 0.05342  time: 0.1980  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:26 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5593  loss_cls: 0.07472  loss_box_reg: 0.2219  loss_mask: 0.1482  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.07049  time: 0.1980  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:31:26 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:38 (0.1980 s / it)\n",
      "\u001b[32m[10/21 12:31:26 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='I56EGFF_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:31:26 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:31:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:31:26 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:31:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:31:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:31:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0558 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.250060 (0.072583 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057530 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/I56EGFF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.568\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.318 | 56.843 | 29.396 | 30.059 | 33.722 | 31.526 |\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.863 | cushion    | 41.528 | door       | 15.392 |\n",
      "| indoor-plant | 38.581 | sofa       | 57.002 | table      | 3.544  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.518\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.666 | 51.782 | 18.675 | 19.533 | 26.205 | 42.646 |\n",
      "\u001b[32m[10/21 12:31:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 16.558 | cushion    | 29.456 | door       | 31.560 |\n",
      "| indoor-plant | 27.797 | sofa       | 51.138 | table      | 3.489  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='I56EGFF0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:31:29 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:31:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:31:30 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:31:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:31:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:31:32 d2.evaluation.evaluator]: \u001b[0mInference done 28/355. 0.0595 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 12:31:37 d2.evaluation.evaluator]: \u001b[0mInference done 86/355. 0.0587 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 12:31:42 d2.evaluation.evaluator]: \u001b[0mInference done 149/355. 0.0583 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:31:48 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.0581 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:31:53 d2.evaluation.evaluator]: \u001b[0mInference done 273/355. 0.0583 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:31:58 d2.evaluation.evaluator]: \u001b[0mInference done 321/355. 0.0587 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:30.745413 (0.087844 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058781 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/I56EGFF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.644 | 39.170 | 28.084 | 13.312 | 21.549 | 22.212 |\n",
      "\u001b[32m[10/21 12:32:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 6.634  | cushion    | 64.511 | door       | 9.288 |\n",
      "| indoor-plant | 13.100 | sofa       | 54.215 | table      | 0.115 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:32:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:32:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 12:32:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:32:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      "\u001b[32m[10/21 12:32:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.962 | 37.649 | 21.281 | 11.883 | 24.535 | 17.150 |\n",
      "\u001b[32m[10/21 12:32:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.827  | cushion    | 72.286 | door       | 9.368 |\n",
      "| indoor-plant | 13.151 | sofa       | 37.017 | table      | 0.121 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='I56EGFF1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:32:02 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:32:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:32:02 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:32:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:32:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0612 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 12:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 72/355. 0.0591 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 12:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 138/355. 0.0588 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 209/355. 0.0584 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 268/355. 0.0590 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.0592 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.792925 (0.082265 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.059267 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/I56EGFF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.726 | 39.189 | 28.191 | 13.379 | 22.003 | 21.694 |\n",
      "\u001b[32m[10/21 12:32:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.458  | cushion    | 66.046 | door       | 11.655 |\n",
      "| indoor-plant | 11.995 | sofa       | 52.055 | table      | 0.151  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:32:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:32:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.47 seconds.\n",
      "\u001b[32m[10/21 12:32:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:32:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      "\u001b[32m[10/21 12:32:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.522 | 37.658 | 22.907 | 12.390 | 24.125 | 17.795 |\n",
      "\u001b[32m[10/21 12:32:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.204  | cushion    | 73.012 | door       | 12.291 |\n",
      "| indoor-plant | 12.836 | sofa       | 37.655 | table      | 0.133  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='I56EGFF2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:32:33 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:32:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:32:33 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:32:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:32:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:32:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0598 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 12:32:40 d2.evaluation.evaluator]: \u001b[0mInference done 72/355. 0.0584 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 12:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 139/355. 0.0585 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:32:50 d2.evaluation.evaluator]: \u001b[0mInference done 209/355. 0.0582 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:32:55 d2.evaluation.evaluator]: \u001b[0mInference done 268/355. 0.0585 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:33:00 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.0589 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.530911 (0.081517 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058893 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/I56EGFF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.413\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.764 | 40.217 | 27.298 | 12.818 | 22.082 | 22.114 |\n",
      "\u001b[32m[10/21 12:33:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.260  | cushion    | 65.898 | door       | 11.756 |\n",
      "| indoor-plant | 12.954 | sofa       | 51.627 | table      | 0.087  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:33:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 12:33:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:33:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.386\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      "\u001b[32m[10/21 12:33:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.330 | 38.561 | 22.984 | 11.961 | 24.138 | 20.209 |\n",
      "\u001b[32m[10/21 12:33:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.145  | cushion    | 71.542 | door       | 11.956 |\n",
      "| indoor-plant | 12.976 | sofa       | 37.200 | table      | 0.161  |\n",
      "all results {'bbox': {'AP50': [39.17038149528617, 39.189041223400174, 40.21724234929681]}, 'segm': {'AP50': [37.64850699188857, 37.65760835019603, 38.56099776664064]}}\n",
      "dataset_name 4RHFF8H\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json', name='4RHFF8H_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/4RHFF8H0\n",
      "output_aug/800/4RHFF8H0\n",
      "\u001b[32m[10/21 12:33:05 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:33:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "217 217\n",
      "\u001b[32m[10/21 12:33:05 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 12:33:05 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 40 images left.\n",
      "\u001b[32m[10/21 12:33:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:33:05 d2.data.common]: \u001b[0mSerializing 40 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:33:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:33:05 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:33:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:33:09 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 19  total_loss: 3.805  loss_cls: 1.94  loss_box_reg: 0.7152  loss_mask: 0.6915  loss_rpn_cls: 0.1802  loss_rpn_loc: 0.2167  time: 0.1943  data_time: 0.0165  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:13 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 39  total_loss: 2.481  loss_cls: 0.7998  loss_box_reg: 0.7713  loss_mask: 0.6655  loss_rpn_cls: 0.08069  loss_rpn_loc: 0.1611  time: 0.1950  data_time: 0.0042  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:17 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 59  total_loss: 2.327  loss_cls: 0.6317  loss_box_reg: 0.839  loss_mask: 0.6075  loss_rpn_cls: 0.06853  loss_rpn_loc: 0.1913  time: 0.1955  data_time: 0.0041  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:21 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 79  total_loss: 2.055  loss_cls: 0.5066  loss_box_reg: 0.8235  loss_mask: 0.5422  loss_rpn_cls: 0.03859  loss_rpn_loc: 0.04731  time: 0.1967  data_time: 0.0043  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:25 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 99  total_loss: 1.623  loss_cls: 0.3693  loss_box_reg: 0.7841  loss_mask: 0.4108  loss_rpn_cls: 0.03427  loss_rpn_loc: 0.1168  time: 0.1966  data_time: 0.0043  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:29 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 119  total_loss: 1.593  loss_cls: 0.3436  loss_box_reg: 0.6565  loss_mask: 0.378  loss_rpn_cls: 0.03497  loss_rpn_loc: 0.1331  time: 0.1968  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:33 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 139  total_loss: 1.135  loss_cls: 0.2335  loss_box_reg: 0.5031  loss_mask: 0.3042  loss_rpn_cls: 0.02847  loss_rpn_loc: 0.1019  time: 0.1974  data_time: 0.0043  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:37 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 159  total_loss: 1.195  loss_cls: 0.2216  loss_box_reg: 0.5484  loss_mask: 0.2736  loss_rpn_cls: 0.02385  loss_rpn_loc: 0.1029  time: 0.1973  data_time: 0.0041  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:41 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 179  total_loss: 1.184  loss_cls: 0.2032  loss_box_reg: 0.4875  loss_mask: 0.2976  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.1115  time: 0.1977  data_time: 0.0043  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:45 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 199  total_loss: 0.9548  loss_cls: 0.1657  loss_box_reg: 0.3906  loss_mask: 0.2285  loss_rpn_cls: 0.01498  loss_rpn_loc: 0.09537  time: 0.1975  data_time: 0.0042  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:49 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 219  total_loss: 0.8612  loss_cls: 0.1534  loss_box_reg: 0.3615  loss_mask: 0.2323  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.1072  time: 0.1974  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:53 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 239  total_loss: 0.7952  loss_cls: 0.1435  loss_box_reg: 0.316  loss_mask: 0.2101  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.1095  time: 0.1976  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:33:57 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 259  total_loss: 0.9635  loss_cls: 0.134  loss_box_reg: 0.375  loss_mask: 0.2324  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.1232  time: 0.1979  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:01 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 279  total_loss: 0.7254  loss_cls: 0.1192  loss_box_reg: 0.3335  loss_mask: 0.1852  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.07234  time: 0.1978  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:05 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 299  total_loss: 0.7317  loss_cls: 0.09251  loss_box_reg: 0.3193  loss_mask: 0.194  loss_rpn_cls: 0.01952  loss_rpn_loc: 0.1063  time: 0.1979  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:09 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 319  total_loss: 0.6577  loss_cls: 0.09793  loss_box_reg: 0.236  loss_mask: 0.1802  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.07492  time: 0.1980  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:13 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 339  total_loss: 0.7049  loss_cls: 0.1241  loss_box_reg: 0.2981  loss_mask: 0.1671  loss_rpn_cls: 0.008012  loss_rpn_loc: 0.0774  time: 0.1980  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:17 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 359  total_loss: 0.6718  loss_cls: 0.1017  loss_box_reg: 0.2677  loss_mask: 0.1805  loss_rpn_cls: 0.01011  loss_rpn_loc: 0.08675  time: 0.1980  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:21 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 379  total_loss: 0.7098  loss_cls: 0.1146  loss_box_reg: 0.2706  loss_mask: 0.1781  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.09692  time: 0.1980  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:25 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 0.5726  loss_cls: 0.08436  loss_box_reg: 0.2428  loss_mask: 0.1883  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.0642  time: 0.1980  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:29 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 419  total_loss: 0.662  loss_cls: 0.09758  loss_box_reg: 0.249  loss_mask: 0.1793  loss_rpn_cls: 0.008146  loss_rpn_loc: 0.08657  time: 0.1981  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:33 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 439  total_loss: 0.584  loss_cls: 0.0912  loss_box_reg: 0.2335  loss_mask: 0.1652  loss_rpn_cls: 0.008775  loss_rpn_loc: 0.07362  time: 0.1982  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:37 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 459  total_loss: 0.5889  loss_cls: 0.09108  loss_box_reg: 0.218  loss_mask: 0.1512  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.09036  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:41 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 479  total_loss: 0.5756  loss_cls: 0.0855  loss_box_reg: 0.2145  loss_mask: 0.163  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.08497  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:45 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 499  total_loss: 0.5177  loss_cls: 0.07593  loss_box_reg: 0.2089  loss_mask: 0.1366  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.07368  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:49 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 519  total_loss: 0.5877  loss_cls: 0.0707  loss_box_reg: 0.22  loss_mask: 0.1556  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.07207  time: 0.1985  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:53 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 0.5582  loss_cls: 0.07401  loss_box_reg: 0.2121  loss_mask: 0.144  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.07464  time: 0.1985  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:34:57 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 0.6339  loss_cls: 0.07574  loss_box_reg: 0.2347  loss_mask: 0.1591  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.07582  time: 0.1984  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:01 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.5236  loss_cls: 0.08577  loss_box_reg: 0.1968  loss_mask: 0.1463  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.07464  time: 0.1984  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:05 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.5233  loss_cls: 0.0721  loss_box_reg: 0.1892  loss_mask: 0.1589  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.08872  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:09 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.5549  loss_cls: 0.08441  loss_box_reg: 0.22  loss_mask: 0.1504  loss_rpn_cls: 0.008928  loss_rpn_loc: 0.07294  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:13 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.5249  loss_cls: 0.07675  loss_box_reg: 0.2099  loss_mask: 0.1483  loss_rpn_cls: 0.008315  loss_rpn_loc: 0.04825  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:17 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.4971  loss_cls: 0.06572  loss_box_reg: 0.1826  loss_mask: 0.1482  loss_rpn_cls: 0.007917  loss_rpn_loc: 0.08857  time: 0.1982  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:21 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.4765  loss_cls: 0.07547  loss_box_reg: 0.1894  loss_mask: 0.1444  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.07226  time: 0.1983  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:25 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.5331  loss_cls: 0.07747  loss_box_reg: 0.1947  loss_mask: 0.154  loss_rpn_cls: 0.005333  loss_rpn_loc: 0.06054  time: 0.1982  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:29 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.5528  loss_cls: 0.07279  loss_box_reg: 0.2113  loss_mask: 0.1405  loss_rpn_cls: 0.007048  loss_rpn_loc: 0.0807  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:33 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.4641  loss_cls: 0.05902  loss_box_reg: 0.2019  loss_mask: 0.1532  loss_rpn_cls: 0.008668  loss_rpn_loc: 0.05073  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:37 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.4277  loss_cls: 0.06568  loss_box_reg: 0.1786  loss_mask: 0.1406  loss_rpn_cls: 0.004942  loss_rpn_loc: 0.06178  time: 0.1983  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:41 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.5015  loss_cls: 0.07326  loss_box_reg: 0.1917  loss_mask: 0.13  loss_rpn_cls: 0.0068  loss_rpn_loc: 0.06748  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:46 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4825  loss_cls: 0.07285  loss_box_reg: 0.192  loss_mask: 0.1289  loss_rpn_cls: 0.006898  loss_rpn_loc: 0.07822  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:35:46 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:38 (0.1983 s / it)\n",
      "\u001b[32m[10/21 12:35:46 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='4RHFF8H_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:35:46 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:35:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:35:46 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:35:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:35:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0553 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.009689 (0.064829 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.056660 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/4RHFF8H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.614\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.486\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 34.056 | 61.382 | 33.615 | 32.903 | 35.427 | 48.606 |\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.593 | cushion    | 41.581 | door       | 19.454 |\n",
      "| indoor-plant | 46.064 | sofa       | 63.797 | table      | 6.848  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.563\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.823 | 56.292 | 23.647 | 24.380 | 24.616 | 63.004 |\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 17.206 | cushion    | 28.523 | door       | 34.491 |\n",
      "| indoor-plant | 41.988 | sofa       | 52.668 | table      | 4.059  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='4RHFF8H0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:35:48 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:35:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:35:48 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:35:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:35:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 41/355. 0.0571 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.0573 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 193/355. 0.0572 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.0572 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 340/355. 0.0570 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.739134 (0.067826 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.057027 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/4RHFF8H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.848 | 34.271 | 25.432 | 11.192 | 19.722 | 23.048 |\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.299 | cushion    | 69.058 | door       | 6.200 |\n",
      "| indoor-plant | 5.410 | sofa       | 52.746 | table      | 0.373 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:36:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:36:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "\u001b[32m[10/21 12:36:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:36:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.232\n",
      "\u001b[32m[10/21 12:36:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.448 | 33.855 | 18.314 | 10.815 | 22.038 | 15.189 |\n",
      "\u001b[32m[10/21 12:36:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.953 | cushion    | 70.789 | door       | 6.525 |\n",
      "| indoor-plant | 9.570 | sofa       | 33.730 | table      | 0.123 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='4RHFF8H1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:36:14 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:36:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:36:14 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:36:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:36:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 39/355. 0.0576 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 114/355. 0.0578 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 190/355. 0.0575 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 263/355. 0.0574 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.0575 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.948297 (0.068424 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057485 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/4RHFF8H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 12:36:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.399 | 33.654 | 25.435 | 11.307 | 20.726 | 22.211 |\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.659 | cushion    | 69.461 | door       | 6.163 |\n",
      "| indoor-plant | 4.972 | sofa       | 50.711 | table      | 0.429 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.644 | 33.315 | 20.357 | 10.966 | 22.560 | 16.635 |\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.884 | cushion    | 71.137 | door       | 6.897 |\n",
      "| indoor-plant | 8.467 | sofa       | 35.293 | table      | 0.187 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='4RHFF8H2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:36:39 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:36:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:36:39 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:36:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:36:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 32/355. 0.0576 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 12:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 107/355. 0.0572 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 184/355. 0.0571 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 12:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 258/355. 0.0570 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 330/355. 0.0570 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.972413 (0.068493 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.057030 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/4RHFF8H0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.347\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.465 | 34.711 | 24.947 | 10.931 | 21.019 | 22.049 |\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.517 | cushion    | 68.730 | door       | 7.658 |\n",
      "| indoor-plant | 5.284 | sofa       | 50.250 | table      | 0.353 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:37:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:37:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 12:37:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:37:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      "\u001b[32m[10/21 12:37:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.223 | 34.033 | 19.616 | 10.578 | 22.059 | 16.578 |\n",
      "\u001b[32m[10/21 12:37:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.062 | cushion    | 68.941 | door       | 7.811 |\n",
      "| indoor-plant | 8.758 | sofa       | 33.619 | table      | 0.145 |\n",
      "all results {'bbox': {'AP50': [34.27089454103863, 33.65386314175778, 34.71058672989717]}, 'segm': {'AP50': [33.85517478888496, 33.31478459977112, 34.0334599472701]}}\n",
      "dataset_name TI2K8M3\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json', name='TI2K8M3_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/TI2K8M30\n",
      "output_aug/500/TI2K8M30\n",
      "\u001b[32m[10/21 12:37:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:37:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "217 217\n",
      "\u001b[32m[10/21 12:37:06 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 12:37:06 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 40 images left.\n",
      "\u001b[32m[10/21 12:37:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:37:06 d2.data.common]: \u001b[0mSerializing 40 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:37:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:37:06 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:37:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:37:10 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.949  loss_cls: 1.985  loss_box_reg: 0.6547  loss_mask: 0.6944  loss_rpn_cls: 0.27  loss_rpn_loc: 0.2265  time: 0.1922  data_time: 0.0163  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:14 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 39  total_loss: 3.804  loss_cls: 1.726  loss_box_reg: 0.602  loss_mask: 0.6897  loss_rpn_cls: 0.2571  loss_rpn_loc: 0.2111  time: 0.1919  data_time: 0.0043  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:18 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 59  total_loss: 3.173  loss_cls: 1.23  loss_box_reg: 0.8039  loss_mask: 0.6855  loss_rpn_cls: 0.128  loss_rpn_loc: 0.2021  time: 0.1930  data_time: 0.0043  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:22 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 79  total_loss: 2.832  loss_cls: 0.8926  loss_box_reg: 0.5618  loss_mask: 0.6746  loss_rpn_cls: 0.1123  loss_rpn_loc: 0.2163  time: 0.1924  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:26 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 99  total_loss: 2.402  loss_cls: 0.6871  loss_box_reg: 0.6451  loss_mask: 0.6605  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.08917  time: 0.1930  data_time: 0.0043  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:30 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 119  total_loss: 2.433  loss_cls: 0.6578  loss_box_reg: 0.7205  loss_mask: 0.6445  loss_rpn_cls: 0.09362  loss_rpn_loc: 0.1653  time: 0.1934  data_time: 0.0043  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:33 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 139  total_loss: 2.33  loss_cls: 0.6543  loss_box_reg: 0.7827  loss_mask: 0.6429  loss_rpn_cls: 0.07309  loss_rpn_loc: 0.1563  time: 0.1936  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:37 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 2.129  loss_cls: 0.5798  loss_box_reg: 0.7128  loss_mask: 0.6063  loss_rpn_cls: 0.05927  loss_rpn_loc: 0.104  time: 0.1935  data_time: 0.0041  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:41 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 2.122  loss_cls: 0.5688  loss_box_reg: 0.796  loss_mask: 0.5932  loss_rpn_cls: 0.05971  loss_rpn_loc: 0.1446  time: 0.1939  data_time: 0.0042  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:45 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 2.045  loss_cls: 0.5203  loss_box_reg: 0.7881  loss_mask: 0.593  loss_rpn_cls: 0.05045  loss_rpn_loc: 0.1327  time: 0.1940  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:49 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 1.984  loss_cls: 0.4864  loss_box_reg: 0.7232  loss_mask: 0.5885  loss_rpn_cls: 0.04685  loss_rpn_loc: 0.1265  time: 0.1941  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:53 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 1.95  loss_cls: 0.434  loss_box_reg: 0.7624  loss_mask: 0.5141  loss_rpn_cls: 0.04463  loss_rpn_loc: 0.1562  time: 0.1945  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:37:57 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 1.765  loss_cls: 0.4268  loss_box_reg: 0.7888  loss_mask: 0.494  loss_rpn_cls: 0.04494  loss_rpn_loc: 0.1032  time: 0.1948  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:01 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 1.7  loss_cls: 0.3656  loss_box_reg: 0.6596  loss_mask: 0.4732  loss_rpn_cls: 0.03805  loss_rpn_loc: 0.09086  time: 0.1950  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:05 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 1.672  loss_cls: 0.3538  loss_box_reg: 0.7413  loss_mask: 0.4681  loss_rpn_cls: 0.03478  loss_rpn_loc: 0.12  time: 0.1953  data_time: 0.0044  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:09 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 1.443  loss_cls: 0.2865  loss_box_reg: 0.6772  loss_mask: 0.4306  loss_rpn_cls: 0.04038  loss_rpn_loc: 0.1171  time: 0.1954  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:13 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.388  loss_cls: 0.292  loss_box_reg: 0.7064  loss_mask: 0.3968  loss_rpn_cls: 0.03016  loss_rpn_loc: 0.07548  time: 0.1954  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:17 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.543  loss_cls: 0.3171  loss_box_reg: 0.6096  loss_mask: 0.4047  loss_rpn_cls: 0.02507  loss_rpn_loc: 0.1131  time: 0.1955  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:21 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.406  loss_cls: 0.2751  loss_box_reg: 0.5713  loss_mask: 0.3747  loss_rpn_cls: 0.02824  loss_rpn_loc: 0.1073  time: 0.1955  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:25 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.293  loss_cls: 0.2594  loss_box_reg: 0.5531  loss_mask: 0.3218  loss_rpn_cls: 0.03191  loss_rpn_loc: 0.1013  time: 0.1956  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:29 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.194  loss_cls: 0.2463  loss_box_reg: 0.5064  loss_mask: 0.3296  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.08272  time: 0.1957  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:33 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.264  loss_cls: 0.2516  loss_box_reg: 0.4847  loss_mask: 0.3832  loss_rpn_cls: 0.02306  loss_rpn_loc: 0.114  time: 0.1957  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:37 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.239  loss_cls: 0.213  loss_box_reg: 0.4785  loss_mask: 0.304  loss_rpn_cls: 0.02459  loss_rpn_loc: 0.09767  time: 0.1958  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:40 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.157  loss_cls: 0.2058  loss_box_reg: 0.5154  loss_mask: 0.3226  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.08874  time: 0.1958  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:46 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.153  loss_cls: 0.2283  loss_box_reg: 0.4602  loss_mask: 0.3084  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.09704  time: 0.1959  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:38:46 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:37 (0.1959 s / it)\n",
      "\u001b[32m[10/21 12:38:46 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='TI2K8M3_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:38:46 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:38:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:38:46 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:38:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:38:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0576 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.135769 (0.101154 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.060682 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TI2K8M30/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.499\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.026 | 49.873 | 21.941 | 19.564 | 32.257 | 34.783 |\n",
      "\u001b[32m[10/21 12:38:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 28.005 | cushion    | 35.756 | door       | 14.106 |\n",
      "| indoor-plant | 10.451 | sofa       | 71.064 | table      | 2.772  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:38:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:38:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 12:38:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:38:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.449\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730\n",
      "\u001b[32m[10/21 12:38:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.613 | 44.893 | 15.130 | 14.054 | 21.690 | 59.616 |\n",
      "\u001b[32m[10/21 12:38:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 22.494 | cushion    | 22.938 | door       | 35.825 |\n",
      "| indoor-plant | 13.359 | sofa       | 26.686 | table      | 2.376  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='TI2K8M30_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:38:50 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:38:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:38:50 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:38:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:38:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0686 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:38:57 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.0677 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 12:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.0658 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 12:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.0650 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 194/355. 0.0637 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 12:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 232/355. 0.0643 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.0646 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 305/355. 0.0650 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 12:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 341/355. 0.0652 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:39:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.740508 (0.124973 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:39:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.065334 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TI2K8M30/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.938 | 31.629 | 17.656 | 8.592 | 16.652 | 20.383 |\n",
      "\u001b[32m[10/21 12:39:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 7.568 | cushion    | 47.419 | door       | 11.143 |\n",
      "| indoor-plant | 0.615 | sofa       | 40.817 | table      | 0.068  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:39:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:39:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "\u001b[32m[10/21 12:39:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:39:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
      "\u001b[32m[10/21 12:39:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.229 | 31.201 | 23.328 | 9.061 | 19.917 | 22.848 |\n",
      "\u001b[32m[10/21 12:39:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.480 | cushion    | 60.625 | door       | 13.690 |\n",
      "| indoor-plant | 1.105 | sofa       | 40.396 | table      | 0.077  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='TI2K8M31_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:39:37 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:39:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:39:37 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:39:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:39:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0679 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 12:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.0674 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 12:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.0651 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 12:39:54 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.0648 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 12:39:59 d2.evaluation.evaluator]: \u001b[0mInference done 195/355. 0.0634 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 232/355. 0.0642 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.0649 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:40:15 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.0653 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:40:20 d2.evaluation.evaluator]: \u001b[0mInference done 347/355. 0.0654 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:40:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.442636 (0.121265 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:40:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.065424 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:40:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:40:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TI2K8M30/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:40:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:40:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:40:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 12:40:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:40:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.304\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
      "\u001b[32m[10/21 12:40:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.196 | 30.368 | 17.187 | 9.131 | 15.757 | 19.468 |\n",
      "\u001b[32m[10/21 12:40:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.769 | cushion    | 48.214 | door       | 12.809 |\n",
      "| indoor-plant | 0.538 | sofa       | 34.749 | table      | 0.094  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:40:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:40:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.51 seconds.\n",
      "\u001b[32m[10/21 12:40:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:40:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.299\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411\n",
      "\u001b[32m[10/21 12:40:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.849 | 29.877 | 23.534 | 9.517 | 19.589 | 21.645 |\n",
      "\u001b[32m[10/21 12:40:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.591 | cushion    | 61.186 | door       | 15.520 |\n",
      "| indoor-plant | 1.016 | sofa       | 35.696 | table      | 0.088  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='TI2K8M32_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:40:24 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:40:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:40:24 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:40:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:40:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:40:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0678 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.0671 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 12:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 84/355. 0.0656 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 12:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 126/355. 0.0646 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 12:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 177/355. 0.0633 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 12:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.0638 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.0642 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.0646 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:41:06 d2.evaluation.evaluator]: \u001b[0mInference done 312/355. 0.0650 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:41:11 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.0652 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:41:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.857398 (0.136735 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:41:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.065249 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:41:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:41:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TI2K8M30/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:41:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:41:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:41:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 12:41:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:41:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.434\n",
      "\u001b[32m[10/21 12:41:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.354 | 31.311 | 19.060 | 8.854 | 17.140 | 20.863 |\n",
      "\u001b[32m[10/21 12:41:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.435 | cushion    | 49.433 | door       | 13.367 |\n",
      "| indoor-plant | 0.712 | sofa       | 40.117 | table      | 0.059  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.37s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:41:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:41:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.64 seconds.\n",
      "\u001b[32m[10/21 12:41:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:41:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.441\n",
      "\u001b[32m[10/21 12:41:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.070 | 31.032 | 25.623 | 9.130 | 21.080 | 24.215 |\n",
      "\u001b[32m[10/21 12:41:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.577 | cushion    | 61.022 | door       | 16.706 |\n",
      "| indoor-plant | 1.210 | sofa       | 41.805 | table      | 0.102  |\n",
      "all results {'bbox': {'AP50': [31.628618250151273, 30.3682010457835, 31.310842040716874]}, 'segm': {'AP50': [31.20142763527281, 29.876769473117136, 31.031946579312358]}}\n",
      "dataset_name H58HEQV\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json', name='H58HEQV_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/H58HEQV0\n",
      "output_aug/800/H58HEQV0\n",
      "\u001b[32m[10/21 12:41:17 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:41:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "217 217\n",
      "\u001b[32m[10/21 12:41:17 d2.data.datasets.coco]: \u001b[0mLoaded 42 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 12:41:17 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 40 images left.\n",
      "\u001b[32m[10/21 12:41:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:41:17 d2.data.common]: \u001b[0mSerializing 40 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:41:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:41:17 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:41:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:41:21 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 19  total_loss: 3.671  loss_cls: 1.695  loss_box_reg: 0.6642  loss_mask: 0.6935  loss_rpn_cls: 0.2362  loss_rpn_loc: 0.2474  time: 0.1921  data_time: 0.0160  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:25 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 39  total_loss: 3.475  loss_cls: 1.473  loss_box_reg: 0.6103  loss_mask: 0.6907  loss_rpn_cls: 0.1538  loss_rpn_loc: 0.1845  time: 0.1924  data_time: 0.0042  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:29 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 59  total_loss: 3.117  loss_cls: 1.121  loss_box_reg: 0.7456  loss_mask: 0.6817  loss_rpn_cls: 0.2224  loss_rpn_loc: 0.2316  time: 0.1927  data_time: 0.0043  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:33 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 79  total_loss: 2.77  loss_cls: 0.7944  loss_box_reg: 0.6746  loss_mask: 0.67  loss_rpn_cls: 0.1381  loss_rpn_loc: 0.2218  time: 0.1933  data_time: 0.0040  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:36 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 99  total_loss: 2.402  loss_cls: 0.7027  loss_box_reg: 0.6924  loss_mask: 0.655  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.1588  time: 0.1933  data_time: 0.0040  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:40 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 119  total_loss: 2.409  loss_cls: 0.6938  loss_box_reg: 0.7612  loss_mask: 0.6361  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.1392  time: 0.1933  data_time: 0.0042  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:44 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 2.368  loss_cls: 0.6774  loss_box_reg: 0.8719  loss_mask: 0.6156  loss_rpn_cls: 0.064  loss_rpn_loc: 0.1658  time: 0.1938  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:48 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 159  total_loss: 2.203  loss_cls: 0.6002  loss_box_reg: 0.8228  loss_mask: 0.6043  loss_rpn_cls: 0.06508  loss_rpn_loc: 0.1725  time: 0.1940  data_time: 0.0042  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:52 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 179  total_loss: 2.12  loss_cls: 0.5307  loss_box_reg: 0.7914  loss_mask: 0.5889  loss_rpn_cls: 0.05192  loss_rpn_loc: 0.1498  time: 0.1940  data_time: 0.0040  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:41:56 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 199  total_loss: 2.028  loss_cls: 0.5177  loss_box_reg: 0.8239  loss_mask: 0.5428  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.1472  time: 0.1945  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:00 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 219  total_loss: 1.873  loss_cls: 0.4599  loss_box_reg: 0.7936  loss_mask: 0.5383  loss_rpn_cls: 0.04523  loss_rpn_loc: 0.09996  time: 0.1946  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:04 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 239  total_loss: 1.86  loss_cls: 0.4499  loss_box_reg: 0.7928  loss_mask: 0.4957  loss_rpn_cls: 0.03456  loss_rpn_loc: 0.1294  time: 0.1950  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:08 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 259  total_loss: 1.753  loss_cls: 0.3889  loss_box_reg: 0.7542  loss_mask: 0.4788  loss_rpn_cls: 0.03222  loss_rpn_loc: 0.1223  time: 0.1951  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:12 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 279  total_loss: 1.753  loss_cls: 0.3928  loss_box_reg: 0.7457  loss_mask: 0.4594  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.1086  time: 0.1953  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:16 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 299  total_loss: 1.587  loss_cls: 0.3533  loss_box_reg: 0.7101  loss_mask: 0.4301  loss_rpn_cls: 0.03726  loss_rpn_loc: 0.1223  time: 0.1955  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:20 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 319  total_loss: 1.55  loss_cls: 0.3176  loss_box_reg: 0.6958  loss_mask: 0.4127  loss_rpn_cls: 0.029  loss_rpn_loc: 0.104  time: 0.1958  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:24 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 339  total_loss: 1.388  loss_cls: 0.296  loss_box_reg: 0.6172  loss_mask: 0.3744  loss_rpn_cls: 0.02355  loss_rpn_loc: 0.1186  time: 0.1958  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:28 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 359  total_loss: 1.472  loss_cls: 0.3078  loss_box_reg: 0.6298  loss_mask: 0.3774  loss_rpn_cls: 0.02577  loss_rpn_loc: 0.1072  time: 0.1960  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:32 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 379  total_loss: 1.32  loss_cls: 0.2385  loss_box_reg: 0.5598  loss_mask: 0.3263  loss_rpn_cls: 0.035  loss_rpn_loc: 0.1136  time: 0.1961  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:36 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 1.269  loss_cls: 0.2541  loss_box_reg: 0.5073  loss_mask: 0.3544  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.09568  time: 0.1961  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:40 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 419  total_loss: 1.256  loss_cls: 0.2562  loss_box_reg: 0.545  loss_mask: 0.3662  loss_rpn_cls: 0.02523  loss_rpn_loc: 0.09347  time: 0.1962  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:44 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 439  total_loss: 1.158  loss_cls: 0.2397  loss_box_reg: 0.5148  loss_mask: 0.3057  loss_rpn_cls: 0.02285  loss_rpn_loc: 0.1025  time: 0.1963  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:48 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 1.2  loss_cls: 0.1996  loss_box_reg: 0.5043  loss_mask: 0.3068  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.09055  time: 0.1963  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:52 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 1.223  loss_cls: 0.225  loss_box_reg: 0.4989  loss_mask: 0.333  loss_rpn_cls: 0.02173  loss_rpn_loc: 0.1046  time: 0.1964  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:42:56 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.093  loss_cls: 0.21  loss_box_reg: 0.5042  loss_mask: 0.339  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.08219  time: 0.1966  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:00 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 1.095  loss_cls: 0.2042  loss_box_reg: 0.4705  loss_mask: 0.3222  loss_rpn_cls: 0.02728  loss_rpn_loc: 0.09805  time: 0.1967  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:04 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 1.073  loss_cls: 0.204  loss_box_reg: 0.4633  loss_mask: 0.3049  loss_rpn_cls: 0.0274  loss_rpn_loc: 0.08747  time: 0.1968  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:08 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 1.075  loss_cls: 0.1685  loss_box_reg: 0.4657  loss_mask: 0.3012  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.09158  time: 0.1968  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:12 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.951  loss_cls: 0.2072  loss_box_reg: 0.3979  loss_mask: 0.2639  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.09601  time: 0.1969  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:16 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.9996  loss_cls: 0.1897  loss_box_reg: 0.3998  loss_mask: 0.2873  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.07966  time: 0.1970  data_time: 0.0044  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:19 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 1.022  loss_cls: 0.1617  loss_box_reg: 0.4064  loss_mask: 0.2562  loss_rpn_cls: 0.01822  loss_rpn_loc: 0.08546  time: 0.1970  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:23 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.9853  loss_cls: 0.1456  loss_box_reg: 0.4027  loss_mask: 0.274  loss_rpn_cls: 0.02262  loss_rpn_loc: 0.0768  time: 0.1970  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:27 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.9351  loss_cls: 0.1536  loss_box_reg: 0.3176  loss_mask: 0.2846  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.08113  time: 0.1971  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:31 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.9315  loss_cls: 0.1406  loss_box_reg: 0.3214  loss_mask: 0.2542  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.0894  time: 0.1971  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:35 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.8751  loss_cls: 0.1568  loss_box_reg: 0.3312  loss_mask: 0.2328  loss_rpn_cls: 0.01912  loss_rpn_loc: 0.09005  time: 0.1971  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:39 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.8316  loss_cls: 0.1396  loss_box_reg: 0.3369  loss_mask: 0.258  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.08187  time: 0.1971  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:43 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.8977  loss_cls: 0.1579  loss_box_reg: 0.3528  loss_mask: 0.2748  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.07976  time: 0.1971  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:47 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.8048  loss_cls: 0.1269  loss_box_reg: 0.3157  loss_mask: 0.2438  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.08446  time: 0.1971  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:51 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.8054  loss_cls: 0.1402  loss_box_reg: 0.3231  loss_mask: 0.2513  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.03557  time: 0.1972  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:56 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.8636  loss_cls: 0.1465  loss_box_reg: 0.3327  loss_mask: 0.2541  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.09312  time: 0.1972  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:43:56 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:37 (0.1972 s / it)\n",
      "\u001b[32m[10/21 12:43:56 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='H58HEQV_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:43:56 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:43:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:43:56 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:43:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:43:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0564 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.746276 (0.088590 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.059755 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H58HEQV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.617\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.353\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.428\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 35.050 | 61.749 | 39.256 | 35.311 | 37.099 | 42.286 |\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 28.070 | cushion    | 37.874 | door       | 18.380 |\n",
      "| indoor-plant | 61.083 | sofa       | 63.069 | table      | 1.821  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.535 | 52.911 | 14.660 | 16.847 | 19.148 | 62.078 |\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 19.393 | cushion    | 21.275 | door       | 33.929 |\n",
      "| indoor-plant | 40.619 | sofa       | 24.936 | table      | 1.060  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='H58HEQV0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:44:00 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:44:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:44:00 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:44:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:44:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 19/355. 0.0645 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 12:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 68/355. 0.0625 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 12:44:12 d2.evaluation.evaluator]: \u001b[0mInference done 128/355. 0.0608 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 12:44:17 d2.evaluation.evaluator]: \u001b[0mInference done 191/355. 0.0600 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:44:22 d2.evaluation.evaluator]: \u001b[0mInference done 240/355. 0.0604 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 292/355. 0.0605 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 329/355. 0.0613 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 12:44:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.260365 (0.100744 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:44:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061628 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:44:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:44:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H58HEQV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:44:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:44:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:44:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 12:44:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:44:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.460\n",
      "\u001b[32m[10/21 12:44:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.754 | 34.612 | 21.137 | 13.106 | 19.422 | 21.631 |\n",
      "\u001b[32m[10/21 12:44:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 6.241  | cushion    | 49.464 | door       | 9.932 |\n",
      "| indoor-plant | 10.674 | sofa       | 42.133 | table      | 0.078 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:44:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:44:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/21 12:44:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:44:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.384\n",
      "\u001b[32m[10/21 12:44:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.335 | 33.805 | 22.175 | 10.399 | 23.319 | 23.608 |\n",
      "\u001b[32m[10/21 12:44:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.808  | cushion    | 58.441 | door       | 12.261 |\n",
      "| indoor-plant | 10.376 | sofa       | 37.085 | table      | 0.039  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='H58HEQV1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:44:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:44:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:44:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:44:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:44:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0639 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 12:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 59/355. 0.0625 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 12:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.0607 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.0602 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 222/355. 0.0602 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.0603 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:45:10 d2.evaluation.evaluator]: \u001b[0mInference done 302/355. 0.0611 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:45:15 d2.evaluation.evaluator]: \u001b[0mInference done 339/355. 0.0615 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.051932 (0.108720 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061639 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H58HEQV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.464\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.515 | 33.616 | 20.694 | 9.868 | 19.921 | 18.778 |\n",
      "\u001b[32m[10/21 12:45:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.532  | cushion    | 50.964 | door       | 10.561 |\n",
      "| indoor-plant | 10.024 | sofa       | 39.915 | table      | 0.095  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:45:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:45:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 12:45:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:45:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n",
      "\u001b[32m[10/21 12:45:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.388 | 32.894 | 23.532 | 8.873 | 23.429 | 20.878 |\n",
      "\u001b[32m[10/21 12:45:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.287 | cushion    | 59.696 | door       | 13.131 |\n",
      "| indoor-plant | 9.639 | sofa       | 36.536 | table      | 0.040  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='H58HEQV2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:45:19 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:45:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:45:19 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:45:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:45:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:45:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0638 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 12:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 63/355. 0.0618 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 12:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.0593 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 12:45:35 d2.evaluation.evaluator]: \u001b[0mInference done 198/355. 0.0584 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 12:45:40 d2.evaluation.evaluator]: \u001b[0mInference done 252/355. 0.0589 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:45:45 d2.evaluation.evaluator]: \u001b[0mInference done 300/355. 0.0595 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:45:50 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.0599 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:45:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:32.172988 (0.091923 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:45:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060089 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/H58HEQV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.484 | 35.208 | 22.059 | 9.923 | 20.519 | 21.360 |\n",
      "\u001b[32m[10/21 12:45:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.103  | cushion    | 50.648 | door       | 11.594 |\n",
      "| indoor-plant | 12.090 | sofa       | 43.385 | table      | 0.087  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:45:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:45:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 12:45:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:45:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\n",
      "\u001b[32m[10/21 12:45:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.065 | 34.025 | 23.842 | 8.904 | 23.653 | 22.627 |\n",
      "\u001b[32m[10/21 12:45:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.528  | cushion    | 59.265 | door       | 14.156 |\n",
      "| indoor-plant | 10.468 | sofa       | 38.934 | table      | 0.038  |\n",
      "all results {'bbox': {'AP50': [34.6116229806242, 33.61573213834627, 35.20794408770662]}, 'segm': {'AP50': [33.80531107261888, 32.89434135993009, 34.025138993576824]}}\n",
      "dataset_name 6W4SXE1\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json', name='6W4SXE1_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/6W4SXE10\n",
      "output_aug/500/6W4SXE10\n",
      "\u001b[32m[10/21 12:45:54 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:45:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "303 303\n",
      "\u001b[32m[10/21 12:45:54 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 12:45:54 d2.data.build]: \u001b[0mRemoved 4 images with no usable annotations. 56 images left.\n",
      "\u001b[32m[10/21 12:45:54 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 32           |  cushion   | 70           |    door    | 97           |\n",
      "| indoor-plant | 40           |    sofa    | 30           |   table    | 34           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 303          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 12:45:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:45:54 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:45:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:45:54 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:45:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:45:58 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.525  loss_cls: 1.814  loss_box_reg: 0.6748  loss_mask: 0.6893  loss_rpn_cls: 0.2179  loss_rpn_loc: 0.04857  time: 0.1940  data_time: 0.0230  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:02 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 39  total_loss: 2.524  loss_cls: 0.7763  loss_box_reg: 0.7496  loss_mask: 0.6618  loss_rpn_cls: 0.09114  loss_rpn_loc: 0.1996  time: 0.1976  data_time: 0.0044  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:06 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 59  total_loss: 2.254  loss_cls: 0.664  loss_box_reg: 0.8455  loss_mask: 0.626  loss_rpn_cls: 0.05639  loss_rpn_loc: 0.0464  time: 0.1974  data_time: 0.0042  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:10 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 79  total_loss: 1.864  loss_cls: 0.4691  loss_box_reg: 0.6942  loss_mask: 0.5252  loss_rpn_cls: 0.04264  loss_rpn_loc: 0.06533  time: 0.1969  data_time: 0.0040  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:14 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 99  total_loss: 1.923  loss_cls: 0.4197  loss_box_reg: 0.7294  loss_mask: 0.5041  loss_rpn_cls: 0.04207  loss_rpn_loc: 0.1178  time: 0.1967  data_time: 0.0040  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:18 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 119  total_loss: 1.332  loss_cls: 0.2633  loss_box_reg: 0.635  loss_mask: 0.3444  loss_rpn_cls: 0.02625  loss_rpn_loc: 0.04311  time: 0.1966  data_time: 0.0040  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:22 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 139  total_loss: 1.365  loss_cls: 0.2595  loss_box_reg: 0.5575  loss_mask: 0.345  loss_rpn_cls: 0.03889  loss_rpn_loc: 0.1208  time: 0.1969  data_time: 0.0041  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:26 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 1.106  loss_cls: 0.1951  loss_box_reg: 0.5512  loss_mask: 0.2735  loss_rpn_cls: 0.02625  loss_rpn_loc: 0.04643  time: 0.1972  data_time: 0.0042  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:30 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 0.9238  loss_cls: 0.1897  loss_box_reg: 0.4221  loss_mask: 0.2274  loss_rpn_cls: 0.02789  loss_rpn_loc: 0.06243  time: 0.1972  data_time: 0.0040  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:34 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 1.105  loss_cls: 0.1782  loss_box_reg: 0.4663  loss_mask: 0.289  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.1336  time: 0.1973  data_time: 0.0041  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:38 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 0.888  loss_cls: 0.1468  loss_box_reg: 0.393  loss_mask: 0.229  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.02813  time: 0.1975  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:42 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 0.8608  loss_cls: 0.157  loss_box_reg: 0.3286  loss_mask: 0.2321  loss_rpn_cls: 0.01943  loss_rpn_loc: 0.07746  time: 0.1975  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:46 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 0.7856  loss_cls: 0.1274  loss_box_reg: 0.3343  loss_mask: 0.2251  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.09002  time: 0.1977  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:50 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 0.9198  loss_cls: 0.1195  loss_box_reg: 0.3132  loss_mask: 0.2157  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.1075  time: 0.1977  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:54 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 0.6854  loss_cls: 0.1028  loss_box_reg: 0.3088  loss_mask: 0.1775  loss_rpn_cls: 0.008602  loss_rpn_loc: 0.06446  time: 0.1977  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:46:58 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.5591  loss_cls: 0.09293  loss_box_reg: 0.2653  loss_mask: 0.1666  loss_rpn_cls: 0.004905  loss_rpn_loc: 0.08084  time: 0.1977  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:02 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.7225  loss_cls: 0.1011  loss_box_reg: 0.3032  loss_mask: 0.2052  loss_rpn_cls: 0.008493  loss_rpn_loc: 0.09535  time: 0.1978  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:06 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.6609  loss_cls: 0.1044  loss_box_reg: 0.2709  loss_mask: 0.1693  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.09106  time: 0.1978  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:10 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.5836  loss_cls: 0.09509  loss_box_reg: 0.228  loss_mask: 0.1968  loss_rpn_cls: 0.008892  loss_rpn_loc: 0.09445  time: 0.1977  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:14 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.5974  loss_cls: 0.0861  loss_box_reg: 0.2276  loss_mask: 0.1745  loss_rpn_cls: 0.009425  loss_rpn_loc: 0.08562  time: 0.1977  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:18 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.6552  loss_cls: 0.1023  loss_box_reg: 0.2788  loss_mask: 0.1459  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.05874  time: 0.1979  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:22 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.5811  loss_cls: 0.08212  loss_box_reg: 0.2037  loss_mask: 0.1625  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.08616  time: 0.1979  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:26 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.686  loss_cls: 0.09861  loss_box_reg: 0.2969  loss_mask: 0.1955  loss_rpn_cls: 0.009793  loss_rpn_loc: 0.06805  time: 0.1979  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:30 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.4962  loss_cls: 0.06685  loss_box_reg: 0.2091  loss_mask: 0.1335  loss_rpn_cls: 0.006196  loss_rpn_loc: 0.03479  time: 0.1980  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:35 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.57  loss_cls: 0.07798  loss_box_reg: 0.2371  loss_mask: 0.1793  loss_rpn_cls: 0.006622  loss_rpn_loc: 0.07317  time: 0.1981  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:47:35 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:38 (0.1981 s / it)\n",
      "\u001b[32m[10/21 12:47:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:40 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='6W4SXE1_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:47:35 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:47:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:47:35 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:47:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:47:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0549 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.049444 (0.066111 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.055452 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6W4SXE10/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.566\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.347\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.709 | 56.611 | 34.706 | 26.450 | 36.422 | 35.197 |\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 21.265 | cushion    | 40.986 | door       | 14.672 |\n",
      "| indoor-plant | 51.898 | sofa       | 59.219 | table      | 2.215  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.500\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.196 | 50.047 | 18.372 | 17.449 | 25.116 | 33.374 |\n",
      "\u001b[32m[10/21 12:47:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 7.810  | cushion    | 21.111 | door       | 28.328 |\n",
      "| indoor-plant | 44.901 | sofa       | 46.781 | table      | 2.244  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='6W4SXE10_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:47:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:47:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:47:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:47:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:47:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 34/355. 0.0591 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 12:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0574 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 12:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.0573 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 248/355. 0.0570 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 12:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 307/355. 0.0572 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 12:48:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.047796 (0.077279 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:48:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057882 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:48:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:48:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6W4SXE10/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:48:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:48:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.202 | 29.418 | 24.789 | 10.441 | 18.201 | 20.964 |\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 2.888 | cushion    | 62.667 | door       | 10.285 |\n",
      "| indoor-plant | 0.960 | sofa       | 44.342 | table      | 0.067  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.201 | 28.577 | 16.761 | 10.692 | 17.602 | 10.946 |\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.358 | cushion    | 68.975 | door       | 5.700 |\n",
      "| indoor-plant | 0.624 | sofa       | 19.407 | table      | 0.140 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='6W4SXE11_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:48:06 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:48:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:48:06 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:48:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:48:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:48:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0589 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 12:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 70/355. 0.0583 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 12:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 141/355. 0.0574 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.0569 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 278/355. 0.0571 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 337/355. 0.0572 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.641041 (0.078974 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057359 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6W4SXE10/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.457 | 28.649 | 24.264 | 11.193 | 18.224 | 17.949 |\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 2.866 | cushion    | 64.285 | door       | 10.664 |\n",
      "| indoor-plant | 0.745 | sofa       | 38.086 | table      | 0.094  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:48:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:48:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 12:48:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:48:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "\u001b[32m[10/21 12:48:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.259 | 27.568 | 16.946 | 11.044 | 17.291 | 12.190 |\n",
      "\u001b[32m[10/21 12:48:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.463 | cushion    | 69.959 | door       | 7.541 |\n",
      "| indoor-plant | 0.438 | sofa       | 17.040 | table      | 0.110 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='6W4SXE12_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:48:36 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:48:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:48:36 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:48:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:48:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 20/355. 0.0594 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 12:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.0581 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 12:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 160/355. 0.0576 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 234/355. 0.0573 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 12:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 292/355. 0.0575 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 350/355. 0.0576 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.231730 (0.077805 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057690 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/6W4SXE10/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.381\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.368 | 29.825 | 24.702 | 11.061 | 18.543 | 19.339 |\n",
      "\u001b[32m[10/21 12:49:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.089 | cushion    | 63.455 | door       | 10.752 |\n",
      "| indoor-plant | 0.883 | sofa       | 43.986 | table      | 0.042  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:49:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:49:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 12:49:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:49:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      "\u001b[32m[10/21 12:49:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.498 | 28.499 | 17.486 | 10.923 | 17.419 | 13.048 |\n",
      "\u001b[32m[10/21 12:49:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.786 | cushion    | 69.250 | door       | 6.798 |\n",
      "| indoor-plant | 0.530 | sofa       | 19.467 | table      | 0.154 |\n",
      "all results {'bbox': {'AP50': [29.41781813110469, 28.64892977852158, 29.824595639333744]}, 'segm': {'AP50': [28.57680493189456, 27.567683381235454, 28.49923969211574]}}\n",
      "dataset_name RW8FZ35\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json', name='RW8FZ35_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/RW8FZ350\n",
      "output_aug/800/RW8FZ350\n",
      "\u001b[32m[10/21 12:49:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:49:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "303 303\n",
      "\u001b[32m[10/21 12:49:06 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 12:49:06 d2.data.build]: \u001b[0mRemoved 4 images with no usable annotations. 56 images left.\n",
      "\u001b[32m[10/21 12:49:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:49:06 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:49:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:49:06 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:49:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:49:10 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 19  total_loss: 3.604  loss_cls: 1.797  loss_box_reg: 0.7596  loss_mask: 0.6926  loss_rpn_cls: 0.1619  loss_rpn_loc: 0.2257  time: 0.1913  data_time: 0.0167  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:14 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 39  total_loss: 2.527  loss_cls: 0.7808  loss_box_reg: 0.6724  loss_mask: 0.6738  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.1489  time: 0.1929  data_time: 0.0041  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:18 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 59  total_loss: 2.207  loss_cls: 0.6713  loss_box_reg: 0.8209  loss_mask: 0.6109  loss_rpn_cls: 0.05053  loss_rpn_loc: 0.0397  time: 0.1941  data_time: 0.0042  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:22 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 79  total_loss: 2.164  loss_cls: 0.5604  loss_box_reg: 0.8101  loss_mask: 0.6079  loss_rpn_cls: 0.05031  loss_rpn_loc: 0.1542  time: 0.1949  data_time: 0.0043  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:26 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 99  total_loss: 1.683  loss_cls: 0.3756  loss_box_reg: 0.6947  loss_mask: 0.4459  loss_rpn_cls: 0.04286  loss_rpn_loc: 0.1423  time: 0.1952  data_time: 0.0042  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:30 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 119  total_loss: 1.441  loss_cls: 0.313  loss_box_reg: 0.6418  loss_mask: 0.362  loss_rpn_cls: 0.03344  loss_rpn_loc: 0.1197  time: 0.1959  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:34 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 139  total_loss: 1.286  loss_cls: 0.2296  loss_box_reg: 0.5701  loss_mask: 0.2987  loss_rpn_cls: 0.01958  loss_rpn_loc: 0.1245  time: 0.1965  data_time: 0.0042  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:38 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 159  total_loss: 1.22  loss_cls: 0.2155  loss_box_reg: 0.4857  loss_mask: 0.2535  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.1142  time: 0.1969  data_time: 0.0042  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:42 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 179  total_loss: 1.011  loss_cls: 0.1638  loss_box_reg: 0.4401  loss_mask: 0.2767  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.0697  time: 0.1970  data_time: 0.0041  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:46 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 199  total_loss: 1.097  loss_cls: 0.1839  loss_box_reg: 0.4367  loss_mask: 0.2996  loss_rpn_cls: 0.02252  loss_rpn_loc: 0.115  time: 0.1972  data_time: 0.0041  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:50 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 219  total_loss: 0.8239  loss_cls: 0.1495  loss_box_reg: 0.3686  loss_mask: 0.1848  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.05553  time: 0.1974  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:54 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 239  total_loss: 0.7958  loss_cls: 0.1256  loss_box_reg: 0.3492  loss_mask: 0.2415  loss_rpn_cls: 0.01498  loss_rpn_loc: 0.0464  time: 0.1976  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:49:58 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 259  total_loss: 0.7837  loss_cls: 0.1292  loss_box_reg: 0.3253  loss_mask: 0.2198  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.117  time: 0.1978  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:02 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 279  total_loss: 0.8472  loss_cls: 0.129  loss_box_reg: 0.333  loss_mask: 0.1899  loss_rpn_cls: 0.01197  loss_rpn_loc: 0.1188  time: 0.1981  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:06 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 299  total_loss: 0.7987  loss_cls: 0.1112  loss_box_reg: 0.3168  loss_mask: 0.1987  loss_rpn_cls: 0.0188  loss_rpn_loc: 0.1185  time: 0.1981  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:10 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 319  total_loss: 0.6607  loss_cls: 0.09575  loss_box_reg: 0.269  loss_mask: 0.185  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.07644  time: 0.1982  data_time: 0.0044  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:14 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 339  total_loss: 0.6014  loss_cls: 0.09005  loss_box_reg: 0.2763  loss_mask: 0.1717  loss_rpn_cls: 0.007323  loss_rpn_loc: 0.03404  time: 0.1982  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:18 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 359  total_loss: 0.6612  loss_cls: 0.09678  loss_box_reg: 0.256  loss_mask: 0.199  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.09872  time: 0.1982  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:22 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 379  total_loss: 0.7081  loss_cls: 0.1255  loss_box_reg: 0.2748  loss_mask: 0.2097  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.0666  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:26 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 399  total_loss: 0.6656  loss_cls: 0.08843  loss_box_reg: 0.2716  loss_mask: 0.1868  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.08583  time: 0.1984  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:30 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 419  total_loss: 0.5782  loss_cls: 0.079  loss_box_reg: 0.2336  loss_mask: 0.16  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.04679  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:34 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 439  total_loss: 0.5746  loss_cls: 0.09048  loss_box_reg: 0.2448  loss_mask: 0.1655  loss_rpn_cls: 0.01155  loss_rpn_loc: 0.07064  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:38 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 459  total_loss: 0.6155  loss_cls: 0.09056  loss_box_reg: 0.2334  loss_mask: 0.1806  loss_rpn_cls: 0.01107  loss_rpn_loc: 0.08539  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:42 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 479  total_loss: 0.5549  loss_cls: 0.07822  loss_box_reg: 0.2315  loss_mask: 0.1673  loss_rpn_cls: 0.006447  loss_rpn_loc: 0.08441  time: 0.1983  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:46 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 499  total_loss: 0.5617  loss_cls: 0.08399  loss_box_reg: 0.2289  loss_mask: 0.1548  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.07928  time: 0.1983  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:50 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 519  total_loss: 0.547  loss_cls: 0.0766  loss_box_reg: 0.2383  loss_mask: 0.1523  loss_rpn_cls: 0.007057  loss_rpn_loc: 0.07553  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:54 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 0.5976  loss_cls: 0.0902  loss_box_reg: 0.1819  loss_mask: 0.1636  loss_rpn_cls: 0.02049  loss_rpn_loc: 0.08732  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:50:58 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 0.5825  loss_cls: 0.07283  loss_box_reg: 0.2199  loss_mask: 0.1642  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.07219  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:02 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.5893  loss_cls: 0.08814  loss_box_reg: 0.224  loss_mask: 0.1454  loss_rpn_cls: 0.00796  loss_rpn_loc: 0.02228  time: 0.1982  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:06 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.5809  loss_cls: 0.08673  loss_box_reg: 0.2229  loss_mask: 0.1619  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.07362  time: 0.1982  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:10 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.5637  loss_cls: 0.08291  loss_box_reg: 0.2285  loss_mask: 0.1472  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.04958  time: 0.1981  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:14 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.5041  loss_cls: 0.05813  loss_box_reg: 0.1956  loss_mask: 0.137  loss_rpn_cls: 0.007209  loss_rpn_loc: 0.06661  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:18 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.4981  loss_cls: 0.07885  loss_box_reg: 0.1834  loss_mask: 0.1446  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.0659  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:22 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.5338  loss_cls: 0.08025  loss_box_reg: 0.2482  loss_mask: 0.1448  loss_rpn_cls: 0.006606  loss_rpn_loc: 0.05361  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:26 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.5656  loss_cls: 0.06872  loss_box_reg: 0.2149  loss_mask: 0.132  loss_rpn_cls: 0.008249  loss_rpn_loc: 0.06259  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:30 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.4854  loss_cls: 0.07612  loss_box_reg: 0.208  loss_mask: 0.1354  loss_rpn_cls: 0.005758  loss_rpn_loc: 0.06527  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:34 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.51  loss_cls: 0.06955  loss_box_reg: 0.2049  loss_mask: 0.1409  loss_rpn_cls: 0.00585  loss_rpn_loc: 0.07617  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:38 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.5359  loss_cls: 0.06969  loss_box_reg: 0.2218  loss_mask: 0.1447  loss_rpn_cls: 0.0072  loss_rpn_loc: 0.07285  time: 0.1983  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:42 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.4161  loss_cls: 0.06644  loss_box_reg: 0.1754  loss_mask: 0.1277  loss_rpn_cls: 0.00648  loss_rpn_loc: 0.0452  time: 0.1983  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:47 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4178  loss_cls: 0.0556  loss_box_reg: 0.1723  loss_mask: 0.1149  loss_rpn_cls: 0.005023  loss_rpn_loc: 0.03869  time: 0.1984  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:51:47 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:38 (0.1984 s / it)\n",
      "\u001b[32m[10/21 12:51:47 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='RW8FZ35_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:51:47 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:51:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:51:47 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:51:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:51:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:51:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0569 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.016194 (0.065039 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057205 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/RW8FZ350/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.570\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 32.291 | 57.038 | 34.243 | 27.611 | 36.660 | 35.666 |\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 28.691 | cushion    | 44.651 | door       | 16.648 |\n",
      "| indoor-plant | 42.822 | sofa       | 55.515 | table      | 5.416  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.534\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.587\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.860 | 53.379 | 18.332 | 19.390 | 23.430 | 45.603 |\n",
      "\u001b[32m[10/21 12:51:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 15.757 | cushion    | 29.081 | door       | 27.955 |\n",
      "| indoor-plant | 34.776 | sofa       | 46.347 | table      | 1.246  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='RW8FZ350_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:51:50 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:51:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:51:50 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:51:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:51:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:51:53 d2.evaluation.evaluator]: \u001b[0mInference done 40/355. 0.0571 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:51:58 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.0573 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 195/355. 0.0573 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.0571 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 343/355. 0.0572 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.591663 (0.067405 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057243 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/RW8FZ350/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.013 | 30.331 | 25.752 | 13.878 | 17.935 | 21.775 |\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.924 | cushion    | 66.104 | door       | 8.495 |\n",
      "| indoor-plant | 1.459 | sofa       | 54.079 | table      | 0.019 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.129 | 29.659 | 20.755 | 11.013 | 17.976 | 15.623 |\n",
      "\u001b[32m[10/21 12:52:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.258 | cushion    | 69.115 | door       | 7.381 |\n",
      "| indoor-plant | 1.943 | sofa       | 34.861 | table      | 0.217 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='RW8FZ351_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:52:15 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:52:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:52:15 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:52:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:52:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 42/355. 0.0571 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 12:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 119/355. 0.0568 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 12:52:28 d2.evaluation.evaluator]: \u001b[0mInference done 198/355. 0.0569 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:52:33 d2.evaluation.evaluator]: \u001b[0mInference done 272/355. 0.0570 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:52:38 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.0571 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.646503 (0.067561 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.057058 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/RW8FZ350/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.556 | 30.038 | 25.249 | 10.749 | 19.029 | 19.601 |\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.682 | cushion    | 67.052 | door       | 8.679 |\n",
      "| indoor-plant | 1.447 | sofa       | 50.439 | table      | 0.034 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:52:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:52:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 12:52:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:52:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
      "\u001b[32m[10/21 12:52:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.495 | 28.872 | 22.761 | 10.806 | 18.682 | 15.364 |\n",
      "\u001b[32m[10/21 12:52:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.973 | cushion    | 70.287 | door       | 8.528 |\n",
      "| indoor-plant | 1.601 | sofa       | 35.219 | table      | 0.361 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='RW8FZ352_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:52:40 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:52:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:52:40 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:52:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:52:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 42/355. 0.0573 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 12:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.0574 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 12:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 195/355. 0.0572 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 12:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.0571 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.0571 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.287719 (0.069393 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.057130 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/RW8FZ350/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.368 | 30.574 | 25.244 | 10.329 | 18.519 | 19.824 |\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 1.349 | cushion    | 64.750 | door       | 10.260 |\n",
      "| indoor-plant | 1.234 | sofa       | 50.595 | table      | 0.021  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.850 | 29.343 | 21.453 | 10.467 | 18.432 | 14.941 |\n",
      "\u001b[32m[10/21 12:53:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.034 | cushion    | 67.817 | door       | 8.693 |\n",
      "| indoor-plant | 1.932 | sofa       | 33.422 | table      | 0.202 |\n",
      "all results {'bbox': {'AP50': [30.331062907749136, 30.037849540732008, 30.574495502515347]}, 'segm': {'AP50': [29.65922945335691, 28.872434841394266, 29.343471226066864]}}\n",
      "dataset_name ETXMDCL\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json', name='ETXMDCL_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/ETXMDCL0\n",
      "output_aug/500/ETXMDCL0\n",
      "\u001b[32m[10/21 12:53:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:53:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "303 303\n",
      "\u001b[32m[10/21 12:53:06 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 12:53:06 d2.data.build]: \u001b[0mRemoved 4 images with no usable annotations. 56 images left.\n",
      "\u001b[32m[10/21 12:53:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:53:06 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:53:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:53:06 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:53:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:53:11 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.938  loss_cls: 1.926  loss_box_reg: 0.7846  loss_mask: 0.6928  loss_rpn_cls: 0.2371  loss_rpn_loc: 0.2404  time: 0.1920  data_time: 0.0168  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:15 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 39  total_loss: 3.671  loss_cls: 1.674  loss_box_reg: 0.6238  loss_mask: 0.6906  loss_rpn_cls: 0.1844  loss_rpn_loc: 0.234  time: 0.1925  data_time: 0.0040  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:19 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 59  total_loss: 3.209  loss_cls: 1.218  loss_box_reg: 0.7715  loss_mask: 0.6832  loss_rpn_cls: 0.2646  loss_rpn_loc: 0.09199  time: 0.1931  data_time: 0.0041  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:22 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 79  total_loss: 2.489  loss_cls: 0.8226  loss_box_reg: 0.6588  loss_mask: 0.6693  loss_rpn_cls: 0.08712  loss_rpn_loc: 0.1307  time: 0.1925  data_time: 0.0040  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:26 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 99  total_loss: 2.422  loss_cls: 0.7208  loss_box_reg: 0.7355  loss_mask: 0.6466  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.1326  time: 0.1927  data_time: 0.0041  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:30 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 119  total_loss: 2.507  loss_cls: 0.7008  loss_box_reg: 0.789  loss_mask: 0.6333  loss_rpn_cls: 0.06421  loss_rpn_loc: 0.2097  time: 0.1933  data_time: 0.0040  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:34 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 2.331  loss_cls: 0.6708  loss_box_reg: 0.8499  loss_mask: 0.6146  loss_rpn_cls: 0.05995  loss_rpn_loc: 0.1943  time: 0.1939  data_time: 0.0040  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:38 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 2.261  loss_cls: 0.6325  loss_box_reg: 0.7958  loss_mask: 0.6228  loss_rpn_cls: 0.08103  loss_rpn_loc: 0.1862  time: 0.1940  data_time: 0.0042  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:42 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 2.188  loss_cls: 0.5777  loss_box_reg: 0.8322  loss_mask: 0.5718  loss_rpn_cls: 0.03345  loss_rpn_loc: 0.1569  time: 0.1949  data_time: 0.0042  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:46 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 2.116  loss_cls: 0.5192  loss_box_reg: 0.8399  loss_mask: 0.5784  loss_rpn_cls: 0.0404  loss_rpn_loc: 0.08775  time: 0.1954  data_time: 0.0043  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:50 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 1.994  loss_cls: 0.4956  loss_box_reg: 0.7912  loss_mask: 0.5416  loss_rpn_cls: 0.0466  loss_rpn_loc: 0.09613  time: 0.1954  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:54 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 1.981  loss_cls: 0.4761  loss_box_reg: 0.795  loss_mask: 0.5144  loss_rpn_cls: 0.04164  loss_rpn_loc: 0.1293  time: 0.1956  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:53:58 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 259  total_loss: 1.796  loss_cls: 0.4208  loss_box_reg: 0.7664  loss_mask: 0.4621  loss_rpn_cls: 0.03209  loss_rpn_loc: 0.07633  time: 0.1957  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:02 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 1.666  loss_cls: 0.373  loss_box_reg: 0.6948  loss_mask: 0.4526  loss_rpn_cls: 0.03007  loss_rpn_loc: 0.04922  time: 0.1959  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:06 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 1.569  loss_cls: 0.3427  loss_box_reg: 0.6982  loss_mask: 0.4332  loss_rpn_cls: 0.03002  loss_rpn_loc: 0.06126  time: 0.1961  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:10 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 1.77  loss_cls: 0.3624  loss_box_reg: 0.7054  loss_mask: 0.4699  loss_rpn_cls: 0.0284  loss_rpn_loc: 0.09327  time: 0.1963  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:14 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.383  loss_cls: 0.2529  loss_box_reg: 0.6422  loss_mask: 0.3905  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.07312  time: 0.1962  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:18 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.383  loss_cls: 0.2733  loss_box_reg: 0.5954  loss_mask: 0.3733  loss_rpn_cls: 0.03026  loss_rpn_loc: 0.1231  time: 0.1964  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:22 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.512  loss_cls: 0.3172  loss_box_reg: 0.6304  loss_mask: 0.4202  loss_rpn_cls: 0.03647  loss_rpn_loc: 0.1191  time: 0.1965  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:26 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.149  loss_cls: 0.2265  loss_box_reg: 0.4771  loss_mask: 0.3068  loss_rpn_cls: 0.02351  loss_rpn_loc: 0.09746  time: 0.1966  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:30 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.334  loss_cls: 0.2707  loss_box_reg: 0.5045  loss_mask: 0.3607  loss_rpn_cls: 0.02734  loss_rpn_loc: 0.1136  time: 0.1966  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:34 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.147  loss_cls: 0.2305  loss_box_reg: 0.4925  loss_mask: 0.31  loss_rpn_cls: 0.02894  loss_rpn_loc: 0.0731  time: 0.1967  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:38 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.295  loss_cls: 0.2602  loss_box_reg: 0.5642  loss_mask: 0.3553  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.1099  time: 0.1967  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:42 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.141  loss_cls: 0.2133  loss_box_reg: 0.4622  loss_mask: 0.3153  loss_rpn_cls: 0.02724  loss_rpn_loc: 0.0998  time: 0.1967  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:47 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.063  loss_cls: 0.1891  loss_box_reg: 0.4864  loss_mask: 0.3081  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.08638  time: 0.1967  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:54:47 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:37 (0.1967 s / it)\n",
      "\u001b[32m[10/21 12:54:47 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='ETXMDCL_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:54:47 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:54:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:54:47 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:54:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:54:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0572 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.863274 (0.092364 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.060363 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ETXMDCL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.516\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.557\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.398 | 51.630 | 18.230 | 18.972 | 24.805 | 41.652 |\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 23.152 | cushion    | 34.468 | door       | 15.037 |\n",
      "| indoor-plant | 13.028 | sofa       | 52.720 | table      | 1.980  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.466\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.757\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.036 | 46.633 | 12.352 | 15.307 | 17.174 | 64.783 |\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 20.397 | cushion    | 23.578 | door       | 36.006 |\n",
      "| indoor-plant | 15.593 | sofa       | 24.643 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='ETXMDCL0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:54:50 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:54:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:54:50 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:54:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:54:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0683 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.0699 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 12:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.0670 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 12:55:08 d2.evaluation.evaluator]: \u001b[0mInference done 138/355. 0.0660 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 194/355. 0.0642 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 12:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 232/355. 0.0645 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.0646 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 306/355. 0.0650 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.0651 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:55:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.045302 (0.125844 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:55:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.065254 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ETXMDCL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.728 | 32.226 | 14.800 | 8.351 | 19.788 | 18.457 |\n",
      "\u001b[32m[10/21 12:55:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 10.146 | cushion    | 43.011 | door       | 13.566 |\n",
      "| indoor-plant | 1.630  | sofa       | 31.762 | table      | 0.254  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:55:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:55:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "\u001b[32m[10/21 12:55:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:55:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
      "\u001b[32m[10/21 12:55:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.593 | 30.760 | 21.811 | 7.829 | 23.453 | 23.547 |\n",
      "\u001b[32m[10/21 12:55:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.908 | cushion    | 55.733 | door       | 18.071 |\n",
      "| indoor-plant | 1.506 | sofa       | 35.341 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='ETXMDCL1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 12:55:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 12:55:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:55:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:55:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 12:55:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:55:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0683 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 47/355. 0.0679 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 12:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.0662 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 12:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 136/355. 0.0650 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 12:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 194/355. 0.0632 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 232/355. 0.0638 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 12:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 273/355. 0.0640 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 309/355. 0.0644 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 12:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 348/355. 0.0645 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 12:56:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.419526 (0.121199 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:56:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064554 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:56:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:56:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ETXMDCL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:56:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:56:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:56:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 12:56:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:56:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.404\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n",
      "\u001b[32m[10/21 12:56:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.302 | 32.175 | 15.329 | 8.489 | 20.105 | 17.554 |\n",
      "\u001b[32m[10/21 12:56:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 9.710 | cushion    | 43.505 | door       | 15.113 |\n",
      "| indoor-plant | 1.595 | sofa       | 33.833 | table      | 0.058  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:56:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:56:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.49 seconds.\n",
      "\u001b[32m[10/21 12:56:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:56:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
      "\u001b[32m[10/21 12:56:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.922 | 31.057 | 23.615 | 8.038 | 24.931 | 21.790 |\n",
      "\u001b[32m[10/21 12:56:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.646 | cushion    | 56.432 | door       | 18.968 |\n",
      "| indoor-plant | 1.391 | sofa       | 36.096 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='ETXMDCL2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 12:56:25 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 12:56:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:56:25 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:56:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 12:56:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 12:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0695 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 12:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 44/355. 0.0680 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 12:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.0659 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 12:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 124/355. 0.0648 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 12:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 178/355. 0.0630 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 12:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 213/355. 0.0636 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 12:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.0640 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 12:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.0644 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 12:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 319/355. 0.0648 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 12:57:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.448497 (0.132710 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:57:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064897 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:57:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:57:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/ETXMDCL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:57:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:57:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:57:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 12:57:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:57:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.418\n",
      "\u001b[32m[10/21 12:57:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.884 | 33.321 | 16.086 | 8.187 | 21.566 | 17.819 |\n",
      "\u001b[32m[10/21 12:57:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 9.698 | cushion    | 43.606 | door       | 15.442 |\n",
      "| indoor-plant | 1.939 | sofa       | 36.573 | table      | 0.049  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:57:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:57:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.51 seconds.\n",
      "\u001b[32m[10/21 12:57:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:57:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[10/21 12:57:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.700 | 32.221 | 24.218 | 7.873 | 25.426 | 23.713 |\n",
      "\u001b[32m[10/21 12:57:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.912 | cushion    | 55.842 | door       | 19.474 |\n",
      "| indoor-plant | 1.730 | sofa       | 40.240 | table      | 0.000  |\n",
      "all results {'bbox': {'AP50': [32.22590925101609, 32.17541549909211, 33.32114081219615]}, 'segm': {'AP50': [30.76033300247853, 31.057374291695982, 32.22141538437444]}}\n",
      "dataset_name Y2008LS\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json', name='Y2008LS_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/Y2008LS0\n",
      "output_aug/800/Y2008LS0\n",
      "\u001b[32m[10/21 12:57:16 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 12:57:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "303 303\n",
      "\u001b[32m[10/21 12:57:16 d2.data.datasets.coco]: \u001b[0mLoaded 60 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p6/coco_train.json\n",
      "\u001b[32m[10/21 12:57:16 d2.data.build]: \u001b[0mRemoved 4 images with no usable annotations. 56 images left.\n",
      "\u001b[32m[10/21 12:57:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 12:57:16 d2.data.common]: \u001b[0mSerializing 56 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:57:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 12:57:16 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 12:57:16 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 12:57:20 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 19  total_loss: 3.822  loss_cls: 1.955  loss_box_reg: 0.8196  loss_mask: 0.694  loss_rpn_cls: 0.2158  loss_rpn_loc: 0.2283  time: 0.1923  data_time: 0.0173  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:24 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 39  total_loss: 3.514  loss_cls: 1.687  loss_box_reg: 0.6528  loss_mask: 0.6916  loss_rpn_cls: 0.1963  loss_rpn_loc: 0.2308  time: 0.1927  data_time: 0.0040  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:28 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 59  total_loss: 2.969  loss_cls: 1.195  loss_box_reg: 0.6308  loss_mask: 0.6833  loss_rpn_cls: 0.1621  loss_rpn_loc: 0.1474  time: 0.1918  data_time: 0.0043  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:32 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 79  total_loss: 2.598  loss_cls: 0.8422  loss_box_reg: 0.6747  loss_mask: 0.6734  loss_rpn_cls: 0.0881  loss_rpn_loc: 0.1681  time: 0.1930  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:36 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 99  total_loss: 2.552  loss_cls: 0.726  loss_box_reg: 0.8239  loss_mask: 0.6631  loss_rpn_cls: 0.05779  loss_rpn_loc: 0.2139  time: 0.1930  data_time: 0.0042  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:40 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 119  total_loss: 2.432  loss_cls: 0.6716  loss_box_reg: 0.7998  loss_mask: 0.6391  loss_rpn_cls: 0.05522  loss_rpn_loc: 0.0587  time: 0.1937  data_time: 0.0041  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:44 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 2.287  loss_cls: 0.6045  loss_box_reg: 0.8057  loss_mask: 0.6073  loss_rpn_cls: 0.05306  loss_rpn_loc: 0.127  time: 0.1942  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:48 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 159  total_loss: 2.268  loss_cls: 0.5891  loss_box_reg: 0.8695  loss_mask: 0.5853  loss_rpn_cls: 0.04767  loss_rpn_loc: 0.1291  time: 0.1947  data_time: 0.0042  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:52 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 179  total_loss: 1.977  loss_cls: 0.4832  loss_box_reg: 0.8445  loss_mask: 0.5655  loss_rpn_cls: 0.04397  loss_rpn_loc: 0.125  time: 0.1945  data_time: 0.0040  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:56 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 199  total_loss: 2.109  loss_cls: 0.5009  loss_box_reg: 0.8161  loss_mask: 0.583  loss_rpn_cls: 0.04607  loss_rpn_loc: 0.1401  time: 0.1948  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:57:59 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 219  total_loss: 2.007  loss_cls: 0.4529  loss_box_reg: 0.7936  loss_mask: 0.5204  loss_rpn_cls: 0.04199  loss_rpn_loc: 0.1144  time: 0.1950  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:03 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 239  total_loss: 1.685  loss_cls: 0.3759  loss_box_reg: 0.7251  loss_mask: 0.4845  loss_rpn_cls: 0.04168  loss_rpn_loc: 0.09233  time: 0.1953  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:07 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 259  total_loss: 1.904  loss_cls: 0.4354  loss_box_reg: 0.6889  loss_mask: 0.5159  loss_rpn_cls: 0.05308  loss_rpn_loc: 0.121  time: 0.1954  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:11 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 279  total_loss: 1.645  loss_cls: 0.3618  loss_box_reg: 0.7296  loss_mask: 0.4495  loss_rpn_cls: 0.03505  loss_rpn_loc: 0.1281  time: 0.1955  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:15 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 299  total_loss: 1.637  loss_cls: 0.3573  loss_box_reg: 0.6708  loss_mask: 0.4495  loss_rpn_cls: 0.04198  loss_rpn_loc: 0.1041  time: 0.1955  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:19 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 319  total_loss: 1.392  loss_cls: 0.2941  loss_box_reg: 0.6263  loss_mask: 0.3842  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.119  time: 0.1957  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:23 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 339  total_loss: 1.373  loss_cls: 0.2673  loss_box_reg: 0.6009  loss_mask: 0.3719  loss_rpn_cls: 0.03101  loss_rpn_loc: 0.08399  time: 0.1957  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:27 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 359  total_loss: 1.422  loss_cls: 0.2872  loss_box_reg: 0.5641  loss_mask: 0.4297  loss_rpn_cls: 0.02924  loss_rpn_loc: 0.143  time: 0.1958  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:31 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 379  total_loss: 1.305  loss_cls: 0.248  loss_box_reg: 0.5511  loss_mask: 0.3484  loss_rpn_cls: 0.03248  loss_rpn_loc: 0.1015  time: 0.1958  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:35 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 1.28  loss_cls: 0.2401  loss_box_reg: 0.5452  loss_mask: 0.3822  loss_rpn_cls: 0.02619  loss_rpn_loc: 0.06347  time: 0.1959  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:39 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 419  total_loss: 1.263  loss_cls: 0.2273  loss_box_reg: 0.4306  loss_mask: 0.2841  loss_rpn_cls: 0.03103  loss_rpn_loc: 0.1121  time: 0.1959  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:43 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 439  total_loss: 1.109  loss_cls: 0.2205  loss_box_reg: 0.4752  loss_mask: 0.3065  loss_rpn_cls: 0.02828  loss_rpn_loc: 0.07166  time: 0.1960  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:47 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 459  total_loss: 1.206  loss_cls: 0.2108  loss_box_reg: 0.5231  loss_mask: 0.3421  loss_rpn_cls: 0.02346  loss_rpn_loc: 0.06769  time: 0.1961  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:51 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 1.164  loss_cls: 0.2023  loss_box_reg: 0.4491  loss_mask: 0.3229  loss_rpn_cls: 0.02926  loss_rpn_loc: 0.1042  time: 0.1961  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:55 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.089  loss_cls: 0.1962  loss_box_reg: 0.4684  loss_mask: 0.3026  loss_rpn_cls: 0.02512  loss_rpn_loc: 0.09018  time: 0.1962  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:58:59 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 1.076  loss_cls: 0.2065  loss_box_reg: 0.4365  loss_mask: 0.3045  loss_rpn_cls: 0.0181  loss_rpn_loc: 0.1091  time: 0.1962  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:03 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 1.057  loss_cls: 0.1991  loss_box_reg: 0.4067  loss_mask: 0.2946  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.07019  time: 0.1962  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:07 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 0.9916  loss_cls: 0.182  loss_box_reg: 0.4663  loss_mask: 0.2697  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.04929  time: 0.1963  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:11 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 1.12  loss_cls: 0.2048  loss_box_reg: 0.47  loss_mask: 0.3206  loss_rpn_cls: 0.02101  loss_rpn_loc: 0.09718  time: 0.1963  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:15 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.8633  loss_cls: 0.1584  loss_box_reg: 0.3623  loss_mask: 0.2669  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.04447  time: 0.1963  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:19 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.9898  loss_cls: 0.2021  loss_box_reg: 0.4258  loss_mask: 0.28  loss_rpn_cls: 0.02511  loss_rpn_loc: 0.07322  time: 0.1964  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:23 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 1.011  loss_cls: 0.1611  loss_box_reg: 0.3866  loss_mask: 0.2772  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.09074  time: 0.1964  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:26 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.9066  loss_cls: 0.1525  loss_box_reg: 0.3728  loss_mask: 0.2677  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.03874  time: 0.1965  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:30 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 1.154  loss_cls: 0.171  loss_box_reg: 0.4312  loss_mask: 0.3111  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.1202  time: 0.1966  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:34 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.8768  loss_cls: 0.1436  loss_box_reg: 0.3541  loss_mask: 0.25  loss_rpn_cls: 0.02338  loss_rpn_loc: 0.1041  time: 0.1966  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:38 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.7413  loss_cls: 0.1355  loss_box_reg: 0.3212  loss_mask: 0.2458  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.0765  time: 0.1967  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:42 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.9293  loss_cls: 0.1596  loss_box_reg: 0.352  loss_mask: 0.2747  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.08342  time: 0.1967  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:46 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.7907  loss_cls: 0.1269  loss_box_reg: 0.3476  loss_mask: 0.2411  loss_rpn_cls: 0.01872  loss_rpn_loc: 0.09126  time: 0.1969  data_time: 0.0044  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:50 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.8426  loss_cls: 0.1424  loss_box_reg: 0.3401  loss_mask: 0.2505  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.08154  time: 0.1969  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.7711  loss_cls: 0.124  loss_box_reg: 0.2933  loss_mask: 0.2607  loss_rpn_cls: 0.01994  loss_rpn_loc: 0.02277  time: 0.1969  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 12:59:55 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:37 (0.1969 s / it)\n",
      "\u001b[32m[10/21 12:59:55 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='Y2008LS_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 12:59:55 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 12:59:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:59:55 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:59:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 12:59:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 12:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0589 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.634621 (0.084988 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.059432 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Y2008LS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.562\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.061 | 56.250 | 22.041 | 23.938 | 32.576 | 39.127 |\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.870 | cushion    | 30.599 | door       | 16.416 |\n",
      "| indoor-plant | 30.081 | sofa       | 67.349 | table      | 3.050  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.491\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.382 | 49.061 | 9.863  | 10.756 | 21.005 | 61.254 |\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 18.465 | cushion    | 15.750 | door       | 32.823 |\n",
      "| indoor-plant | 23.301 | sofa       | 29.577 | table      | 2.376  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='Y2008LS0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 12:59:59 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 12:59:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 12:59:59 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 12:59:59 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 12:59:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 20/355. 0.0659 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 13:00:07 d2.evaluation.evaluator]: \u001b[0mInference done 66/355. 0.0637 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 13:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 123/355. 0.0620 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 13:00:17 d2.evaluation.evaluator]: \u001b[0mInference done 177/355. 0.0615 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 13:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.0616 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 13:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.0616 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 317/355. 0.0622 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 13:00:37 d2.evaluation.evaluator]: \u001b[0mInference done 354/355. 0.0627 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:00:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:37.633202 (0.107523 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:00:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.062687 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Y2008LS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.700 | 27.731 | 20.389 | 10.731 | 19.950 | 20.700 |\n",
      "\u001b[32m[10/21 13:00:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.745 | cushion    | 52.464 | door       | 9.710 |\n",
      "| indoor-plant | 5.583 | sofa       | 33.435 | table      | 0.260 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:00:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:00:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/21 13:00:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:00:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.394\n",
      "\u001b[32m[10/21 13:00:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.470 | 27.375 | 20.573 | 9.546 | 22.582 | 21.805 |\n",
      "\u001b[32m[10/21 13:00:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.478 | cushion    | 60.361 | door       | 11.507 |\n",
      "| indoor-plant | 4.858 | sofa       | 30.472 | table      | 0.144  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='Y2008LS1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:00:40 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:00:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:00:40 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:00:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:00:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:00:42 d2.evaluation.evaluator]: \u001b[0mInference done 18/355. 0.0659 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 13:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 64/355. 0.0634 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 13:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 119/355. 0.0620 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 13:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.0614 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 13:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.0615 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 13:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 277/355. 0.0616 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:01:13 d2.evaluation.evaluator]: \u001b[0mInference done 314/355. 0.0622 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:01:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.651459 (0.104718 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:01:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.062375 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:01:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:01:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Y2008LS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:01:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:01:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:01:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 13:01:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:01:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n",
      "\u001b[32m[10/21 13:01:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.286 | 27.040 | 20.176 | 9.267 | 19.635 | 17.027 |\n",
      "\u001b[32m[10/21 13:01:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 4.399 | cushion    | 52.700 | door       | 11.362 |\n",
      "| indoor-plant | 4.436 | sofa       | 30.546 | table      | 0.276  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:01:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:01:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 13:01:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:01:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
      "\u001b[32m[10/21 13:01:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.174 | 26.547 | 20.805 | 8.541 | 22.567 | 20.760 |\n",
      "\u001b[32m[10/21 13:01:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.081 | cushion    | 60.599 | door       | 13.284 |\n",
      "| indoor-plant | 3.948 | sofa       | 27.972 | table      | 0.163  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='Y2008LS2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:01:19 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:01:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:01:19 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:01:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:01:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:01:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0642 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 13:01:25 d2.evaluation.evaluator]: \u001b[0mInference done 62/355. 0.0613 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 13:01:30 d2.evaluation.evaluator]: \u001b[0mInference done 123/355. 0.0596 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 13:01:35 d2.evaluation.evaluator]: \u001b[0mInference done 190/355. 0.0585 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 13:01:40 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.0590 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 13:01:45 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.0596 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 13:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 334/355. 0.0601 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:01:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:33.437969 (0.095537 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:01:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060441 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:01:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:01:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Y2008LS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:01:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:01:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:01:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 13:01:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:01:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471\n",
      "\u001b[32m[10/21 13:01:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.337 | 28.433 | 21.209 | 9.401 | 21.523 | 18.967 |\n",
      "\u001b[32m[10/21 13:01:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 4.318 | cushion    | 52.724 | door       | 12.562 |\n",
      "| indoor-plant | 6.178 | sofa       | 33.997 | table      | 0.245  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:01:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:01:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 13:01:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:01:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n",
      "\u001b[32m[10/21 13:01:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.179 | 28.198 | 22.143 | 8.567 | 23.827 | 22.087 |\n",
      "\u001b[32m[10/21 13:01:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.689 | cushion    | 59.627 | door       | 14.627 |\n",
      "| indoor-plant | 5.417 | sofa       | 31.562 | table      | 0.150  |\n",
      "all results {'bbox': {'AP50': [27.73144254816361, 27.039882976015228, 28.432766258101584]}, 'segm': {'AP50': [27.375004159003563, 26.54746227058341, 28.198241897195985]}}\n",
      "dataset_name KDCAFXY\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json', name='KDCAFXY_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/KDCAFXY0\n",
      "output_aug/500/KDCAFXY0\n",
      "\u001b[32m[10/21 13:01:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:01:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "389 389\n",
      "\u001b[32m[10/21 13:01:55 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 13:01:55 d2.data.build]: \u001b[0mRemoved 6 images with no usable annotations. 72 images left.\n",
      "\u001b[32m[10/21 13:01:55 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 40           |  cushion   | 90           |    door    | 126          |\n",
      "| indoor-plant | 51           |    sofa    | 38           |   table    | 44           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 389          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 13:01:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:01:55 d2.data.common]: \u001b[0mSerializing 72 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:01:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:01:55 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:01:56 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:02:00 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 19  total_loss: 3.5  loss_cls: 1.647  loss_box_reg: 0.7468  loss_mask: 0.693  loss_rpn_cls: 0.2226  loss_rpn_loc: 0.07051  time: 0.1940  data_time: 0.0168  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:04 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 39  total_loss: 2.538  loss_cls: 0.6858  loss_box_reg: 0.6899  loss_mask: 0.6658  loss_rpn_cls: 0.08423  loss_rpn_loc: 0.2182  time: 0.1945  data_time: 0.0042  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:08 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 59  total_loss: 2.313  loss_cls: 0.6084  loss_box_reg: 0.8185  loss_mask: 0.6292  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.1733  time: 0.1959  data_time: 0.0042  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:12 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 79  total_loss: 1.762  loss_cls: 0.4139  loss_box_reg: 0.7395  loss_mask: 0.5027  loss_rpn_cls: 0.05119  loss_rpn_loc: 0.03432  time: 0.1966  data_time: 0.0043  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:16 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 99  total_loss: 1.77  loss_cls: 0.3944  loss_box_reg: 0.7073  loss_mask: 0.5113  loss_rpn_cls: 0.03441  loss_rpn_loc: 0.1199  time: 0.1963  data_time: 0.0041  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:20 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 119  total_loss: 1.614  loss_cls: 0.3238  loss_box_reg: 0.7007  loss_mask: 0.3995  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.1409  time: 0.1964  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:24 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 139  total_loss: 1.445  loss_cls: 0.2448  loss_box_reg: 0.5535  loss_mask: 0.3796  loss_rpn_cls: 0.02769  loss_rpn_loc: 0.1193  time: 0.1967  data_time: 0.0043  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:28 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 1.027  loss_cls: 0.1588  loss_box_reg: 0.489  loss_mask: 0.2994  loss_rpn_cls: 0.02669  loss_rpn_loc: 0.1058  time: 0.1968  data_time: 0.0042  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:31 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 0.9794  loss_cls: 0.1892  loss_box_reg: 0.4553  loss_mask: 0.2588  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.08245  time: 0.1963  data_time: 0.0041  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:35 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 0.7527  loss_cls: 0.1584  loss_box_reg: 0.411  loss_mask: 0.2212  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.02601  time: 0.1967  data_time: 0.0041  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:39 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 219  total_loss: 0.9747  loss_cls: 0.1572  loss_box_reg: 0.3867  loss_mask: 0.2448  loss_rpn_cls: 0.009707  loss_rpn_loc: 0.1148  time: 0.1970  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:43 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 0.9295  loss_cls: 0.1373  loss_box_reg: 0.3606  loss_mask: 0.2418  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.1394  time: 0.1970  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:47 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 0.8275  loss_cls: 0.1255  loss_box_reg: 0.3741  loss_mask: 0.1951  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.07269  time: 0.1970  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:51 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 0.7487  loss_cls: 0.118  loss_box_reg: 0.3176  loss_mask: 0.2145  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.0996  time: 0.1970  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:55 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 0.6834  loss_cls: 0.108  loss_box_reg: 0.2915  loss_mask: 0.2172  loss_rpn_cls: 0.009477  loss_rpn_loc: 0.04187  time: 0.1971  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:02:59 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.6529  loss_cls: 0.09033  loss_box_reg: 0.2623  loss_mask: 0.1814  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.08655  time: 0.1972  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:03 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.7495  loss_cls: 0.1061  loss_box_reg: 0.287  loss_mask: 0.1874  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.1017  time: 0.1973  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:07 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.601  loss_cls: 0.09374  loss_box_reg: 0.2888  loss_mask: 0.1718  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.07438  time: 0.1973  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:11 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.6527  loss_cls: 0.09939  loss_box_reg: 0.2656  loss_mask: 0.1781  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.09027  time: 0.1975  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:15 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.6339  loss_cls: 0.0918  loss_box_reg: 0.2711  loss_mask: 0.1636  loss_rpn_cls: 0.007674  loss_rpn_loc: 0.07161  time: 0.1976  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:19 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.5269  loss_cls: 0.07252  loss_box_reg: 0.2219  loss_mask: 0.1391  loss_rpn_cls: 0.00713  loss_rpn_loc: 0.05437  time: 0.1977  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:23 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.6888  loss_cls: 0.1179  loss_box_reg: 0.2485  loss_mask: 0.2044  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.09476  time: 0.1978  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:27 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.632  loss_cls: 0.08699  loss_box_reg: 0.2185  loss_mask: 0.1739  loss_rpn_cls: 0.007149  loss_rpn_loc: 0.09145  time: 0.1978  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:31 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.5805  loss_cls: 0.08361  loss_box_reg: 0.2065  loss_mask: 0.1647  loss_rpn_cls: 0.017  loss_rpn_loc: 0.07806  time: 0.1979  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:36 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5947  loss_cls: 0.0946  loss_box_reg: 0.2345  loss_mask: 0.1595  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.07869  time: 0.1978  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:03:36 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:38 (0.1978 s / it)\n",
      "\u001b[32m[10/21 13:03:36 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='KDCAFXY_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:03:36 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:03:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:03:36 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:03:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:03:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0571 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.190092 (0.070648 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.056988 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KDCAFXY0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.557\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.618\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.348 | 55.719 | 29.295 | 27.833 | 33.404 | 30.060 |\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 24.008 | cushion    | 42.335 | door       | 22.538 |\n",
      "| indoor-plant | 36.098 | sofa       | 59.741 | table      | 3.369  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.518\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.919 | 51.785 | 18.025 | 15.365 | 26.524 | 43.592 |\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 13.269 | cushion    | 23.775 | door       | 38.096 |\n",
      "| indoor-plant | 31.430 | sofa       | 47.517 | table      | 1.429  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='KDCAFXY0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:03:39 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:03:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:03:39 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:03:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:03:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:03:42 d2.evaluation.evaluator]: \u001b[0mInference done 33/355. 0.0580 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 13:03:47 d2.evaluation.evaluator]: \u001b[0mInference done 100/355. 0.0579 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 13:03:52 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.0577 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:03:57 d2.evaluation.evaluator]: \u001b[0mInference done 241/355. 0.0574 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 13:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 299/355. 0.0576 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:04:07 d2.evaluation.evaluator]: \u001b[0mInference done 352/355. 0.0579 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.794658 (0.079413 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057929 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KDCAFXY0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.182 | 30.547 | 23.242 | 11.113 | 17.707 | 18.558 |\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.655 | cushion    | 61.472 | door       | 11.478 |\n",
      "| indoor-plant | 4.314 | sofa       | 40.147 | table      | 0.026  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:04:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:04:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 13:04:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:04:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
      "\u001b[32m[10/21 13:04:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.632 | 30.162 | 22.799 | 11.128 | 20.120 | 15.655 |\n",
      "\u001b[32m[10/21 13:04:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.103 | cushion    | 71.740 | door       | 12.348 |\n",
      "| indoor-plant | 3.293 | sofa       | 27.257 | table      | 0.051  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='KDCAFXY1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:04:09 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:04:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:04:09 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:04:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:04:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/355. 0.0579 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 13:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 110/355. 0.0572 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 13:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.0572 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 13:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.0573 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 13:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 300/355. 0.0576 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 354/355. 0.0579 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.121688 (0.080348 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057872 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KDCAFXY0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.353\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.580 | 29.367 | 23.252 | 11.353 | 18.195 | 16.627 |\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 2.813 | cushion    | 62.794 | door       | 12.099 |\n",
      "| indoor-plant | 4.091 | sofa       | 35.642 | table      | 0.044  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:04:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:04:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 13:04:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:04:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.287\n",
      "\u001b[32m[10/21 13:04:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.299 | 28.940 | 22.322 | 11.321 | 19.841 | 15.997 |\n",
      "\u001b[32m[10/21 13:04:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 2.798 | cushion    | 71.409 | door       | 14.247 |\n",
      "| indoor-plant | 2.699 | sofa       | 24.590 | table      | 0.053  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='KDCAFXY2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:04:39 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:04:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:04:39 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:04:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:04:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 41/355. 0.0579 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 13:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 110/355. 0.0585 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 13:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 183/355. 0.0578 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 13:04:58 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.0578 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 13:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 299/355. 0.0580 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.0582 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.460792 (0.081317 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058213 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/KDCAFXY0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.998 | 30.141 | 23.696 | 11.825 | 18.353 | 17.581 |\n",
      "\u001b[32m[10/21 13:05:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 2.983 | cushion    | 62.775 | door       | 11.317 |\n",
      "| indoor-plant | 3.887 | sofa       | 39.003 | table      | 0.024  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:05:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:05:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 13:05:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:05:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      "\u001b[32m[10/21 13:05:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.413 | 29.705 | 22.330 | 11.371 | 20.270 | 16.029 |\n",
      "\u001b[32m[10/21 13:05:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.361 | cushion    | 71.393 | door       | 12.388 |\n",
      "| indoor-plant | 2.705 | sofa       | 26.572 | table      | 0.059  |\n",
      "all results {'bbox': {'AP50': [30.546928904211875, 29.36712645551388, 30.14147270380584]}, 'segm': {'AP50': [30.162302741544277, 28.94000358006898, 29.70526053610469]}}\n",
      "dataset_name OGR4G0A\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json', name='OGR4G0A_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/OGR4G0A0\n",
      "output_aug/800/OGR4G0A0\n",
      "\u001b[32m[10/21 13:05:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:05:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "389 389\n",
      "\u001b[32m[10/21 13:05:10 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 13:05:10 d2.data.build]: \u001b[0mRemoved 6 images with no usable annotations. 72 images left.\n",
      "\u001b[32m[10/21 13:05:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:05:10 d2.data.common]: \u001b[0mSerializing 72 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:05:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:05:10 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:05:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:05:15 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 19  total_loss: 3.488  loss_cls: 1.707  loss_box_reg: 0.695  loss_mask: 0.6912  loss_rpn_cls: 0.2222  loss_rpn_loc: 0.1834  time: 0.1968  data_time: 0.0164  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:19 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 39  total_loss: 2.351  loss_cls: 0.7503  loss_box_reg: 0.6839  loss_mask: 0.6611  loss_rpn_cls: 0.0918  loss_rpn_loc: 0.1106  time: 0.1956  data_time: 0.0043  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:23 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 59  total_loss: 2.24  loss_cls: 0.6497  loss_box_reg: 0.8295  loss_mask: 0.6052  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.1586  time: 0.1960  data_time: 0.0043  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:26 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 79  total_loss: 1.962  loss_cls: 0.4626  loss_box_reg: 0.7096  loss_mask: 0.5319  loss_rpn_cls: 0.04706  loss_rpn_loc: 0.1237  time: 0.1956  data_time: 0.0040  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:30 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 99  total_loss: 1.645  loss_cls: 0.3908  loss_box_reg: 0.6764  loss_mask: 0.4763  loss_rpn_cls: 0.0416  loss_rpn_loc: 0.1263  time: 0.1963  data_time: 0.0042  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:34 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 119  total_loss: 1.564  loss_cls: 0.2776  loss_box_reg: 0.5808  loss_mask: 0.4105  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.1347  time: 0.1970  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:38 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 139  total_loss: 1.21  loss_cls: 0.201  loss_box_reg: 0.5298  loss_mask: 0.3234  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.07679  time: 0.1970  data_time: 0.0040  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:42 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 159  total_loss: 1.044  loss_cls: 0.1965  loss_box_reg: 0.417  loss_mask: 0.2892  loss_rpn_cls: 0.03131  loss_rpn_loc: 0.1101  time: 0.1971  data_time: 0.0042  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:46 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 179  total_loss: 1.081  loss_cls: 0.1676  loss_box_reg: 0.4925  loss_mask: 0.3004  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.08671  time: 0.1976  data_time: 0.0042  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:50 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 199  total_loss: 1.028  loss_cls: 0.1652  loss_box_reg: 0.4263  loss_mask: 0.2792  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.1014  time: 0.1976  data_time: 0.0040  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:54 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 219  total_loss: 0.9348  loss_cls: 0.1323  loss_box_reg: 0.361  loss_mask: 0.2412  loss_rpn_cls: 0.02868  loss_rpn_loc: 0.08559  time: 0.1977  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:05:58 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 239  total_loss: 0.9559  loss_cls: 0.1448  loss_box_reg: 0.4026  loss_mask: 0.2373  loss_rpn_cls: 0.02564  loss_rpn_loc: 0.159  time: 0.1976  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:02 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 259  total_loss: 0.6234  loss_cls: 0.09916  loss_box_reg: 0.2965  loss_mask: 0.1666  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.02938  time: 0.1975  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:06 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 279  total_loss: 0.8137  loss_cls: 0.1353  loss_box_reg: 0.3185  loss_mask: 0.1937  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.0989  time: 0.1976  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:10 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 299  total_loss: 0.7672  loss_cls: 0.1099  loss_box_reg: 0.2913  loss_mask: 0.1993  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.09304  time: 0.1977  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:14 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 319  total_loss: 0.706  loss_cls: 0.09914  loss_box_reg: 0.313  loss_mask: 0.1853  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.0592  time: 0.1977  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:18 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 339  total_loss: 0.6874  loss_cls: 0.08708  loss_box_reg: 0.3027  loss_mask: 0.1826  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.09084  time: 0.1980  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:22 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 359  total_loss: 0.7012  loss_cls: 0.1117  loss_box_reg: 0.2747  loss_mask: 0.2035  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.08393  time: 0.1981  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:26 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 379  total_loss: 0.5333  loss_cls: 0.08746  loss_box_reg: 0.2284  loss_mask: 0.1456  loss_rpn_cls: 0.004961  loss_rpn_loc: 0.08035  time: 0.1982  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:30 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 399  total_loss: 0.6989  loss_cls: 0.1217  loss_box_reg: 0.288  loss_mask: 0.203  loss_rpn_cls: 0.009243  loss_rpn_loc: 0.07419  time: 0.1982  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:34 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 419  total_loss: 0.6874  loss_cls: 0.1112  loss_box_reg: 0.2453  loss_mask: 0.1788  loss_rpn_cls: 0.009795  loss_rpn_loc: 0.09881  time: 0.1984  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:38 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 439  total_loss: 0.5886  loss_cls: 0.07382  loss_box_reg: 0.2447  loss_mask: 0.1744  loss_rpn_cls: 0.008786  loss_rpn_loc: 0.06271  time: 0.1986  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:42 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 459  total_loss: 0.5623  loss_cls: 0.1003  loss_box_reg: 0.2479  loss_mask: 0.1628  loss_rpn_cls: 0.009287  loss_rpn_loc: 0.0549  time: 0.1985  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:46 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 479  total_loss: 0.5997  loss_cls: 0.08375  loss_box_reg: 0.2111  loss_mask: 0.167  loss_rpn_cls: 0.007821  loss_rpn_loc: 0.0975  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:50 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 499  total_loss: 0.5594  loss_cls: 0.08  loss_box_reg: 0.2128  loss_mask: 0.1646  loss_rpn_cls: 0.00847  loss_rpn_loc: 0.08684  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:54 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 519  total_loss: 0.6004  loss_cls: 0.08026  loss_box_reg: 0.2118  loss_mask: 0.1553  loss_rpn_cls: 0.008778  loss_rpn_loc: 0.07195  time: 0.1984  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:06:58 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 0.6167  loss_cls: 0.08109  loss_box_reg: 0.2351  loss_mask: 0.167  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.09398  time: 0.1984  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:02 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 0.6209  loss_cls: 0.07974  loss_box_reg: 0.2345  loss_mask: 0.1579  loss_rpn_cls: 0.009346  loss_rpn_loc: 0.05896  time: 0.1985  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:06 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.6303  loss_cls: 0.07959  loss_box_reg: 0.2356  loss_mask: 0.1625  loss_rpn_cls: 0.008272  loss_rpn_loc: 0.1049  time: 0.1985  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:10 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.508  loss_cls: 0.05402  loss_box_reg: 0.1963  loss_mask: 0.1503  loss_rpn_cls: 0.01776  loss_rpn_loc: 0.08155  time: 0.1985  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:14 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.5408  loss_cls: 0.07432  loss_box_reg: 0.2374  loss_mask: 0.1477  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.06728  time: 0.1986  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:18 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.5656  loss_cls: 0.06941  loss_box_reg: 0.214  loss_mask: 0.1426  loss_rpn_cls: 0.009992  loss_rpn_loc: 0.08433  time: 0.1986  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:22 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.5099  loss_cls: 0.06857  loss_box_reg: 0.2212  loss_mask: 0.1489  loss_rpn_cls: 0.005167  loss_rpn_loc: 0.05449  time: 0.1986  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:26 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.5494  loss_cls: 0.08441  loss_box_reg: 0.2088  loss_mask: 0.1458  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.07305  time: 0.1986  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:30 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.4792  loss_cls: 0.06743  loss_box_reg: 0.2094  loss_mask: 0.1387  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.05575  time: 0.1986  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:34 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.4892  loss_cls: 0.0669  loss_box_reg: 0.2043  loss_mask: 0.1386  loss_rpn_cls: 0.009202  loss_rpn_loc: 0.06134  time: 0.1986  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:38 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.524  loss_cls: 0.07432  loss_box_reg: 0.1933  loss_mask: 0.152  loss_rpn_cls: 0.005896  loss_rpn_loc: 0.06332  time: 0.1986  data_time: 0.0039  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:42 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.5493  loss_cls: 0.08151  loss_box_reg: 0.2279  loss_mask: 0.1402  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.06403  time: 0.1986  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:46 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.439  loss_cls: 0.05699  loss_box_reg: 0.1895  loss_mask: 0.1291  loss_rpn_cls: 0.006707  loss_rpn_loc: 0.04219  time: 0.1987  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:51 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5854  loss_cls: 0.07355  loss_box_reg: 0.2083  loss_mask: 0.1633  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.07924  time: 0.1987  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:07:51 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:38 (0.1987 s / it)\n",
      "\u001b[32m[10/21 13:07:51 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='OGR4G0A_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:07:51 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:07:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:07:51 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:07:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:07:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0617 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.193178 (0.070748 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.059534 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/OGR4G0A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.557\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 32.303 | 55.711 | 36.663 | 27.164 | 34.819 | 29.326 |\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 15.394 | cushion    | 42.118 | door       | 18.327 |\n",
      "| indoor-plant | 50.572 | sofa       | 60.772 | table      | 6.639  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.531\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.027 | 53.081 | 16.760 | 16.953 | 24.820 | 45.723 |\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 8.423  | cushion    | 26.099 | door       | 30.307 |\n",
      "| indoor-plant | 36.309 | sofa       | 51.606 | table      | 3.416  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='OGR4G0A0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:07:54 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:07:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:07:54 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:07:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:07:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 36/355. 0.0599 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 13:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 108/355. 0.0589 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 13:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.0587 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 13:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 251/355. 0.0585 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 318/355. 0.0584 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.308306 (0.072309 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058376 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/OGR4G0A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.353\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.800 | 35.329 | 27.594 | 11.548 | 20.291 | 25.484 |\n",
      "\u001b[32m[10/21 13:08:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.742 | cushion    | 63.156 | door       | 9.592 |\n",
      "| indoor-plant | 6.171 | sofa       | 60.050 | table      | 0.088 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:08:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:08:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 13:08:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:08:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\n",
      "\u001b[32m[10/21 13:08:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.530 | 32.891 | 19.364 | 10.342 | 21.049 | 13.864 |\n",
      "\u001b[32m[10/21 13:08:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.044 | cushion    | 66.950 | door       | 5.941 |\n",
      "| indoor-plant | 6.739 | sofa       | 35.372 | table      | 0.135 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='OGR4G0A1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:08:21 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:08:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:08:21 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:08:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:08:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0581 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 13:08:27 d2.evaluation.evaluator]: \u001b[0mInference done 84/355. 0.0580 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 13:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 156/355. 0.0585 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 13:08:37 d2.evaluation.evaluator]: \u001b[0mInference done 227/355. 0.0586 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 13:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.0585 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:25.408163 (0.072595 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058543 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/OGR4G0A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 13:08:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.353\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.738 | 35.344 | 27.547 | 11.179 | 21.330 | 24.855 |\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 4.177 | cushion    | 63.363 | door       | 10.334 |\n",
      "| indoor-plant | 5.707 | sofa       | 58.706 | table      | 0.141  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.244\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.913 | 33.202 | 21.589 | 10.454 | 21.692 | 14.798 |\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.124 | cushion    | 66.655 | door       | 7.979 |\n",
      "| indoor-plant | 6.025 | sofa       | 36.520 | table      | 0.177 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='OGR4G0A2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:08:48 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:08:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:08:48 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:08:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:08:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0591 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 13:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 78/355. 0.0582 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 13:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 146/355. 0.0592 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 13:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 217/355. 0.0588 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 283/355. 0.0587 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 349/355. 0.0588 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.266579 (0.075047 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058763 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/OGR4G0A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.384\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.270 | 35.387 | 27.208 | 10.529 | 21.044 | 24.519 |\n",
      "\u001b[32m[10/21 13:09:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.394 | cushion    | 61.725 | door       | 10.579 |\n",
      "| indoor-plant | 6.435 | sofa       | 57.435 | table      | 0.053  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:09:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      "\u001b[32m[10/21 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.215 | 32.654 | 19.866 | 10.016 | 21.252 | 15.361 |\n",
      "\u001b[32m[10/21 13:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.226 | cushion    | 64.477 | door       | 6.869 |\n",
      "| indoor-plant | 6.443 | sofa       | 35.179 | table      | 0.099 |\n",
      "all results {'bbox': {'AP50': [35.328522687162504, 35.343618376474126, 35.38723378473262]}, 'segm': {'AP50': [32.89098001691666, 33.20188586545999, 32.654473415957085]}}\n",
      "dataset_name AI7TQTG\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json', name='AI7TQTG_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/AI7TQTG0\n",
      "output_aug/500/AI7TQTG0\n",
      "\u001b[32m[10/21 13:09:17 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:09:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "389 389\n",
      "\u001b[32m[10/21 13:09:17 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 13:09:17 d2.data.build]: \u001b[0mRemoved 6 images with no usable annotations. 72 images left.\n",
      "\u001b[32m[10/21 13:09:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:09:17 d2.data.common]: \u001b[0mSerializing 72 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:09:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:09:17 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:09:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:09:21 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 19  total_loss: 3.794  loss_cls: 1.813  loss_box_reg: 0.6386  loss_mask: 0.6922  loss_rpn_cls: 0.2112  loss_rpn_loc: 0.2163  time: 0.1925  data_time: 0.0170  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:25 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 39  total_loss: 3.279  loss_cls: 1.568  loss_box_reg: 0.6238  loss_mask: 0.6893  loss_rpn_cls: 0.2084  loss_rpn_loc: 0.04371  time: 0.1927  data_time: 0.0044  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:29 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 59  total_loss: 2.968  loss_cls: 1.113  loss_box_reg: 0.7091  loss_mask: 0.6798  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.2228  time: 0.1934  data_time: 0.0045  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:33 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 79  total_loss: 2.693  loss_cls: 0.8836  loss_box_reg: 0.647  loss_mask: 0.6695  loss_rpn_cls: 0.1679  loss_rpn_loc: 0.2314  time: 0.1935  data_time: 0.0041  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:37 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 99  total_loss: 2.554  loss_cls: 0.7373  loss_box_reg: 0.773  loss_mask: 0.6586  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.1783  time: 0.1936  data_time: 0.0042  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:41 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 119  total_loss: 2.283  loss_cls: 0.7079  loss_box_reg: 0.7838  loss_mask: 0.6484  loss_rpn_cls: 0.05272  loss_rpn_loc: 0.09064  time: 0.1943  data_time: 0.0042  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:45 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 139  total_loss: 2.287  loss_cls: 0.6692  loss_box_reg: 0.7987  loss_mask: 0.621  loss_rpn_cls: 0.06729  loss_rpn_loc: 0.1253  time: 0.1941  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:49 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 159  total_loss: 2.34  loss_cls: 0.65  loss_box_reg: 0.8113  loss_mask: 0.6191  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1638  time: 0.1947  data_time: 0.0041  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:53 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 179  total_loss: 2.072  loss_cls: 0.5456  loss_box_reg: 0.8184  loss_mask: 0.5519  loss_rpn_cls: 0.04633  loss_rpn_loc: 0.14  time: 0.1951  data_time: 0.0041  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:09:57 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 199  total_loss: 2.02  loss_cls: 0.4961  loss_box_reg: 0.7979  loss_mask: 0.5308  loss_rpn_cls: 0.04699  loss_rpn_loc: 0.0932  time: 0.1954  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:01 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 219  total_loss: 2.015  loss_cls: 0.4886  loss_box_reg: 0.8098  loss_mask: 0.5411  loss_rpn_cls: 0.03606  loss_rpn_loc: 0.1561  time: 0.1958  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:05 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 239  total_loss: 1.801  loss_cls: 0.4144  loss_box_reg: 0.7758  loss_mask: 0.4694  loss_rpn_cls: 0.04166  loss_rpn_loc: 0.06898  time: 0.1962  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:09 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 1.761  loss_cls: 0.3621  loss_box_reg: 0.7512  loss_mask: 0.4674  loss_rpn_cls: 0.04684  loss_rpn_loc: 0.1385  time: 0.1963  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:13 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 1.76  loss_cls: 0.388  loss_box_reg: 0.7251  loss_mask: 0.4723  loss_rpn_cls: 0.03733  loss_rpn_loc: 0.111  time: 0.1968  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:17 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 1.651  loss_cls: 0.3645  loss_box_reg: 0.6767  loss_mask: 0.4546  loss_rpn_cls: 0.04339  loss_rpn_loc: 0.1448  time: 0.1969  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:21 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 1.355  loss_cls: 0.2564  loss_box_reg: 0.6372  loss_mask: 0.399  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.05948  time: 0.1968  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:25 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.426  loss_cls: 0.2911  loss_box_reg: 0.6505  loss_mask: 0.3835  loss_rpn_cls: 0.02557  loss_rpn_loc: 0.09414  time: 0.1969  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:29 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.28  loss_cls: 0.2545  loss_box_reg: 0.5316  loss_mask: 0.374  loss_rpn_cls: 0.03402  loss_rpn_loc: 0.1189  time: 0.1968  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:33 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.357  loss_cls: 0.2794  loss_box_reg: 0.5526  loss_mask: 0.3727  loss_rpn_cls: 0.03789  loss_rpn_loc: 0.1187  time: 0.1970  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:36 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.304  loss_cls: 0.265  loss_box_reg: 0.5502  loss_mask: 0.3454  loss_rpn_cls: 0.02882  loss_rpn_loc: 0.1114  time: 0.1970  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:40 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.282  loss_cls: 0.2556  loss_box_reg: 0.5401  loss_mask: 0.345  loss_rpn_cls: 0.02785  loss_rpn_loc: 0.09943  time: 0.1970  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:44 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 1.192  loss_cls: 0.2384  loss_box_reg: 0.5072  loss_mask: 0.3459  loss_rpn_cls: 0.03113  loss_rpn_loc: 0.09452  time: 0.1969  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:48 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.296  loss_cls: 0.2541  loss_box_reg: 0.4911  loss_mask: 0.3715  loss_rpn_cls: 0.02808  loss_rpn_loc: 0.1067  time: 0.1969  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:52 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 1.146  loss_cls: 0.1947  loss_box_reg: 0.5403  loss_mask: 0.3432  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.09498  time: 0.1970  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:57 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.066  loss_cls: 0.2064  loss_box_reg: 0.4289  loss_mask: 0.2952  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.09887  time: 0.1970  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:10:57 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:38 (0.1970 s / it)\n",
      "\u001b[32m[10/21 13:10:57 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='AI7TQTG_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:10:57 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:10:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:10:57 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:10:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:10:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:10:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0581 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.872647 (0.092666 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.060601 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AI7TQTG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.590\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.761 | 58.987 | 27.907 | 32.652 | 31.901 | 35.547 |\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 24.407 | cushion    | 27.519 | door       | 15.193 |\n",
      "| indoor-plant | 57.252 | sofa       | 58.218 | table      | 1.980  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.534\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.062 | 53.373 | 14.316 | 23.846 | 20.023 | 58.482 |\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 20.061 | cushion    | 17.197 | door       | 32.830 |\n",
      "| indoor-plant | 47.668 | sofa       | 26.421 | table      | 0.198  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='AI7TQTG0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:11:01 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:11:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:11:01 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:11:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:11:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:11:03 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0682 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 13:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 54/355. 0.0666 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 13:11:14 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0639 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 13:11:19 d2.evaluation.evaluator]: \u001b[0mInference done 150/355. 0.0646 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 13:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 205/355. 0.0632 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 13:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 239/355. 0.0639 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.0639 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 13:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.0644 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.0646 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:11:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.321883 (0.120920 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:11:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064579 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AI7TQTG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.438\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.239 | 33.225 | 17.125 | 9.290 | 19.434 | 18.047 |\n",
      "\u001b[32m[10/21 13:11:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 9.197 | cushion    | 43.847 | door       | 11.547 |\n",
      "| indoor-plant | 2.687 | sofa       | 42.023 | table      | 0.132  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:11:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:11:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.48 seconds.\n",
      "\u001b[32m[10/21 13:11:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:11:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.430\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
      "\u001b[32m[10/21 13:11:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.905 | 32.982 | 24.870 | 8.161 | 22.544 | 20.592 |\n",
      "\u001b[32m[10/21 13:11:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.531 | cushion    | 56.631 | door       | 14.726 |\n",
      "| indoor-plant | 2.596 | sofa       | 44.944 | table      | 0.001  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='AI7TQTG1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:11:47 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:11:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:11:47 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:11:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:11:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.0695 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 13:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.0667 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 13:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 103/355. 0.0639 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 13:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 153/355. 0.0632 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 13:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 206/355. 0.0629 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 13:12:14 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.0635 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 13:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.0637 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:12:25 d2.evaluation.evaluator]: \u001b[0mInference done 320/355. 0.0641 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:12:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.021458 (0.117204 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:12:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064246 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AI7TQTG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.773 | 33.677 | 18.766 | 8.742 | 20.344 | 17.327 |\n",
      "\u001b[32m[10/21 13:12:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 8.492 | cushion    | 45.124 | door       | 12.413 |\n",
      "| indoor-plant | 2.089 | sofa       | 44.431 | table      | 0.091  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:12:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:12:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.49 seconds.\n",
      "\u001b[32m[10/21 13:12:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:12:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[10/21 13:12:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.393 | 32.934 | 25.802 | 8.414 | 23.775 | 18.938 |\n",
      "\u001b[32m[10/21 13:12:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.368 | cushion    | 57.765 | door       | 15.416 |\n",
      "| indoor-plant | 2.115 | sofa       | 46.690 | table      | 0.003  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='AI7TQTG2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:12:32 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:12:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:12:32 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:12:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:12:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:12:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0678 s / img. ETA=0:00:53\n",
      "\u001b[32m[10/21 13:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.0665 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 13:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.0644 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 13:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 138/355. 0.0634 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 13:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 191/355. 0.0627 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 13:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.0635 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 13:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 263/355. 0.0637 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 13:13:10 d2.evaluation.evaluator]: \u001b[0mInference done 296/355. 0.0641 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 334/355. 0.0644 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 13:13:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.443323 (0.126981 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:13:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:22 (0.064532 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AI7TQTG0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.153 | 34.786 | 18.217 | 7.901 | 21.578 | 18.880 |\n",
      "\u001b[32m[10/21 13:13:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 9.175 | cushion    | 43.721 | door       | 14.167 |\n",
      "| indoor-plant | 2.930 | sofa       | 44.752 | table      | 0.173  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:13:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:13:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.36 seconds.\n",
      "\u001b[32m[10/21 13:13:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:13:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
      "\u001b[32m[10/21 13:13:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.941 | 34.204 | 26.514 | 7.914 | 25.109 | 21.644 |\n",
      "\u001b[32m[10/21 13:13:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.838 | cushion    | 55.978 | door       | 17.163 |\n",
      "| indoor-plant | 2.732 | sofa       | 48.934 | table      | 0.002  |\n",
      "all results {'bbox': {'AP50': [33.22489053021499, 33.67709508170925, 34.78602576694572]}, 'segm': {'AP50': [32.98168813282971, 32.934335332982826, 34.203760707961216]}}\n",
      "dataset_name Q2GSKHZ\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/2/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json', name='Q2GSKHZ_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/Q2GSKHZ0\n",
      "output_aug/800/Q2GSKHZ0\n",
      "\u001b[32m[10/21 13:13:20 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:13:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "389 389\n",
      "\u001b[32m[10/21 13:13:20 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/2/default/pred_label_gt5p8/coco_train.json\n",
      "\u001b[32m[10/21 13:13:20 d2.data.build]: \u001b[0mRemoved 6 images with no usable annotations. 72 images left.\n",
      "\u001b[32m[10/21 13:13:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:13:20 d2.data.common]: \u001b[0mSerializing 72 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:13:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:13:20 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:13:20 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:13:24 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 19  total_loss: 3.816  loss_cls: 1.977  loss_box_reg: 0.6204  loss_mask: 0.6941  loss_rpn_cls: 0.2283  loss_rpn_loc: 0.2028  time: 0.1867  data_time: 0.0153  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:28 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 39  total_loss: 3.509  loss_cls: 1.702  loss_box_reg: 0.6865  loss_mask: 0.6901  loss_rpn_cls: 0.1706  loss_rpn_loc: 0.1512  time: 0.1894  data_time: 0.0040  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:32 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 59  total_loss: 3.108  loss_cls: 1.189  loss_box_reg: 0.6343  loss_mask: 0.6814  loss_rpn_cls: 0.1823  loss_rpn_loc: 0.197  time: 0.1895  data_time: 0.0041  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:36 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 79  total_loss: 2.733  loss_cls: 0.8962  loss_box_reg: 0.7889  loss_mask: 0.6747  loss_rpn_cls: 0.09738  loss_rpn_loc: 0.19  time: 0.1904  data_time: 0.0040  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:40 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 99  total_loss: 2.431  loss_cls: 0.7146  loss_box_reg: 0.6969  loss_mask: 0.6691  loss_rpn_cls: 0.08455  loss_rpn_loc: 0.1726  time: 0.1908  data_time: 0.0041  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:43 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 119  total_loss: 2.25  loss_cls: 0.653  loss_box_reg: 0.6743  loss_mask: 0.642  loss_rpn_cls: 0.0739  loss_rpn_loc: 0.1072  time: 0.1896  data_time: 0.0036  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:47 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 139  total_loss: 2.23  loss_cls: 0.6494  loss_box_reg: 0.7796  loss_mask: 0.6347  loss_rpn_cls: 0.05484  loss_rpn_loc: 0.1406  time: 0.1897  data_time: 0.0040  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:51 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 159  total_loss: 2.341  loss_cls: 0.6177  loss_box_reg: 0.7832  loss_mask: 0.6084  loss_rpn_cls: 0.08993  loss_rpn_loc: 0.1947  time: 0.1907  data_time: 0.0042  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:55 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 179  total_loss: 2.116  loss_cls: 0.5703  loss_box_reg: 0.7081  loss_mask: 0.6062  loss_rpn_cls: 0.04902  loss_rpn_loc: 0.1455  time: 0.1905  data_time: 0.0037  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:13:59 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 199  total_loss: 2.046  loss_cls: 0.4969  loss_box_reg: 0.7597  loss_mask: 0.5691  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.1227  time: 0.1909  data_time: 0.0043  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:03 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 219  total_loss: 1.952  loss_cls: 0.4686  loss_box_reg: 0.7961  loss_mask: 0.5202  loss_rpn_cls: 0.05033  loss_rpn_loc: 0.1341  time: 0.1911  data_time: 0.0037  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:07 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 239  total_loss: 1.853  loss_cls: 0.439  loss_box_reg: 0.7754  loss_mask: 0.5127  loss_rpn_cls: 0.04066  loss_rpn_loc: 0.1175  time: 0.1914  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:11 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 259  total_loss: 1.665  loss_cls: 0.3974  loss_box_reg: 0.7072  loss_mask: 0.5417  loss_rpn_cls: 0.03571  loss_rpn_loc: 0.08454  time: 0.1917  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:15 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 279  total_loss: 1.693  loss_cls: 0.3307  loss_box_reg: 0.6919  loss_mask: 0.4691  loss_rpn_cls: 0.03652  loss_rpn_loc: 0.1232  time: 0.1920  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:18 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 299  total_loss: 1.68  loss_cls: 0.338  loss_box_reg: 0.7224  loss_mask: 0.4919  loss_rpn_cls: 0.04554  loss_rpn_loc: 0.1171  time: 0.1923  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:22 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 319  total_loss: 1.439  loss_cls: 0.2753  loss_box_reg: 0.6056  loss_mask: 0.382  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.07056  time: 0.1924  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:26 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 339  total_loss: 1.726  loss_cls: 0.3572  loss_box_reg: 0.7332  loss_mask: 0.491  loss_rpn_cls: 0.03044  loss_rpn_loc: 0.0919  time: 0.1926  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:30 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 359  total_loss: 1.291  loss_cls: 0.2332  loss_box_reg: 0.5723  loss_mask: 0.3378  loss_rpn_cls: 0.03774  loss_rpn_loc: 0.1112  time: 0.1928  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:34 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 379  total_loss: 1.354  loss_cls: 0.2852  loss_box_reg: 0.5621  loss_mask: 0.3901  loss_rpn_cls: 0.02364  loss_rpn_loc: 0.1019  time: 0.1928  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:38 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 399  total_loss: 1.375  loss_cls: 0.2752  loss_box_reg: 0.5941  loss_mask: 0.3853  loss_rpn_cls: 0.03163  loss_rpn_loc: 0.1155  time: 0.1928  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:42 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 419  total_loss: 1.256  loss_cls: 0.2334  loss_box_reg: 0.6178  loss_mask: 0.3144  loss_rpn_cls: 0.02955  loss_rpn_loc: 0.08674  time: 0.1927  data_time: 0.0034  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:46 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 439  total_loss: 1.388  loss_cls: 0.2343  loss_box_reg: 0.5472  loss_mask: 0.3369  loss_rpn_cls: 0.02572  loss_rpn_loc: 0.08612  time: 0.1927  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:50 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 459  total_loss: 1.247  loss_cls: 0.2554  loss_box_reg: 0.507  loss_mask: 0.3441  loss_rpn_cls: 0.03078  loss_rpn_loc: 0.1005  time: 0.1929  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:54 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 479  total_loss: 1.155  loss_cls: 0.1941  loss_box_reg: 0.5066  loss_mask: 0.3158  loss_rpn_cls: 0.0214  loss_rpn_loc: 0.08294  time: 0.1932  data_time: 0.0045  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:14:57 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 499  total_loss: 1.201  loss_cls: 0.2221  loss_box_reg: 0.4956  loss_mask: 0.3346  loss_rpn_cls: 0.02952  loss_rpn_loc: 0.09311  time: 0.1932  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:02 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 519  total_loss: 1.186  loss_cls: 0.2034  loss_box_reg: 0.4597  loss_mask: 0.3094  loss_rpn_cls: 0.02978  loss_rpn_loc: 0.09376  time: 0.1935  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:06 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 539  total_loss: 1.056  loss_cls: 0.2011  loss_box_reg: 0.4291  loss_mask: 0.3244  loss_rpn_cls: 0.02122  loss_rpn_loc: 0.0721  time: 0.1937  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:10 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 559  total_loss: 1.104  loss_cls: 0.1961  loss_box_reg: 0.4977  loss_mask: 0.3143  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.1029  time: 0.1939  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:13 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 579  total_loss: 1.172  loss_cls: 0.2026  loss_box_reg: 0.4446  loss_mask: 0.3333  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.1175  time: 0.1941  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:17 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 599  total_loss: 1.069  loss_cls: 0.2154  loss_box_reg: 0.4239  loss_mask: 0.3377  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.08686  time: 0.1941  data_time: 0.0036  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:21 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.9384  loss_cls: 0.1629  loss_box_reg: 0.4124  loss_mask: 0.2801  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.06227  time: 0.1942  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:25 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 1.04  loss_cls: 0.1685  loss_box_reg: 0.454  loss_mask: 0.2899  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.1017  time: 0.1944  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:29 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.9877  loss_cls: 0.162  loss_box_reg: 0.4033  loss_mask: 0.2574  loss_rpn_cls: 0.02735  loss_rpn_loc: 0.07152  time: 0.1945  data_time: 0.0038  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:33 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.935  loss_cls: 0.1486  loss_box_reg: 0.4125  loss_mask: 0.2557  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.09313  time: 0.1946  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:37 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.8953  loss_cls: 0.1326  loss_box_reg: 0.3955  loss_mask: 0.2713  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.09177  time: 0.1943  data_time: 0.0035  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:41 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.9324  loss_cls: 0.1656  loss_box_reg: 0.4008  loss_mask: 0.2642  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.05245  time: 0.1945  data_time: 0.0044  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:45 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.9632  loss_cls: 0.1609  loss_box_reg: 0.3873  loss_mask: 0.3074  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.09307  time: 0.1946  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:49 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.7015  loss_cls: 0.1171  loss_box_reg: 0.3002  loss_mask: 0.2175  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.03461  time: 0.1947  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:53 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.8499  loss_cls: 0.1432  loss_box_reg: 0.3188  loss_mask: 0.2502  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.07428  time: 0.1948  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.8917  loss_cls: 0.1482  loss_box_reg: 0.3563  loss_mask: 0.2637  loss_rpn_cls: 0.01977  loss_rpn_loc: 0.09805  time: 0.1949  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:15:58 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:35 (0.1949 s / it)\n",
      "\u001b[32m[10/21 13:15:58 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:36 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='Q2GSKHZ_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:15:58 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:15:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:15:58 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:15:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:15:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:15:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0566 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.491996 (0.080387 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.058412 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Q2GSKHZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.606\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.599\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 31.151 | 60.618 | 31.206 | 33.747 | 28.594 | 40.796 |\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.638 | cushion    | 40.496 | door       | 19.354 |\n",
      "| indoor-plant | 46.721 | sofa       | 52.657 | table      | 2.037  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.528\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.576 | 52.757 | 11.758 | 13.591 | 16.643 | 60.220 |\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 18.385 | cushion    | 23.746 | door       | 38.787 |\n",
      "| indoor-plant | 27.215 | sofa       | 19.344 | table      | 1.980  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='Q2GSKHZ0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:16:01 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:16:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:16:01 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:16:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:16:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:16:04 d2.evaluation.evaluator]: \u001b[0mInference done 20/355. 0.0630 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 13:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 65/355. 0.0621 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 13:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 122/355. 0.0607 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 13:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 177/355. 0.0603 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 13:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 233/355. 0.0600 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 13:16:29 d2.evaluation.evaluator]: \u001b[0mInference done 282/355. 0.0602 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:16:34 d2.evaluation.evaluator]: \u001b[0mInference done 320/355. 0.0607 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 13:16:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.749693 (0.104999 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:16:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061053 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:16:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:16:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Q2GSKHZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:16:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:16:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:16:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 13:16:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:16:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\n",
      "\u001b[32m[10/21 13:16:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.901 | 32.332 | 20.443 | 8.403 | 23.020 | 20.493 |\n",
      "\u001b[32m[10/21 13:16:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.638 | cushion    | 45.942 | door       | 13.993 |\n",
      "| indoor-plant | 9.694 | sofa       | 38.096 | table      | 0.047  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:16:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:16:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.52 seconds.\n",
      "\u001b[32m[10/21 13:16:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:16:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.383\n",
      "\u001b[32m[10/21 13:16:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.635 | 31.888 | 22.662 | 7.427 | 24.473 | 22.297 |\n",
      "\u001b[32m[10/21 13:16:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.739 | cushion    | 54.179 | door       | 16.274 |\n",
      "| indoor-plant | 7.753 | sofa       | 35.752 | table      | 0.112  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='Q2GSKHZ1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:16:41 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:16:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:16:41 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:16:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:16:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0630 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 13:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 60/355. 0.0619 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 13:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 120/355. 0.0606 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 13:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 181/355. 0.0601 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 13:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 236/355. 0.0602 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.0604 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 13:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 333/355. 0.0607 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 13:17:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.012560 (0.097179 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:17:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060979 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:17:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:17:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Q2GSKHZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:17:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:17:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:17:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 13:17:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:17:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
      "\u001b[32m[10/21 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.707 | 31.368 | 21.850 | 8.282 | 22.967 | 18.054 |\n",
      "\u001b[32m[10/21 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.207 | cushion    | 47.951 | door       | 15.537 |\n",
      "| indoor-plant | 7.894 | sofa       | 34.589 | table      | 0.062  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:17:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:17:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.54 seconds.\n",
      "\u001b[32m[10/21 13:17:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:17:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.382\n",
      "\u001b[32m[10/21 13:17:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.435 | 30.862 | 23.463 | 7.916 | 24.753 | 21.301 |\n",
      "\u001b[32m[10/21 13:17:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.957 | cushion    | 55.589 | door       | 18.223 |\n",
      "| indoor-plant | 6.347 | sofa       | 32.289 | table      | 0.205  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='Q2GSKHZ2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:17:18 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:17:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:17:18 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:17:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:17:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0633 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 13:17:25 d2.evaluation.evaluator]: \u001b[0mInference done 57/355. 0.0621 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 13:17:30 d2.evaluation.evaluator]: \u001b[0mInference done 115/355. 0.0602 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 13:17:35 d2.evaluation.evaluator]: \u001b[0mInference done 177/355. 0.0596 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 13:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 229/355. 0.0597 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 13:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 276/355. 0.0601 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.0606 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.960787 (0.102745 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.060934 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/Q2GSKHZ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.458\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.702 | 33.035 | 22.482 | 8.017 | 23.955 | 21.228 |\n",
      "\u001b[32m[10/21 13:17:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.690 | cushion    | 46.900 | door       | 17.399 |\n",
      "| indoor-plant | 8.995 | sofa       | 39.201 | table      | 0.028  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:17:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:17:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 13:17:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:17:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
      "\u001b[32m[10/21 13:17:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.346 | 32.402 | 24.498 | 7.782 | 25.167 | 22.363 |\n",
      "\u001b[32m[10/21 13:17:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP     |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 3.968 | cushion    | 55.226 | door       | 19.570 |\n",
      "| indoor-plant | 7.110 | sofa       | 36.092 | table      | 0.112  |\n",
      "all results {'bbox': {'AP50': [32.33208226086638, 31.367760264201834, 33.034815484336875]}, 'segm': {'AP50': [31.887960365807327, 30.862323412097563, 32.40215855200678]}}\n",
      "dataset_name D75WU69\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/3/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json', name='D75WU69_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/D75WU690\n",
      "output_aug/500/D75WU690\n",
      "\u001b[32m[10/21 13:17:58 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:17:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "107 107\n",
      "\u001b[32m[10/21 13:17:58 d2.data.datasets.coco]: \u001b[0mLoaded 25 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 13:17:58 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 13:17:58 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 15           |  cushion   | 32           |    door    | 15           |\n",
      "| indoor-plant | 15           |    sofa    | 10           |   table    | 20           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 107          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 13:17:58 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:17:58 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:17:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:17:58 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:17:58 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:18:02 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 19  total_loss: 3.412  loss_cls: 1.743  loss_box_reg: 0.9025  loss_mask: 0.6883  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.03619  time: 0.1980  data_time: 0.0169  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:06 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 39  total_loss: 2.495  loss_cls: 0.8805  loss_box_reg: 0.8909  loss_mask: 0.6464  loss_rpn_cls: 0.03556  loss_rpn_loc: 0.04031  time: 0.1989  data_time: 0.0044  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:10 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 59  total_loss: 2.251  loss_cls: 0.7239  loss_box_reg: 0.8842  loss_mask: 0.5746  loss_rpn_cls: 0.02158  loss_rpn_loc: 0.02885  time: 0.1997  data_time: 0.0044  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:14 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 79  total_loss: 1.962  loss_cls: 0.5887  loss_box_reg: 0.8519  loss_mask: 0.4961  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.02593  time: 0.1993  data_time: 0.0041  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:18 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 99  total_loss: 1.746  loss_cls: 0.4715  loss_box_reg: 0.8311  loss_mask: 0.3724  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.02278  time: 0.1997  data_time: 0.0044  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:22 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 119  total_loss: 1.509  loss_cls: 0.3359  loss_box_reg: 0.749  loss_mask: 0.2921  loss_rpn_cls: 0.009034  loss_rpn_loc: 0.02394  time: 0.2004  data_time: 0.0043  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:26 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 139  total_loss: 1.077  loss_cls: 0.2165  loss_box_reg: 0.6058  loss_mask: 0.2519  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.02292  time: 0.2009  data_time: 0.0044  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:30 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 159  total_loss: 0.9211  loss_cls: 0.1872  loss_box_reg: 0.4906  loss_mask: 0.2177  loss_rpn_cls: 0.008162  loss_rpn_loc: 0.02297  time: 0.2009  data_time: 0.0042  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:34 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 179  total_loss: 0.8125  loss_cls: 0.1465  loss_box_reg: 0.4132  loss_mask: 0.2084  loss_rpn_cls: 0.008231  loss_rpn_loc: 0.02181  time: 0.2007  data_time: 0.0041  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:38 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 199  total_loss: 0.6745  loss_cls: 0.1225  loss_box_reg: 0.3431  loss_mask: 0.1869  loss_rpn_cls: 0.00389  loss_rpn_loc: 0.01933  time: 0.2009  data_time: 0.0042  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:43 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 219  total_loss: 0.6176  loss_cls: 0.1234  loss_box_reg: 0.3125  loss_mask: 0.1683  loss_rpn_cls: 0.002252  loss_rpn_loc: 0.02011  time: 0.2011  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:47 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 0.6133  loss_cls: 0.1031  loss_box_reg: 0.2813  loss_mask: 0.1538  loss_rpn_cls: 0.003728  loss_rpn_loc: 0.02202  time: 0.2012  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:51 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 0.5291  loss_cls: 0.09125  loss_box_reg: 0.2537  loss_mask: 0.1519  loss_rpn_cls: 0.002113  loss_rpn_loc: 0.01827  time: 0.2012  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:55 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 0.5317  loss_cls: 0.09521  loss_box_reg: 0.2528  loss_mask: 0.1443  loss_rpn_cls: 0.001116  loss_rpn_loc: 0.01848  time: 0.2010  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:18:59 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 0.4924  loss_cls: 0.08638  loss_box_reg: 0.234  loss_mask: 0.1433  loss_rpn_cls: 0.001067  loss_rpn_loc: 0.01596  time: 0.2010  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:03 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.4938  loss_cls: 0.07685  loss_box_reg: 0.2343  loss_mask: 0.1248  loss_rpn_cls: 0.001447  loss_rpn_loc: 0.0156  time: 0.2010  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:07 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.4684  loss_cls: 0.08291  loss_box_reg: 0.2173  loss_mask: 0.1349  loss_rpn_cls: 0.001459  loss_rpn_loc: 0.01761  time: 0.2009  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:11 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.4608  loss_cls: 0.07477  loss_box_reg: 0.2371  loss_mask: 0.1254  loss_rpn_cls: 0.001413  loss_rpn_loc: 0.01591  time: 0.2009  data_time: 0.0044  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:15 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.4272  loss_cls: 0.07953  loss_box_reg: 0.2133  loss_mask: 0.1201  loss_rpn_cls: 0.001107  loss_rpn_loc: 0.01452  time: 0.2010  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:19 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.4141  loss_cls: 0.07249  loss_box_reg: 0.1991  loss_mask: 0.127  loss_rpn_cls: 0.00103  loss_rpn_loc: 0.01303  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:23 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.4524  loss_cls: 0.07979  loss_box_reg: 0.2007  loss_mask: 0.1216  loss_rpn_cls: 0.001488  loss_rpn_loc: 0.01494  time: 0.2012  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:27 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.3968  loss_cls: 0.07355  loss_box_reg: 0.1965  loss_mask: 0.1133  loss_rpn_cls: 0.000478  loss_rpn_loc: 0.01338  time: 0.2013  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:31 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.4031  loss_cls: 0.06619  loss_box_reg: 0.1854  loss_mask: 0.1316  loss_rpn_cls: 0.000555  loss_rpn_loc: 0.01304  time: 0.2013  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:35 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.3978  loss_cls: 0.06457  loss_box_reg: 0.1941  loss_mask: 0.1196  loss_rpn_cls: 0.0008837  loss_rpn_loc: 0.0153  time: 0.2013  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:40 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.3859  loss_cls: 0.0762  loss_box_reg: 0.1822  loss_mask: 0.1229  loss_rpn_cls: 0.000548  loss_rpn_loc: 0.0151  time: 0.2014  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:19:40 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:40 (0.2014 s / it)\n",
      "\u001b[32m[10/21 13:19:40 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:41 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='D75WU69_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:19:40 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:19:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:19:40 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:19:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:19:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0553 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.193995 (0.070774 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057097 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D75WU690/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.633\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.431\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.412\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.508\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.540\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.534 | 63.290 | 43.690 | 43.059 | 42.375 | 10.146 |\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 35.075 | cushion    | 30.744 | door       | 14.213 |\n",
      "| indoor-plant | 68.614 | sofa       | 87.618 | table      | 18.941 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.153 | 46.968 | 18.677 | 29.402 | 21.334 | 12.487 |\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.637 | cushion    | 17.529 | door       | 17.374 |\n",
      "| indoor-plant | 48.144 | sofa       | 28.457 | table      | 6.778  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='D75WU690_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:19:43 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:19:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:19:43 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:19:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:19:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 34/355. 0.0591 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 13:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 103/355. 0.0579 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 13:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.0580 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 235/355. 0.0581 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 13:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 295/355. 0.0582 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.0583 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.857648 (0.079593 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058312 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D75WU690/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.448\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.791 | 44.773 | 37.236 | 14.624 | 34.372 | 25.740 |\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 13.935 | cushion    | 63.617 | door       | 4.732  |\n",
      "| indoor-plant | 36.721 | sofa       | 55.714 | table      | 10.027 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:20:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:20:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 13:20:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:20:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n",
      "\u001b[32m[10/21 13:20:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.008 | 38.865 | 22.970 | 11.709 | 27.093 | 17.307 |\n",
      "\u001b[32m[10/21 13:20:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.106 | cushion    | 66.621 | door       | 6.519 |\n",
      "| indoor-plant | 26.538 | sofa       | 33.637 | table      | 0.624 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='D75WU691_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:20:13 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:20:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:20:13 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:20:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:20:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 42/355. 0.0586 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 13:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 114/355. 0.0582 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 13:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 189/355. 0.0577 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 13:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.0580 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.0581 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.321453 (0.075204 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058272 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D75WU690/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.440\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.273 | 43.968 | 37.132 | 14.794 | 35.204 | 23.306 |\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.722 | cushion    | 64.923 | door       | 3.446 |\n",
      "| indoor-plant | 36.614 | sofa       | 52.088 | table      | 9.843 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:20:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:20:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 13:20:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:20:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.383\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
      "\u001b[32m[10/21 13:20:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.064 | 38.306 | 22.905 | 12.169 | 27.224 | 14.734 |\n",
      "\u001b[32m[10/21 13:20:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.943 | cushion    | 66.861 | door       | 4.743 |\n",
      "| indoor-plant | 26.266 | sofa       | 34.896 | table      | 0.677 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='D75WU692_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:20:41 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:20:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:20:41 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:20:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:20:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0593 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 13:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 80/355. 0.0575 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 13:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 151/355. 0.0578 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 13:20:57 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.0578 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:21:02 d2.evaluation.evaluator]: \u001b[0mInference done 276/355. 0.0580 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 13:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 338/355. 0.0580 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.375081 (0.078215 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058171 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D75WU690/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.652 | 44.495 | 37.801 | 14.881 | 34.180 | 26.417 |\n",
      "\u001b[32m[10/21 13:21:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.839 | cushion    | 63.910 | door       | 3.952 |\n",
      "| indoor-plant | 39.924 | sofa       | 52.862 | table      | 9.426 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:21:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:21:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 13:21:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:21:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.388\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.259\n",
      "\u001b[32m[10/21 13:21:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.882 | 38.798 | 22.362 | 11.901 | 27.038 | 16.408 |\n",
      "\u001b[32m[10/21 13:21:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.236 | cushion    | 66.121 | door       | 5.261 |\n",
      "| indoor-plant | 27.919 | sofa       | 33.234 | table      | 0.522 |\n",
      "all results {'bbox': {'AP50': [44.77264815596738, 43.96794067082736, 44.49526284255779]}, 'segm': {'AP50': [38.865198469312965, 38.30571412055176, 38.79800257936585]}}\n",
      "dataset_name K95L79B\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/3/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json', name='K95L79B_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/K95L79B0\n",
      "output_aug/800/K95L79B0\n",
      "\u001b[32m[10/21 13:21:11 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:21:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "107 107\n",
      "\u001b[32m[10/21 13:21:11 d2.data.datasets.coco]: \u001b[0mLoaded 25 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 13:21:11 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 13:21:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:21:11 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:21:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:21:11 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:21:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:21:16 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 19  total_loss: 3.449  loss_cls: 1.824  loss_box_reg: 0.9106  loss_mask: 0.6893  loss_rpn_cls: 0.08683  loss_rpn_loc: 0.04299  time: 0.2010  data_time: 0.0170  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:20 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 39  total_loss: 2.518  loss_cls: 0.891  loss_box_reg: 0.9385  loss_mask: 0.6504  loss_rpn_cls: 0.0334  loss_rpn_loc: 0.03349  time: 0.2020  data_time: 0.0044  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:24 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 59  total_loss: 2.303  loss_cls: 0.7375  loss_box_reg: 0.8993  loss_mask: 0.582  loss_rpn_cls: 0.02583  loss_rpn_loc: 0.03051  time: 0.2013  data_time: 0.0044  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:28 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 79  total_loss: 1.971  loss_cls: 0.6014  loss_box_reg: 0.8293  loss_mask: 0.5109  loss_rpn_cls: 0.01706  loss_rpn_loc: 0.03081  time: 0.2015  data_time: 0.0042  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:32 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 99  total_loss: 1.667  loss_cls: 0.443  loss_box_reg: 0.8015  loss_mask: 0.3862  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.02129  time: 0.2011  data_time: 0.0041  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:36 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 119  total_loss: 1.396  loss_cls: 0.3236  loss_box_reg: 0.7384  loss_mask: 0.3041  loss_rpn_cls: 0.008957  loss_rpn_loc: 0.02732  time: 0.2013  data_time: 0.0042  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:40 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 139  total_loss: 1.09  loss_cls: 0.2137  loss_box_reg: 0.5835  loss_mask: 0.2491  loss_rpn_cls: 0.009461  loss_rpn_loc: 0.02636  time: 0.2014  data_time: 0.0042  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:44 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 159  total_loss: 0.8852  loss_cls: 0.1674  loss_box_reg: 0.4645  loss_mask: 0.2057  loss_rpn_cls: 0.007409  loss_rpn_loc: 0.02525  time: 0.2010  data_time: 0.0043  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:48 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 179  total_loss: 0.8273  loss_cls: 0.1646  loss_box_reg: 0.4391  loss_mask: 0.1987  loss_rpn_cls: 0.005559  loss_rpn_loc: 0.02119  time: 0.2011  data_time: 0.0042  lr: 0.00089511  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:52 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 199  total_loss: 0.7424  loss_cls: 0.1414  loss_box_reg: 0.4035  loss_mask: 0.1756  loss_rpn_cls: 0.001895  loss_rpn_loc: 0.02179  time: 0.2012  data_time: 0.0043  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:21:56 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 219  total_loss: 0.6873  loss_cls: 0.1387  loss_box_reg: 0.3408  loss_mask: 0.1752  loss_rpn_cls: 0.002226  loss_rpn_loc: 0.01861  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:00 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 239  total_loss: 0.5979  loss_cls: 0.1133  loss_box_reg: 0.2935  loss_mask: 0.1654  loss_rpn_cls: 0.003277  loss_rpn_loc: 0.01816  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:04 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 259  total_loss: 0.5938  loss_cls: 0.1016  loss_box_reg: 0.2784  loss_mask: 0.1591  loss_rpn_cls: 0.003831  loss_rpn_loc: 0.0181  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:08 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 279  total_loss: 0.4935  loss_cls: 0.08423  loss_box_reg: 0.2479  loss_mask: 0.1385  loss_rpn_cls: 0.001739  loss_rpn_loc: 0.01751  time: 0.2010  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:12 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 299  total_loss: 0.5034  loss_cls: 0.09113  loss_box_reg: 0.2606  loss_mask: 0.1446  loss_rpn_cls: 0.001131  loss_rpn_loc: 0.0167  time: 0.2010  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:16 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 319  total_loss: 0.5031  loss_cls: 0.09088  loss_box_reg: 0.2406  loss_mask: 0.14  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.01576  time: 0.2010  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:20 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 339  total_loss: 0.4547  loss_cls: 0.07329  loss_box_reg: 0.2066  loss_mask: 0.1348  loss_rpn_cls: 0.001141  loss_rpn_loc: 0.01447  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:24 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 359  total_loss: 0.4331  loss_cls: 0.07521  loss_box_reg: 0.2082  loss_mask: 0.1318  loss_rpn_cls: 0.001609  loss_rpn_loc: 0.01547  time: 0.2012  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:28 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 379  total_loss: 0.4315  loss_cls: 0.06878  loss_box_reg: 0.2006  loss_mask: 0.1298  loss_rpn_cls: 0.001646  loss_rpn_loc: 0.0132  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:32 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 399  total_loss: 0.429  loss_cls: 0.08552  loss_box_reg: 0.2071  loss_mask: 0.122  loss_rpn_cls: 0.0008975  loss_rpn_loc: 0.01581  time: 0.2010  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:36 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 419  total_loss: 0.4378  loss_cls: 0.07208  loss_box_reg: 0.2054  loss_mask: 0.1282  loss_rpn_cls: 0.0009018  loss_rpn_loc: 0.01454  time: 0.2010  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:40 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 439  total_loss: 0.4366  loss_cls: 0.07588  loss_box_reg: 0.2091  loss_mask: 0.1345  loss_rpn_cls: 0.0009051  loss_rpn_loc: 0.01399  time: 0.2010  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:44 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 459  total_loss: 0.4039  loss_cls: 0.07348  loss_box_reg: 0.2028  loss_mask: 0.123  loss_rpn_cls: 0.0006605  loss_rpn_loc: 0.01485  time: 0.2010  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:48 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 479  total_loss: 0.4109  loss_cls: 0.06625  loss_box_reg: 0.1982  loss_mask: 0.1151  loss_rpn_cls: 0.0005786  loss_rpn_loc: 0.01387  time: 0.2010  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:52 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 499  total_loss: 0.4118  loss_cls: 0.07231  loss_box_reg: 0.1921  loss_mask: 0.1242  loss_rpn_cls: 0.0008864  loss_rpn_loc: 0.01418  time: 0.2010  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:22:56 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 519  total_loss: 0.3837  loss_cls: 0.06048  loss_box_reg: 0.1914  loss_mask: 0.1113  loss_rpn_cls: 0.0007265  loss_rpn_loc: 0.01397  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:00 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 0.4089  loss_cls: 0.06692  loss_box_reg: 0.2028  loss_mask: 0.1161  loss_rpn_cls: 0.001737  loss_rpn_loc: 0.01674  time: 0.2011  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:04 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 0.3673  loss_cls: 0.05988  loss_box_reg: 0.1662  loss_mask: 0.1083  loss_rpn_cls: 0.0008999  loss_rpn_loc: 0.01403  time: 0.2011  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:08 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.3514  loss_cls: 0.05732  loss_box_reg: 0.1665  loss_mask: 0.1107  loss_rpn_cls: 0.0006905  loss_rpn_loc: 0.01385  time: 0.2010  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:13 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.3911  loss_cls: 0.07135  loss_box_reg: 0.1773  loss_mask: 0.1143  loss_rpn_cls: 0.0008591  loss_rpn_loc: 0.0123  time: 0.2010  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:17 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.3371  loss_cls: 0.06498  loss_box_reg: 0.1506  loss_mask: 0.1091  loss_rpn_cls: 0.0005215  loss_rpn_loc: 0.0126  time: 0.2010  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:21 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.372  loss_cls: 0.0528  loss_box_reg: 0.1807  loss_mask: 0.1137  loss_rpn_cls: 0.0009631  loss_rpn_loc: 0.01216  time: 0.2010  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:25 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.352  loss_cls: 0.05809  loss_box_reg: 0.1665  loss_mask: 0.1114  loss_rpn_cls: 0.0007344  loss_rpn_loc: 0.01138  time: 0.2010  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:29 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 679  total_loss: 0.3767  loss_cls: 0.0679  loss_box_reg: 0.1797  loss_mask: 0.106  loss_rpn_cls: 0.0004994  loss_rpn_loc: 0.0111  time: 0.2011  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:33 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 699  total_loss: 0.3493  loss_cls: 0.05638  loss_box_reg: 0.1764  loss_mask: 0.1096  loss_rpn_cls: 0.0004049  loss_rpn_loc: 0.01108  time: 0.2011  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:37 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 719  total_loss: 0.354  loss_cls: 0.05643  loss_box_reg: 0.1632  loss_mask: 0.1112  loss_rpn_cls: 0.000634  loss_rpn_loc: 0.01496  time: 0.2011  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:41 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 739  total_loss: 0.3571  loss_cls: 0.05395  loss_box_reg: 0.1667  loss_mask: 0.1096  loss_rpn_cls: 0.0005583  loss_rpn_loc: 0.01308  time: 0.2010  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:45 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 759  total_loss: 0.3247  loss_cls: 0.05268  loss_box_reg: 0.1489  loss_mask: 0.1052  loss_rpn_cls: 0.0003828  loss_rpn_loc: 0.01241  time: 0.2009  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:49 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 779  total_loss: 0.3291  loss_cls: 0.06656  loss_box_reg: 0.1552  loss_mask: 0.1022  loss_rpn_cls: 0.0003972  loss_rpn_loc: 0.01032  time: 0.2008  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:54 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.3147  loss_cls: 0.04552  loss_box_reg: 0.1651  loss_mask: 0.0977  loss_rpn_cls: 0.0005314  loss_rpn_loc: 0.01176  time: 0.2008  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:23:54 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:40 (0.2009 s / it)\n",
      "\u001b[32m[10/21 13:23:54 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:41 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='K95L79B_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:23:54 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:23:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:23:54 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:23:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:23:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0566 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.155475 (0.069531 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.056519 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/K95L79B0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.671\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.442\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.458\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.407\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.521\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.321 | 67.150 | 44.227 | 45.847 | 40.738 | 11.266 |\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 32.357 | cushion    | 43.244 | door       | 15.595 |\n",
      "| indoor-plant | 70.666 | sofa       | 86.280 | table      | 17.784 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.532\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.955 | 53.215 | 20.138 | 31.210 | 21.179 | 13.991 |\n",
      "\u001b[32m[10/21 13:23:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.685 | cushion    | 25.394 | door       | 19.305 |\n",
      "| indoor-plant | 48.144 | sofa       | 29.450 | table      | 6.751  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='K95L79B0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:23:57 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:23:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:23:57 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:23:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:23:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 35/355. 0.0584 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 13:24:05 d2.evaluation.evaluator]: \u001b[0mInference done 105/355. 0.0580 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 13:24:10 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.0580 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:24:15 d2.evaluation.evaluator]: \u001b[0mInference done 236/355. 0.0583 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 13:24:20 d2.evaluation.evaluator]: \u001b[0mInference done 300/355. 0.0584 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:24:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.038017 (0.077251 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:24:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058577 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:24:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:24:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/K95L79B0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:24:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.404\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 33.702 | 47.005 | 40.350 | 16.456 | 38.454 | 25.460 |\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.542 | cushion    | 68.974 | door       | 4.429 |\n",
      "| indoor-plant | 41.059 | sofa       | 61.999 | table      | 9.212 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/21 13:24:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:24:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.419\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
      "\u001b[32m[10/21 13:24:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.770 | 41.851 | 25.430 | 12.796 | 28.868 | 17.030 |\n",
      "\u001b[32m[10/21 13:24:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.366 | cushion    | 71.983 | door       | 6.041 |\n",
      "| indoor-plant | 26.798 | sofa       | 34.827 | table      | 0.606 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='K95L79B1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:24:26 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:24:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:24:26 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:24:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:24:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0567 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 13:24:32 d2.evaluation.evaluator]: \u001b[0mInference done 79/355. 0.0573 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 13:24:37 d2.evaluation.evaluator]: \u001b[0mInference done 148/355. 0.0577 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 13:24:42 d2.evaluation.evaluator]: \u001b[0mInference done 217/355. 0.0575 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:24:47 d2.evaluation.evaluator]: \u001b[0mInference done 274/355. 0.0578 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 13:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 334/355. 0.0579 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.542354 (0.078692 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057933 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/K95L79B0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.376\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 32.480 | 46.109 | 39.277 | 16.711 | 37.271 | 22.560 |\n",
      "\u001b[32m[10/21 13:24:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.284 | cushion    | 69.943 | door       | 2.934 |\n",
      "| indoor-plant | 39.592 | sofa       | 56.184 | table      | 8.943 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:24:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:24:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 13:24:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:24:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
      "\u001b[32m[10/21 13:24:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.504 | 40.803 | 25.154 | 13.293 | 28.952 | 14.813 |\n",
      "\u001b[32m[10/21 13:24:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.762 | cushion    | 72.812 | door       | 3.814 |\n",
      "| indoor-plant | 27.014 | sofa       | 33.959 | table      | 0.661 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='K95L79B2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:24:55 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:24:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:24:55 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:24:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:24:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 20/355. 0.0580 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 13:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.0580 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 13:25:07 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.0587 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 13:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 221/355. 0.0588 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.0587 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 13:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 349/355. 0.0586 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.113133 (0.077466 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058619 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/K95L79B0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.471\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.504\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 32.938 | 47.131 | 39.263 | 17.628 | 36.759 | 25.936 |\n",
      "\u001b[32m[10/21 13:25:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.738 | cushion    | 69.283 | door       | 3.566 |\n",
      "| indoor-plant | 44.211 | sofa       | 56.286 | table      | 8.543 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:25:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:25:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 13:25:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:25:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.417\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
      "\u001b[32m[10/21 13:25:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.110 | 41.688 | 23.475 | 13.089 | 28.102 | 16.272 |\n",
      "\u001b[32m[10/21 13:25:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.282 | cushion    | 71.725 | door       | 4.509 |\n",
      "| indoor-plant | 28.858 | sofa       | 31.691 | table      | 0.596 |\n",
      "all results {'bbox': {'AP50': [47.00466286605358, 46.1086750352776, 47.13115603924545]}, 'segm': {'AP50': [41.85052793639401, 40.80267671511237, 41.687728233642495]}}\n",
      "dataset_name AA7S532\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/3/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json', name='AA7S532_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/AA7S5320\n",
      "output_aug/500/AA7S5320\n",
      "\u001b[32m[10/21 13:25:25 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:25:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "107 107\n",
      "\u001b[32m[10/21 13:25:25 d2.data.datasets.coco]: \u001b[0mLoaded 25 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 13:25:25 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 13:25:25 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:25:25 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:25:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:25:25 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:25:25 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:25:30 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 19  total_loss: 3.634  loss_cls: 1.881  loss_box_reg: 0.9299  loss_mask: 0.6908  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.03797  time: 0.1968  data_time: 0.0168  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:25:34 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 39  total_loss: 3.398  loss_cls: 1.695  loss_box_reg: 0.9135  loss_mask: 0.6866  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.03513  time: 0.1980  data_time: 0.0042  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:25:38 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 59  total_loss: 2.971  loss_cls: 1.326  loss_box_reg: 0.8951  loss_mask: 0.6796  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.03819  time: 0.1979  data_time: 0.0042  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:25:41 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 79  total_loss: 2.596  loss_cls: 0.9872  loss_box_reg: 0.8754  loss_mask: 0.6658  loss_rpn_cls: 0.04289  loss_rpn_loc: 0.03386  time: 0.1980  data_time: 0.0041  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:25:45 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 99  total_loss: 2.485  loss_cls: 0.8648  loss_box_reg: 0.8897  loss_mask: 0.6471  loss_rpn_cls: 0.03153  loss_rpn_loc: 0.03404  time: 0.1979  data_time: 0.0039  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:25:49 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 119  total_loss: 2.408  loss_cls: 0.8347  loss_box_reg: 0.9032  loss_mask: 0.6202  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.03068  time: 0.1977  data_time: 0.0041  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:25:53 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 139  total_loss: 2.28  loss_cls: 0.7709  loss_box_reg: 0.8541  loss_mask: 0.6053  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.02958  time: 0.1982  data_time: 0.0043  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:25:57 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 159  total_loss: 2.262  loss_cls: 0.7277  loss_box_reg: 0.876  loss_mask: 0.5776  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.03177  time: 0.1982  data_time: 0.0040  lr: 7.952e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:01 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 179  total_loss: 2.2  loss_cls: 0.6969  loss_box_reg: 0.8776  loss_mask: 0.5392  loss_rpn_cls: 0.01832  loss_rpn_loc: 0.02985  time: 0.1987  data_time: 0.0044  lr: 8.951e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:05 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 199  total_loss: 2.069  loss_cls: 0.6451  loss_box_reg: 0.8585  loss_mask: 0.5114  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.02777  time: 0.1986  data_time: 0.0042  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:09 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 219  total_loss: 1.973  loss_cls: 0.5852  loss_box_reg: 0.8511  loss_mask: 0.4947  loss_rpn_cls: 0.01697  loss_rpn_loc: 0.0254  time: 0.1989  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:14 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 1.881  loss_cls: 0.5117  loss_box_reg: 0.8474  loss_mask: 0.4545  loss_rpn_cls: 0.02059  loss_rpn_loc: 0.02352  time: 0.1990  data_time: 0.0039  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:18 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 1.746  loss_cls: 0.4698  loss_box_reg: 0.8503  loss_mask: 0.4143  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.02279  time: 0.1993  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:22 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 1.684  loss_cls: 0.4254  loss_box_reg: 0.7962  loss_mask: 0.3933  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.02584  time: 0.1993  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:26 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 1.598  loss_cls: 0.3878  loss_box_reg: 0.7903  loss_mask: 0.3804  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.0229  time: 0.1991  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:30 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 1.471  loss_cls: 0.3355  loss_box_reg: 0.7669  loss_mask: 0.3415  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.02448  time: 0.1993  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:34 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 1.426  loss_cls: 0.346  loss_box_reg: 0.7198  loss_mask: 0.3306  loss_rpn_cls: 0.007471  loss_rpn_loc: 0.02295  time: 0.1994  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:38 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 1.245  loss_cls: 0.2648  loss_box_reg: 0.6808  loss_mask: 0.2909  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.02573  time: 0.1997  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:42 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 1.215  loss_cls: 0.2778  loss_box_reg: 0.6539  loss_mask: 0.2894  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.02329  time: 0.1999  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:46 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 1.162  loss_cls: 0.2509  loss_box_reg: 0.6065  loss_mask: 0.2673  loss_rpn_cls: 0.007266  loss_rpn_loc: 0.02426  time: 0.1999  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:50 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 1.07  loss_cls: 0.2058  loss_box_reg: 0.5486  loss_mask: 0.2653  loss_rpn_cls: 0.008239  loss_rpn_loc: 0.02238  time: 0.2000  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:54 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.9824  loss_cls: 0.2015  loss_box_reg: 0.5117  loss_mask: 0.2503  loss_rpn_cls: 0.006808  loss_rpn_loc: 0.01969  time: 0.2001  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:26:58 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 1.025  loss_cls: 0.21  loss_box_reg: 0.5115  loss_mask: 0.2554  loss_rpn_cls: 0.005944  loss_rpn_loc: 0.02288  time: 0.2001  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:27:02 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.9997  loss_cls: 0.2092  loss_box_reg: 0.4671  loss_mask: 0.2546  loss_rpn_cls: 0.007169  loss_rpn_loc: 0.02167  time: 0.2002  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:27:07 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.927  loss_cls: 0.1747  loss_box_reg: 0.4485  loss_mask: 0.2278  loss_rpn_cls: 0.005815  loss_rpn_loc: 0.02135  time: 0.2003  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:27:07 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:39 (0.2003 s / it)\n",
      "\u001b[32m[10/21 13:27:07 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:41 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='AA7S532_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:27:07 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:27:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:27:07 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:27:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:27:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0570 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.572945 (0.082998 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.058981 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AA7S5320/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.632\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.554\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 34.376 | 63.154 | 34.314 | 39.980 | 36.003 | 22.359 |\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 32.689 | cushion    | 26.599 | door       | 9.948 |\n",
      "| indoor-plant | 68.548 | sofa       | 60.042 | table      | 8.431 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.511\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.391 | 51.098 | 15.719 | 27.132 | 23.897 | 33.409 |\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.653 | cushion    | 18.879 | door       | 11.361 |\n",
      "| indoor-plant | 46.782 | sofa       | 36.137 | table      | 0.531  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='AA7S5320_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:27:10 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:27:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:27:10 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:27:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:27:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 21/355. 0.0634 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 13:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 69/355. 0.0618 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 13:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 128/355. 0.0602 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 13:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 188/355. 0.0598 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 13:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 234/355. 0.0604 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 13:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 279/355. 0.0608 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 13:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.0611 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 13:27:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.910190 (0.102601 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:27:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061188 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:27:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:27:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AA7S5320/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:27:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:27:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:27:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 13:27:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:27:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.412\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
      "\u001b[32m[10/21 13:27:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.829 | 41.188 | 23.348 | 13.240 | 27.044 | 17.392 |\n",
      "\u001b[32m[10/21 13:27:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.520 | cushion    | 40.702 | door       | 3.990 |\n",
      "| indoor-plant | 28.997 | sofa       | 41.838 | table      | 4.928 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:27:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:27:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/21 13:27:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:27:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.353\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315\n",
      "\u001b[32m[10/21 13:27:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.832 | 35.342 | 21.345 | 10.731 | 24.290 | 19.595 |\n",
      "\u001b[32m[10/21 13:27:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.155 | cushion    | 46.308 | door       | 4.761 |\n",
      "| indoor-plant | 26.143 | sofa       | 40.587 | table      | 0.038 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='AA7S5321_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:27:49 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:27:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:27:49 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:27:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:27:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0638 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 13:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 60/355. 0.0619 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 13:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 119/355. 0.0605 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 13:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.0600 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 13:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.0605 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 13:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.0609 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 13:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 309/355. 0.0613 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 355/355. 0.0615 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:28:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:36.195032 (0.103414 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:28:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061456 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AA7S5320/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.950 | 40.793 | 21.417 | 11.074 | 26.313 | 13.855 |\n",
      "\u001b[32m[10/21 13:28:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.820 | cushion    | 39.464 | door       | 3.180 |\n",
      "| indoor-plant | 28.336 | sofa       | 39.228 | table      | 4.673 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:28:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:28:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/21 13:28:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:28:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n",
      "\u001b[32m[10/21 13:28:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 21.637 | 34.594 | 22.007 | 7.946 | 23.341 | 15.969 |\n",
      "\u001b[32m[10/21 13:28:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.935 | cushion    | 46.130 | door       | 3.721 |\n",
      "| indoor-plant | 25.493 | sofa       | 40.508 | table      | 0.035 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='AA7S5322_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:28:28 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:28:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:28:28 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:28:28 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:28:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 25/355. 0.0639 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 13:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 79/355. 0.0614 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 13:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 139/355. 0.0603 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 13:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 201/355. 0.0600 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.0607 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.0613 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 13:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 341/355. 0.0613 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.601861 (0.098862 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:21 (0.061477 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/AA7S5320/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.832 | 41.556 | 23.720 | 10.607 | 26.639 | 17.246 |\n",
      "\u001b[32m[10/21 13:29:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.740 | cushion    | 39.633 | door       | 3.591 |\n",
      "| indoor-plant | 30.601 | sofa       | 41.845 | table      | 4.582 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:29:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:29:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.60 seconds.\n",
      "\u001b[32m[10/21 13:29:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:29:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n",
      "\u001b[32m[10/21 13:29:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 22.404 | 36.169 | 22.800 | 7.347 | 24.461 | 19.009 |\n",
      "\u001b[32m[10/21 13:29:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.451 | cushion    | 45.296 | door       | 4.483 |\n",
      "| indoor-plant | 28.539 | sofa       | 42.616 | table      | 0.042 |\n",
      "all results {'bbox': {'AP50': [41.18756860788557, 40.79304154548456, 41.55622472485842]}, 'segm': {'AP50': [35.34174122762136, 34.59447115764714, 36.169032751318284]}}\n",
      "dataset_name WCQAG6Z\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/3/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json', name='WCQAG6Z_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/WCQAG6Z0\n",
      "output_aug/800/WCQAG6Z0\n",
      "\u001b[32m[10/21 13:29:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:29:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "107 107\n",
      "\u001b[32m[10/21 13:29:07 d2.data.datasets.coco]: \u001b[0mLoaded 25 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 13:29:07 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 13:29:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:29:07 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:29:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:29:07 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:29:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:29:11 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 19  total_loss: 3.796  loss_cls: 2.011  loss_box_reg: 0.9399  loss_mask: 0.6916  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.03906  time: 0.2012  data_time: 0.0166  lr: 9.5905e-06  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:15 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 39  total_loss: 3.583  loss_cls: 1.813  loss_box_reg: 0.9063  loss_mask: 0.6879  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.04274  time: 0.1999  data_time: 0.0044  lr: 1.958e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:19 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 59  total_loss: 3.097  loss_cls: 1.476  loss_box_reg: 0.9023  loss_mask: 0.6787  loss_rpn_cls: 0.05327  loss_rpn_loc: 0.0306  time: 0.1999  data_time: 0.0043  lr: 2.9571e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:23 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 79  total_loss: 2.755  loss_cls: 1.075  loss_box_reg: 0.9311  loss_mask: 0.6685  loss_rpn_cls: 0.0531  loss_rpn_loc: 0.03511  time: 0.1997  data_time: 0.0042  lr: 3.9561e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:27 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 99  total_loss: 2.565  loss_cls: 0.885  loss_box_reg: 0.8834  loss_mask: 0.6535  loss_rpn_cls: 0.04408  loss_rpn_loc: 0.03839  time: 0.2001  data_time: 0.0044  lr: 4.955e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:31 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 119  total_loss: 2.418  loss_cls: 0.8317  loss_box_reg: 0.8444  loss_mask: 0.6262  loss_rpn_cls: 0.02799  loss_rpn_loc: 0.03088  time: 0.2000  data_time: 0.0041  lr: 5.954e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:35 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 139  total_loss: 2.385  loss_cls: 0.8071  loss_box_reg: 0.9007  loss_mask: 0.6061  loss_rpn_cls: 0.0252  loss_rpn_loc: 0.03523  time: 0.1997  data_time: 0.0043  lr: 6.9531e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:39 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 159  total_loss: 2.23  loss_cls: 0.7522  loss_box_reg: 0.8671  loss_mask: 0.5768  loss_rpn_cls: 0.02358  loss_rpn_loc: 0.03478  time: 0.1996  data_time: 0.0042  lr: 7.9521e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:43 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 179  total_loss: 2.153  loss_cls: 0.6828  loss_box_reg: 0.875  loss_mask: 0.5481  loss_rpn_cls: 0.02085  loss_rpn_loc: 0.02911  time: 0.1997  data_time: 0.0042  lr: 8.9511e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:47 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 199  total_loss: 2.18  loss_cls: 0.6742  loss_box_reg: 0.8549  loss_mask: 0.5189  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.0284  time: 0.1997  data_time: 0.0041  lr: 9.9501e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:51 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 219  total_loss: 2.07  loss_cls: 0.6312  loss_box_reg: 0.8454  loss_mask: 0.5029  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.02582  time: 0.1998  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:29:55 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 239  total_loss: 1.93  loss_cls: 0.5662  loss_box_reg: 0.8238  loss_mask: 0.4634  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.02505  time: 0.2000  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:00 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 259  total_loss: 1.821  loss_cls: 0.4939  loss_box_reg: 0.8269  loss_mask: 0.4447  loss_rpn_cls: 0.01667  loss_rpn_loc: 0.02537  time: 0.2001  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:04 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 279  total_loss: 1.734  loss_cls: 0.4629  loss_box_reg: 0.8368  loss_mask: 0.3933  loss_rpn_cls: 0.008797  loss_rpn_loc: 0.02277  time: 0.2003  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:08 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 299  total_loss: 1.616  loss_cls: 0.3792  loss_box_reg: 0.797  loss_mask: 0.3604  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.02219  time: 0.2004  data_time: 0.0043  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:12 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 319  total_loss: 1.486  loss_cls: 0.365  loss_box_reg: 0.7742  loss_mask: 0.335  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.02367  time: 0.2006  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:16 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 339  total_loss: 1.483  loss_cls: 0.3406  loss_box_reg: 0.7821  loss_mask: 0.3324  loss_rpn_cls: 0.008456  loss_rpn_loc: 0.02308  time: 0.2005  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:20 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 359  total_loss: 1.333  loss_cls: 0.307  loss_box_reg: 0.7146  loss_mask: 0.3042  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.02311  time: 0.2004  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:24 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 379  total_loss: 1.225  loss_cls: 0.2726  loss_box_reg: 0.6515  loss_mask: 0.2862  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.02312  time: 0.2006  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:28 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 399  total_loss: 1.231  loss_cls: 0.2393  loss_box_reg: 0.6542  loss_mask: 0.2767  loss_rpn_cls: 0.009169  loss_rpn_loc: 0.02663  time: 0.2006  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:32 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 419  total_loss: 1.113  loss_cls: 0.2387  loss_box_reg: 0.5888  loss_mask: 0.2739  loss_rpn_cls: 0.005465  loss_rpn_loc: 0.02256  time: 0.2007  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:36 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 439  total_loss: 1.072  loss_cls: 0.2303  loss_box_reg: 0.5495  loss_mask: 0.2605  loss_rpn_cls: 0.007452  loss_rpn_loc: 0.02044  time: 0.2006  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:40 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 459  total_loss: 1.043  loss_cls: 0.2279  loss_box_reg: 0.5229  loss_mask: 0.2647  loss_rpn_cls: 0.007422  loss_rpn_loc: 0.02238  time: 0.2006  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:44 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 479  total_loss: 0.9287  loss_cls: 0.1889  loss_box_reg: 0.4667  loss_mask: 0.2357  loss_rpn_cls: 0.006517  loss_rpn_loc: 0.0238  time: 0.2007  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:48 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 499  total_loss: 0.9212  loss_cls: 0.1967  loss_box_reg: 0.4464  loss_mask: 0.2466  loss_rpn_cls: 0.005003  loss_rpn_loc: 0.02136  time: 0.2006  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:52 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 519  total_loss: 0.871  loss_cls: 0.2047  loss_box_reg: 0.4417  loss_mask: 0.2362  loss_rpn_cls: 0.004367  loss_rpn_loc: 0.02182  time: 0.2006  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:30:56 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 539  total_loss: 0.8645  loss_cls: 0.1705  loss_box_reg: 0.4326  loss_mask: 0.2319  loss_rpn_cls: 0.003848  loss_rpn_loc: 0.02062  time: 0.2005  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:00 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 559  total_loss: 0.8849  loss_cls: 0.1813  loss_box_reg: 0.4158  loss_mask: 0.2316  loss_rpn_cls: 0.005247  loss_rpn_loc: 0.02236  time: 0.2005  data_time: 0.0042  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:04 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 579  total_loss: 0.8044  loss_cls: 0.1738  loss_box_reg: 0.386  loss_mask: 0.2079  loss_rpn_cls: 0.003239  loss_rpn_loc: 0.01964  time: 0.2006  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:08 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 0.7762  loss_cls: 0.1729  loss_box_reg: 0.367  loss_mask: 0.2089  loss_rpn_cls: 0.006659  loss_rpn_loc: 0.02285  time: 0.2006  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:12 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 619  total_loss: 0.7551  loss_cls: 0.1599  loss_box_reg: 0.3439  loss_mask: 0.2091  loss_rpn_cls: 0.006154  loss_rpn_loc: 0.01723  time: 0.2007  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:16 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 639  total_loss: 0.7628  loss_cls: 0.1451  loss_box_reg: 0.3762  loss_mask: 0.2104  loss_rpn_cls: 0.004758  loss_rpn_loc: 0.02214  time: 0.2007  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:20 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 659  total_loss: 0.7408  loss_cls: 0.148  loss_box_reg: 0.3504  loss_mask: 0.2088  loss_rpn_cls: 0.003158  loss_rpn_loc: 0.0183  time: 0.2008  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:24 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 679  total_loss: 0.682  loss_cls: 0.1428  loss_box_reg: 0.3263  loss_mask: 0.2001  loss_rpn_cls: 0.003844  loss_rpn_loc: 0.01982  time: 0.2008  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:28 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 699  total_loss: 0.6485  loss_cls: 0.1359  loss_box_reg: 0.3111  loss_mask: 0.2058  loss_rpn_cls: 0.001016  loss_rpn_loc: 0.02016  time: 0.2009  data_time: 0.0040  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:32 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 719  total_loss: 0.6731  loss_cls: 0.1374  loss_box_reg: 0.3033  loss_mask: 0.1935  loss_rpn_cls: 0.004306  loss_rpn_loc: 0.0184  time: 0.2009  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:36 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 739  total_loss: 0.6411  loss_cls: 0.128  loss_box_reg: 0.3079  loss_mask: 0.1949  loss_rpn_cls: 0.003462  loss_rpn_loc: 0.01747  time: 0.2009  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:40 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 759  total_loss: 0.692  loss_cls: 0.1319  loss_box_reg: 0.3104  loss_mask: 0.2084  loss_rpn_cls: 0.002932  loss_rpn_loc: 0.01872  time: 0.2009  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:44 d2.utils.events]: \u001b[0m eta: 0:00:04  iter: 779  total_loss: 0.5733  loss_cls: 0.1042  loss_box_reg: 0.2917  loss_mask: 0.1918  loss_rpn_cls: 0.002573  loss_rpn_loc: 0.01586  time: 0.2009  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:50 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5815  loss_cls: 0.1156  loss_box_reg: 0.2552  loss_mask: 0.187  loss_rpn_cls: 0.004742  loss_rpn_loc: 0.01558  time: 0.2009  data_time: 0.0041  lr: 0.0001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:31:50 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:02:40 (0.2009 s / it)\n",
      "\u001b[32m[10/21 13:31:50 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:41 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='WCQAG6Z_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:31:50 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:31:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:31:50 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:31:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:31:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:31:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0564 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.206230 (0.071169 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057551 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WCQAG6Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.609\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.404\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.380\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 36.028 | 60.930 | 40.393 | 37.956 | 36.681 | 7.703 |\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 32.161 | cushion    | 21.973 | door       | 8.675  |\n",
      "| indoor-plant | 60.347 | sofa       | 81.017 | table      | 11.994 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.471\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.744 | 47.124 | 22.098 | 26.232 | 24.537 | 14.658 |\n",
      "\u001b[32m[10/21 13:31:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.422 | cushion    | 14.526 | door       | 13.142 |\n",
      "| indoor-plant | 51.931 | sofa       | 36.149 | table      | 1.298  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='WCQAG6Z0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:31:52 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:31:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:31:53 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:31:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:31:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 35/355. 0.0589 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 13:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.0582 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 13:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.0582 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 241/355. 0.0580 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 13:32:16 d2.evaluation.evaluator]: \u001b[0mInference done 306/355. 0.0581 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:26.773860 (0.076497 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058224 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WCQAG6Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.404\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.371\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 27.366 | 41.027 | 33.387 | 9.904 | 31.116 | 22.702 |\n",
      "\u001b[32m[10/21 13:32:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 20.887 | cushion    | 40.294 | door       | 5.313 |\n",
      "| indoor-plant | 36.374 | sofa       | 55.160 | table      | 6.168 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:32:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:32:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 13:32:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:32:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.356\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.290\n",
      "\u001b[32m[10/21 13:32:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 23.244 | 35.575 | 25.052 | 7.099 | 25.656 | 20.414 |\n",
      "\u001b[32m[10/21 13:32:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.509 | cushion    | 46.241 | door       | 6.501 |\n",
      "| indoor-plant | 25.754 | sofa       | 48.278 | table      | 0.183 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='WCQAG6Z1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:32:21 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:32:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:32:21 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:32:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:32:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:32:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0587 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 13:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 74/355. 0.0578 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 13:32:32 d2.evaluation.evaluator]: \u001b[0mInference done 143/355. 0.0583 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 13:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 214/355. 0.0578 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 274/355. 0.0580 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 13:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.0580 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:32:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.439112 (0.078397 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:32:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058129 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:32:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:32:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WCQAG6Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:32:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.405\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.938 | 40.512 | 32.301 | 10.591 | 31.144 | 19.946 |\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.972 | cushion    | 40.498 | door       | 3.679 |\n",
      "| indoor-plant | 35.624 | sofa       | 53.506 | table      | 6.352 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.259\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 22.907 | 34.837 | 24.693 | 7.812 | 25.790 | 17.288 |\n",
      "\u001b[32m[10/21 13:32:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.312 | cushion    | 46.263 | door       | 4.657 |\n",
      "| indoor-plant | 25.093 | sofa       | 47.972 | table      | 0.146 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='WCQAG6Z2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:32:51 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:32:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:32:51 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:32:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:32:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 21/355. 0.0587 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 13:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 86/355. 0.0582 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 13:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 156/355. 0.0579 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 13:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 221/355. 0.0579 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 282/355. 0.0581 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 13:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 345/355. 0.0580 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.530990 (0.078660 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058059 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/WCQAG6Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 27.263 | 41.032 | 32.566 | 9.849 | 31.479 | 23.362 |\n",
      "\u001b[32m[10/21 13:33:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.125 | cushion    | 40.964 | door       | 4.954 |\n",
      "| indoor-plant | 38.033 | sofa       | 52.435 | table      | 6.066 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:33:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:33:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 13:33:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:33:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
      "\u001b[32m[10/21 13:33:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 23.206 | 35.908 | 24.809 | 7.227 | 26.397 | 19.757 |\n",
      "\u001b[32m[10/21 13:33:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.384 | cushion    | 46.021 | door       | 6.079 |\n",
      "| indoor-plant | 28.075 | sofa       | 46.563 | table      | 0.112 |\n",
      "all results {'bbox': {'AP50': [41.026517841374, 40.51153054238329, 41.03171171494066]}, 'segm': {'AP50': [35.57485976962684, 34.83693581620769, 35.90797279948466]}}\n",
      "dataset_name O4DTV2W\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/3/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p4/coco_train.json', name='O4DTV2W_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/O4DTV2W0\n",
      "output_aug/500/O4DTV2W0\n",
      "\u001b[32m[10/21 13:33:21 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:33:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "186 186\n",
      "\u001b[32m[10/21 13:33:21 d2.data.datasets.coco]: \u001b[0mLoaded 43 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 13:33:21 d2.data.build]: \u001b[0mRemoved 7 images with no usable annotations. 36 images left.\n",
      "\u001b[32m[10/21 13:33:21 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 27           |  cushion   | 54           |    door    | 27           |\n",
      "| indoor-plant | 25           |    sofa    | 17           |   table    | 36           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 186          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 13:33:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:33:21 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:33:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:33:21 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:33:21 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:33:26 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 19  total_loss: 3.514  loss_cls: 1.865  loss_box_reg: 0.9089  loss_mask: 0.692  loss_rpn_cls: 0.07625  loss_rpn_loc: 0.03843  time: 0.2019  data_time: 0.0177  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:30 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 39  total_loss: 2.529  loss_cls: 0.8777  loss_box_reg: 0.885  loss_mask: 0.6609  loss_rpn_cls: 0.03514  loss_rpn_loc: 0.02837  time: 0.1999  data_time: 0.0043  lr: 0.0001958  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:34 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 59  total_loss: 2.223  loss_cls: 0.7025  loss_box_reg: 0.8618  loss_mask: 0.5867  loss_rpn_cls: 0.02452  loss_rpn_loc: 0.03474  time: 0.1995  data_time: 0.0042  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:38 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 79  total_loss: 1.985  loss_cls: 0.5878  loss_box_reg: 0.8378  loss_mask: 0.5023  loss_rpn_cls: 0.02058  loss_rpn_loc: 0.0294  time: 0.1999  data_time: 0.0044  lr: 0.0003956  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:42 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 99  total_loss: 1.656  loss_cls: 0.4271  loss_box_reg: 0.8157  loss_mask: 0.402  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.02247  time: 0.1999  data_time: 0.0041  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:46 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 119  total_loss: 1.425  loss_cls: 0.3056  loss_box_reg: 0.7591  loss_mask: 0.3123  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.02697  time: 0.2001  data_time: 0.0043  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:50 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 139  total_loss: 1.105  loss_cls: 0.2223  loss_box_reg: 0.587  loss_mask: 0.2556  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.02493  time: 0.2003  data_time: 0.0042  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:54 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 159  total_loss: 0.9514  loss_cls: 0.1901  loss_box_reg: 0.5341  loss_mask: 0.2432  loss_rpn_cls: 0.006821  loss_rpn_loc: 0.02146  time: 0.2002  data_time: 0.0041  lr: 0.00079521  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:33:58 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 179  total_loss: 0.836  loss_cls: 0.1529  loss_box_reg: 0.4618  loss_mask: 0.1832  loss_rpn_cls: 0.007788  loss_rpn_loc: 0.02036  time: 0.2001  data_time: 0.0041  lr: 0.0008951  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:02 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 199  total_loss: 0.7088  loss_cls: 0.1391  loss_box_reg: 0.361  loss_mask: 0.1759  loss_rpn_cls: 0.004246  loss_rpn_loc: 0.018  time: 0.2001  data_time: 0.0043  lr: 0.000995  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:06 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 219  total_loss: 0.7029  loss_cls: 0.1338  loss_box_reg: 0.3708  loss_mask: 0.182  loss_rpn_cls: 0.003039  loss_rpn_loc: 0.01968  time: 0.2001  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:10 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 239  total_loss: 0.5943  loss_cls: 0.117  loss_box_reg: 0.29  loss_mask: 0.169  loss_rpn_cls: 0.002391  loss_rpn_loc: 0.01746  time: 0.2003  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:14 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 259  total_loss: 0.5839  loss_cls: 0.122  loss_box_reg: 0.2943  loss_mask: 0.1541  loss_rpn_cls: 0.003136  loss_rpn_loc: 0.02152  time: 0.2006  data_time: 0.0043  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:18 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 279  total_loss: 0.5647  loss_cls: 0.101  loss_box_reg: 0.2917  loss_mask: 0.1496  loss_rpn_cls: 0.001646  loss_rpn_loc: 0.015  time: 0.2008  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:22 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 299  total_loss: 0.5745  loss_cls: 0.1015  loss_box_reg: 0.2738  loss_mask: 0.143  loss_rpn_cls: 0.001158  loss_rpn_loc: 0.0164  time: 0.2006  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:26 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 319  total_loss: 0.5125  loss_cls: 0.09959  loss_box_reg: 0.2443  loss_mask: 0.1382  loss_rpn_cls: 0.001987  loss_rpn_loc: 0.01854  time: 0.2004  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:30 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 339  total_loss: 0.5025  loss_cls: 0.08558  loss_box_reg: 0.2507  loss_mask: 0.1494  loss_rpn_cls: 0.001261  loss_rpn_loc: 0.01453  time: 0.2002  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:34 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 359  total_loss: 0.4838  loss_cls: 0.08726  loss_box_reg: 0.23  loss_mask: 0.1329  loss_rpn_cls: 0.001185  loss_rpn_loc: 0.01568  time: 0.2003  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:38 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 379  total_loss: 0.4768  loss_cls: 0.08441  loss_box_reg: 0.2236  loss_mask: 0.1458  loss_rpn_cls: 0.001234  loss_rpn_loc: 0.01246  time: 0.2005  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:42 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 399  total_loss: 0.4756  loss_cls: 0.07463  loss_box_reg: 0.2159  loss_mask: 0.1409  loss_rpn_cls: 0.001364  loss_rpn_loc: 0.0159  time: 0.2005  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:46 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 419  total_loss: 0.4654  loss_cls: 0.07404  loss_box_reg: 0.205  loss_mask: 0.1366  loss_rpn_cls: 0.001935  loss_rpn_loc: 0.01768  time: 0.2006  data_time: 0.0041  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:50 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 439  total_loss: 0.448  loss_cls: 0.08365  loss_box_reg: 0.2095  loss_mask: 0.1322  loss_rpn_cls: 0.001532  loss_rpn_loc: 0.01598  time: 0.2007  data_time: 0.0042  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:54 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 459  total_loss: 0.4568  loss_cls: 0.06695  loss_box_reg: 0.2  loss_mask: 0.131  loss_rpn_cls: 0.001335  loss_rpn_loc: 0.01199  time: 0.2007  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:34:58 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 479  total_loss: 0.4243  loss_cls: 0.07066  loss_box_reg: 0.2182  loss_mask: 0.1253  loss_rpn_cls: 0.001716  loss_rpn_loc: 0.01413  time: 0.2008  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:35:03 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.4515  loss_cls: 0.076  loss_box_reg: 0.2351  loss_mask: 0.1287  loss_rpn_cls: 0.001356  loss_rpn_loc: 0.01586  time: 0.2007  data_time: 0.0040  lr: 0.001  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:35:03 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:39 (0.2007 s / it)\n",
      "\u001b[32m[10/21 13:35:03 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:41 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json', name='O4DTV2W_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "160 160\n",
      "\u001b[32m[10/21 13:35:03 d2.data.datasets.coco]: \u001b[0mLoaded 36 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json\n",
      "\u001b[32m[10/21 13:35:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:35:03 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:35:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[10/21 13:35:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 36 images\n",
      "\u001b[32m[10/21 13:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/36. 0.0558 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.140063 (0.069034 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.057031 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O4DTV2W0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.629\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.398\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 38.867 | 62.920 | 42.057 | 39.828 | 37.785 | 11.217 |\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.742 | cushion    | 30.602 | door       | 15.567 |\n",
      "| indoor-plant | 63.552 | sofa       | 81.224 | table      | 15.513 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.358 | 47.324 | 20.243 | 29.219 | 20.124 | 11.345 |\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 23.366 | cushion    | 21.364 | door       | 15.344 |\n",
      "| indoor-plant | 46.510 | sofa       | 26.328 | table      | 7.236  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='O4DTV2W0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 13:35:06 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 13:35:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:35:06 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:35:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 13:35:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 36/355. 0.0578 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 13:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 105/355. 0.0582 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 13:35:19 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.0579 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:35:24 d2.evaluation.evaluator]: \u001b[0mInference done 236/355. 0.0583 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 13:35:29 d2.evaluation.evaluator]: \u001b[0mInference done 296/355. 0.0585 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 13:35:34 d2.evaluation.evaluator]: \u001b[0mInference done 355/355. 0.0586 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.747391 (0.079278 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058622 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O4DTV2W0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.440\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.583 | 43.982 | 36.147 | 15.416 | 33.504 | 20.972 |\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.380 | cushion    | 65.827 | door       | 3.003 |\n",
      "| indoor-plant | 38.905 | sofa       | 54.403 | table      | 6.979 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:35:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:35:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 13:35:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:35:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
      "\u001b[32m[10/21 13:35:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.157 | 37.775 | 24.768 | 11.798 | 26.895 | 14.068 |\n",
      "\u001b[32m[10/21 13:35:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.717  | cushion    | 70.257 | door       | 3.578 |\n",
      "| indoor-plant | 26.008 | sofa       | 36.060 | table      | 0.324 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='O4DTV2W1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 13:35:36 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 13:35:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:35:36 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:35:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 13:35:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:35:39 d2.evaluation.evaluator]: \u001b[0mInference done 43/355. 0.0577 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 13:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 111/355. 0.0574 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 13:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 179/355. 0.0575 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:35:55 d2.evaluation.evaluator]: \u001b[0mInference done 234/355. 0.0578 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 13:36:00 d2.evaluation.evaluator]: \u001b[0mInference done 292/355. 0.0581 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 13:36:05 d2.evaluation.evaluator]: \u001b[0mInference done 351/355. 0.0582 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:36:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.589641 (0.081685 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:36:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058231 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:36:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:36:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O4DTV2W0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:36:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:36:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.432\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.356\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.952 | 43.241 | 35.607 | 15.681 | 32.658 | 19.404 |\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.926 | cushion    | 66.400 | door       | 1.925 |\n",
      "| indoor-plant | 38.400 | sofa       | 50.394 | table      | 6.667 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.631 | 37.081 | 23.020 | 11.954 | 25.844 | 13.347 |\n",
      "\u001b[32m[10/21 13:36:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.328  | cushion    | 69.201 | door       | 2.210 |\n",
      "| indoor-plant | 25.857 | sofa       | 34.852 | table      | 0.341 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='O4DTV2W2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 13:36:07 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 13:36:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 13:36:07 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:36:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 13:36:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 13:36:10 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.0580 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 13:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 105/355. 0.0577 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 13:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 175/355. 0.0576 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 13:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.0581 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 13:36:30 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.0582 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 13:36:35 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.0583 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 13:36:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:28.967622 (0.082765 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:36:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.058401 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 13:36:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 13:36:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O4DTV2W0/coco_instances_results.json\n",
      "\u001b[32m[10/21 13:36:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:36:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.432\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.095 | 43.243 | 35.914 | 15.597 | 31.844 | 21.625 |\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.323 | cushion    | 64.950 | door       | 2.597 |\n",
      "| indoor-plant | 42.052 | sofa       | 49.940 | table      | 6.708 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.484 | 37.564 | 22.701 | 11.949 | 25.459 | 13.215 |\n",
      "\u001b[32m[10/21 13:36:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.680  | cushion    | 68.810 | door       | 2.953 |\n",
      "| indoor-plant | 27.817 | sofa       | 32.382 | table      | 0.258 |\n",
      "all results {'bbox': {'AP50': [43.9819975136485, 43.24069293876699, 43.24338200034923]}, 'segm': {'AP50': [37.77485093374277, 37.08088521209182, 37.56367735014051]}}\n",
      "dataset_name 39TFIA6\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/3/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p4/coco_train.json', name='39TFIA6_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/39TFIA60\n",
      "output_aug/800/39TFIA60\n",
      "\u001b[32m[10/21 13:36:38 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 13:36:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "186 186\n",
      "\u001b[32m[10/21 13:36:38 d2.data.datasets.coco]: \u001b[0mLoaded 43 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/3/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[10/21 13:36:38 d2.data.build]: \u001b[0mRemoved 7 images with no usable annotations. 36 images left.\n",
      "\u001b[32m[10/21 13:36:38 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 13:36:38 d2.data.common]: \u001b[0mSerializing 36 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 13:36:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.09 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 13:36:38 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 13:36:39 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 13:36:43 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 19  total_loss: 3.554  loss_cls: 1.849  loss_box_reg: 0.8877  loss_mask: 0.6906  loss_rpn_cls: 0.1086  loss_rpn_loc: 0.0496  time: 0.2023  data_time: 0.0176  lr: 9.5905e-05  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:36:47 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 39  total_loss: 2.585  loss_cls: 0.9246  loss_box_reg: 0.8657  loss_mask: 0.6609  loss_rpn_cls: 0.03959  loss_rpn_loc: 0.03201  time: 0.1999  data_time: 0.0044  lr: 0.00019581  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:36:51 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 59  total_loss: 2.196  loss_cls: 0.723  loss_box_reg: 0.8254  loss_mask: 0.585  loss_rpn_cls: 0.02602  loss_rpn_loc: 0.02868  time: 0.1994  data_time: 0.0041  lr: 0.00029571  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:36:55 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 79  total_loss: 1.955  loss_cls: 0.602  loss_box_reg: 0.8207  loss_mask: 0.4831  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.02527  time: 0.1997  data_time: 0.0041  lr: 0.00039561  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:36:59 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 99  total_loss: 1.736  loss_cls: 0.4733  loss_box_reg: 0.8273  loss_mask: 0.3974  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.02628  time: 0.2005  data_time: 0.0044  lr: 0.00049551  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:37:03 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 119  total_loss: 1.467  loss_cls: 0.3359  loss_box_reg: 0.7474  loss_mask: 0.3174  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.02147  time: 0.2009  data_time: 0.0045  lr: 0.00059541  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:37:07 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 139  total_loss: 1.187  loss_cls: 0.2504  loss_box_reg: 0.6142  loss_mask: 0.2638  loss_rpn_cls: 0.007772  loss_rpn_loc: 0.02687  time: 0.2008  data_time: 0.0043  lr: 0.00069531  max_mem: 3097M\n",
      "\u001b[32m[10/21 13:37:11 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 159  total_loss: 0.9356  loss_cls: 0.1835  loss_box_reg: 0.5089  loss_mask: 0.2102  loss_rpn_cls: 0.004849  loss_rpn_loc: 0.02232  time: 0.2009  data_time: 0.0044  lr: 0.00079521  max_mem: 3097M\n"
     ]
    }
   ],
   "source": [
    "# _runner([1,2,3,4], 5, [2,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc838dac-4db0-4a76-bb13-9b7536e2a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loco",
   "language": "python",
   "name": "loco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
