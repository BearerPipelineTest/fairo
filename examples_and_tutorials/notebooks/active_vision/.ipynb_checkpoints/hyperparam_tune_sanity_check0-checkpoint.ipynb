{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889b02e6-e845-484b-bf6a-e1eed6bd266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a copy of slurm_train.py from anurag/slurm_onebutton\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "import cv2\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import detectron2.data.transforms as T\n",
    "import shutil\n",
    "from setuptools.namespaces import flatten\n",
    "\n",
    "import random\n",
    "import torch \n",
    "import base64\n",
    "import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "coco_yaml = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "lvis_yaml = \"LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n",
    "lvis_yaml2 = \"LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml\"\n",
    "pano_yaml = \"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"\n",
    "\n",
    "jsons_root = '/checkpoint/apratik/finals/jsons/active_vision/'\n",
    "img_dir_test = '/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb'\n",
    "test_jsons = ['frlapt1_20n0.json', 'frlapt1_20n1.json', 'frlapt1_20n2.json']\n",
    "test_jsons = [os.path.join(jsons_root, x) for x in test_jsons]\n",
    "\n",
    "# val_json = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json'\n",
    "# val_json = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_valgtfix.json'\n",
    "# img_dir_val = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb'\n",
    "# img_dir_val = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb'\n",
    "\n",
    "## Detectron2 Setup\n",
    "\n",
    "# from copy_paste import CopyPaste\n",
    "# import albumentations as A\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "#     @classmethod\n",
    "#     def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "#         if output_folder is None:\n",
    "#             output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "#         return COCOEvaluator(dataset_name, output_dir=output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        mapper = DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "            T.ResizeShortestEdge(short_edge_length=cfg.INPUT.MIN_SIZE_TRAIN, max_size=1333, sample_style='choice'),\n",
    "            T.RandomFlip(prob=0.5),\n",
    "            T.RandomCrop(\"absolute\", (640, 640)),\n",
    "            T.RandomBrightness(0.9, 1.1)\n",
    "        ])\n",
    "        return build_detection_train_loader(cfg, mapper=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d30a90e-0131-4f70-8339-d7c6d28625d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)\n",
    "        \n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "                     \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            self.cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee15745e-d902-40a0-b2c9-0ee1f9fa2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCOTrain:\n",
    "    def __init__(self, lr, w, maxiters, seed):\n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.merge_from_file(model_zoo.get_config_file(coco_yaml))\n",
    "        self.cfg.SOLVER.BASE_LR = lr  # pick a good LR\n",
    "        self.cfg.SOLVER.MAX_ITER = maxiters\n",
    "        self.cfg.SOLVER.WARMUP_ITERS = w\n",
    "        self.seed = seed\n",
    "        \n",
    "    def reset(self, train_json, img_dir_train, dataset_name):\n",
    "        DatasetCatalog.clear()\n",
    "        MetadataCatalog.clear()\n",
    "        self.train_data = dataset_name +  \"_train\"\n",
    "        self.dataset_name = dataset_name\n",
    "        self.train_json = train_json\n",
    "        register_coco_instances(self.train_data, {}, train_json, img_dir_train)\n",
    "        self.results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "        self.val_results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def vis(self):\n",
    "        dataset_dicts = DatasetCatalog.get(self.train_data)\n",
    "        for d in random.sample(dataset_dicts, 2):\n",
    "            img = cv2.imread(d[\"file_name\"])\n",
    "            visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(self.train_data), scale=0.5)\n",
    "            vis = visualizer.draw_dataset_dict(d)\n",
    "            img = vis.get_image()\n",
    "            plt.figure(figsize=(12,8))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "#     ['chair', 'door', 'table', 'indoor-plant', 'cushion', 'sofa'] != ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "\n",
    "            \n",
    "    def train(self, val_json, img_dir_val):\n",
    "        cfg = self.cfg\n",
    "        print(f'SOLVER PARAMS {cfg.SOLVER.MAX_ITER, cfg.SOLVER.WARMUP_ITERS, cfg.SOLVER.BASE_LR}')\n",
    "        cfg.DATASETS.TRAIN = (self.train_data,)\n",
    "        \n",
    "        self.val_data = self.dataset_name + \"_val\" + str(self.seed)\n",
    "        self.val_json = val_json\n",
    "        cfg.DATASETS.TEST = (self.val_data,self.train_data)\n",
    "        register_coco_instances(self.val_data, {}, val_json, img_dir_val)\n",
    "        MetadataCatalog.get(self.val_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        \n",
    "        cfg.TEST.EVAL_PERIOD = 100\n",
    "        cfg.DATALOADER.NUM_WORKERS = 2\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(coco_yaml)  # Let training initialize from model zoo\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "        \n",
    "        cfg.SOLVER.GAMMA=0.75\n",
    "        cfg.SOLVER.STEPS=tuple([150*(i+1) for i in range(100) if 150*(i+1) < cfg.SOLVER.MAX_ITER])\n",
    "        \n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "        MetadataCatalog.get(self.train_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.train_data)}')\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(self.train_data).get(\"thing_classes\"))  \n",
    "        cfg.OUTPUT_DIR = os.path.join('output_aug_1108', str(cfg.SOLVER.MAX_ITER), self.dataset_name + str(self.seed))\n",
    "        print(f\"recreating {cfg.OUTPUT_DIR}\")\n",
    "        # if os.path.isdir(cfg.OUTPUT_DIR):\n",
    "        #     shutil.rmtree(cfg.OUTPUT_DIR)\n",
    "        print(cfg.OUTPUT_DIR)\n",
    "        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "        self.trainer = MyTrainer(cfg) #DefaultTrainer(cfg)  #Trainer(cfg)\n",
    "        self.trainer.resume_or_load(resume=False)\n",
    "        self.trainer.train()\n",
    "        \n",
    "    def run_val(self, dataset_name, val_json, img_dir_val):\n",
    "#         self.val_data = dataset_name + \"_val\" + str(self.seed)\n",
    "#         self.val_json = val_json\n",
    "#         self.cfg.DATASETS.TEST = (self.val_data,)\n",
    "#         register_coco_instances(self.val_data, {}, val_json, img_dir_val)\n",
    "#         MetadataCatalog.get(self.val_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "#         print(f'classes {MetadataCatalog.get(self.val_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.val_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.val_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.val_results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.val_results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "\n",
    "    def run_test(self, dataset_name, test_json, img_dir_test):\n",
    "        self.test_data = dataset_name + \"_test\" + str(self.seed)\n",
    "        self.test_json = test_json\n",
    "        self.cfg.DATASETS.TEST = (self.test_data,)\n",
    "        register_coco_instances(self.test_data, {}, test_json, img_dir_test)\n",
    "        MetadataCatalog.get(self.test_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.test_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.test_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.test_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "        \n",
    "    def run_train(self, train_json, img_dir_train, dataset_name, val_json, img_dir_val):\n",
    "        self.reset(train_json, img_dir_train, dataset_name)\n",
    "        # self.vis()\n",
    "        self.train(val_json, img_dir_val)\n",
    "\n",
    "\n",
    "# maxiters = [500, 800]\n",
    "# lrs = [0.0001, 0.0005, 0.001, 0.002, 0.005]\n",
    "# warmups = [100, 200]\n",
    "lrs = [0.004]\n",
    "maxiters = [2000]\n",
    "warmups = [200]\n",
    "\n",
    "def write_summary_to_file(filename, results, header_str):\n",
    "    if isinstance(results['bbox']['AP50'][0], list):\n",
    "        results['bbox']['AP50'] = list(flatten(results['bbox']['AP50']))\n",
    "        results['segm']['AP50'] = list(flatten(results['segm']['AP50']))\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(header_str)\n",
    "        f.write(f\"\\nbbox AP50 {sum(results['bbox']['AP50'])/len(results['bbox']['AP50'])}\")\n",
    "        f.write(f\"\\nsegm AP50 {sum(results['segm']['AP50'])/len(results['segm']['AP50'])}\")\n",
    "        f.write(f'\\nall results {results}')\n",
    "\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "def run_training(img_dir_train, n, traj, x, gt, p, train_json, val_json):\n",
    "    results_dir = os.path.join('results1021_sanity1105_7', str(traj), x, str(gt), str(p))\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "#     train_json = os.path.join(out_dir, tr_json)\n",
    "#     val_json = os.path.join(out_dir, val_json)\n",
    "    for lr in lrs:\n",
    "        for warmup in warmups:\n",
    "            for maxiter in maxiters:\n",
    "                results = {\n",
    "                    \"bbox\": {\n",
    "                        \"AP50\": []\n",
    "                    },\n",
    "                    \"segm\": {\n",
    "                        \"AP50\": []\n",
    "                    }\n",
    "                }\n",
    "                for i in range(n):\n",
    "                    c = COCOTrain(lr, warmup, maxiter, i)\n",
    "                    dataset_name = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(7))\n",
    "                    print(f'dataset_name {dataset_name}')\n",
    "                    c.run_train(train_json, img_dir_train, dataset_name, val_json, img_dir_train)\n",
    "                    res_eval = c.run_val(dataset_name, val_json, img_dir_train)\n",
    "                    with open(os.path.join(results_dir, \"validation_results.txt\"), \"a\") as f:\n",
    "                        f.write(f'val_json {val_json}\\n')\n",
    "                        f.write(f'lr {lr} warmup {warmup} maxiter {maxiter}\\n')\n",
    "                        f.write(json.dumps(res_eval) + '\\n')\n",
    "#                     for yix in range(len(test_jsons)):\n",
    "#                         r = c.run_test(dataset_name + str(yix), test_jsons[yix], img_dir_test)\n",
    "#                         with open(os.path.join(results_dir, \"all_results.txt\"), \"a\") as f:\n",
    "#                             f.write(json.dumps(r) + '\\n')\n",
    "#                     print(f'all results {c.results}')\n",
    "#                     results['bbox']['AP50'].append(c.results['bbox']['AP50'])\n",
    "#                     results['segm']['AP50'].append(c.results['segm']['AP50'])\n",
    "#                     write_summary_to_file(os.path.join(results_dir, str(n) + '_granular.txt'), c.results, f'\\ntrain_json {train_json}')\n",
    "                \n",
    "#                 itername = str(lr) + ' ' + str(warmup) + ' ' + str(maxiter) + ' ' + str(n)\n",
    "#                 write_summary_to_file(os.path.join(results_dir, itername + '_results_averaged.txt'), results, f'\\ntrain_json {train_json}, average over {n} runs')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47185a2c-ad5d-4952-923d-088337c6693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name VCKWB6J\n",
      "SOLVER PARAMS (2000, 200, 0.004)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json', name='VCKWB6J_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug_1108/2000/VCKWB6J0\n",
      "output_aug_1108/2000/VCKWB6J0\n",
      "\u001b[32m[11/05 19:17:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "262 262\n",
      "\u001b[32m[11/05 19:17:55 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:17:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 45 images left.\n",
      "\u001b[32m[11/05 19:17:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[11/05 19:17:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/05 19:17:55 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:17:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[11/05 19:17:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "62 62\n",
      "\u001b[32m[11/05 19:17:55 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:17:55 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:17:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/05 19:17:55 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[11/05 19:18:28 d2.utils.events]: \u001b[0m eta: 0:53:55  iter: 19  total_loss: 3.317  loss_cls: 1.364  loss_box_reg: 0.8519  loss_mask: 0.6851  loss_rpn_cls: 0.1853  loss_rpn_loc: 0.2498  time: 1.6190  data_time: 0.1731  lr: 0.00028862  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:19:01 d2.utils.events]: \u001b[0m eta: 0:53:42  iter: 39  total_loss: 2.273  loss_cls: 0.6434  loss_box_reg: 0.8123  loss_mask: 0.5851  loss_rpn_cls: 0.04347  loss_rpn_loc: 0.1762  time: 1.6386  data_time: 0.1668  lr: 0.00058822  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:19:34 d2.utils.events]: \u001b[0m eta: 0:53:27  iter: 59  total_loss: 1.767  loss_cls: 0.4293  loss_box_reg: 0.7562  loss_mask: 0.4332  loss_rpn_cls: 0.0248  loss_rpn_loc: 0.1277  time: 1.6491  data_time: 0.1682  lr: 0.00088782  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:20:08 d2.utils.events]: \u001b[0m eta: 0:52:57  iter: 79  total_loss: 1.291  loss_cls: 0.2795  loss_box_reg: 0.5976  loss_mask: 0.2987  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.124  time: 1.6547  data_time: 0.1683  lr: 0.0011874  max_mem: 11157M\n",
      "62 62\n",
      "\u001b[32m[11/05 19:20:41 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:20:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:20:41 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:20:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:20:41 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:20:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.658221 (0.131644 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.064071 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.530\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.593\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.556\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.556\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 47.263 | 77.282 | 53.003 | 41.114 | 60.156 | 59.334 |\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 52.197 | cushion    | 55.316 | door       | 36.817 |\n",
      "| indoor-plant | 34.140 | sofa       | 75.083 | table      | 30.022 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.584\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.708\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.714\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.771 | 58.440 | 23.830 | 14.748 | 52.681 | 70.759 |\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 40.508 | cushion    | 34.475 | door       | 50.659 |\n",
      "| indoor-plant | 27.651 | sofa       | 19.336 | table      | 0.000  |\n",
      "\u001b[32m[11/05 19:20:43 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_val0 in csv format:\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: 47.2627,77.2822,53.0025,41.1140,60.1562,59.3340\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.testing]: \u001b[0mcopypaste: 28.7714,58.4397,23.8302,14.7480,52.6811,70.7591\n",
      "262 262\n",
      "\u001b[32m[11/05 19:20:43 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:20:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:20:43 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:20:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:20:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:20:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 45 images\n",
      "\u001b[32m[11/05 19:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/45. 0.0572 s / img. ETA=0:00:02\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.035198 (0.100880 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.061132 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.579\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.411\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.588\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.691\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 52.533 | 85.971 | 57.880 | 41.094 | 58.840 | 74.266 |\n",
      "\u001b[32m[11/05 19:20:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 52.337 | cushion    | 53.984 | door       | 53.938 |\n",
      "| indoor-plant | 57.249 | sofa       | 66.672 | table      | 31.019 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.591\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.848\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.861\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.651 | 66.484 | 26.048 | 17.051 | 59.097 | 84.846 |\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 39.589 | cushion    | 28.052 | door       | 62.261 |\n",
      "| indoor-plant | 31.853 | sofa       | 22.154 | table      | 0.000  |\n",
      "\u001b[32m[11/05 19:20:48 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_train in csv format:\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.testing]: \u001b[0mcopypaste: 52.5329,85.9713,57.8797,41.0940,58.8399,74.2659\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:20:48 d2.evaluation.testing]: \u001b[0mcopypaste: 30.6515,66.4837,26.0479,17.0515,59.0969,84.8463\n",
      "\u001b[32m[11/05 19:20:48 d2.utils.events]: \u001b[0m eta: 0:52:37  iter: 99  total_loss: 1.064  loss_cls: 0.2146  loss_box_reg: 0.4794  loss_mask: 0.2511  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.1021  validation_loss: 1.214  time: 1.6595  data_time: 0.1709  lr: 0.001487  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:21:22 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 119  total_loss: 0.8904  loss_cls: 0.1645  loss_box_reg: 0.392  loss_mask: 0.2206  loss_rpn_cls: 0.007691  loss_rpn_loc: 0.08794  validation_loss: 1.214  time: 1.6598  data_time: 0.1679  lr: 0.0017866  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:21:56 d2.utils.events]: \u001b[0m eta: 0:51:42  iter: 139  total_loss: 0.7481  loss_cls: 0.1364  loss_box_reg: 0.3159  loss_mask: 0.1973  loss_rpn_cls: 0.007484  loss_rpn_loc: 0.07966  validation_loss: 1.214  time: 1.6652  data_time: 0.1734  lr: 0.0020862  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:22:29 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 159  total_loss: 0.6416  loss_cls: 0.1222  loss_box_reg: 0.2521  loss_mask: 0.1716  loss_rpn_cls: 0.005576  loss_rpn_loc: 0.08196  validation_loss: 1.214  time: 1.6672  data_time: 0.1733  lr: 0.0023858  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:23:03 d2.utils.events]: \u001b[0m eta: 0:50:44  iter: 179  total_loss: 0.5752  loss_cls: 0.1021  loss_box_reg: 0.232  loss_mask: 0.166  loss_rpn_cls: 0.004079  loss_rpn_loc: 0.074  validation_loss: 1.214  time: 1.6703  data_time: 0.1735  lr: 0.0026854  max_mem: 11157M\n",
      "62 62\n",
      "\u001b[32m[11/05 19:23:37 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:23:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:23:37 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:23:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:23:37 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:23:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.410523 (0.082105 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.055811 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.837\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.764\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.469\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.798\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.512\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.817\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.743\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 65.970 | 83.665 | 76.363 | 46.896 | 79.788 | 73.158 |\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 57.169 | cushion    | 78.459 | door       | 57.421 |\n",
      "| indoor-plant | 53.168 | sofa       | 87.550 | table      | 62.056 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.699\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.665\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 39.265 | 69.886 | 34.945 | 18.991 | 58.882 | 81.386 |\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 43.372 | cushion    | 56.343 | door       | 57.960 |\n",
      "| indoor-plant | 24.348 | sofa       | 45.149 | table      | 8.416  |\n",
      "\u001b[32m[11/05 19:23:38 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_val0 in csv format:\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.testing]: \u001b[0mcopypaste: 65.9704,83.6653,76.3632,46.8957,79.7875,73.1584\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:23:38 d2.evaluation.testing]: \u001b[0mcopypaste: 39.2646,69.8858,34.9447,18.9913,58.8824,81.3861\n",
      "262 262\n",
      "\u001b[32m[11/05 19:23:38 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:23:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:23:39 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:23:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:23:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:23:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 45 images\n",
      "\u001b[32m[11/05 19:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/45. 0.0572 s / img. ETA=0:00:02\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.891106 (0.072278 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.057110 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.770\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.934\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.878\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.597\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.876\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.568\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.797\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.797\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.640\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.891\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.892\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 76.987 | 93.441 | 87.831 | 59.707 | 85.979 | 87.583 |\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 54.704 | cushion    | 78.753 | door       | 79.896 |\n",
      "| indoor-plant | 85.430 | sofa       | 91.683 | table      | 71.453 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.773\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.680\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.933\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.728\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.944\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.029 | 77.317 | 40.996 | 24.591 | 68.010 | 93.260 |\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 43.414 | cushion    | 54.523 | door       | 83.484 |\n",
      "| indoor-plant | 35.468 | sofa       | 43.984 | table      | 3.301  |\n",
      "\u001b[32m[11/05 19:23:42 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_train in csv format:\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: 76.9866,93.4408,87.8305,59.7069,85.9795,87.5827\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:23:42 d2.evaluation.testing]: \u001b[0mcopypaste: 44.0290,77.3169,40.9961,24.5914,68.0104,93.2602\n",
      "\u001b[32m[11/05 19:23:43 d2.utils.events]: \u001b[0m eta: 0:50:16  iter: 199  total_loss: 0.543  loss_cls: 0.09921  loss_box_reg: 0.2098  loss_mask: 0.151  loss_rpn_cls: 0.004536  loss_rpn_loc: 0.08315  validation_loss: 1.117  time: 1.6751  data_time: 0.1848  lr: 0.002985  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:24:17 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 219  total_loss: 0.4948  loss_cls: 0.09456  loss_box_reg: 0.1897  loss_mask: 0.1375  loss_rpn_cls: 0.00315  loss_rpn_loc: 0.08145  validation_loss: 1.117  time: 1.6777  data_time: 0.1717  lr: 0.003  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:24:51 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 239  total_loss: 0.4522  loss_cls: 0.07829  loss_box_reg: 0.1843  loss_mask: 0.1308  loss_rpn_cls: 0.003275  loss_rpn_loc: 0.06799  validation_loss: 1.117  time: 1.6794  data_time: 0.1749  lr: 0.003  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:25:25 d2.utils.events]: \u001b[0m eta: 0:48:41  iter: 259  total_loss: 0.4756  loss_cls: 0.08236  loss_box_reg: 0.1932  loss_mask: 0.1369  loss_rpn_cls: 0.002809  loss_rpn_loc: 0.06245  validation_loss: 1.117  time: 1.6802  data_time: 0.1769  lr: 0.003  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:25:58 d2.utils.events]: \u001b[0m eta: 0:48:07  iter: 279  total_loss: 0.4254  loss_cls: 0.07083  loss_box_reg: 0.1714  loss_mask: 0.1293  loss_rpn_cls: 0.002465  loss_rpn_loc: 0.05829  validation_loss: 1.117  time: 1.6801  data_time: 0.1644  lr: 0.003  max_mem: 11157M\n",
      "62 62\n",
      "\u001b[32m[11/05 19:26:32 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:26:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:26:32 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:26:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:26:32 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:26:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.391771 (0.078354 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.056148 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.859\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.756\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.830\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.503\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.721\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.721\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.858\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 69.290 | 85.948 | 75.617 | 52.467 | 82.979 | 74.617 |\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 62.280 | cushion    | 85.326 | door       | 54.913 |\n",
      "| indoor-plant | 54.851 | sofa       | 96.287 | table      | 62.083 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.707\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.648\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 42.959 | 70.651 | 36.082 | 19.572 | 64.804 | 83.168 |\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 46.969 | cushion    | 56.414 | door       | 57.594 |\n",
      "| indoor-plant | 26.452 | sofa       | 60.990 | table      | 9.335  |\n",
      "\u001b[32m[11/05 19:26:33 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_val0 in csv format:\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.testing]: \u001b[0mcopypaste: 69.2902,85.9482,75.6169,52.4669,82.9790,74.6172\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.testing]: \u001b[0mcopypaste: 42.9592,70.6506,36.0818,19.5723,64.8045,83.1683\n",
      "262 262\n",
      "\u001b[32m[11/05 19:26:33 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:26:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:26:33 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:26:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:26:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:26:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 45 images\n",
      "\u001b[32m[11/05 19:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/45. 0.0550 s / img. ETA=0:00:02\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.720705 (0.068018 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.056382 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.823\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.948\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.908\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.681\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.917\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.952\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.850\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.705\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.938\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.968\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 82.341 | 94.776 | 90.816 | 68.080 | 91.663 | 95.220 |\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 65.096 | cushion    | 84.613 | door       | 88.058 |\n",
      "| indoor-plant | 87.921 | sofa       | 94.321 | table      | 74.039 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.806\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.419\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.739\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.969\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.567\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.782\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.980\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 49.810 | 80.634 | 41.860 | 30.809 | 73.869 | 96.907 |\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 50.319 | cushion    | 59.732 | door       | 83.688 |\n",
      "| indoor-plant | 40.770 | sofa       | 58.218 | table      | 6.134  |\n",
      "\u001b[32m[11/05 19:26:36 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_train in csv format:\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.testing]: \u001b[0mcopypaste: 82.3415,94.7761,90.8158,68.0797,91.6632,95.2200\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:26:36 d2.evaluation.testing]: \u001b[0mcopypaste: 49.8101,80.6341,41.8603,30.8091,73.8686,96.9072\n",
      "\u001b[32m[11/05 19:26:37 d2.utils.events]: \u001b[0m eta: 0:47:36  iter: 299  total_loss: 0.4166  loss_cls: 0.06697  loss_box_reg: 0.1569  loss_mask: 0.129  loss_rpn_cls: 0.002388  loss_rpn_loc: 0.06869  validation_loss: 1.061  time: 1.6810  data_time: 0.1731  lr: 0.003  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:27:11 d2.utils.events]: \u001b[0m eta: 0:47:04  iter: 319  total_loss: 0.4014  loss_cls: 0.0662  loss_box_reg: 0.1479  loss_mask: 0.1255  loss_rpn_cls: 0.002503  loss_rpn_loc: 0.05501  validation_loss: 1.061  time: 1.6814  data_time: 0.1687  lr: 0.00225  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:27:45 d2.utils.events]: \u001b[0m eta: 0:46:32  iter: 339  total_loss: 0.3636  loss_cls: 0.06199  loss_box_reg: 0.136  loss_mask: 0.1185  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.0478  validation_loss: 1.061  time: 1.6829  data_time: 0.1778  lr: 0.00225  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:28:19 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 359  total_loss: 0.3891  loss_cls: 0.06105  loss_box_reg: 0.1453  loss_mask: 0.1202  loss_rpn_cls: 0.002378  loss_rpn_loc: 0.0579  validation_loss: 1.061  time: 1.6832  data_time: 0.1703  lr: 0.00225  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:28:53 d2.utils.events]: \u001b[0m eta: 0:45:27  iter: 379  total_loss: 0.3769  loss_cls: 0.06215  loss_box_reg: 0.1368  loss_mask: 0.1151  loss_rpn_cls: 0.002236  loss_rpn_loc: 0.05492  validation_loss: 1.061  time: 1.6844  data_time: 0.1747  lr: 0.00225  max_mem: 11157M\n",
      "62 62\n",
      "\u001b[32m[11/05 19:29:27 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:29:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:29:27 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:29:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:29:27 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:29:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.402503 (0.080501 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.058861 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.715\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.749\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.584\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.851\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.799\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.515\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.595\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.883\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 71.527 | 86.394 | 74.921 | 58.370 | 85.058 | 79.874 |\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 68.507 | cushion    | 83.450 | door       | 58.983 |\n",
      "| indoor-plant | 55.693 | sofa       | 95.644 | table      | 66.884 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.726\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.654\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.828\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.721\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.463 | 72.612 | 34.868 | 21.270 | 65.426 | 82.797 |\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 45.606 | cushion    | 53.460 | door       | 57.349 |\n",
      "| indoor-plant | 29.158 | sofa       | 63.465 | table      | 17.741 |\n",
      "\u001b[32m[11/05 19:29:28 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_val0 in csv format:\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: 71.5268,86.3936,74.9207,58.3696,85.0578,79.8738\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.testing]: \u001b[0mcopypaste: 44.4634,72.6120,34.8677,21.2700,65.4257,82.7970\n",
      "262 262\n",
      "\u001b[32m[11/05 19:29:28 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:29:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:29:28 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:29:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:29:28 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:29:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 45 images\n",
      "\u001b[32m[11/05 19:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/45. 0.0589 s / img. ETA=0:00:02\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.735058 (0.068376 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.057472 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.858\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.960\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.932\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.746\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.936\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.982\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.617\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.879\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.879\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.769\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.950\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.995\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 85.846 | 96.039 | 93.216 | 74.624 | 93.557 | 98.175 |\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 70.193 | cushion    | 87.184 | door       | 91.321 |\n",
      "| indoor-plant | 91.431 | sofa       | 96.279 | table      | 78.666 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.820\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.425\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.749\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.972\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.788\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.982\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 52.078 | 82.011 | 42.477 | 36.094 | 74.915 | 97.232 |\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 48.934 | cushion    | 61.496 | door       | 86.830 |\n",
      "| indoor-plant | 45.462 | sofa       | 60.972 | table      | 8.773  |\n",
      "\u001b[32m[11/05 19:29:31 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_train in csv format:\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.testing]: \u001b[0mcopypaste: 85.8459,96.0386,93.2160,74.6244,93.5565,98.1753\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:29:31 d2.evaluation.testing]: \u001b[0mcopypaste: 52.0777,82.0106,42.4775,36.0940,74.9149,97.2318\n",
      "\u001b[32m[11/05 19:29:32 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 399  total_loss: 0.3576  loss_cls: 0.05595  loss_box_reg: 0.1359  loss_mask: 0.118  loss_rpn_cls: 0.002121  loss_rpn_loc: 0.04581  validation_loss: 1.069  time: 1.6849  data_time: 0.1735  lr: 0.00225  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:30:06 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 419  total_loss: 0.353  loss_cls: 0.05769  loss_box_reg: 0.128  loss_mask: 0.1159  loss_rpn_cls: 0.002256  loss_rpn_loc: 0.04594  validation_loss: 1.069  time: 1.6854  data_time: 0.1756  lr: 0.00225  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:30:40 d2.utils.events]: \u001b[0m eta: 0:43:47  iter: 439  total_loss: 0.3496  loss_cls: 0.05685  loss_box_reg: 0.1242  loss_mask: 0.1147  loss_rpn_cls: 0.002559  loss_rpn_loc: 0.04658  validation_loss: 1.069  time: 1.6855  data_time: 0.1698  lr: 0.00225  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:31:14 d2.utils.events]: \u001b[0m eta: 0:43:14  iter: 459  total_loss: 0.3498  loss_cls: 0.0525  loss_box_reg: 0.1292  loss_mask: 0.1125  loss_rpn_cls: 0.002265  loss_rpn_loc: 0.04804  validation_loss: 1.069  time: 1.6859  data_time: 0.1734  lr: 0.0016875  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:31:48 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 479  total_loss: 0.3327  loss_cls: 0.05267  loss_box_reg: 0.1197  loss_mask: 0.1106  loss_rpn_cls: 0.002172  loss_rpn_loc: 0.0455  validation_loss: 1.069  time: 1.6861  data_time: 0.1674  lr: 0.0016875  max_mem: 11157M\n",
      "62 62\n",
      "\u001b[32m[11/05 19:32:21 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:32:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:32:21 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:32:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:32:21 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:32:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.386622 (0.077324 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.057260 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.766\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.488\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.819\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.720\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.720\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 68.480 | 86.394 | 76.618 | 48.838 | 81.867 | 81.842 |\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 63.077 | cushion    | 80.034 | door       | 57.356 |\n",
      "| indoor-plant | 50.743 | sofa       | 93.366 | table      | 66.301 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.647\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.501\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.829\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 43.783 | 71.924 | 35.506 | 21.053 | 64.673 | 82.450 |\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 46.535 | cushion    | 52.222 | door       | 55.604 |\n",
      "| indoor-plant | 29.158 | sofa       | 63.465 | table      | 15.714 |\n",
      "\u001b[32m[11/05 19:32:22 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_val0 in csv format:\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.testing]: \u001b[0mcopypaste: 68.4795,86.3936,76.6180,48.8375,81.8672,81.8416\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.testing]: \u001b[0mcopypaste: 43.7832,71.9236,35.5061,21.0527,64.6733,82.4505\n",
      "262 262\n",
      "\u001b[32m[11/05 19:32:22 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:32:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:32:22 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:32:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:32:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:32:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 45 images\n",
      "\u001b[32m[11/05 19:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/45. 0.0546 s / img. ETA=0:00:02\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.631531 (0.065788 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.055856 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.869\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.964\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.929\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.753\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.942\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.621\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.889\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.889\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.775\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.961\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |   APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-------:|\n",
      "| 86.945 | 96.393 | 92.912 | 75.311 | 94.189 | 100.000 |\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 69.841 | cushion    | 89.899 | door       | 93.655 |\n",
      "| indoor-plant | 90.631 | sofa       | 95.672 | table      | 81.973 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.535\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.817\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.472\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.766\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.976\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.799\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.982\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 53.481 | 81.655 | 47.150 | 37.637 | 76.550 | 97.565 |\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 50.800 | cushion    | 63.613 | door       | 88.722 |\n",
      "| indoor-plant | 46.018 | sofa       | 62.755 | table      | 8.980  |\n",
      "\u001b[32m[11/05 19:32:25 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_train in csv format:\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.testing]: \u001b[0mcopypaste: 86.9451,96.3931,92.9119,75.3112,94.1887,100.0000\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:32:25 d2.evaluation.testing]: \u001b[0mcopypaste: 53.4811,81.6545,47.1500,37.6370,76.5501,97.5646\n",
      "\u001b[32m[11/05 19:32:26 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 499  total_loss: 0.3129  loss_cls: 0.04994  loss_box_reg: 0.1077  loss_mask: 0.1063  loss_rpn_cls: 0.001763  loss_rpn_loc: 0.04509  validation_loss: 1.077  time: 1.6863  data_time: 0.1700  lr: 0.0016875  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:33:00 d2.utils.events]: \u001b[0m eta: 0:41:35  iter: 519  total_loss: 0.316  loss_cls: 0.0469  loss_box_reg: 0.1188  loss_mask: 0.1097  loss_rpn_cls: 0.001129  loss_rpn_loc: 0.04498  validation_loss: 1.077  time: 1.6871  data_time: 0.1737  lr: 0.0016875  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:33:34 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 539  total_loss: 0.3114  loss_cls: 0.04887  loss_box_reg: 0.1102  loss_mask: 0.1055  loss_rpn_cls: 0.002033  loss_rpn_loc: 0.04099  validation_loss: 1.077  time: 1.6875  data_time: 0.1718  lr: 0.0016875  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:34:08 d2.utils.events]: \u001b[0m eta: 0:40:30  iter: 559  total_loss: 0.3045  loss_cls: 0.04678  loss_box_reg: 0.1074  loss_mask: 0.1054  loss_rpn_cls: 0.001738  loss_rpn_loc: 0.04567  validation_loss: 1.077  time: 1.6880  data_time: 0.1701  lr: 0.0016875  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:34:42 d2.utils.events]: \u001b[0m eta: 0:39:57  iter: 579  total_loss: 0.3112  loss_cls: 0.04765  loss_box_reg: 0.1106  loss_mask: 0.1035  loss_rpn_cls: 0.002999  loss_rpn_loc: 0.03983  validation_loss: 1.077  time: 1.6884  data_time: 0.1716  lr: 0.0016875  max_mem: 11157M\n",
      "62 62\n",
      "\u001b[32m[11/05 19:35:16 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:35:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:35:16 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:35:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:35:16 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:35:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.377470 (0.075494 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.056051 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.704\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.867\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.770\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.572\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.826\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.512\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.580\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.879\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 70.366 | 86.664 | 77.040 | 57.244 | 82.585 | 80.000 |\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 67.722 | cushion    | 79.346 | door       | 57.437 |\n",
      "| indoor-plant | 50.743 | sofa       | 95.644 | table      | 71.307 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.450\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.742\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.345\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.649\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.827\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.510\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.510\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.727\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 45.034 | 74.214 | 34.495 | 23.128 | 64.906 | 82.653 |\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 47.909 | cushion    | 54.770 | door       | 57.287 |\n",
      "| indoor-plant | 32.005 | sofa       | 60.099 | table      | 18.133 |\n",
      "\u001b[32m[11/05 19:35:17 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_val0 in csv format:\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: 70.3662,86.6637,77.0402,57.2440,82.5850,80.0000\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.testing]: \u001b[0mcopypaste: 45.0338,74.2137,34.4953,23.1282,64.9059,82.6535\n",
      "262 262\n",
      "\u001b[32m[11/05 19:35:17 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:35:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:35:17 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:35:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:35:17 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:35:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 45 images\n",
      "\u001b[32m[11/05 19:35:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/45. 0.0577 s / img. ETA=0:00:02\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.664818 (0.066620 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.057010 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.884\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.939\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.791\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.956\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.990\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.638\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.902\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.902\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.807\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.981\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.994\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 88.400 | 96.206 | 93.875 | 79.117 | 95.585 | 99.029 |\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP      | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:--------|:-----------|:-------|\n",
      "| chair        | 69.062 | cushion    | 90.012  | door       | 95.097 |\n",
      "| indoor-plant | 91.647 | sofa       | 100.000 | table      | 84.580 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.550\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.766\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.965\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.617\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.497\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.804\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.978\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 55.799 | 82.810 | 54.991 | 44.520 | 76.580 | 96.525 |\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 53.081 | cushion    | 69.512 | door       | 90.193 |\n",
      "| indoor-plant | 48.003 | sofa       | 63.371 | table      | 10.636 |\n",
      "\u001b[32m[11/05 19:35:20 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_train in csv format:\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.testing]: \u001b[0mcopypaste: 88.3995,96.2062,93.8752,79.1166,95.5845,99.0288\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:35:20 d2.evaluation.testing]: \u001b[0mcopypaste: 55.7995,82.8098,54.9906,44.5195,76.5797,96.5248\n",
      "\u001b[32m[11/05 19:35:21 d2.utils.events]: \u001b[0m eta: 0:39:24  iter: 599  total_loss: 0.3147  loss_cls: 0.04823  loss_box_reg: 0.1038  loss_mask: 0.1057  loss_rpn_cls: 0.001849  loss_rpn_loc: 0.04509  validation_loss: 1.097  time: 1.6883  data_time: 0.1673  lr: 0.0016875  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:35:55 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 619  total_loss: 0.2861  loss_cls: 0.04734  loss_box_reg: 0.1033  loss_mask: 0.1011  loss_rpn_cls: 0.001577  loss_rpn_loc: 0.04037  validation_loss: 1.097  time: 1.6882  data_time: 0.1699  lr: 0.0012656  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:36:29 d2.utils.events]: \u001b[0m eta: 0:38:16  iter: 639  total_loss: 0.2889  loss_cls: 0.04518  loss_box_reg: 0.09491  loss_mask: 0.0997  loss_rpn_cls: 0.002164  loss_rpn_loc: 0.04166  validation_loss: 1.097  time: 1.6882  data_time: 0.1750  lr: 0.0012656  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:37:03 d2.utils.events]: \u001b[0m eta: 0:37:43  iter: 659  total_loss: 0.2829  loss_cls: 0.0438  loss_box_reg: 0.09692  loss_mask: 0.09996  loss_rpn_cls: 0.001428  loss_rpn_loc: 0.04263  validation_loss: 1.097  time: 1.6886  data_time: 0.1703  lr: 0.0012656  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:37:37 d2.utils.events]: \u001b[0m eta: 0:37:09  iter: 679  total_loss: 0.2925  loss_cls: 0.04511  loss_box_reg: 0.09722  loss_mask: 0.09846  loss_rpn_cls: 0.001923  loss_rpn_loc: 0.04176  validation_loss: 1.097  time: 1.6889  data_time: 0.1807  lr: 0.0012656  max_mem: 11157M\n",
      "62 62\n",
      "\u001b[32m[11/05 19:38:11 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json\n",
      "\u001b[32m[11/05 19:38:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:38:11 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:38:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:38:11 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:38:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 images\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.396195 (0.079239 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.059849 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.757\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.548\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.830\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.506\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.730\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.567\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.873\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 69.110 | 85.989 | 75.711 | 54.802 | 82.998 | 80.000 |\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 68.429 | cushion    | 78.548 | door       | 56.748 |\n",
      "| indoor-plant | 52.748 | sofa       | 91.287 | table      | 66.899 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.657\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.827\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.507\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.507\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.727\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.836\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 44.741 | 71.658 | 33.622 | 22.072 | 65.748 | 82.653 |\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 46.414 | cushion    | 54.952 | door       | 57.287 |\n",
      "| indoor-plant | 32.005 | sofa       | 63.465 | table      | 14.319 |\n",
      "\u001b[32m[11/05 19:38:12 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_val0 in csv format:\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 69.1098,85.9886,75.7108,54.8022,82.9975,80.0000\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 44.7406,71.6584,33.6221,22.0721,65.7475,82.6535\n",
      "262 262\n",
      "\u001b[32m[11/05 19:38:12 d2.data.datasets.coco]: \u001b[0mLoaded 45 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json\n",
      "\u001b[32m[11/05 19:38:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/05 19:38:12 d2.data.common]: \u001b[0mSerializing 45 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/05 19:38:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/05 19:38:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[11/05 19:38:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 45 images\n",
      "\u001b[32m[11/05 19:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/45. 0.0549 s / img. ETA=0:00:02\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.634313 (0.065858 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.056410 s / img per device, on 1 devices)\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug_1108/2000/VCKWB6J0/inference/coco_instances_results.json\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.901\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.967\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.947\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.971\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.995\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.644\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.918\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.918\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.845\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.983\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 90.110 | 96.685 | 94.673 | 82.793 | 97.142 | 99.500 |\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 73.742 | cushion    | 92.373 | door       | 96.213 |\n",
      "| indoor-plant | 94.642 | sofa       | 98.448 | table      | 85.239 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.830\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.584\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.808\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.968\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.454\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.621\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.621\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.841\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.980\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 56.066 | 83.025 | 58.381 | 42.057 | 80.757 | 96.812 |\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 50.346 | cushion    | 67.308 | door       | 90.487 |\n",
      "| indoor-plant | 49.434 | sofa       | 67.272 | table      | 11.551 |\n",
      "\u001b[32m[11/05 19:38:15 d2.engine.defaults]: \u001b[0mEvaluation results for VCKWB6J_train in csv format:\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.testing]: \u001b[0mcopypaste: 90.1095,96.6848,94.6728,82.7926,97.1421,99.5000\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[11/05 19:38:15 d2.evaluation.testing]: \u001b[0mcopypaste: 56.0661,83.0249,58.3809,42.0573,80.7566,96.8119\n",
      "\u001b[32m[11/05 19:38:16 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 699  total_loss: 0.2884  loss_cls: 0.04169  loss_box_reg: 0.09389  loss_mask: 0.1053  loss_rpn_cls: 0.001621  loss_rpn_loc: 0.03848  validation_loss: 1.097  time: 1.6893  data_time: 0.1704  lr: 0.0012656  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:38:50 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 719  total_loss: 0.2739  loss_cls: 0.0384  loss_box_reg: 0.09466  loss_mask: 0.1008  loss_rpn_cls: 0.001811  loss_rpn_loc: 0.04147  validation_loss: 1.097  time: 1.6897  data_time: 0.1798  lr: 0.0012656  max_mem: 11157M\n",
      "\u001b[32m[11/05 19:38:53 d2.engine.hooks]: \u001b[0mOverall training speed: 719 iterations in 0:20:16 (1.6920 s / it)\n",
      "\u001b[32m[11/05 19:38:53 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:54 (0:00:37 on hooks)\n",
      "\u001b[32m[11/05 19:38:53 d2.utils.events]: \u001b[0m eta: 0:35:59  iter: 721  total_loss: 0.2754  loss_cls: 0.04115  loss_box_reg: 0.09481  loss_mask: 0.103  loss_rpn_cls: 0.001811  loss_rpn_loc: 0.04202  validation_loss: 1.097  time: 1.6897  data_time: 0.1795  lr: 0.0012656  max_mem: 11157M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ccd447202dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 0, p0_train, pr_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp4_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaky_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# gt = 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1b8508aeae4c>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(img_dir_train, n, traj, x, gt, p, train_json, val_json)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_uppercase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'dataset_name {dataset_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0mres_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation_results.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1b8508aeae4c>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, train_json, img_dir_train, dataset_name, val_json, img_dir_val)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# self.vis()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1b8508aeae4c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, val_json, img_dir_val)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#DefaultTrainer(cfg)  #Trainer(cfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \"\"\"\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             assert hasattr(\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \"\"\"\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36m_write_metrics\u001b[0;34m(self, loss_dict, data_time, prefix)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mdata_time\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mtaken\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \"\"\"\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mmetrics_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mmetrics_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mdata_time\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mtaken\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \"\"\"\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mmetrics_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mmetrics_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# have a bunch of json\n",
    "# /checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt_0.json\n",
    "# '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/20-10-2021/23:04:37/1/default/seg/coco_gt_0.json'\n",
    "\n",
    "# train_jsons = [f'coco_gt_{p}.json' for p in [0,2,4,6,8]]\n",
    "\n",
    "data_path = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019'\n",
    "job_dir = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11'\n",
    "\n",
    "\n",
    "p0_train = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_0train.json'\n",
    "p4_train = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/04-11-2021/14:30:11/1/default/pred_label_gt5p4/coco_train.json'\n",
    "pr_val = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4val.json'\n",
    "# leaky_val = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/seg/coco_gt5_4leakyval.json'\n",
    "\n",
    "gt = 5\n",
    "x = 'default'\n",
    "traj = 1\n",
    "# for traj in range(1, 4):\n",
    "traj_path = os.path.join(data_path, str(traj), x)\n",
    "\n",
    "# run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 0, p0_train, pr_val)\n",
    "run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 4, p4_train, pr_val) \n",
    "\n",
    "# gt = 5\n",
    "# x = 'default'\n",
    "# for traj in range(1, 4):\n",
    "#     traj_path = os.path.join(data_path, str(traj), x)\n",
    "#     # first train p0\n",
    "#     val_json = os.path.join(data_path, str(traj), f'default/seg/coco_gt{gt}_{p}val.json')\n",
    "    \n",
    "#     for p in range(2,10,2):\n",
    "#         f = os.path.join(job_dir, str(traj), 'default', f'pred_label_gt{gt}p{p}')\n",
    "#         val_json = os.path.join(data_path, str(traj), f'default/seg/coco_gt{gt}_{p}val.json')\n",
    "        \n",
    "#         train_json = os.path.join(f, f'coco_train.json')\n",
    "#         train_json_baseline = os.path.join(data_path, str(traj), f'default/seg/coco_gt{gt}_0train.json')\n",
    "        \n",
    "#         if not os.path.isfile(train_json_baseline):\n",
    "#             print(f\"Baseline train json {data_path, train_json_baseline} not found!! {p, traj, f}\")\n",
    "            \n",
    "#         run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, 0, train_json_baseline, val_json)\n",
    "        \n",
    "#         if not os.path.isfile(train_json) or not os.path.isfile(val_json):\n",
    "#             print('train/val json missing...')\n",
    "#             continue\n",
    "#         run_training(os.path.join(traj_path, 'rgb'), 1, str(traj), x, gt, p, train_json, val_json)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c31b8a-c490-480d-8ee1-21f44ce55404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _runner([1,2,3,4], 5, [2,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc838dac-4db0-4a76-bb13-9b7536e2a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loco",
   "language": "python",
   "name": "loco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
