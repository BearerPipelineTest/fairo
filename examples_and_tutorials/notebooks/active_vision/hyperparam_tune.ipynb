{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167bde65-e878-4de0-909f-7ee608f9947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is a copy of slurm_train.py from anurag/slurm_onebutton\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import sys\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "import cv2\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import detectron2.data.transforms as T\n",
    "import shutil\n",
    "from setuptools.namespaces import flatten\n",
    "\n",
    "import random\n",
    "import torch \n",
    "import base64\n",
    "import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "coco_yaml = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "lvis_yaml = \"LVIS-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml\"\n",
    "lvis_yaml2 = \"LVIS-InstanceSegmentation/mask_rcnn_R_101_FPN_1x.yaml\"\n",
    "pano_yaml = \"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\"\n",
    "\n",
    "jsons_root = '/checkpoint/apratik/finals/jsons/active_vision/'\n",
    "img_dir_test = '/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb'\n",
    "test_jsons = ['frlapt1_20n0.json', 'frlapt1_20n1.json', 'frlapt1_20n2.json']\n",
    "test_jsons = [os.path.join(jsons_root, x) for x in test_jsons]\n",
    "\n",
    "val_json = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json'\n",
    "img_dir_val = '/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb'\n",
    "\n",
    "## Detectron2 Setup\n",
    "\n",
    "# from copy_paste import CopyPaste\n",
    "# import albumentations as A\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "#     @classmethod\n",
    "#     def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "#         if output_folder is None:\n",
    "#             output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "#         return COCOEvaluator(dataset_name, output_dir=output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        mapper = DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "            T.ResizeShortestEdge(short_edge_length=cfg.INPUT.MIN_SIZE_TRAIN, max_size=1333, sample_style='choice'),\n",
    "            T.RandomFlip(prob=0.5),\n",
    "            T.RandomCrop(\"absolute\", (640, 640)),\n",
    "            T.RandomBrightness(0.9, 1.1)\n",
    "        ])\n",
    "        return build_detection_train_loader(cfg, mapper=mapper)\n",
    "\n",
    "class COCOTrain:\n",
    "    def __init__(self, lr, w, maxiters, seed):\n",
    "        self.cfg = get_cfg()\n",
    "        self.cfg.merge_from_file(model_zoo.get_config_file(coco_yaml))\n",
    "        self.cfg.SOLVER.BASE_LR = lr  # pick a good LR\n",
    "        self.cfg.SOLVER.MAX_ITER = maxiters\n",
    "        self.cfg.SOLVER.WARMUP_ITERS = w\n",
    "        self.seed = seed\n",
    "        \n",
    "    def reset(self, train_json, img_dir_train, dataset_name):\n",
    "        DatasetCatalog.clear()\n",
    "        MetadataCatalog.clear()\n",
    "        self.train_data = dataset_name +  \"_train\"\n",
    "        self.dataset_name = dataset_name\n",
    "        self.train_json = train_json\n",
    "        register_coco_instances(self.train_data, {}, train_json, img_dir_train)\n",
    "        self.results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "        self.val_results = {\n",
    "            \"bbox\": {\n",
    "                \"AP50\": []\n",
    "            },\n",
    "            \"segm\": {\n",
    "                \"AP50\": []\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def vis(self):\n",
    "        dataset_dicts = DatasetCatalog.get(self.train_data)\n",
    "        for d in random.sample(dataset_dicts, 2):\n",
    "            img = cv2.imread(d[\"file_name\"])\n",
    "            visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(self.train_data), scale=0.5)\n",
    "            vis = visualizer.draw_dataset_dict(d)\n",
    "            img = vis.get_image()\n",
    "            plt.figure(figsize=(12,8))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            \n",
    "    def train(self):\n",
    "        cfg = self.cfg\n",
    "        print(f'SOLVER PARAMS {cfg.SOLVER.MAX_ITER, cfg.SOLVER.WARMUP_ITERS, cfg.SOLVER.BASE_LR}')\n",
    "        cfg.DATASETS.TRAIN = (self.train_data,)\n",
    "        cfg.DATASETS.TEST = ()\n",
    "        cfg.DATALOADER.NUM_WORKERS = 2\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(coco_yaml)  # Let training initialize from model zoo\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128 \n",
    "        MetadataCatalog.get(self.train_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.train_data)}')\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(self.train_data).get(\"thing_classes\"))  \n",
    "        cfg.OUTPUT_DIR = os.path.join('output_aug', str(cfg.SOLVER.MAX_ITER), self.dataset_name + str(self.seed))\n",
    "        print(f\"recreating {cfg.OUTPUT_DIR}\")\n",
    "        # if os.path.isdir(cfg.OUTPUT_DIR):\n",
    "        #     shutil.rmtree(cfg.OUTPUT_DIR)\n",
    "        print(cfg.OUTPUT_DIR)\n",
    "        os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "        self.trainer = Trainer(cfg) #DefaultTrainer(cfg) \n",
    "        self.trainer.resume_or_load(resume=False)\n",
    "        self.trainer.train()\n",
    "        \n",
    "    def run_val(self, dataset_name, val_json, img_dir_val):\n",
    "        self.val_data = dataset_name + \"_val\" + str(self.seed)\n",
    "        self.val_json = val_json\n",
    "        self.cfg.DATASETS.TEST = (self.val_data,)\n",
    "        register_coco_instances(self.val_data, {}, val_json, img_dir_val)\n",
    "        MetadataCatalog.get(self.val_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.val_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.val_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.val_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.val_results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.val_results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "\n",
    "    def run_test(self, dataset_name, test_json, img_dir_test):\n",
    "        self.test_data = dataset_name + \"_test\" + str(self.seed)\n",
    "        self.test_json = test_json\n",
    "        self.cfg.DATASETS.TEST = (self.test_data,)\n",
    "        register_coco_instances(self.test_data, {}, test_json, img_dir_test)\n",
    "        MetadataCatalog.get(self.test_data).thing_classes = ['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table']\n",
    "        print(f'classes {MetadataCatalog.get(self.test_data)}')\n",
    "        self.evaluator = COCOEvaluator(self.test_data, (\"bbox\", \"segm\"), False, output_dir=self.cfg.OUTPUT_DIR)\n",
    "        self.val_loader = build_detection_test_loader(self.cfg, self.test_data)\n",
    "        results = inference_on_dataset(self.trainer.model, self.val_loader, self.evaluator)\n",
    "        self.results['bbox']['AP50'].append(results['bbox']['AP50'])\n",
    "        self.results['segm']['AP50'].append(results['segm']['AP50'])\n",
    "        return results\n",
    "        \n",
    "    def run_train(self, train_json, img_dir_train, dataset_name):\n",
    "        self.reset(train_json, img_dir_train, dataset_name)\n",
    "        # self.vis()\n",
    "        self.train()\n",
    "\n",
    "\n",
    "maxiters = [500, 800]\n",
    "lrs = [0.0001, 0.0005, 0.001, 0.002, 0.005]\n",
    "warmups = [100, 200]\n",
    "\n",
    "def write_summary_to_file(filename, results, header_str):\n",
    "    if isinstance(results['bbox']['AP50'][0], list):\n",
    "        results['bbox']['AP50'] = list(flatten(results['bbox']['AP50']))\n",
    "        results['segm']['AP50'] = list(flatten(results['segm']['AP50']))\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(header_str)\n",
    "        f.write(f\"\\nbbox AP50 {sum(results['bbox']['AP50'])/len(results['bbox']['AP50'])}\")\n",
    "        f.write(f\"\\nsegm AP50 {sum(results['segm']['AP50'])/len(results['segm']['AP50'])}\")\n",
    "        f.write(f'\\nall results {results}')\n",
    "\n",
    "from pathlib import Path\n",
    "import string\n",
    "\n",
    "def run_training(out_dir, img_dir_train, n, traj, x, gt, p):\n",
    "    results_dir = os.path.join('results1021', str(traj), x, str(gt), str(p))\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    train_json = os.path.join(out_dir, 'coco_train.json')\n",
    "    for lr in lrs:\n",
    "        for warmup in warmups:\n",
    "            for maxiter in maxiters:\n",
    "                results = {\n",
    "                    \"bbox\": {\n",
    "                        \"AP50\": []\n",
    "                    },\n",
    "                    \"segm\": {\n",
    "                        \"AP50\": []\n",
    "                    }\n",
    "                }\n",
    "                for i in range(n):\n",
    "                    c = COCOTrain(lr, warmup, maxiter, i)\n",
    "                    dataset_name = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(7))\n",
    "                    print(f'dataset_name {dataset_name}')\n",
    "                    c.run_train(train_json, img_dir_train, dataset_name)\n",
    "                    res_eval = c.run_val(dataset_name, val_json, img_dir_val)\n",
    "                    with open(os.path.join(results_dir, \"validation_results.txt\"), \"a\") as f:\n",
    "                        f.write(f'lr {lr} warmup {warmup} maxiter {maxiter}\\n')\n",
    "                        f.write(json.dumps(res_eval) + '\\n')\n",
    "                    for yix in range(len(test_jsons)):\n",
    "                        r = c.run_test(dataset_name + str(yix), test_jsons[yix], img_dir_test)\n",
    "                        with open(os.path.join(results_dir, \"all_results.txt\"), \"a\") as f:\n",
    "                            f.write(json.dumps(r) + '\\n')\n",
    "                    print(f'all results {c.results}')\n",
    "                    results['bbox']['AP50'].append(c.results['bbox']['AP50'])\n",
    "                    results['segm']['AP50'].append(c.results['segm']['AP50'])\n",
    "                    write_summary_to_file(os.path.join(results_dir, str(n) + '_granular.txt'), c.results, f'\\ntrain_json {train_json}')\n",
    "                \n",
    "                itername = str(lr) + ' ' + str(warmup) + ' ' + str(maxiter) + ' ' + str(n)\n",
    "                write_summary_to_file(os.path.join(results_dir, itername + '_results_averaged.txt'), results, f'\\ntrain_json {train_json}, average over {n} runs')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed79e3a-2333-45d2-9c83-235962fef130",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019'\n",
    "job_folder = '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17'\n",
    "\n",
    "import glob\n",
    "\n",
    "def _runner(trajs, gt, ps):\n",
    "    for traj in trajs:\n",
    "        for p in ps:\n",
    "            for x in ['default', 'activeonly']:\n",
    "                traj_path = os.path.join(data_path, str(traj), x)\n",
    "                if os.path.isdir(traj_path):\n",
    "                    outdir = os.path.join(job_folder, str(traj), x, f'pred_label_gt{gt}p{p}')\n",
    "                    if len(glob.glob1(outdir,\"*.npy\")) > 0:\n",
    "                        run_training(outdir, os.path.join(traj_path, 'rgb'), 1, traj, x, gt, p)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6c31b8a-c490-480d-8ee1-21f44ce55404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name MEWZYRX\n",
      "SOLVER PARAMS (500, 100, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='MEWZYRX_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/MEWZYRX0\n",
      "output_aug/500/MEWZYRX0\n",
      "\u001b[32m[10/21 06:01:03 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:01:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:01:03 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:01:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:01:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:01:03 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:01:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:01:03 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:01:04 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:01:10 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 19  total_loss: 3.571  loss_cls: 2.023  loss_box_reg: 0.6218  loss_mask: 0.6919  loss_rpn_cls: 0.1404  loss_rpn_loc: 0.03771  time: 0.3204  data_time: 0.0153  lr: 1.9081e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:16 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 39  total_loss: 2.985  loss_cls: 1.419  loss_box_reg: 0.6147  loss_mask: 0.6838  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.02979  time: 0.3097  data_time: 0.0036  lr: 3.9061e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:22 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 59  total_loss: 2.276  loss_cls: 0.7749  loss_box_reg: 0.6721  loss_mask: 0.6727  loss_rpn_cls: 0.05928  loss_rpn_loc: 0.03121  time: 0.2995  data_time: 0.0036  lr: 5.9041e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:28 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 79  total_loss: 1.974  loss_cls: 0.6056  loss_box_reg: 0.6369  loss_mask: 0.652  loss_rpn_cls: 0.03666  loss_rpn_loc: 0.03185  time: 0.2980  data_time: 0.0036  lr: 7.9021e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:33 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 99  total_loss: 1.993  loss_cls: 0.5849  loss_box_reg: 0.6523  loss_mask: 0.6244  loss_rpn_cls: 0.03063  loss_rpn_loc: 0.04174  time: 0.2945  data_time: 0.0038  lr: 9.9001e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:39 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 119  total_loss: 1.586  loss_cls: 0.4435  loss_box_reg: 0.5907  loss_mask: 0.5842  loss_rpn_cls: 0.02324  loss_rpn_loc: 0.02697  time: 0.2924  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:44 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 139  total_loss: 1.715  loss_cls: 0.4117  loss_box_reg: 0.6348  loss_mask: 0.5519  loss_rpn_cls: 0.03448  loss_rpn_loc: 0.03108  time: 0.2835  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:49 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 159  total_loss: 1.615  loss_cls: 0.4096  loss_box_reg: 0.6289  loss_mask: 0.5445  loss_rpn_cls: 0.01695  loss_rpn_loc: 0.03014  time: 0.2836  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:01:55 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 179  total_loss: 1.686  loss_cls: 0.3829  loss_box_reg: 0.6691  loss_mask: 0.4905  loss_rpn_cls: 0.021  loss_rpn_loc: 0.02638  time: 0.2857  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:02 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 199  total_loss: 1.395  loss_cls: 0.2853  loss_box_reg: 0.5865  loss_mask: 0.4423  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.0373  time: 0.2874  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:08 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 219  total_loss: 1.319  loss_cls: 0.236  loss_box_reg: 0.6004  loss_mask: 0.3857  loss_rpn_cls: 0.02247  loss_rpn_loc: 0.02505  time: 0.2892  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:14 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 239  total_loss: 1.385  loss_cls: 0.311  loss_box_reg: 0.6491  loss_mask: 0.3473  loss_rpn_cls: 0.0309  loss_rpn_loc: 0.02113  time: 0.2913  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:20 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 259  total_loss: 1.366  loss_cls: 0.3033  loss_box_reg: 0.631  loss_mask: 0.3544  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.02456  time: 0.2902  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:25 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 279  total_loss: 1.29  loss_cls: 0.2573  loss_box_reg: 0.5501  loss_mask: 0.3294  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.03188  time: 0.2901  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:31 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 299  total_loss: 1.196  loss_cls: 0.2707  loss_box_reg: 0.5376  loss_mask: 0.3161  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.02375  time: 0.2900  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:37 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 319  total_loss: 1.132  loss_cls: 0.2236  loss_box_reg: 0.5566  loss_mask: 0.2616  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.0313  time: 0.2904  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:43 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 339  total_loss: 1.139  loss_cls: 0.2672  loss_box_reg: 0.5019  loss_mask: 0.2762  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.02814  time: 0.2902  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:48 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 359  total_loss: 1.098  loss_cls: 0.1564  loss_box_reg: 0.5165  loss_mask: 0.2839  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.02796  time: 0.2871  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:02:53 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 379  total_loss: 1.071  loss_cls: 0.1922  loss_box_reg: 0.5269  loss_mask: 0.2745  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.02206  time: 0.2876  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:03:00 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 399  total_loss: 0.841  loss_cls: 0.1742  loss_box_reg: 0.5087  loss_mask: 0.2173  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.02817  time: 0.2888  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:03:06 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 419  total_loss: 1.015  loss_cls: 0.1746  loss_box_reg: 0.4538  loss_mask: 0.2551  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.02465  time: 0.2901  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:03:12 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 439  total_loss: 0.8626  loss_cls: 0.1646  loss_box_reg: 0.4188  loss_mask: 0.2798  loss_rpn_cls: 0.007735  loss_rpn_loc: 0.01627  time: 0.2915  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:03:18 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 459  total_loss: 1.039  loss_cls: 0.1792  loss_box_reg: 0.4293  loss_mask: 0.2594  loss_rpn_cls: 0.009012  loss_rpn_loc: 0.02282  time: 0.2918  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:03:24 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 479  total_loss: 0.8615  loss_cls: 0.1447  loss_box_reg: 0.4147  loss_mask: 0.2287  loss_rpn_cls: 0.006633  loss_rpn_loc: 0.01212  time: 0.2919  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:03:31 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.8629  loss_cls: 0.1284  loss_box_reg: 0.3455  loss_mask: 0.2036  loss_rpn_cls: 0.005812  loss_rpn_loc: 0.01974  time: 0.2918  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:03:31 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:25 (0.2919 s / it)\n",
      "\u001b[32m[10/21 06:03:31 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:26 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='MEWZYRX_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:03:31 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:03:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:03:31 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:03:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:03:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:03:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.0872 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 46/126. 0.1049 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 85/126. 0.1005 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.479557 (0.127930 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.094022 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MEWZYRX0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 10.884 | 28.116 | 5.421  | 8.909 | 18.198 | 8.833 |\n",
      "\u001b[32m[10/21 06:03:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 19.386 | cushion    | 17.015 | door       | 4.686 |\n",
      "| indoor-plant | 12.172 | sofa       | 11.138 | table      | 0.908 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:03:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:03:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.12 seconds.\n",
      "\u001b[32m[10/21 06:03:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:03:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "\u001b[32m[10/21 06:03:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 7.271 | 17.789 | 3.462  | 4.910 | 9.982 | 10.113 |\n",
      "\u001b[32m[10/21 06:03:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.811 | cushion    | 15.765 | door       | 4.210 |\n",
      "| indoor-plant | 0.052  | sofa       | 11.788 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='MEWZYRX0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:03:48 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:03:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:03:48 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:03:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:03:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1500 s / img. ETA=0:01:11\n",
      "\u001b[32m[10/21 06:03:55 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.1418 s / img. ETA=0:01:02\n",
      "\u001b[32m[10/21 06:04:00 d2.evaluation.evaluator]: \u001b[0mInference done 68/355. 0.1306 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 06:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 103/355. 0.1270 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 06:04:11 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.1271 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 06:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 166/355. 0.1276 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 06:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 202/355. 0.1262 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 06:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.1289 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 06:04:31 d2.evaluation.evaluator]: \u001b[0mInference done 252/355. 0.1302 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 06:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 283/355. 0.1295 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 06:04:41 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.1305 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:04:46 d2.evaluation.evaluator]: \u001b[0mInference done 337/355. 0.1305 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 06:04:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:00.965877 (0.174188 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:04:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:45 (0.131301 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:04:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:04:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MEWZYRX0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:04:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:04:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:04:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 06:04:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:04:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      "\u001b[32m[10/21 06:04:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.994 | 28.247 | 7.894  | 8.601 | 15.785 | 5.778 |\n",
      "\u001b[32m[10/21 06:04:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.556 | cushion    | 30.991 | door       | 1.651 |\n",
      "| indoor-plant | 17.688 | sofa       | 7.046  | table      | 0.031 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:04:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:04:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 06:04:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:04:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      "\u001b[32m[10/21 06:04:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 10.808 | 21.746 | 10.358 | 7.846 | 14.698 | 8.424 |\n",
      "\u001b[32m[10/21 06:04:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.617 | cushion    | 43.063 | door       | 1.108 |\n",
      "| indoor-plant | 2.737 | sofa       | 9.323  | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='MEWZYRX1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:04:52 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:04:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:04:52 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:04:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:04:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1445 s / img. ETA=0:01:07\n",
      "\u001b[32m[10/21 06:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 40/355. 0.1324 s / img. ETA=0:00:55\n",
      "\u001b[32m[10/21 06:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 73/355. 0.1264 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 06:05:10 d2.evaluation.evaluator]: \u001b[0mInference done 108/355. 0.1253 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 06:05:15 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.1252 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 06:05:20 d2.evaluation.evaluator]: \u001b[0mInference done 177/355. 0.1241 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 06:05:25 d2.evaluation.evaluator]: \u001b[0mInference done 210/355. 0.1242 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:05:30 d2.evaluation.evaluator]: \u001b[0mInference done 235/355. 0.1263 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 06:05:35 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.1261 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:05:40 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1275 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:05:45 d2.evaluation.evaluator]: \u001b[0mInference done 324/355. 0.1272 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 06:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 354/355. 0.1276 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 06:05:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:57.118250 (0.163195 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:05:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:44 (0.127672 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MEWZYRX0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 12.459 | 29.159 | 7.371  | 8.581 | 15.081 | 6.636 |\n",
      "\u001b[32m[10/21 06:05:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.287 | cushion    | 33.788 | door       | 1.470 |\n",
      "| indoor-plant | 16.260 | sofa       | 7.930  | table      | 0.018 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:05:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:05:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.51 seconds.\n",
      "\u001b[32m[10/21 06:05:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:05:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.084\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280\n",
      "\u001b[32m[10/21 06:05:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.386 | 22.576 | 10.655 | 7.964 | 14.701 | 8.417 |\n",
      "\u001b[32m[10/21 06:05:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.168 | cushion    | 46.394 | door       | 1.066 |\n",
      "| indoor-plant | 2.308 | sofa       | 9.381  | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='MEWZYRX2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:05:52 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:05:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:05:52 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:05:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:05:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1569 s / img. ETA=0:01:20\n",
      "\u001b[32m[10/21 06:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.1416 s / img. ETA=0:01:05\n",
      "\u001b[32m[10/21 06:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 66/355. 0.1358 s / img. ETA=0:00:55\n",
      "\u001b[32m[10/21 06:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 104/355. 0.1238 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 06:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.1186 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 06:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 181/355. 0.1148 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 06:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 209/355. 0.1140 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 241/355. 0.1120 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 06:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 270/355. 0.1125 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 298/355. 0.1121 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 331/355. 0.1113 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 06:06:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:56.470386 (0.161344 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:06:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.110855 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:06:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:06:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MEWZYRX0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:06:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:06:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:06:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 06:06:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:06:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
      "\u001b[32m[10/21 06:06:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.783 | 28.353 | 7.002  | 7.802 | 14.475 | 7.393 |\n",
      "\u001b[32m[10/21 06:06:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.285 | cushion    | 31.071 | door       | 2.023 |\n",
      "| indoor-plant | 17.395 | sofa       | 6.913  | table      | 0.013 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:06:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:06:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/21 06:06:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:06:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      "\u001b[32m[10/21 06:06:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 10.720 | 21.228 | 10.127 | 7.170 | 13.930 | 9.173 |\n",
      "\u001b[32m[10/21 06:06:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.159 | cushion    | 42.928 | door       | 1.578 |\n",
      "| indoor-plant | 2.405 | sofa       | 9.249  | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [28.24720903089372, 29.158972712487873, 28.352602038598114]}, 'segm': {'AP50': [21.746482883559402, 22.575907546714067, 21.228096747866925]}}\n",
      "dataset_name QXJGIOI\n",
      "SOLVER PARAMS (800, 100, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='QXJGIOI_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/QXJGIOI0\n",
      "output_aug/800/QXJGIOI0\n",
      "\u001b[32m[10/21 06:06:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:06:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:06:53 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:06:53 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:06:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:06:53 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:06:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:06:53 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:06:53 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:06:59 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 19  total_loss: 3.35  loss_cls: 1.851  loss_box_reg: 0.6252  loss_mask: 0.6932  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.03007  time: 0.2766  data_time: 0.0166  lr: 1.9081e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:05 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 39  total_loss: 2.944  loss_cls: 1.33  loss_box_reg: 0.6396  loss_mask: 0.6863  loss_rpn_cls: 0.1265  loss_rpn_loc: 0.03939  time: 0.2794  data_time: 0.0035  lr: 3.9061e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:11 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 59  total_loss: 2.316  loss_cls: 0.8117  loss_box_reg: 0.6722  loss_mask: 0.6726  loss_rpn_cls: 0.04793  loss_rpn_loc: 0.02973  time: 0.2787  data_time: 0.0036  lr: 5.9041e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:16 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 79  total_loss: 2.036  loss_cls: 0.6672  loss_box_reg: 0.6687  loss_mask: 0.6522  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.03366  time: 0.2790  data_time: 0.0037  lr: 7.9021e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:22 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 99  total_loss: 1.944  loss_cls: 0.5746  loss_box_reg: 0.6959  loss_mask: 0.6255  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.03374  time: 0.2806  data_time: 0.0037  lr: 9.9001e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:26 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 119  total_loss: 1.758  loss_cls: 0.4789  loss_box_reg: 0.6446  loss_mask: 0.5855  loss_rpn_cls: 0.02332  loss_rpn_loc: 0.02901  time: 0.2715  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:32 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 139  total_loss: 1.734  loss_cls: 0.4755  loss_box_reg: 0.641  loss_mask: 0.5418  loss_rpn_cls: 0.02419  loss_rpn_loc: 0.01813  time: 0.2740  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:38 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 159  total_loss: 1.622  loss_cls: 0.4106  loss_box_reg: 0.6592  loss_mask: 0.5446  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.02631  time: 0.2781  data_time: 0.0039  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:45 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 179  total_loss: 1.567  loss_cls: 0.3815  loss_box_reg: 0.6252  loss_mask: 0.5004  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.03061  time: 0.2816  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:51 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 199  total_loss: 1.69  loss_cls: 0.4307  loss_box_reg: 0.6429  loss_mask: 0.4753  loss_rpn_cls: 0.02355  loss_rpn_loc: 0.04513  time: 0.2847  data_time: 0.0039  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:07:57 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 219  total_loss: 1.455  loss_cls: 0.3071  loss_box_reg: 0.5858  loss_mask: 0.4253  loss_rpn_cls: 0.0172  loss_rpn_loc: 0.02372  time: 0.2875  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:03 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 239  total_loss: 1.424  loss_cls: 0.3305  loss_box_reg: 0.5977  loss_mask: 0.4007  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.03576  time: 0.2873  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:09 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 259  total_loss: 1.384  loss_cls: 0.2813  loss_box_reg: 0.586  loss_mask: 0.3772  loss_rpn_cls: 0.02142  loss_rpn_loc: 0.02897  time: 0.2875  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:14 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 279  total_loss: 1.353  loss_cls: 0.2589  loss_box_reg: 0.5239  loss_mask: 0.3187  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.02734  time: 0.2876  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:21 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 299  total_loss: 1.231  loss_cls: 0.2741  loss_box_reg: 0.541  loss_mask: 0.3159  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.01904  time: 0.2890  data_time: 0.0034  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:26 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 319  total_loss: 1.107  loss_cls: 0.2547  loss_box_reg: 0.5181  loss_mask: 0.3213  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.01709  time: 0.2870  data_time: 0.0034  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:31 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 339  total_loss: 1.215  loss_cls: 0.2434  loss_box_reg: 0.5393  loss_mask: 0.3076  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.02802  time: 0.2850  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:37 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 359  total_loss: 1.19  loss_cls: 0.1923  loss_box_reg: 0.5064  loss_mask: 0.2691  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.01991  time: 0.2860  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:43 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 379  total_loss: 1.154  loss_cls: 0.1834  loss_box_reg: 0.4783  loss_mask: 0.2701  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.02321  time: 0.2875  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:50 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 399  total_loss: 0.982  loss_cls: 0.2041  loss_box_reg: 0.43  loss_mask: 0.2381  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.0169  time: 0.2889  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:08:56 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 419  total_loss: 0.9163  loss_cls: 0.1597  loss_box_reg: 0.4506  loss_mask: 0.2668  loss_rpn_cls: 0.007255  loss_rpn_loc: 0.01803  time: 0.2908  data_time: 0.0039  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:02 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 439  total_loss: 1.017  loss_cls: 0.1626  loss_box_reg: 0.4118  loss_mask: 0.2561  loss_rpn_cls: 0.006432  loss_rpn_loc: 0.02203  time: 0.2907  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:08 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 459  total_loss: 0.8225  loss_cls: 0.1381  loss_box_reg: 0.3658  loss_mask: 0.2485  loss_rpn_cls: 0.005663  loss_rpn_loc: 0.01634  time: 0.2908  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:14 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 479  total_loss: 0.797  loss_cls: 0.1431  loss_box_reg: 0.4261  loss_mask: 0.24  loss_rpn_cls: 0.00827  loss_rpn_loc: 0.01618  time: 0.2907  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:19 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 499  total_loss: 0.8665  loss_cls: 0.1455  loss_box_reg: 0.4468  loss_mask: 0.2424  loss_rpn_cls: 0.009464  loss_rpn_loc: 0.02545  time: 0.2906  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:25 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 519  total_loss: 0.9931  loss_cls: 0.1799  loss_box_reg: 0.4359  loss_mask: 0.239  loss_rpn_cls: 0.00386  loss_rpn_loc: 0.02156  time: 0.2909  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:30 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 539  total_loss: 0.8742  loss_cls: 0.1519  loss_box_reg: 0.4226  loss_mask: 0.2513  loss_rpn_cls: 0.006849  loss_rpn_loc: 0.01885  time: 0.2888  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:36 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 559  total_loss: 0.7098  loss_cls: 0.1583  loss_box_reg: 0.3585  loss_mask: 0.1656  loss_rpn_cls: 0.005014  loss_rpn_loc: 0.01469  time: 0.2888  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:43 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 579  total_loss: 0.8445  loss_cls: 0.146  loss_box_reg: 0.3712  loss_mask: 0.2446  loss_rpn_cls: 0.008612  loss_rpn_loc: 0.01839  time: 0.2910  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:50 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 599  total_loss: 0.6852  loss_cls: 0.1346  loss_box_reg: 0.3599  loss_mask: 0.1985  loss_rpn_cls: 0.004974  loss_rpn_loc: 0.01872  time: 0.2930  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:09:57 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 619  total_loss: 0.6642  loss_cls: 0.1157  loss_box_reg: 0.3071  loss_mask: 0.191  loss_rpn_cls: 0.005067  loss_rpn_loc: 0.02235  time: 0.2950  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:04 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 639  total_loss: 0.6209  loss_cls: 0.1208  loss_box_reg: 0.2967  loss_mask: 0.2111  loss_rpn_cls: 0.004939  loss_rpn_loc: 0.02375  time: 0.2972  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:11 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 659  total_loss: 0.7751  loss_cls: 0.1443  loss_box_reg: 0.3575  loss_mask: 0.2125  loss_rpn_cls: 0.006887  loss_rpn_loc: 0.02048  time: 0.2986  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:18 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 679  total_loss: 0.6913  loss_cls: 0.1586  loss_box_reg: 0.3007  loss_mask: 0.194  loss_rpn_cls: 0.005667  loss_rpn_loc: 0.01722  time: 0.3003  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:26 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 699  total_loss: 0.6117  loss_cls: 0.08815  loss_box_reg: 0.3287  loss_mask: 0.2156  loss_rpn_cls: 0.008777  loss_rpn_loc: 0.01874  time: 0.3022  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:33 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 719  total_loss: 0.6192  loss_cls: 0.09079  loss_box_reg: 0.3169  loss_mask: 0.1705  loss_rpn_cls: 0.004826  loss_rpn_loc: 0.01842  time: 0.3037  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:40 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 739  total_loss: 0.7041  loss_cls: 0.1089  loss_box_reg: 0.299  loss_mask: 0.2208  loss_rpn_cls: 0.002737  loss_rpn_loc: 0.01112  time: 0.3052  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:47 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 759  total_loss: 0.6892  loss_cls: 0.1307  loss_box_reg: 0.3014  loss_mask: 0.2257  loss_rpn_cls: 0.006483  loss_rpn_loc: 0.0168  time: 0.3067  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:10:54 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.6998  loss_cls: 0.1235  loss_box_reg: 0.269  loss_mask: 0.2113  loss_rpn_cls: 0.00504  loss_rpn_loc: 0.02153  time: 0.3079  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:11:02 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.6856  loss_cls: 0.09643  loss_box_reg: 0.2635  loss_mask: 0.2014  loss_rpn_cls: 0.008967  loss_rpn_loc: 0.01811  time: 0.3091  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:11:02 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:06 (0.3091 s / it)\n",
      "\u001b[32m[10/21 06:11:02 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:07 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='QXJGIOI_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:11:02 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:11:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:11:02 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:11:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:11:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1077 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 44/126. 0.1256 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 06:11:14 d2.evaluation.evaluator]: \u001b[0mInference done 79/126. 0.1244 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:11:19 d2.evaluation.evaluator]: \u001b[0mInference done 110/126. 0.1266 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.292636 (0.151179 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.124978 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QXJGIOI0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 15.775 | 33.561 | 10.734 | 10.654 | 24.691 | 14.582 |\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 29.880 | cushion    | 18.600 | door       | 4.975 |\n",
      "| indoor-plant | 12.368 | sofa       | 23.829 | table      | 4.995 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 9.044 | 26.280 | 4.463  | 5.568 | 15.097 | 11.857 |\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.191 | cushion    | 16.029 | door       | 4.969 |\n",
      "| indoor-plant | 6.282  | sofa       | 14.790 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='QXJGIOI0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:11:22 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:11:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:11:22 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:11:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:11:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.1406 s / img. ETA=0:01:01\n",
      "\u001b[32m[10/21 06:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1267 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 06:11:35 d2.evaluation.evaluator]: \u001b[0mInference done 82/355. 0.1216 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 06:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 120/355. 0.1207 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 06:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 155/355. 0.1215 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 195/355. 0.1200 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:11:55 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.1211 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:12:00 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.1216 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:12:05 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1213 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:12:10 d2.evaluation.evaluator]: \u001b[0mInference done 325/355. 0.1219 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.903262 (0.148295 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.122239 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QXJGIOI0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 06:12:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:12:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "\u001b[32m[10/21 06:12:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.271 | 30.466 | 7.444  | 8.429 | 15.251 | 10.080 |\n",
      "\u001b[32m[10/21 06:12:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.192 | cushion    | 32.797 | door       | 1.291 |\n",
      "| indoor-plant | 15.165 | sofa       | 18.757 | table      | 0.420 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:12:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:12:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 06:12:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:12:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
      "\u001b[32m[10/21 06:12:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.014 | 28.724 | 11.700 | 8.316 | 18.827 | 12.202 |\n",
      "\u001b[32m[10/21 06:12:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 6.557  | cushion    | 42.926 | door       | 0.605 |\n",
      "| indoor-plant | 12.676 | sofa       | 21.319 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='QXJGIOI1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:12:17 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:12:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:12:17 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:12:17 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:12:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:12:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1224 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 06:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 44/355. 0.1236 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 06:12:29 d2.evaluation.evaluator]: \u001b[0mInference done 82/355. 0.1202 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 06:12:34 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.1185 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 06:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 158/355. 0.1182 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 06:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 198/355. 0.1177 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 06:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.1201 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.1211 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 291/355. 0.1215 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 326/355. 0.1216 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:13:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.508665 (0.147168 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:13:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121825 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:13:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:13:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QXJGIOI0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:13:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:13:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 13.325 | 30.709 | 6.908  | 8.394 | 14.972 | 9.502 |\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.840 | cushion    | 31.784 | door       | 1.470 |\n",
      "| indoor-plant | 14.598 | sofa       | 18.868 | table      | 0.388 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 06:13:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:13:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
      "\u001b[32m[10/21 06:13:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.246 | 29.022 | 11.813 | 7.785 | 18.678 | 11.635 |\n",
      "\u001b[32m[10/21 06:13:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.634  | cushion    | 42.484 | door       | 1.140 |\n",
      "| indoor-plant | 12.588 | sofa       | 21.629 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='QXJGIOI2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:13:11 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:13:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:13:11 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:13:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:13:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1390 s / img. ETA=0:01:06\n",
      "\u001b[32m[10/21 06:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 42/355. 0.1259 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 06:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 77/355. 0.1235 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 06:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 113/355. 0.1224 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 06:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 149/355. 0.1220 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 06:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 188/355. 0.1211 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 06:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.1216 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 252/355. 0.1190 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 06:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.1171 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 327/355. 0.1139 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:14:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.658993 (0.147597 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:14:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.114075 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:14:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:14:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/QXJGIOI0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.115\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.257 | 30.844 | 7.073  | 8.374 | 14.610 | 11.471 |\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.933 | cushion    | 32.507 | door       | 1.563 |\n",
      "| indoor-plant | 14.818 | sofa       | 18.266 | table      | 0.457 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:14:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:14:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 06:14:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:14:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      "\u001b[32m[10/21 06:14:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.192 | 28.922 | 11.532 | 7.882 | 17.983 | 12.967 |\n",
      "\u001b[32m[10/21 06:14:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.465  | cushion    | 42.226 | door       | 1.142 |\n",
      "| indoor-plant | 13.167 | sofa       | 21.151 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [30.46647113509289, 30.708665098158423, 30.844079532058423]}, 'segm': {'AP50': [28.72376766156237, 29.02163282135569, 28.9221490284923]}}\n",
      "dataset_name XWBB9IJ\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='XWBB9IJ_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/XWBB9IJ0\n",
      "output_aug/500/XWBB9IJ0\n",
      "\u001b[32m[10/21 06:14:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:14:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:14:06 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:14:06 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:14:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:14:06 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:14:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:14:06 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:14:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:14:13 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 19  total_loss: 3.418  loss_cls: 1.909  loss_box_reg: 0.6178  loss_mask: 0.693  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.03514  time: 0.3292  data_time: 0.0159  lr: 9.5905e-06  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:14:19 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 39  total_loss: 3.278  loss_cls: 1.629  loss_box_reg: 0.6563  loss_mask: 0.6904  loss_rpn_cls: 0.09008  loss_rpn_loc: 0.04042  time: 0.3241  data_time: 0.0038  lr: 1.958e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:14:26 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 59  total_loss: 2.492  loss_cls: 1.105  loss_box_reg: 0.6132  loss_mask: 0.6841  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.03105  time: 0.3251  data_time: 0.0037  lr: 2.9571e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:14:32 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 79  total_loss: 2.154  loss_cls: 0.8021  loss_box_reg: 0.6288  loss_mask: 0.6725  loss_rpn_cls: 0.03886  loss_rpn_loc: 0.03273  time: 0.3219  data_time: 0.0037  lr: 3.9561e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:14:38 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 99  total_loss: 2.027  loss_cls: 0.6473  loss_box_reg: 0.6165  loss_mask: 0.6536  loss_rpn_cls: 0.04546  loss_rpn_loc: 0.02086  time: 0.3187  data_time: 0.0037  lr: 4.955e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:14:44 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 119  total_loss: 2.056  loss_cls: 0.6214  loss_box_reg: 0.6234  loss_mask: 0.6287  loss_rpn_cls: 0.0251  loss_rpn_loc: 0.03492  time: 0.3158  data_time: 0.0037  lr: 5.954e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:14:49 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 139  total_loss: 1.967  loss_cls: 0.5838  loss_box_reg: 0.6448  loss_mask: 0.6152  loss_rpn_cls: 0.01698  loss_rpn_loc: 0.02985  time: 0.3059  data_time: 0.0036  lr: 6.9531e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:14:55 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 159  total_loss: 1.736  loss_cls: 0.4794  loss_box_reg: 0.6257  loss_mask: 0.5996  loss_rpn_cls: 0.0249  loss_rpn_loc: 0.03179  time: 0.3041  data_time: 0.0036  lr: 7.952e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:01 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 179  total_loss: 1.801  loss_cls: 0.4678  loss_box_reg: 0.651  loss_mask: 0.5689  loss_rpn_cls: 0.02645  loss_rpn_loc: 0.03336  time: 0.3047  data_time: 0.0035  lr: 8.951e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:08 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 199  total_loss: 1.682  loss_cls: 0.4171  loss_box_reg: 0.6427  loss_mask: 0.5345  loss_rpn_cls: 0.0192  loss_rpn_loc: 0.03667  time: 0.3061  data_time: 0.0037  lr: 9.9501e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:14 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 219  total_loss: 1.732  loss_cls: 0.3604  loss_box_reg: 0.6308  loss_mask: 0.4867  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.03022  time: 0.3069  data_time: 0.0034  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:21 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 239  total_loss: 1.519  loss_cls: 0.3709  loss_box_reg: 0.6669  loss_mask: 0.4653  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.03119  time: 0.3085  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:27 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 259  total_loss: 1.486  loss_cls: 0.3624  loss_box_reg: 0.5958  loss_mask: 0.4448  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.02143  time: 0.3087  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:33 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 279  total_loss: 1.41  loss_cls: 0.3111  loss_box_reg: 0.5936  loss_mask: 0.3797  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.02803  time: 0.3086  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:39 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 299  total_loss: 1.23  loss_cls: 0.2733  loss_box_reg: 0.5908  loss_mask: 0.3584  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.03113  time: 0.3086  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:44 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 319  total_loss: 1.313  loss_cls: 0.2767  loss_box_reg: 0.5758  loss_mask: 0.3305  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.02253  time: 0.3055  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:51 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 339  total_loss: 1.106  loss_cls: 0.214  loss_box_reg: 0.5342  loss_mask: 0.2555  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.02541  time: 0.3065  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:15:57 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 359  total_loss: 1.214  loss_cls: 0.2651  loss_box_reg: 0.5276  loss_mask: 0.3217  loss_rpn_cls: 0.00739  loss_rpn_loc: 0.02586  time: 0.3072  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:04 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 379  total_loss: 1.197  loss_cls: 0.2473  loss_box_reg: 0.5202  loss_mask: 0.2662  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.0267  time: 0.3080  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:10 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 399  total_loss: 0.9898  loss_cls: 0.201  loss_box_reg: 0.4746  loss_mask: 0.2859  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.01715  time: 0.3090  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:16 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 419  total_loss: 0.9941  loss_cls: 0.1418  loss_box_reg: 0.4136  loss_mask: 0.2319  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.03509  time: 0.3086  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:22 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 439  total_loss: 1.041  loss_cls: 0.1819  loss_box_reg: 0.5001  loss_mask: 0.2396  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.02495  time: 0.3086  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:29 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 459  total_loss: 1.067  loss_cls: 0.1528  loss_box_reg: 0.4554  loss_mask: 0.2722  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.02844  time: 0.3085  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:35 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.9892  loss_cls: 0.214  loss_box_reg: 0.4805  loss_mask: 0.2615  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.02167  time: 0.3086  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:40 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.9007  loss_cls: 0.1702  loss_box_reg: 0.3758  loss_mask: 0.2187  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.02096  time: 0.3054  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:16:40 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:32 (0.3054 s / it)\n",
      "\u001b[32m[10/21 06:16:40 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:33 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='XWBB9IJ_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:16:40 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:16:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:16:40 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:16:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:16:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1105 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 06:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 42/126. 0.1274 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 75/126. 0.1258 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 06:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 106/126. 0.1262 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.577131 (0.161794 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.127390 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XWBB9IJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.349\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.405 | 26.655 | 6.642  | 7.148 | 17.324 | 13.974 |\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 28.079 | cushion    | 10.225 | door       | 4.330 |\n",
      "| indoor-plant | 9.110  | sofa       | 16.673 | table      | 0.014 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.11 seconds.\n",
      "\u001b[32m[10/21 06:17:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:17:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.066\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
      "\u001b[32m[10/21 06:17:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.866 | 13.473 | 2.973  | 2.479 | 9.258 | 7.870 |\n",
      "\u001b[32m[10/21 06:17:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP    | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:------|:-----------|:------|\n",
      "| chair        | 12.379 | cushion    | 8.317 | door       | 3.771 |\n",
      "| indoor-plant | 0.095  | sofa       | 4.633 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='XWBB9IJ0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:17:02 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:17:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:17:02 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:17:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:17:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1505 s / img. ETA=0:01:12\n",
      "\u001b[32m[10/21 06:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 39/355. 0.1362 s / img. ETA=0:00:58\n",
      "\u001b[32m[10/21 06:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 71/355. 0.1296 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 06:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 105/355. 0.1284 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 06:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 139/355. 0.1260 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 06:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.1255 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:17:34 d2.evaluation.evaluator]: \u001b[0mInference done 208/355. 0.1253 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.1285 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:17:44 d2.evaluation.evaluator]: \u001b[0mInference done 257/355. 0.1293 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.1300 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.1316 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.1318 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:00.969116 (0.174197 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:46 (0.132669 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XWBB9IJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 14.061 | 29.320 | 10.211 | 9.126 | 15.343 | 7.302 |\n",
      "\u001b[32m[10/21 06:18:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.783 | cushion    | 31.812 | door       | 1.053 |\n",
      "| indoor-plant | 13.995 | sofa       | 18.497 | table      | 0.226 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:18:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:18:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 06:18:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:18:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.276\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
      "\u001b[32m[10/21 06:18:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 11.914 | 23.656 | 10.324 | 7.172 | 12.558 | 9.594 |\n",
      "\u001b[32m[10/21 06:18:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.208 | cushion    | 37.225 | door       | 0.426 |\n",
      "| indoor-plant | 0.897  | sofa       | 22.725 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='XWBB9IJ1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:18:06 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:18:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:18:06 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:18:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:18:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1681 s / img. ETA=0:01:22\n",
      "\u001b[32m[10/21 06:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.1435 s / img. ETA=0:01:04\n",
      "\u001b[32m[10/21 06:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 68/355. 0.1337 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 06:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 101/355. 0.1314 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 06:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.1301 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 06:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 165/355. 0.1292 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 06:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 200/355. 0.1277 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 06:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 219/355. 0.1319 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 06:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 240/355. 0.1348 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:18:54 d2.evaluation.evaluator]: \u001b[0mInference done 268/355. 0.1345 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 06:18:59 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.1361 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 312/355. 0.1375 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 339/355. 0.1377 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:19:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:06.325130 (0.189500 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:19:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:48 (0.138554 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XWBB9IJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 14.229 | 29.645 | 10.708 | 8.483 | 15.536 | 7.725 |\n",
      "\u001b[32m[10/21 06:19:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 20.439 | cushion    | 32.313 | door       | 1.137 |\n",
      "| indoor-plant | 14.205 | sofa       | 17.193 | table      | 0.090 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:19:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:19:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 06:19:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:19:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.071\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
      "\u001b[32m[10/21 06:19:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 12.150 | 24.282 | 9.608  | 7.070 | 13.450 | 9.346 |\n",
      "\u001b[32m[10/21 06:19:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.696 | cushion    | 38.799 | door       | 0.651 |\n",
      "| indoor-plant | 1.051  | sofa       | 20.706 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='XWBB9IJ2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:19:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:19:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:19:16 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:19:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:19:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1463 s / img. ETA=0:01:15\n",
      "\u001b[32m[10/21 06:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 38/355. 0.1383 s / img. ETA=0:01:02\n",
      "\u001b[32m[10/21 06:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 71/355. 0.1278 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 06:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 105/355. 0.1267 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 06:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 138/355. 0.1261 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 06:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.1241 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 200/355. 0.1274 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 06:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 220/355. 0.1318 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 06:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.1324 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 274/355. 0.1330 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 06:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 295/355. 0.1355 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 318/355. 0.1364 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.1369 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:05.883135 (0.188238 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:48 (0.138089 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XWBB9IJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 06:20:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:20:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
      "\u001b[32m[10/21 06:20:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 13.652 | 28.483 | 10.267 | 7.994 | 14.339 | 8.809 |\n",
      "\u001b[32m[10/21 06:20:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.081 | cushion    | 30.789 | door       | 1.067 |\n",
      "| indoor-plant | 15.363 | sofa       | 16.449 | table      | 0.163 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:20:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:20:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.46 seconds.\n",
      "\u001b[32m[10/21 06:20:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:20:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "\u001b[32m[10/21 06:20:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.739 | 22.504 | 9.287  | 6.359 | 12.691 | 10.272 |\n",
      "\u001b[32m[10/21 06:20:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.489 | cushion    | 37.069 | door       | 0.676 |\n",
      "| indoor-plant | 0.871  | sofa       | 21.331 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [29.319520377929965, 29.64478112892881, 28.482987085111926]}, 'segm': {'AP50': [23.655592412960356, 24.281957222676173, 22.50389667388766]}}\n",
      "dataset_name M1WZ58Q\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='M1WZ58Q_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/M1WZ58Q0\n",
      "output_aug/800/M1WZ58Q0\n",
      "\u001b[32m[10/21 06:20:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:20:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:20:26 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:20:26 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:20:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:20:26 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:20:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:20:26 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:20:26 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:20:33 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 19  total_loss: 3.298  loss_cls: 1.81  loss_box_reg: 0.555  loss_mask: 0.6905  loss_rpn_cls: 0.1315  loss_rpn_loc: 0.02817  time: 0.3065  data_time: 0.0166  lr: 9.5905e-06  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:20:39 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 39  total_loss: 3.173  loss_cls: 1.545  loss_box_reg: 0.6495  loss_mask: 0.6885  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.03563  time: 0.3082  data_time: 0.0036  lr: 1.958e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:20:45 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 59  total_loss: 2.718  loss_cls: 1.118  loss_box_reg: 0.7071  loss_mask: 0.6806  loss_rpn_cls: 0.04578  loss_rpn_loc: 0.03144  time: 0.3055  data_time: 0.0036  lr: 2.9571e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:20:51 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 79  total_loss: 2.178  loss_cls: 0.7625  loss_box_reg: 0.5413  loss_mask: 0.6682  loss_rpn_cls: 0.03803  loss_rpn_loc: 0.02808  time: 0.3099  data_time: 0.0038  lr: 3.9561e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:20:58 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 99  total_loss: 2.345  loss_cls: 0.6945  loss_box_reg: 0.7665  loss_mask: 0.6607  loss_rpn_cls: 0.03867  loss_rpn_loc: 0.05073  time: 0.3159  data_time: 0.0040  lr: 4.955e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:05 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 119  total_loss: 1.964  loss_cls: 0.5983  loss_box_reg: 0.6398  loss_mask: 0.6295  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.03974  time: 0.3223  data_time: 0.0037  lr: 5.954e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:12 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 139  total_loss: 1.857  loss_cls: 0.5405  loss_box_reg: 0.6301  loss_mask: 0.6187  loss_rpn_cls: 0.01909  loss_rpn_loc: 0.02462  time: 0.3243  data_time: 0.0037  lr: 6.9531e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:18 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 159  total_loss: 1.776  loss_cls: 0.4308  loss_box_reg: 0.6149  loss_mask: 0.5964  loss_rpn_cls: 0.03344  loss_rpn_loc: 0.02196  time: 0.3224  data_time: 0.0036  lr: 7.9521e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:24 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 179  total_loss: 1.603  loss_cls: 0.415  loss_box_reg: 0.6311  loss_mask: 0.568  loss_rpn_cls: 0.02381  loss_rpn_loc: 0.01621  time: 0.3202  data_time: 0.0036  lr: 8.9511e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:31 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 199  total_loss: 1.715  loss_cls: 0.4546  loss_box_reg: 0.6143  loss_mask: 0.5192  loss_rpn_cls: 0.02321  loss_rpn_loc: 0.03526  time: 0.3191  data_time: 0.0038  lr: 9.9501e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:36 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 219  total_loss: 1.803  loss_cls: 0.4112  loss_box_reg: 0.6349  loss_mask: 0.4981  loss_rpn_cls: 0.02996  loss_rpn_loc: 0.03343  time: 0.3145  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:42 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 239  total_loss: 1.417  loss_cls: 0.3177  loss_box_reg: 0.638  loss_mask: 0.4368  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.02242  time: 0.3122  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:48 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 259  total_loss: 1.525  loss_cls: 0.3102  loss_box_reg: 0.5923  loss_mask: 0.4174  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.02983  time: 0.3126  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:21:55 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 279  total_loss: 1.252  loss_cls: 0.251  loss_box_reg: 0.6357  loss_mask: 0.3385  loss_rpn_cls: 0.01681  loss_rpn_loc: 0.02736  time: 0.3137  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:01 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 299  total_loss: 1.339  loss_cls: 0.294  loss_box_reg: 0.6836  loss_mask: 0.3062  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.01655  time: 0.3140  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:07 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 319  total_loss: 1.301  loss_cls: 0.2974  loss_box_reg: 0.5893  loss_mask: 0.3421  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.02499  time: 0.3146  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:14 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 339  total_loss: 1.148  loss_cls: 0.2663  loss_box_reg: 0.5118  loss_mask: 0.2597  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.0253  time: 0.3143  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:20 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 359  total_loss: 1.198  loss_cls: 0.2632  loss_box_reg: 0.5904  loss_mask: 0.2621  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.02693  time: 0.3135  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:26 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 379  total_loss: 1.145  loss_cls: 0.2631  loss_box_reg: 0.5529  loss_mask: 0.2712  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.03024  time: 0.3138  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:31 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 399  total_loss: 1.163  loss_cls: 0.2223  loss_box_reg: 0.5632  loss_mask: 0.2897  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.02184  time: 0.3108  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:37 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 419  total_loss: 0.9847  loss_cls: 0.2011  loss_box_reg: 0.4482  loss_mask: 0.2625  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.01899  time: 0.3108  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:44 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 439  total_loss: 0.9805  loss_cls: 0.215  loss_box_reg: 0.406  loss_mask: 0.2268  loss_rpn_cls: 0.006591  loss_rpn_loc: 0.02556  time: 0.3115  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:51 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 459  total_loss: 0.9913  loss_cls: 0.1759  loss_box_reg: 0.5324  loss_mask: 0.2528  loss_rpn_cls: 0.008348  loss_rpn_loc: 0.01316  time: 0.3128  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:22:57 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 479  total_loss: 0.9422  loss_cls: 0.1723  loss_box_reg: 0.4761  loss_mask: 0.2593  loss_rpn_cls: 0.009145  loss_rpn_loc: 0.01426  time: 0.3137  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:04 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 499  total_loss: 0.837  loss_cls: 0.1391  loss_box_reg: 0.4298  loss_mask: 0.2538  loss_rpn_cls: 0.008229  loss_rpn_loc: 0.02286  time: 0.3134  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:10 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 519  total_loss: 0.9397  loss_cls: 0.1636  loss_box_reg: 0.4505  loss_mask: 0.2295  loss_rpn_cls: 0.005843  loss_rpn_loc: 0.01769  time: 0.3131  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:16 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 539  total_loss: 0.8081  loss_cls: 0.1373  loss_box_reg: 0.3605  loss_mask: 0.169  loss_rpn_cls: 0.007101  loss_rpn_loc: 0.01722  time: 0.3131  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:22 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 559  total_loss: 0.9414  loss_cls: 0.1623  loss_box_reg: 0.3948  loss_mask: 0.238  loss_rpn_cls: 0.00755  loss_rpn_loc: 0.02443  time: 0.3127  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:27 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 579  total_loss: 0.8094  loss_cls: 0.1406  loss_box_reg: 0.3964  loss_mask: 0.2338  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.02438  time: 0.3105  data_time: 0.0040  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:34 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 599  total_loss: 0.7534  loss_cls: 0.1165  loss_box_reg: 0.3372  loss_mask: 0.2075  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.02001  time: 0.3122  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:41 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 619  total_loss: 0.6751  loss_cls: 0.1218  loss_box_reg: 0.3435  loss_mask: 0.21  loss_rpn_cls: 0.009544  loss_rpn_loc: 0.01686  time: 0.3134  data_time: 0.0039  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:48 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 639  total_loss: 0.788  loss_cls: 0.1436  loss_box_reg: 0.3746  loss_mask: 0.2067  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.02012  time: 0.3146  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:23:55 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 659  total_loss: 0.5758  loss_cls: 0.1037  loss_box_reg: 0.2949  loss_mask: 0.187  loss_rpn_cls: 0.006838  loss_rpn_loc: 0.01647  time: 0.3158  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:02 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 679  total_loss: 0.7653  loss_cls: 0.1161  loss_box_reg: 0.3012  loss_mask: 0.2238  loss_rpn_cls: 0.007639  loss_rpn_loc: 0.01759  time: 0.3169  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:10 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 699  total_loss: 0.7702  loss_cls: 0.13  loss_box_reg: 0.3409  loss_mask: 0.2207  loss_rpn_cls: 0.007133  loss_rpn_loc: 0.02082  time: 0.3182  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:17 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 719  total_loss: 0.6628  loss_cls: 0.1091  loss_box_reg: 0.2761  loss_mask: 0.1805  loss_rpn_cls: 0.005662  loss_rpn_loc: 0.01347  time: 0.3191  data_time: 0.0035  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:24 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 739  total_loss: 0.7213  loss_cls: 0.1204  loss_box_reg: 0.3175  loss_mask: 0.1901  loss_rpn_cls: 0.008229  loss_rpn_loc: 0.02147  time: 0.3200  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:31 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 759  total_loss: 0.5335  loss_cls: 0.09155  loss_box_reg: 0.2232  loss_mask: 0.1469  loss_rpn_cls: 0.009462  loss_rpn_loc: 0.01001  time: 0.3209  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:38 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.6432  loss_cls: 0.1167  loss_box_reg: 0.2864  loss_mask: 0.1986  loss_rpn_cls: 0.004925  loss_rpn_loc: 0.01694  time: 0.3217  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:46 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.6609  loss_cls: 0.1173  loss_box_reg: 0.3057  loss_mask: 0.1815  loss_rpn_cls: 0.006078  loss_rpn_loc: 0.01638  time: 0.3228  data_time: 0.0040  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:24:46 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:17 (0.3228 s / it)\n",
      "\u001b[32m[10/21 06:24:46 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:18 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='M1WZ58Q_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:24:46 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:24:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:24:46 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:24:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:24:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:24:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1184 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 06:24:53 d2.evaluation.evaluator]: \u001b[0mInference done 45/126. 0.1245 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 06:24:58 d2.evaluation.evaluator]: \u001b[0mInference done 80/126. 0.1239 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 112/126. 0.1251 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.202460 (0.150434 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.123915 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/M1WZ58Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.350\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.477\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.426 | 34.963 | 14.718 | 10.542 | 30.718 | 19.413 |\n",
      "\u001b[32m[10/21 06:25:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 32.306 | cushion    | 19.286 | door       | 5.856 |\n",
      "| indoor-plant | 14.425 | sofa       | 29.332 | table      | 3.350 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:25:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:25:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 06:25:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:25:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
      "\u001b[32m[10/21 06:25:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 10.260 | 27.310 | 5.993  | 4.973 | 18.261 | 9.940 |\n",
      "\u001b[32m[10/21 06:25:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.854 | cushion    | 17.256 | door       | 5.317 |\n",
      "| indoor-plant | 5.693  | sofa       | 20.441 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='M1WZ58Q0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:25:06 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:25:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:25:06 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:25:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:25:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.1308 s / img. ETA=0:00:58\n",
      "\u001b[32m[10/21 06:25:13 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1225 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 06:25:18 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.1226 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 06:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 119/355. 0.1218 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 06:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 154/355. 0.1222 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 06:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 194/355. 0.1207 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.1220 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.1230 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 06:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.1229 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.1235 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 347/355. 0.1236 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 06:26:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:53.901284 (0.154004 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:26:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.124038 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:26:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:26:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/M1WZ58Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:26:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:26:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.405 | 36.144 | 11.417 | 9.135 | 20.020 | 12.081 |\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.351 | cushion    | 34.660 | door       | 1.332 |\n",
      "| indoor-plant | 14.794 | sofa       | 30.254 | table      | 1.040 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 06:26:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:26:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
      "\u001b[32m[10/21 06:26:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.610 | 33.445 | 15.173 | 8.713 | 22.602 | 14.814 |\n",
      "\u001b[32m[10/21 06:26:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.301 | cushion    | 43.471 | door       | 0.454 |\n",
      "| indoor-plant | 12.814 | sofa       | 36.620 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='M1WZ58Q1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:26:03 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:26:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:26:03 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:26:03 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:26:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:26:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1072 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 06:26:09 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.0999 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 06:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1032 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 06:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.1040 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 181/355. 0.0994 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 218/355. 0.1001 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.1010 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 06:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.1027 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 319/355. 0.1039 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.1049 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.967541 (0.134193 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.104997 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/M1WZ58Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.789 | 37.149 | 12.085 | 9.276 | 20.157 | 11.288 |\n",
      "\u001b[32m[10/21 06:26:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 23.830 | cushion    | 36.583 | door       | 1.412 |\n",
      "| indoor-plant | 14.650 | sofa       | 29.186 | table      | 1.071 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:26:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:26:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.37 seconds.\n",
      "\u001b[32m[10/21 06:26:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:26:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
      "\u001b[32m[10/21 06:26:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.960 | 34.037 | 15.508 | 8.119 | 22.943 | 13.232 |\n",
      "\u001b[32m[10/21 06:26:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.481 | cushion    | 45.590 | door       | 0.754 |\n",
      "| indoor-plant | 12.761 | sofa       | 35.176 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='M1WZ58Q2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:26:52 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:26:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:26:52 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:26:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:26:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.1145 s / img. ETA=0:00:59\n",
      "\u001b[32m[10/21 06:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1045 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 06:27:05 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1022 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 06:27:10 d2.evaluation.evaluator]: \u001b[0mInference done 135/355. 0.0982 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 179/355. 0.0983 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 213/355. 0.0970 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.0963 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 282/355. 0.0973 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 311/355. 0.0982 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 345/355. 0.0989 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.347371 (0.140992 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.099346 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/M1WZ58Q0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.503 | 36.295 | 12.130 | 8.644 | 19.364 | 14.425 |\n",
      "\u001b[32m[10/21 06:27:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.133 | cushion    | 35.206 | door       | 1.503 |\n",
      "| indoor-plant | 15.583 | sofa       | 30.478 | table      | 1.115 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:27:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:27:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "\u001b[32m[10/21 06:27:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:27:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      "\u001b[32m[10/21 06:27:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.701 | 33.404 | 15.977 | 7.438 | 22.538 | 15.861 |\n",
      "\u001b[32m[10/21 06:27:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.315 | cushion    | 43.765 | door       | 0.732 |\n",
      "| indoor-plant | 13.063 | sofa       | 36.330 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [36.14407383661193, 37.14929182634256, 36.29502821136515]}, 'segm': {'AP50': [33.44534598843153, 34.037348608039366, 33.404351616037154]}}\n",
      "dataset_name O1053RP\n",
      "SOLVER PARAMS (500, 100, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='O1053RP_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/O1053RP0\n",
      "output_aug/500/O1053RP0\n",
      "\u001b[32m[10/21 06:27:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:27:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:27:46 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:27:46 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:27:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:27:46 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:27:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:27:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:27:46 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:27:52 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 19  total_loss: 3.348  loss_cls: 1.791  loss_box_reg: 0.6295  loss_mask: 0.6908  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.03874  time: 0.3068  data_time: 0.0207  lr: 9.5405e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:27:58 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 39  total_loss: 2.385  loss_cls: 0.6827  loss_box_reg: 0.6979  loss_mask: 0.661  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.03924  time: 0.2885  data_time: 0.0038  lr: 0.0001953  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:03 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 59  total_loss: 1.868  loss_cls: 0.5064  loss_box_reg: 0.6286  loss_mask: 0.599  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.05133  time: 0.2894  data_time: 0.0036  lr: 0.0002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:09 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 79  total_loss: 1.56  loss_cls: 0.3479  loss_box_reg: 0.612  loss_mask: 0.5268  loss_rpn_cls: 0.026  loss_rpn_loc: 0.02281  time: 0.2860  data_time: 0.0037  lr: 0.0003951  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:15 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 99  total_loss: 1.422  loss_cls: 0.343  loss_box_reg: 0.6176  loss_mask: 0.3747  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.01756  time: 0.2868  data_time: 0.0037  lr: 0.000495  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:20 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 119  total_loss: 1.11  loss_cls: 0.2232  loss_box_reg: 0.5308  loss_mask: 0.259  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.02224  time: 0.2861  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:25 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 139  total_loss: 0.9822  loss_cls: 0.1872  loss_box_reg: 0.4901  loss_mask: 0.2803  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.02331  time: 0.2767  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:31 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 159  total_loss: 0.9622  loss_cls: 0.1264  loss_box_reg: 0.462  loss_mask: 0.1965  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.02381  time: 0.2781  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:37 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 179  total_loss: 0.7689  loss_cls: 0.1549  loss_box_reg: 0.3968  loss_mask: 0.2196  loss_rpn_cls: 0.008419  loss_rpn_loc: 0.02706  time: 0.2826  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:44 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 199  total_loss: 0.8497  loss_cls: 0.1653  loss_box_reg: 0.3604  loss_mask: 0.2425  loss_rpn_cls: 0.006903  loss_rpn_loc: 0.01926  time: 0.2870  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:50 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 219  total_loss: 0.7074  loss_cls: 0.1054  loss_box_reg: 0.3551  loss_mask: 0.1986  loss_rpn_cls: 0.004118  loss_rpn_loc: 0.01631  time: 0.2900  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:28:56 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 239  total_loss: 0.629  loss_cls: 0.09356  loss_box_reg: 0.3148  loss_mask: 0.1693  loss_rpn_cls: 0.006652  loss_rpn_loc: 0.02256  time: 0.2922  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:02 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 259  total_loss: 0.6429  loss_cls: 0.1077  loss_box_reg: 0.2685  loss_mask: 0.2023  loss_rpn_cls: 0.007982  loss_rpn_loc: 0.01743  time: 0.2912  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:08 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 279  total_loss: 0.6359  loss_cls: 0.0949  loss_box_reg: 0.2782  loss_mask: 0.2139  loss_rpn_cls: 0.002619  loss_rpn_loc: 0.02226  time: 0.2916  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:14 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 299  total_loss: 0.6484  loss_cls: 0.09799  loss_box_reg: 0.2623  loss_mask: 0.1894  loss_rpn_cls: 0.005776  loss_rpn_loc: 0.02092  time: 0.2910  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:19 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 319  total_loss: 0.676  loss_cls: 0.1053  loss_box_reg: 0.2893  loss_mask: 0.1838  loss_rpn_cls: 0.00493  loss_rpn_loc: 0.02055  time: 0.2907  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:25 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 339  total_loss: 0.6117  loss_cls: 0.0915  loss_box_reg: 0.2308  loss_mask: 0.1502  loss_rpn_cls: 0.003946  loss_rpn_loc: 0.032  time: 0.2915  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:30 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 359  total_loss: 0.5174  loss_cls: 0.08841  loss_box_reg: 0.242  loss_mask: 0.1429  loss_rpn_cls: 0.005785  loss_rpn_loc: 0.0249  time: 0.2892  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:35 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 379  total_loss: 0.5369  loss_cls: 0.07178  loss_box_reg: 0.2144  loss_mask: 0.1859  loss_rpn_cls: 0.003595  loss_rpn_loc: 0.01432  time: 0.2860  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:42 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 399  total_loss: 0.5175  loss_cls: 0.0763  loss_box_reg: 0.2276  loss_mask: 0.1642  loss_rpn_cls: 0.001697  loss_rpn_loc: 0.02043  time: 0.2892  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:49 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 419  total_loss: 0.4922  loss_cls: 0.08744  loss_box_reg: 0.1967  loss_mask: 0.1386  loss_rpn_cls: 0.003925  loss_rpn_loc: 0.02035  time: 0.2923  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:29:56 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 439  total_loss: 0.49  loss_cls: 0.07816  loss_box_reg: 0.2065  loss_mask: 0.1596  loss_rpn_cls: 0.002092  loss_rpn_loc: 0.01349  time: 0.2950  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:30:03 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 459  total_loss: 0.4959  loss_cls: 0.07794  loss_box_reg: 0.2157  loss_mask: 0.1753  loss_rpn_cls: 0.002248  loss_rpn_loc: 0.01421  time: 0.2973  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:30:10 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.4872  loss_cls: 0.0697  loss_box_reg: 0.181  loss_mask: 0.1492  loss_rpn_cls: 0.001684  loss_rpn_loc: 0.01346  time: 0.2991  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:30:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5552  loss_cls: 0.07954  loss_box_reg: 0.2157  loss_mask: 0.1833  loss_rpn_cls: 0.00685  loss_rpn_loc: 0.02704  time: 0.3010  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:30:18 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:29 (0.3010 s / it)\n",
      "\u001b[32m[10/21 06:30:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:31 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='O1053RP_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:30:18 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:30:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:30:18 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:30:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:30:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:30:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1077 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 47/126. 0.1172 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:30:29 d2.evaluation.evaluator]: \u001b[0mInference done 84/126. 0.1175 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 06:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 118/126. 0.1199 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.984059 (0.140364 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.119915 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O1053RP0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.553\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.493 | 38.361 | 16.489 | 11.371 | 31.918 | 24.307 |\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 30.891 | cushion    | 21.566 | door       | 9.635 |\n",
      "| indoor-plant | 16.523 | sofa       | 34.238 | table      | 4.107 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.290 | 29.610 | 8.645  | 6.659 | 20.653 | 13.982 |\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.914 | cushion    | 23.716 | door       | 8.774 |\n",
      "| indoor-plant | 8.293  | sofa       | 26.042 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='O1053RP0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:30:36 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:30:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:30:36 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:30:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:30:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 19/355. 0.1290 s / img. ETA=0:00:56\n",
      "\u001b[32m[10/21 06:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.1255 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 06:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 88/355. 0.1248 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 06:30:55 d2.evaluation.evaluator]: \u001b[0mInference done 124/355. 0.1239 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 06:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.1240 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 198/355. 0.1227 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:31:10 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.1229 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:31:15 d2.evaluation.evaluator]: \u001b[0mInference done 265/355. 0.1226 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:31:20 d2.evaluation.evaluator]: \u001b[0mInference done 296/355. 0.1228 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 328/355. 0.1228 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.655604 (0.150445 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.123656 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O1053RP0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.285 | 33.292 | 12.525 | 6.821 | 17.303 | 16.391 |\n",
      "\u001b[32m[10/21 06:31:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.589 | cushion    | 26.185 | door       | 1.780 |\n",
      "| indoor-plant | 25.775 | sofa       | 30.772 | table      | 0.609 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:31:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:31:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 06:31:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:31:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n",
      "\u001b[32m[10/21 06:31:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.225 | 32.335 | 14.925 | 8.197 | 18.115 | 16.250 |\n",
      "\u001b[32m[10/21 06:31:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.781  | cushion    | 37.059 | door       | 0.946 |\n",
      "| indoor-plant | 17.158 | sofa       | 32.404 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='O1053RP1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:31:31 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:31:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:31:32 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:31:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:31:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1390 s / img. ETA=0:01:05\n",
      "\u001b[32m[10/21 06:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 44/355. 0.1249 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 06:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 78/355. 0.1253 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 06:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 113/355. 0.1247 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 06:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 146/355. 0.1248 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 06:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 184/355. 0.1231 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 06:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 218/355. 0.1229 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 254/355. 0.1207 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 06:32:14 d2.evaluation.evaluator]: \u001b[0mInference done 289/355. 0.1181 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 324/355. 0.1169 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.212084 (0.146320 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.115720 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O1053RP0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.527 | 36.063 | 12.716 | 8.653 | 18.332 | 15.198 |\n",
      "\u001b[32m[10/21 06:32:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.816 | cushion    | 28.154 | door       | 1.733 |\n",
      "| indoor-plant | 24.347 | sofa       | 35.558 | table      | 0.552 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:32:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:32:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 06:32:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:32:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.244\n",
      "\u001b[32m[10/21 06:32:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.756 | 35.230 | 16.726 | 9.646 | 19.532 | 15.346 |\n",
      "\u001b[32m[10/21 06:32:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.815 | cushion    | 39.880 | door       | 1.251 |\n",
      "| indoor-plant | 16.433 | sofa       | 38.158 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='O1053RP2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:32:26 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:32:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:32:26 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:32:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:32:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1151 s / img. ETA=0:00:59\n",
      "\u001b[32m[10/21 06:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1101 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 06:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 85/355. 0.1082 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 06:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.1100 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 06:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 160/355. 0.1097 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 06:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 200/355. 0.1089 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 235/355. 0.1084 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 268/355. 0.1089 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 06:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 299/355. 0.1090 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 06:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.1092 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.167087 (0.143335 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.109642 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/O1053RP0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.378 | 34.149 | 11.848 | 8.411 | 16.481 | 16.918 |\n",
      "\u001b[32m[10/21 06:33:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.454 | cushion    | 26.378 | door       | 1.723 |\n",
      "| indoor-plant | 26.669 | sofa       | 30.316 | table      | 0.725 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:33:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:33:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 06:33:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:33:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.270\n",
      "\u001b[32m[10/21 06:33:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.444 | 33.057 | 15.653 | 9.695 | 17.682 | 16.887 |\n",
      "\u001b[32m[10/21 06:33:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.274 | cushion    | 37.289 | door       | 1.200 |\n",
      "| indoor-plant | 17.318 | sofa       | 32.582 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [33.29150872277106, 36.06347349387198, 34.148810261354136]}, 'segm': {'AP50': [32.33532237695634, 35.23042248041426, 33.05671927116072]}}\n",
      "dataset_name G6W44JT\n",
      "SOLVER PARAMS (800, 100, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='G6W44JT_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/G6W44JT0\n",
      "output_aug/800/G6W44JT0\n",
      "\u001b[32m[10/21 06:33:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:33:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:33:19 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:33:19 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:33:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:33:19 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:33:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:33:19 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:33:20 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:33:25 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 19  total_loss: 3.144  loss_cls: 1.8  loss_box_reg: 0.6187  loss_mask: 0.6894  loss_rpn_cls: 0.07716  loss_rpn_loc: 0.02348  time: 0.2785  data_time: 0.0170  lr: 9.5405e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:33:31 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 39  total_loss: 2.258  loss_cls: 0.7089  loss_box_reg: 0.7045  loss_mask: 0.6637  loss_rpn_cls: 0.08033  loss_rpn_loc: 0.02709  time: 0.2850  data_time: 0.0037  lr: 0.00019531  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:33:37 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 59  total_loss: 1.858  loss_cls: 0.5302  loss_box_reg: 0.614  loss_mask: 0.6038  loss_rpn_cls: 0.04227  loss_rpn_loc: 0.04657  time: 0.2914  data_time: 0.0038  lr: 0.0002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:33:43 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 79  total_loss: 1.518  loss_cls: 0.3354  loss_box_reg: 0.6157  loss_mask: 0.521  loss_rpn_cls: 0.03556  loss_rpn_loc: 0.03678  time: 0.2927  data_time: 0.0036  lr: 0.00039511  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:33:49 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 99  total_loss: 1.222  loss_cls: 0.2346  loss_box_reg: 0.5693  loss_mask: 0.4062  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.02971  time: 0.2956  data_time: 0.0037  lr: 0.000495  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:33:55 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 119  total_loss: 1.121  loss_cls: 0.2021  loss_box_reg: 0.5057  loss_mask: 0.2684  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.01237  time: 0.2958  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:01 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 139  total_loss: 1.148  loss_cls: 0.2147  loss_box_reg: 0.4853  loss_mask: 0.3225  loss_rpn_cls: 0.01872  loss_rpn_loc: 0.02479  time: 0.2933  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:06 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 159  total_loss: 0.9699  loss_cls: 0.2193  loss_box_reg: 0.4416  loss_mask: 0.2683  loss_rpn_cls: 0.00971  loss_rpn_loc: 0.02663  time: 0.2924  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:13 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 179  total_loss: 0.839  loss_cls: 0.1526  loss_box_reg: 0.4324  loss_mask: 0.1843  loss_rpn_cls: 0.006518  loss_rpn_loc: 0.02679  time: 0.2933  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:19 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 199  total_loss: 0.9274  loss_cls: 0.1686  loss_box_reg: 0.4097  loss_mask: 0.2149  loss_rpn_cls: 0.008897  loss_rpn_loc: 0.02248  time: 0.2942  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:23 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 219  total_loss: 0.715  loss_cls: 0.1325  loss_box_reg: 0.3112  loss_mask: 0.1914  loss_rpn_cls: 0.007364  loss_rpn_loc: 0.01973  time: 0.2886  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:29 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 239  total_loss: 0.6445  loss_cls: 0.1089  loss_box_reg: 0.302  loss_mask: 0.1911  loss_rpn_cls: 0.002132  loss_rpn_loc: 0.01754  time: 0.2884  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:35 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 259  total_loss: 0.6461  loss_cls: 0.1271  loss_box_reg: 0.3084  loss_mask: 0.1916  loss_rpn_cls: 0.008716  loss_rpn_loc: 0.01633  time: 0.2899  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:41 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 279  total_loss: 0.564  loss_cls: 0.09277  loss_box_reg: 0.2702  loss_mask: 0.1504  loss_rpn_cls: 0.004393  loss_rpn_loc: 0.0185  time: 0.2917  data_time: 0.0048  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:48 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 299  total_loss: 0.6393  loss_cls: 0.1061  loss_box_reg: 0.2787  loss_mask: 0.1687  loss_rpn_cls: 0.003486  loss_rpn_loc: 0.01847  time: 0.2930  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:34:54 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 319  total_loss: 0.5381  loss_cls: 0.0712  loss_box_reg: 0.22  loss_mask: 0.1241  loss_rpn_cls: 0.002855  loss_rpn_loc: 0.01358  time: 0.2947  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:00 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 339  total_loss: 0.5748  loss_cls: 0.09421  loss_box_reg: 0.225  loss_mask: 0.1459  loss_rpn_cls: 0.00493  loss_rpn_loc: 0.01713  time: 0.2940  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:06 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 359  total_loss: 0.6615  loss_cls: 0.1049  loss_box_reg: 0.2911  loss_mask: 0.1814  loss_rpn_cls: 0.004671  loss_rpn_loc: 0.02915  time: 0.2946  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:12 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 379  total_loss: 0.5592  loss_cls: 0.07386  loss_box_reg: 0.2348  loss_mask: 0.1832  loss_rpn_cls: 0.003213  loss_rpn_loc: 0.01408  time: 0.2954  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:18 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 399  total_loss: 0.5522  loss_cls: 0.07771  loss_box_reg: 0.2119  loss_mask: 0.1646  loss_rpn_cls: 0.002866  loss_rpn_loc: 0.01378  time: 0.2959  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:24 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 419  total_loss: 0.4774  loss_cls: 0.06583  loss_box_reg: 0.2125  loss_mask: 0.1522  loss_rpn_cls: 0.002928  loss_rpn_loc: 0.01092  time: 0.2950  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:28 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 439  total_loss: 0.5246  loss_cls: 0.08106  loss_box_reg: 0.2033  loss_mask: 0.1796  loss_rpn_cls: 0.00382  loss_rpn_loc: 0.01327  time: 0.2915  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:35 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 459  total_loss: 0.4709  loss_cls: 0.07418  loss_box_reg: 0.2282  loss_mask: 0.1687  loss_rpn_cls: 0.005021  loss_rpn_loc: 0.01797  time: 0.2936  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:42 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 479  total_loss: 0.5037  loss_cls: 0.06914  loss_box_reg: 0.2153  loss_mask: 0.137  loss_rpn_cls: 0.0033  loss_rpn_loc: 0.01851  time: 0.2957  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:49 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 499  total_loss: 0.5113  loss_cls: 0.08544  loss_box_reg: 0.2234  loss_mask: 0.1561  loss_rpn_cls: 0.001976  loss_rpn_loc: 0.01319  time: 0.2980  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:35:56 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 519  total_loss: 0.5027  loss_cls: 0.09104  loss_box_reg: 0.2115  loss_mask: 0.1668  loss_rpn_cls: 0.003205  loss_rpn_loc: 0.01694  time: 0.2999  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:03 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 539  total_loss: 0.409  loss_cls: 0.0721  loss_box_reg: 0.1892  loss_mask: 0.147  loss_rpn_cls: 0.005585  loss_rpn_loc: 0.01173  time: 0.3018  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:10 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 559  total_loss: 0.5521  loss_cls: 0.08024  loss_box_reg: 0.2002  loss_mask: 0.1466  loss_rpn_cls: 0.004878  loss_rpn_loc: 0.03648  time: 0.3035  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:17 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 579  total_loss: 0.4687  loss_cls: 0.06236  loss_box_reg: 0.1709  loss_mask: 0.1355  loss_rpn_cls: 0.003928  loss_rpn_loc: 0.0242  time: 0.3052  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:24 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 599  total_loss: 0.4141  loss_cls: 0.07615  loss_box_reg: 0.167  loss_mask: 0.1207  loss_rpn_cls: 0.003133  loss_rpn_loc: 0.01121  time: 0.3067  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:31 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 619  total_loss: 0.4739  loss_cls: 0.05852  loss_box_reg: 0.2053  loss_mask: 0.1574  loss_rpn_cls: 0.001873  loss_rpn_loc: 0.01018  time: 0.3080  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:38 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 639  total_loss: 0.4025  loss_cls: 0.06254  loss_box_reg: 0.2044  loss_mask: 0.1267  loss_rpn_cls: 0.002861  loss_rpn_loc: 0.01024  time: 0.3094  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:45 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 659  total_loss: 0.3424  loss_cls: 0.05305  loss_box_reg: 0.1284  loss_mask: 0.1196  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.02821  time: 0.3107  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:52 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 679  total_loss: 0.4321  loss_cls: 0.05931  loss_box_reg: 0.1717  loss_mask: 0.1354  loss_rpn_cls: 0.005307  loss_rpn_loc: 0.01256  time: 0.3120  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:36:59 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 699  total_loss: 0.3467  loss_cls: 0.05681  loss_box_reg: 0.148  loss_mask: 0.1006  loss_rpn_cls: 0.002219  loss_rpn_loc: 0.008609  time: 0.3134  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:37:06 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 719  total_loss: 0.4159  loss_cls: 0.05585  loss_box_reg: 0.1769  loss_mask: 0.1297  loss_rpn_cls: 0.001009  loss_rpn_loc: 0.01159  time: 0.3142  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:37:13 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 739  total_loss: 0.423  loss_cls: 0.06142  loss_box_reg: 0.1778  loss_mask: 0.1497  loss_rpn_cls: 0.001739  loss_rpn_loc: 0.01221  time: 0.3151  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:37:20 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 759  total_loss: 0.3494  loss_cls: 0.058  loss_box_reg: 0.1464  loss_mask: 0.1127  loss_rpn_cls: 0.001325  loss_rpn_loc: 0.01191  time: 0.3160  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:37:27 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.3959  loss_cls: 0.06314  loss_box_reg: 0.1794  loss_mask: 0.1251  loss_rpn_cls: 0.0009644  loss_rpn_loc: 0.008502  time: 0.3168  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:37:35 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4011  loss_cls: 0.05975  loss_box_reg: 0.1579  loss_mask: 0.1239  loss_rpn_cls: 0.002572  loss_rpn_loc: 0.01477  time: 0.3175  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:37:35 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:13 (0.3175 s / it)\n",
      "\u001b[32m[10/21 06:37:35 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:14 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='G6W44JT_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:37:35 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:37:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:37:35 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:37:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:37:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:37:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1201 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 06:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 49/126. 0.1190 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 87/126. 0.1185 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 125/126. 0.1186 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.158509 (0.133541 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.118875 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/G6W44JT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.367 | 38.437 | 21.952 | 11.806 | 35.708 | 23.790 |\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 30.128 | cushion    | 19.564 | door       | 11.293 |\n",
      "| indoor-plant | 18.665 | sofa       | 42.951 | table      | 5.602  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.994 | 29.617 | 8.259  | 6.167 | 20.381 | 15.386 |\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.287 | cushion    | 20.902 | door       | 9.075 |\n",
      "| indoor-plant | 8.903  | sofa       | 27.754 | table      | 0.042 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='G6W44JT0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:37:52 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:37:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:37:52 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:37:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:37:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 28/355. 0.1225 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 06:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 62/355. 0.1242 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 06:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 99/355. 0.1234 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 06:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.1219 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 06:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.1218 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 06:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.1211 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 06:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.1220 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 06:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 279/355. 0.1221 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 311/355. 0.1225 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.1226 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.584746 (0.144528 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.122785 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/G6W44JT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.239 | 36.637 | 16.865 | 10.884 | 21.299 | 15.889 |\n",
      "\u001b[32m[10/21 06:38:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.173 | cushion    | 29.118 | door       | 1.035 |\n",
      "| indoor-plant | 27.406 | sofa       | 42.702 | table      | 1.002 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:38:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:38:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 06:38:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:38:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
      "\u001b[32m[10/21 06:38:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.161 | 34.038 | 19.645 | 10.034 | 22.562 | 14.254 |\n",
      "\u001b[32m[10/21 06:38:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.794  | cushion    | 41.816 | door       | 0.555 |\n",
      "| indoor-plant | 20.908 | sofa       | 41.891 | table      | 0.002 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='G6W44JT1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:38:45 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:38:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:38:45 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:38:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:38:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 14/355. 0.1243 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 06:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.1252 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 06:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.1237 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 06:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 126/355. 0.1218 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 06:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 165/355. 0.1207 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 06:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 205/355. 0.1197 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 239/355. 0.1200 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 06:39:23 d2.evaluation.evaluator]: \u001b[0mInference done 275/355. 0.1204 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:39:28 d2.evaluation.evaluator]: \u001b[0mInference done 309/355. 0.1207 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:39:33 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.1206 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.501720 (0.138576 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.120666 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/G6W44JT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.375\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.479 | 37.501 | 16.881 | 7.651 | 22.100 | 15.028 |\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.271 | cushion    | 31.070 | door       | 1.425 |\n",
      "| indoor-plant | 26.250 | sofa       | 40.861 | table      | 0.995 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:39:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:39:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 06:39:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:39:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.347\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      "\u001b[32m[10/21 06:39:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.629 | 34.674 | 21.356 | 8.880 | 23.810 | 14.013 |\n",
      "\u001b[32m[10/21 06:39:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.015 | cushion    | 43.619 | door       | 1.056 |\n",
      "| indoor-plant | 20.532 | sofa       | 41.553 | table      | 0.002 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='G6W44JT2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:39:36 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:39:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:39:36 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:39:36 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:39:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:39:38 d2.evaluation.evaluator]: \u001b[0mInference done 14/355. 0.1234 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 06:39:43 d2.evaluation.evaluator]: \u001b[0mInference done 54/355. 0.1074 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 06:39:48 d2.evaluation.evaluator]: \u001b[0mInference done 98/355. 0.1049 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 06:39:53 d2.evaluation.evaluator]: \u001b[0mInference done 142/355. 0.1038 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 06:39:58 d2.evaluation.evaluator]: \u001b[0mInference done 183/355. 0.1056 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:40:04 d2.evaluation.evaluator]: \u001b[0mInference done 221/355. 0.1055 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:40:09 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.1057 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 296/355. 0.1059 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 06:40:19 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.1067 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:40:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.616990 (0.127477 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:40:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.106450 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/G6W44JT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.104 | 36.353 | 17.095 | 7.237 | 20.754 | 17.154 |\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.539 | cushion    | 29.004 | door       | 1.332 |\n",
      "| indoor-plant | 27.769 | sofa       | 41.791 | table      | 1.192 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.345\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.244\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.276 | 34.538 | 20.285 | 8.425 | 22.885 | 14.623 |\n",
      "\u001b[32m[10/21 06:40:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.019 | cushion    | 40.570 | door       | 1.069 |\n",
      "| indoor-plant | 21.904 | sofa       | 42.090 | table      | 0.002 |\n",
      "all results {'bbox': {'AP50': [36.637145993143086, 37.50098113975992, 36.35281520031398]}, 'segm': {'AP50': [34.03804339332434, 34.67441409691238, 34.537841855273385]}}\n",
      "dataset_name W2Z3SL7\n",
      "SOLVER PARAMS (500, 200, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='W2Z3SL7_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/W2Z3SL70\n",
      "output_aug/500/W2Z3SL70\n",
      "\u001b[32m[10/21 06:40:23 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:40:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:40:24 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:40:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:40:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:40:24 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:40:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:40:24 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:40:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:40:30 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 19  total_loss: 3.027  loss_cls: 1.555  loss_box_reg: 0.6079  loss_mask: 0.691  loss_rpn_cls: 0.09  loss_rpn_loc: 0.03235  time: 0.3058  data_time: 0.0162  lr: 4.7952e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:40:36 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 39  total_loss: 2.131  loss_cls: 0.7456  loss_box_reg: 0.651  loss_mask: 0.6759  loss_rpn_cls: 0.05187  loss_rpn_loc: 0.02227  time: 0.3048  data_time: 0.0036  lr: 9.7902e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:40:42 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 59  total_loss: 1.895  loss_cls: 0.562  loss_box_reg: 0.6546  loss_mask: 0.6258  loss_rpn_cls: 0.03028  loss_rpn_loc: 0.03377  time: 0.3063  data_time: 0.0037  lr: 0.00014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:40:48 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 79  total_loss: 1.847  loss_cls: 0.5162  loss_box_reg: 0.6564  loss_mask: 0.6148  loss_rpn_cls: 0.03085  loss_rpn_loc: 0.0397  time: 0.2947  data_time: 0.0036  lr: 0.0001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:40:54 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 99  total_loss: 1.741  loss_cls: 0.4311  loss_box_reg: 0.6443  loss_mask: 0.5423  loss_rpn_cls: 0.02517  loss_rpn_loc: 0.03107  time: 0.2960  data_time: 0.0037  lr: 0.00024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:00 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 119  total_loss: 1.625  loss_cls: 0.3873  loss_box_reg: 0.6541  loss_mask: 0.4416  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.02582  time: 0.2983  data_time: 0.0035  lr: 0.0002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:06 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 139  total_loss: 1.155  loss_cls: 0.2544  loss_box_reg: 0.6141  loss_mask: 0.3651  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.02185  time: 0.3014  data_time: 0.0037  lr: 0.00034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:13 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 159  total_loss: 1.138  loss_cls: 0.2227  loss_box_reg: 0.556  loss_mask: 0.2542  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.03179  time: 0.3042  data_time: 0.0036  lr: 0.0003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:19 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 179  total_loss: 1.143  loss_cls: 0.2215  loss_box_reg: 0.5775  loss_mask: 0.2609  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.01767  time: 0.3062  data_time: 0.0036  lr: 0.00044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:25 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 199  total_loss: 0.9749  loss_cls: 0.1788  loss_box_reg: 0.4262  loss_mask: 0.2685  loss_rpn_cls: 0.007417  loss_rpn_loc: 0.02958  time: 0.3067  data_time: 0.0037  lr: 0.0004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:32 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 219  total_loss: 0.7739  loss_cls: 0.1214  loss_box_reg: 0.3615  loss_mask: 0.2055  loss_rpn_cls: 0.004062  loss_rpn_loc: 0.01674  time: 0.3069  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:38 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 239  total_loss: 0.916  loss_cls: 0.1714  loss_box_reg: 0.4203  loss_mask: 0.2316  loss_rpn_cls: 0.007536  loss_rpn_loc: 0.03152  time: 0.3083  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:43 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 259  total_loss: 0.8379  loss_cls: 0.1384  loss_box_reg: 0.3545  loss_mask: 0.1991  loss_rpn_cls: 0.007535  loss_rpn_loc: 0.02067  time: 0.3043  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:50 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 279  total_loss: 0.7183  loss_cls: 0.1181  loss_box_reg: 0.3074  loss_mask: 0.1429  loss_rpn_cls: 0.0062  loss_rpn_loc: 0.02131  time: 0.3049  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:41:56 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 299  total_loss: 0.6366  loss_cls: 0.1076  loss_box_reg: 0.2834  loss_mask: 0.1906  loss_rpn_cls: 0.008098  loss_rpn_loc: 0.01931  time: 0.3062  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:02 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 319  total_loss: 0.6474  loss_cls: 0.0837  loss_box_reg: 0.2871  loss_mask: 0.1627  loss_rpn_cls: 0.005557  loss_rpn_loc: 0.01683  time: 0.3070  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:09 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 339  total_loss: 0.6272  loss_cls: 0.1031  loss_box_reg: 0.269  loss_mask: 0.1732  loss_rpn_cls: 0.002438  loss_rpn_loc: 0.01876  time: 0.3085  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:15 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 359  total_loss: 0.6106  loss_cls: 0.09154  loss_box_reg: 0.2336  loss_mask: 0.1749  loss_rpn_cls: 0.009164  loss_rpn_loc: 0.02355  time: 0.3081  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:21 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 379  total_loss: 0.672  loss_cls: 0.09967  loss_box_reg: 0.2574  loss_mask: 0.1913  loss_rpn_cls: 0.008589  loss_rpn_loc: 0.02374  time: 0.3083  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:27 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 399  total_loss: 0.5411  loss_cls: 0.0819  loss_box_reg: 0.2471  loss_mask: 0.1691  loss_rpn_cls: 0.003421  loss_rpn_loc: 0.02279  time: 0.3080  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:34 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 419  total_loss: 0.584  loss_cls: 0.08684  loss_box_reg: 0.2515  loss_mask: 0.1717  loss_rpn_cls: 0.001841  loss_rpn_loc: 0.02275  time: 0.3084  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:38 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 439  total_loss: 0.5047  loss_cls: 0.086  loss_box_reg: 0.2338  loss_mask: 0.166  loss_rpn_cls: 0.001461  loss_rpn_loc: 0.01738  time: 0.3045  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:45 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 459  total_loss: 0.4871  loss_cls: 0.08451  loss_box_reg: 0.1869  loss_mask: 0.1407  loss_rpn_cls: 0.002364  loss_rpn_loc: 0.01667  time: 0.3066  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:42:53 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.5431  loss_cls: 0.07272  loss_box_reg: 0.1988  loss_mask: 0.1537  loss_rpn_cls: 0.004986  loss_rpn_loc: 0.02296  time: 0.3093  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:43:01 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.541  loss_cls: 0.07654  loss_box_reg: 0.2376  loss_mask: 0.1684  loss_rpn_cls: 0.002575  loss_rpn_loc: 0.02664  time: 0.3123  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:43:01 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:35 (0.3123 s / it)\n",
      "\u001b[32m[10/21 06:43:01 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:36 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='W2Z3SL7_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:43:01 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:43:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:43:01 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:43:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:43:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1129 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 45/126. 0.1235 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 82/126. 0.1217 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 114/126. 0.1246 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.823252 (0.147300 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:15 (0.124165 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W2Z3SL70/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.386 | 36.917 | 22.283 | 12.599 | 36.110 | 19.370 |\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 34.628 | cushion    | 25.051 | door       | 7.844 |\n",
      "| indoor-plant | 20.850 | sofa       | 30.492 | table      | 3.453 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.880 | 28.473 | 8.472  | 6.892 | 17.940 | 11.140 |\n",
      "\u001b[32m[10/21 06:43:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.511 | cushion    | 24.288 | door       | 5.836 |\n",
      "| indoor-plant | 6.358  | sofa       | 20.284 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='W2Z3SL70_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:43:21 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:43:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:43:21 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:43:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:43:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 16/355. 0.1214 s / img. ETA=0:00:53\n",
      "\u001b[32m[10/21 06:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1202 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 06:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 85/355. 0.1219 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 06:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 122/355. 0.1225 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 06:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 158/355. 0.1231 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 198/355. 0.1221 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.1231 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 261/355. 0.1236 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1234 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 324/355. 0.1236 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 355/355. 0.1240 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.895997 (0.151131 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.123977 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W2Z3SL70/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.767 | 37.835 | 11.474 | 9.813 | 22.062 | 13.670 |\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 19.179 | cushion    | 33.914 | door       | 0.675 |\n",
      "| indoor-plant | 25.732 | sofa       | 32.531 | table      | 0.571 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:44:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:44:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 06:44:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:44:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      "\u001b[32m[10/21 06:44:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.430 | 35.412 | 16.586 | 10.004 | 22.102 | 14.147 |\n",
      "\u001b[32m[10/21 06:44:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.464 | cushion    | 46.015 | door       | 0.383 |\n",
      "| indoor-plant | 19.188 | sofa       | 34.533 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='W2Z3SL71_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:44:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:44:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:44:16 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:44:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:44:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.1204 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 06:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 56/355. 0.1214 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 06:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 94/355. 0.1196 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 06:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1191 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 06:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 170/355. 0.1182 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 06:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 207/355. 0.1186 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:44:50 d2.evaluation.evaluator]: \u001b[0mInference done 236/355. 0.1201 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:44:55 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.1200 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 06:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 301/355. 0.1205 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 06:45:05 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.1203 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.679923 (0.147657 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121079 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W2Z3SL70/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.811 | 38.948 | 12.824 | 9.763 | 23.310 | 12.873 |\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.783 | cushion    | 37.381 | door       | 0.651 |\n",
      "| indoor-plant | 25.195 | sofa       | 33.430 | table      | 0.427 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:45:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:45:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 06:45:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:45:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      "\u001b[32m[10/21 06:45:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.215 | 36.595 | 16.258 | 9.506 | 23.446 | 12.592 |\n",
      "\u001b[32m[10/21 06:45:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.130 | cushion    | 48.818 | door       | 0.531 |\n",
      "| indoor-plant | 19.029 | sofa       | 34.781 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='W2Z3SL72_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:45:10 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:45:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:45:10 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:45:10 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:45:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1229 s / img. ETA=0:00:55\n",
      "\u001b[32m[10/21 06:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1205 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 06:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.1210 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 06:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 118/355. 0.1210 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 06:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.1188 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 06:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 197/355. 0.1184 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 06:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 229/355. 0.1190 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 06:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 262/355. 0.1198 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1202 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 327/355. 0.1205 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.988571 (0.145682 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.120882 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W2Z3SL70/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:46:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.820 | 37.334 | 11.745 | 9.440 | 21.383 | 14.705 |\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 19.113 | cushion    | 34.280 | door       | 0.620 |\n",
      "| indoor-plant | 26.721 | sofa       | 31.678 | table      | 0.509 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.352\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.235 | 35.159 | 15.884 | 8.950 | 21.711 | 14.273 |\n",
      "\u001b[32m[10/21 06:46:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.269 | cushion    | 44.704 | door       | 0.483 |\n",
      "| indoor-plant | 19.461 | sofa       | 33.491 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [37.83470192282685, 38.94822348022576, 37.334464257571305]}, 'segm': {'AP50': [35.41203354068211, 36.59539311042466, 35.15927973035297]}}\n",
      "dataset_name 0KKK7CL\n",
      "SOLVER PARAMS (800, 200, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='0KKK7CL_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/0KKK7CL0\n",
      "output_aug/800/0KKK7CL0\n",
      "\u001b[32m[10/21 06:46:04 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:46:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:46:04 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:46:04 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:46:04 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:46:04 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:46:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:46:04 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:46:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:46:12 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 19  total_loss: 3.253  loss_cls: 1.827  loss_box_reg: 0.6192  loss_mask: 0.6934  loss_rpn_cls: 0.1768  loss_rpn_loc: 0.0403  time: 0.3441  data_time: 0.0158  lr: 4.7953e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:46:19 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 39  total_loss: 2.349  loss_cls: 0.833  loss_box_reg: 0.592  loss_mask: 0.6789  loss_rpn_cls: 0.06288  loss_rpn_loc: 0.04307  time: 0.3449  data_time: 0.0039  lr: 9.7903e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:46:26 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 59  total_loss: 1.965  loss_cls: 0.5785  loss_box_reg: 0.606  loss_mask: 0.6315  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.04151  time: 0.3440  data_time: 0.0037  lr: 0.00014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:46:33 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 79  total_loss: 1.726  loss_cls: 0.4753  loss_box_reg: 0.6463  loss_mask: 0.5854  loss_rpn_cls: 0.02723  loss_rpn_loc: 0.03545  time: 0.3435  data_time: 0.0036  lr: 0.0001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:46:40 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 99  total_loss: 1.738  loss_cls: 0.4866  loss_box_reg: 0.5848  loss_mask: 0.5263  loss_rpn_cls: 0.0246  loss_rpn_loc: 0.02622  time: 0.3448  data_time: 0.0035  lr: 0.00024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:46:46 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 119  total_loss: 1.482  loss_cls: 0.3787  loss_box_reg: 0.6469  loss_mask: 0.4624  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.02844  time: 0.3369  data_time: 0.0036  lr: 0.0002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:46:52 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 139  total_loss: 1.36  loss_cls: 0.2843  loss_box_reg: 0.5862  loss_mask: 0.3621  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.02938  time: 0.3345  data_time: 0.0036  lr: 0.00034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:46:58 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 159  total_loss: 1.224  loss_cls: 0.2257  loss_box_reg: 0.5694  loss_mask: 0.3281  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.02877  time: 0.3319  data_time: 0.0037  lr: 0.0003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:04 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 179  total_loss: 0.947  loss_cls: 0.182  loss_box_reg: 0.4637  loss_mask: 0.3051  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.02246  time: 0.3271  data_time: 0.0038  lr: 0.00044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:10 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 199  total_loss: 0.9534  loss_cls: 0.1564  loss_box_reg: 0.3975  loss_mask: 0.238  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.02338  time: 0.3254  data_time: 0.0036  lr: 0.0004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:17 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 219  total_loss: 0.9664  loss_cls: 0.1344  loss_box_reg: 0.474  loss_mask: 0.2202  loss_rpn_cls: 0.006449  loss_rpn_loc: 0.01806  time: 0.3253  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:23 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 239  total_loss: 0.922  loss_cls: 0.1466  loss_box_reg: 0.3583  loss_mask: 0.2071  loss_rpn_cls: 0.009255  loss_rpn_loc: 0.02423  time: 0.3243  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:30 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 259  total_loss: 0.7426  loss_cls: 0.129  loss_box_reg: 0.3619  loss_mask: 0.1761  loss_rpn_cls: 0.005902  loss_rpn_loc: 0.02896  time: 0.3245  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:36 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 279  total_loss: 0.8189  loss_cls: 0.1216  loss_box_reg: 0.3603  loss_mask: 0.2312  loss_rpn_cls: 0.005157  loss_rpn_loc: 0.02669  time: 0.3232  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:42 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 299  total_loss: 0.7222  loss_cls: 0.1405  loss_box_reg: 0.3212  loss_mask: 0.2259  loss_rpn_cls: 0.005509  loss_rpn_loc: 0.02397  time: 0.3221  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:48 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 319  total_loss: 0.6693  loss_cls: 0.1053  loss_box_reg: 0.2952  loss_mask: 0.1789  loss_rpn_cls: 0.003851  loss_rpn_loc: 0.0187  time: 0.3215  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:53 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 339  total_loss: 0.5018  loss_cls: 0.08473  loss_box_reg: 0.2399  loss_mask: 0.1274  loss_rpn_cls: 0.006381  loss_rpn_loc: 0.0111  time: 0.3174  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:47:59 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 359  total_loss: 0.575  loss_cls: 0.09781  loss_box_reg: 0.2062  loss_mask: 0.143  loss_rpn_cls: 0.01905  loss_rpn_loc: 0.01964  time: 0.3164  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:06 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 379  total_loss: 0.5865  loss_cls: 0.0805  loss_box_reg: 0.2194  loss_mask: 0.1575  loss_rpn_cls: 0.00479  loss_rpn_loc: 0.02703  time: 0.3166  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:12 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 399  total_loss: 0.6164  loss_cls: 0.09653  loss_box_reg: 0.26  loss_mask: 0.1768  loss_rpn_cls: 0.007006  loss_rpn_loc: 0.02608  time: 0.3168  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:18 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 419  total_loss: 0.5441  loss_cls: 0.08097  loss_box_reg: 0.2052  loss_mask: 0.1591  loss_rpn_cls: 0.008885  loss_rpn_loc: 0.01999  time: 0.3168  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:25 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 439  total_loss: 0.5561  loss_cls: 0.08343  loss_box_reg: 0.2611  loss_mask: 0.1368  loss_rpn_cls: 0.002482  loss_rpn_loc: 0.01092  time: 0.3170  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:31 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 459  total_loss: 0.5119  loss_cls: 0.0811  loss_box_reg: 0.2311  loss_mask: 0.1439  loss_rpn_cls: 0.00442  loss_rpn_loc: 0.02307  time: 0.3168  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:37 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 479  total_loss: 0.5664  loss_cls: 0.08921  loss_box_reg: 0.2437  loss_mask: 0.1885  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.0236  time: 0.3165  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:44 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 499  total_loss: 0.5036  loss_cls: 0.06074  loss_box_reg: 0.2041  loss_mask: 0.1404  loss_rpn_cls: 0.006337  loss_rpn_loc: 0.01775  time: 0.3169  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:49 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 519  total_loss: 0.4449  loss_cls: 0.06812  loss_box_reg: 0.2031  loss_mask: 0.1455  loss_rpn_cls: 0.004352  loss_rpn_loc: 0.01566  time: 0.3149  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:48:55 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 539  total_loss: 0.5398  loss_cls: 0.07785  loss_box_reg: 0.2234  loss_mask: 0.1465  loss_rpn_cls: 0.005211  loss_rpn_loc: 0.02092  time: 0.3145  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:01 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 559  total_loss: 0.507  loss_cls: 0.07515  loss_box_reg: 0.2264  loss_mask: 0.1416  loss_rpn_cls: 0.008465  loss_rpn_loc: 0.01722  time: 0.3143  data_time: 0.0034  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:08 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 579  total_loss: 0.4923  loss_cls: 0.07399  loss_box_reg: 0.2073  loss_mask: 0.1454  loss_rpn_cls: 0.005166  loss_rpn_loc: 0.01346  time: 0.3141  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:14 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 599  total_loss: 0.4536  loss_cls: 0.07271  loss_box_reg: 0.1959  loss_mask: 0.1662  loss_rpn_cls: 0.002186  loss_rpn_loc: 0.008203  time: 0.3143  data_time: 0.0034  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:20 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 619  total_loss: 0.4591  loss_cls: 0.06092  loss_box_reg: 0.1984  loss_mask: 0.1296  loss_rpn_cls: 0.002996  loss_rpn_loc: 0.01213  time: 0.3139  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:26 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 639  total_loss: 0.524  loss_cls: 0.072  loss_box_reg: 0.219  loss_mask: 0.17  loss_rpn_cls: 0.002313  loss_rpn_loc: 0.01312  time: 0.3133  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:32 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 659  total_loss: 0.4815  loss_cls: 0.06374  loss_box_reg: 0.1938  loss_mask: 0.1309  loss_rpn_cls: 0.002604  loss_rpn_loc: 0.01952  time: 0.3129  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:38 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 679  total_loss: 0.4275  loss_cls: 0.057  loss_box_reg: 0.175  loss_mask: 0.1406  loss_rpn_cls: 0.00276  loss_rpn_loc: 0.01767  time: 0.3126  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:43 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 699  total_loss: 0.4677  loss_cls: 0.0583  loss_box_reg: 0.1547  loss_mask: 0.1683  loss_rpn_cls: 0.002263  loss_rpn_loc: 0.01451  time: 0.3114  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:48 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 719  total_loss: 0.425  loss_cls: 0.05055  loss_box_reg: 0.1715  loss_mask: 0.1125  loss_rpn_cls: 0.004006  loss_rpn_loc: 0.0125  time: 0.3094  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:49:55 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 739  total_loss: 0.4123  loss_cls: 0.06724  loss_box_reg: 0.1789  loss_mask: 0.1224  loss_rpn_cls: 0.0007312  loss_rpn_loc: 0.01204  time: 0.3104  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:50:02 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 759  total_loss: 0.4423  loss_cls: 0.06547  loss_box_reg: 0.1911  loss_mask: 0.1507  loss_rpn_cls: 0.00139  loss_rpn_loc: 0.01799  time: 0.3116  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:50:09 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.3807  loss_cls: 0.06278  loss_box_reg: 0.192  loss_mask: 0.1132  loss_rpn_cls: 0.00089  loss_rpn_loc: 0.008887  time: 0.3126  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:50:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4112  loss_cls: 0.06194  loss_box_reg: 0.1565  loss_mask: 0.09153  loss_rpn_cls: 0.002187  loss_rpn_loc: 0.01902  time: 0.3135  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:50:17 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:10 (0.3135 s / it)\n",
      "\u001b[32m[10/21 06:50:17 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:11 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='0KKK7CL_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:50:17 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:50:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:50:17 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:50:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:50:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1097 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 49/126. 0.1166 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 87/126. 0.1162 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 126/126. 0.1164 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.877114 (0.131216 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.116356 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0KKK7CL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.879 | 38.139 | 21.906 | 11.798 | 35.667 | 22.324 |\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 33.694 | cushion    | 22.814 | door       | 9.893 |\n",
      "| indoor-plant | 18.756 | sofa       | 41.112 | table      | 5.006 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.845 | 28.900 | 9.872  | 6.106 | 19.031 | 14.314 |\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.075 | cushion    | 24.914 | door       | 8.212 |\n",
      "| indoor-plant | 4.558  | sofa       | 25.310 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='0KKK7CL0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:50:34 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:50:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:50:34 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:50:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:50:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 29/355. 0.1249 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 06:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 64/355. 0.1253 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 06:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 103/355. 0.1213 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 06:50:54 d2.evaluation.evaluator]: \u001b[0mInference done 143/355. 0.1192 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:50:59 d2.evaluation.evaluator]: \u001b[0mInference done 184/355. 0.1181 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:51:04 d2.evaluation.evaluator]: \u001b[0mInference done 220/355. 0.1184 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:51:09 d2.evaluation.evaluator]: \u001b[0mInference done 255/355. 0.1188 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:51:14 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.1197 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:51:19 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.1204 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.747060 (0.139277 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.120444 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0KKK7CL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.380\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.844 | 37.982 | 13.050 | 6.767 | 20.975 | 15.091 |\n",
      "\u001b[32m[10/21 06:51:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.113 | cushion    | 28.045 | door       | 1.022 |\n",
      "| indoor-plant | 25.484 | sofa       | 36.921 | table      | 0.481 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:51:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:51:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 06:51:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:51:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "\u001b[32m[10/21 06:51:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.514 | 36.254 | 18.818 | 8.438 | 20.842 | 15.315 |\n",
      "\u001b[32m[10/21 06:51:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.099 | cushion    | 43.047 | door       | 0.867 |\n",
      "| indoor-plant | 18.149 | sofa       | 36.922 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='0KKK7CL1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:51:25 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:51:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:51:25 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:51:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:51:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1193 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 06:51:32 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1253 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 06:51:37 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.1222 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 06:51:42 d2.evaluation.evaluator]: \u001b[0mInference done 123/355. 0.1201 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 06:51:47 d2.evaluation.evaluator]: \u001b[0mInference done 162/355. 0.1195 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 06:51:52 d2.evaluation.evaluator]: \u001b[0mInference done 201/355. 0.1190 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 06:51:57 d2.evaluation.evaluator]: \u001b[0mInference done 233/355. 0.1199 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.1204 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 303/355. 0.1206 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 06:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 341/355. 0.1205 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.880897 (0.139660 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.120480 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0KKK7CL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.335 | 39.287 | 13.430 | 7.272 | 21.890 | 14.113 |\n",
      "\u001b[32m[10/21 06:52:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 23.695 | cushion    | 29.812 | door       | 1.110 |\n",
      "| indoor-plant | 23.424 | sofa       | 37.653 | table      | 0.316 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:52:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:52:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 06:52:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:52:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      "\u001b[32m[10/21 06:52:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.243 | 37.668 | 20.208 | 8.886 | 22.491 | 14.063 |\n",
      "\u001b[32m[10/21 06:52:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.566 | cushion    | 45.855 | door       | 1.073 |\n",
      "| indoor-plant | 16.836 | sofa       | 38.128 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='0KKK7CL2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:52:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:52:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:52:16 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:52:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:52:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1144 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 06:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.1091 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 06:52:28 d2.evaluation.evaluator]: \u001b[0mInference done 94/355. 0.1040 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 06:52:33 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.1050 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 06:52:38 d2.evaluation.evaluator]: \u001b[0mInference done 181/355. 0.1057 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 06:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 220/355. 0.1043 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.1047 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 06:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 298/355. 0.1045 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 06:52:59 d2.evaluation.evaluator]: \u001b[0mInference done 338/355. 0.1051 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.855756 (0.125302 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.104837 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/0KKK7CL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.383\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.951 | 38.349 | 13.239 | 6.795 | 20.446 | 17.223 |\n",
      "\u001b[32m[10/21 06:53:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.160 | cushion    | 29.222 | door       | 1.114 |\n",
      "| indoor-plant | 26.363 | sofa       | 35.490 | table      | 0.356 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:53:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:53:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 06:53:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:53:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      "\u001b[32m[10/21 06:53:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.043 | 37.082 | 20.278 | 8.433 | 21.550 | 16.596 |\n",
      "\u001b[32m[10/21 06:53:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.455 | cushion    | 43.954 | door       | 1.135 |\n",
      "| indoor-plant | 18.659 | sofa       | 37.053 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [37.981792317001485, 39.286646164159734, 38.34884264295385]}, 'segm': {'AP50': [36.25437703006062, 37.667985545403745, 37.0824220583873]}}\n",
      "dataset_name XIXIWKQ\n",
      "SOLVER PARAMS (500, 100, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='XIXIWKQ_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/XIXIWKQ0\n",
      "output_aug/500/XIXIWKQ0\n",
      "\u001b[32m[10/21 06:53:03 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:53:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:53:03 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:53:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:53:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:53:03 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:53:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:53:03 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:53:03 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:53:10 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 19  total_loss: 3.036  loss_cls: 1.614  loss_box_reg: 0.6302  loss_mask: 0.6886  loss_rpn_cls: 0.08891  loss_rpn_loc: 0.02444  time: 0.3135  data_time: 0.0159  lr: 0.00019081  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:16 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 39  total_loss: 2.022  loss_cls: 0.5935  loss_box_reg: 0.6292  loss_mask: 0.6177  loss_rpn_cls: 0.04841  loss_rpn_loc: 0.04306  time: 0.3109  data_time: 0.0035  lr: 0.00039061  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:22 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 59  total_loss: 1.613  loss_cls: 0.3941  loss_box_reg: 0.6061  loss_mask: 0.5175  loss_rpn_cls: 0.03217  loss_rpn_loc: 0.03338  time: 0.3098  data_time: 0.0035  lr: 0.00059041  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:28 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 79  total_loss: 1.376  loss_cls: 0.3294  loss_box_reg: 0.5705  loss_mask: 0.3643  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.03111  time: 0.3019  data_time: 0.0036  lr: 0.00079021  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:33 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 99  total_loss: 1.18  loss_cls: 0.196  loss_box_reg: 0.5209  loss_mask: 0.3062  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.02108  time: 0.2954  data_time: 0.0035  lr: 0.00099001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:39 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 119  total_loss: 0.8593  loss_cls: 0.1716  loss_box_reg: 0.4002  loss_mask: 0.2546  loss_rpn_cls: 0.006944  loss_rpn_loc: 0.01993  time: 0.2980  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:46 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 139  total_loss: 0.8934  loss_cls: 0.1458  loss_box_reg: 0.4344  loss_mask: 0.2437  loss_rpn_cls: 0.004766  loss_rpn_loc: 0.02164  time: 0.3003  data_time: 0.0033  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:52 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 159  total_loss: 0.8522  loss_cls: 0.1193  loss_box_reg: 0.4183  loss_mask: 0.2453  loss_rpn_cls: 0.002244  loss_rpn_loc: 0.0121  time: 0.3020  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:53:58 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 179  total_loss: 0.7533  loss_cls: 0.1138  loss_box_reg: 0.3331  loss_mask: 0.2161  loss_rpn_cls: 0.003513  loss_rpn_loc: 0.01827  time: 0.3048  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:05 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 199  total_loss: 0.7652  loss_cls: 0.1194  loss_box_reg: 0.3088  loss_mask: 0.2037  loss_rpn_cls: 0.004937  loss_rpn_loc: 0.02504  time: 0.3056  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:11 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 219  total_loss: 0.7023  loss_cls: 0.09026  loss_box_reg: 0.3227  loss_mask: 0.1978  loss_rpn_cls: 0.005526  loss_rpn_loc: 0.02831  time: 0.3052  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:17 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 239  total_loss: 0.5975  loss_cls: 0.09087  loss_box_reg: 0.2672  loss_mask: 0.1505  loss_rpn_cls: 0.003944  loss_rpn_loc: 0.01537  time: 0.3064  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:22 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 259  total_loss: 0.6174  loss_cls: 0.1007  loss_box_reg: 0.2533  loss_mask: 0.1547  loss_rpn_cls: 0.003169  loss_rpn_loc: 0.02418  time: 0.3024  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:28 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 279  total_loss: 0.5699  loss_cls: 0.0682  loss_box_reg: 0.2431  loss_mask: 0.1568  loss_rpn_cls: 0.006417  loss_rpn_loc: 0.0321  time: 0.3021  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:35 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 299  total_loss: 0.5493  loss_cls: 0.08081  loss_box_reg: 0.2247  loss_mask: 0.1863  loss_rpn_cls: 0.004125  loss_rpn_loc: 0.01842  time: 0.3035  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:41 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 319  total_loss: 0.4484  loss_cls: 0.0642  loss_box_reg: 0.2101  loss_mask: 0.1423  loss_rpn_cls: 0.002598  loss_rpn_loc: 0.006974  time: 0.3040  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:48 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 339  total_loss: 0.5327  loss_cls: 0.08906  loss_box_reg: 0.2242  loss_mask: 0.1622  loss_rpn_cls: 0.005059  loss_rpn_loc: 0.01809  time: 0.3057  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:54:54 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 359  total_loss: 0.4799  loss_cls: 0.06826  loss_box_reg: 0.2192  loss_mask: 0.1575  loss_rpn_cls: 0.005178  loss_rpn_loc: 0.01336  time: 0.3056  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:00 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 379  total_loss: 0.5074  loss_cls: 0.07368  loss_box_reg: 0.2033  loss_mask: 0.1516  loss_rpn_cls: 0.007345  loss_rpn_loc: 0.02614  time: 0.3056  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:06 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 399  total_loss: 0.4755  loss_cls: 0.06491  loss_box_reg: 0.217  loss_mask: 0.1522  loss_rpn_cls: 0.005546  loss_rpn_loc: 0.01611  time: 0.3051  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:12 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 419  total_loss: 0.4274  loss_cls: 0.05069  loss_box_reg: 0.1784  loss_mask: 0.127  loss_rpn_cls: 0.002012  loss_rpn_loc: 0.01853  time: 0.3054  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:16 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 439  total_loss: 0.4749  loss_cls: 0.05571  loss_box_reg: 0.1672  loss_mask: 0.1344  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01871  time: 0.3012  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:23 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 459  total_loss: 0.3997  loss_cls: 0.0484  loss_box_reg: 0.1773  loss_mask: 0.1409  loss_rpn_cls: 0.003456  loss_rpn_loc: 0.01657  time: 0.3031  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:30 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.4223  loss_cls: 0.06482  loss_box_reg: 0.1831  loss_mask: 0.1392  loss_rpn_cls: 0.002544  loss_rpn_loc: 0.01767  time: 0.3047  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.4164  loss_cls: 0.05181  loss_box_reg: 0.1731  loss_mask: 0.1327  loss_rpn_cls: 0.003633  loss_rpn_loc: 0.01709  time: 0.3061  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:55:38 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:32 (0.3061 s / it)\n",
      "\u001b[32m[10/21 06:55:38 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:33 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='XIXIWKQ_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 06:55:38 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 06:55:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:55:38 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:55:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 06:55:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 06:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1110 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 50/126. 0.1150 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:55:49 d2.evaluation.evaluator]: \u001b[0mInference done 89/126. 0.1143 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.451053 (0.127695 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.113938 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XIXIWKQ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.382\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.048 | 38.241 | 17.735 | 11.763 | 33.109 | 22.175 |\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 29.517 | cushion    | 23.220 | door       | 11.921 |\n",
      "| indoor-plant | 19.142 | sofa       | 31.306 | table      | 5.186  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.708 | 25.977 | 8.391  | 6.204 | 16.581 | 20.012 |\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.135 | cushion    | 22.308 | door       | 9.969 |\n",
      "| indoor-plant | 3.348  | sofa       | 22.487 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='XIXIWKQ0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 06:55:54 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 06:55:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:55:54 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:55:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 06:55:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1227 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 06:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 47/355. 0.1222 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 06:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.1181 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 06:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 128/355. 0.1166 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 06:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 169/355. 0.1160 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 06:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 210/355. 0.1155 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 06:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 243/355. 0.1167 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 06:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.1167 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 06:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.1177 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.1175 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.837498 (0.133821 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.117468 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XIXIWKQ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.227\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.389 | 32.107 | 11.873 | 7.804 | 17.174 | 11.778 |\n",
      "\u001b[32m[10/21 06:56:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.194 | cushion    | 30.662 | door       | 1.963 |\n",
      "| indoor-plant | 22.901 | sofa       | 23.151 | table      | 0.462 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:56:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 06:56:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:56:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
      "\u001b[32m[10/21 06:56:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.598 | 30.807 | 14.364 | 8.521 | 16.351 | 13.548 |\n",
      "\u001b[32m[10/21 06:56:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.790  | cushion    | 42.010 | door       | 2.931 |\n",
      "| indoor-plant | 10.642 | sofa       | 24.215 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='XIXIWKQ1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 06:56:43 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 06:56:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:56:43 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:56:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 06:56:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 24/355. 0.1264 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 06:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 60/355. 0.1237 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 06:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 100/355. 0.1206 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 06:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 141/355. 0.1184 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 182/355. 0.1177 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 219/355. 0.1176 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 06:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 256/355. 0.1177 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 06:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 292/355. 0.1183 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 06:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 329/355. 0.1184 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.945718 (0.134131 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.118191 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XIXIWKQ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.431 | 33.491 | 12.403 | 8.000 | 18.110 | 12.780 |\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.222 | cushion    | 32.523 | door       | 1.723 |\n",
      "| indoor-plant | 21.134 | sofa       | 26.586 | table      | 0.402 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:57:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:57:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 06:57:32 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:57:32 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      "\u001b[32m[10/21 06:57:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.444 | 32.099 | 15.865 | 8.837 | 17.511 | 14.051 |\n",
      "\u001b[32m[10/21 06:57:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.061 | cushion    | 43.626 | door       | 3.004 |\n",
      "| indoor-plant | 9.398 | sofa       | 27.573 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='XIXIWKQ2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 06:57:32 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 06:57:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 06:57:32 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:57:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 06:57:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 06:57:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1222 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 06:57:39 d2.evaluation.evaluator]: \u001b[0mInference done 47/355. 0.1211 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 06:57:44 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.1173 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 06:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.1151 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 06:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 173/355. 0.1142 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 06:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 221/355. 0.1076 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 06:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 264/355. 0.1066 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 06:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 304/355. 0.1064 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 06:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 349/355. 0.1053 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.124578 (0.120356 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.105161 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/XIXIWKQ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.127\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.339 | 32.208 | 10.590 | 7.448 | 16.661 | 12.657 |\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.120 | cushion    | 30.687 | door       | 2.261 |\n",
      "| indoor-plant | 21.314 | sofa       | 24.163 | table      | 0.491 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 06:58:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 06:58:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 06:58:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 06:58:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      "\u001b[32m[10/21 06:58:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.813 | 30.996 | 15.016 | 8.337 | 16.766 | 14.121 |\n",
      "\u001b[32m[10/21 06:58:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.435 | cushion    | 41.172 | door       | 4.337 |\n",
      "| indoor-plant | 9.577 | sofa       | 25.360 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [32.106874192133155, 33.490674280520864, 32.20759174034889]}, 'segm': {'AP50': [30.8073987405799, 32.0985574961735, 30.996405990650416]}}\n",
      "dataset_name 94RKY31\n",
      "SOLVER PARAMS (800, 100, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='94RKY31_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/94RKY310\n",
      "output_aug/800/94RKY310\n",
      "\u001b[32m[10/21 06:58:17 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 06:58:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 06:58:17 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 06:58:17 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 06:58:17 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 06:58:17 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 06:58:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 06:58:17 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 06:58:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 06:58:24 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 19  total_loss: 3.015  loss_cls: 1.533  loss_box_reg: 0.574  loss_mask: 0.6879  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.03128  time: 0.3124  data_time: 0.0153  lr: 0.00019081  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:58:30 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 39  total_loss: 1.879  loss_cls: 0.5924  loss_box_reg: 0.6176  loss_mask: 0.6357  loss_rpn_cls: 0.03003  loss_rpn_loc: 0.03093  time: 0.3132  data_time: 0.0036  lr: 0.00039061  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:58:36 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 59  total_loss: 1.665  loss_cls: 0.4408  loss_box_reg: 0.6348  loss_mask: 0.5335  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.02814  time: 0.3157  data_time: 0.0035  lr: 0.00059041  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:58:43 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 79  total_loss: 1.293  loss_cls: 0.3092  loss_box_reg: 0.5577  loss_mask: 0.4012  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.02548  time: 0.3173  data_time: 0.0037  lr: 0.00079021  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:58:49 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 99  total_loss: 1.138  loss_cls: 0.1782  loss_box_reg: 0.5118  loss_mask: 0.2569  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.02301  time: 0.3187  data_time: 0.0037  lr: 0.00099001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:58:56 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 119  total_loss: 1.053  loss_cls: 0.2008  loss_box_reg: 0.4731  loss_mask: 0.2751  loss_rpn_cls: 0.007234  loss_rpn_loc: 0.03094  time: 0.3194  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:01 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 139  total_loss: 0.8529  loss_cls: 0.1525  loss_box_reg: 0.4215  loss_mask: 0.2261  loss_rpn_cls: 0.006689  loss_rpn_loc: 0.02051  time: 0.3150  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:07 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 159  total_loss: 0.7894  loss_cls: 0.1336  loss_box_reg: 0.3718  loss_mask: 0.1984  loss_rpn_cls: 0.008736  loss_rpn_loc: 0.02062  time: 0.3117  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:14 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 179  total_loss: 0.7629  loss_cls: 0.1249  loss_box_reg: 0.3306  loss_mask: 0.1967  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.04453  time: 0.3135  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:20 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 199  total_loss: 0.6937  loss_cls: 0.1247  loss_box_reg: 0.2696  loss_mask: 0.2035  loss_rpn_cls: 0.008828  loss_rpn_loc: 0.03109  time: 0.3147  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:27 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 219  total_loss: 0.6396  loss_cls: 0.1078  loss_box_reg: 0.2648  loss_mask: 0.1533  loss_rpn_cls: 0.00864  loss_rpn_loc: 0.03654  time: 0.3172  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:33 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 239  total_loss: 0.6194  loss_cls: 0.09553  loss_box_reg: 0.263  loss_mask: 0.1583  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.02843  time: 0.3170  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:40 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 259  total_loss: 0.6115  loss_cls: 0.09338  loss_box_reg: 0.2483  loss_mask: 0.1732  loss_rpn_cls: 0.006939  loss_rpn_loc: 0.02656  time: 0.3170  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:46 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 279  total_loss: 0.5685  loss_cls: 0.08261  loss_box_reg: 0.2567  loss_mask: 0.1596  loss_rpn_cls: 0.003196  loss_rpn_loc: 0.01861  time: 0.3167  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:52 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 299  total_loss: 0.5561  loss_cls: 0.09276  loss_box_reg: 0.2465  loss_mask: 0.1709  loss_rpn_cls: 0.002565  loss_rpn_loc: 0.01588  time: 0.3154  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 06:59:58 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 319  total_loss: 0.513  loss_cls: 0.0599  loss_box_reg: 0.1998  loss_mask: 0.1609  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.01578  time: 0.3129  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:04 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 339  total_loss: 0.4984  loss_cls: 0.06557  loss_box_reg: 0.1914  loss_mask: 0.1638  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.02037  time: 0.3136  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:11 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 359  total_loss: 0.4496  loss_cls: 0.05828  loss_box_reg: 0.1961  loss_mask: 0.1306  loss_rpn_cls: 0.005047  loss_rpn_loc: 0.01233  time: 0.3142  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:17 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 379  total_loss: 0.4645  loss_cls: 0.04936  loss_box_reg: 0.1843  loss_mask: 0.1376  loss_rpn_cls: 0.006683  loss_rpn_loc: 0.01594  time: 0.3153  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:24 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 399  total_loss: 0.4171  loss_cls: 0.05841  loss_box_reg: 0.1808  loss_mask: 0.1327  loss_rpn_cls: 0.004915  loss_rpn_loc: 0.008666  time: 0.3152  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:30 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 419  total_loss: 0.464  loss_cls: 0.05881  loss_box_reg: 0.2034  loss_mask: 0.1564  loss_rpn_cls: 0.006134  loss_rpn_loc: 0.01812  time: 0.3147  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:36 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 439  total_loss: 0.4024  loss_cls: 0.0483  loss_box_reg: 0.1321  loss_mask: 0.1104  loss_rpn_cls: 0.005468  loss_rpn_loc: 0.02093  time: 0.3140  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:42 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 459  total_loss: 0.4469  loss_cls: 0.06287  loss_box_reg: 0.1683  loss_mask: 0.142  loss_rpn_cls: 0.008465  loss_rpn_loc: 0.01876  time: 0.3146  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:47 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 479  total_loss: 0.4318  loss_cls: 0.05758  loss_box_reg: 0.1649  loss_mask: 0.1376  loss_rpn_cls: 0.005651  loss_rpn_loc: 0.02367  time: 0.3104  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:00:53 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 499  total_loss: 0.4814  loss_cls: 0.04926  loss_box_reg: 0.1508  loss_mask: 0.1514  loss_rpn_cls: 0.007781  loss_rpn_loc: 0.01821  time: 0.3118  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:00 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 519  total_loss: 0.37  loss_cls: 0.05071  loss_box_reg: 0.1665  loss_mask: 0.1303  loss_rpn_cls: 0.004328  loss_rpn_loc: 0.01659  time: 0.3130  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:07 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 539  total_loss: 0.4287  loss_cls: 0.06521  loss_box_reg: 0.1805  loss_mask: 0.1149  loss_rpn_cls: 0.003756  loss_rpn_loc: 0.02786  time: 0.3143  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:14 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 559  total_loss: 0.4151  loss_cls: 0.04416  loss_box_reg: 0.184  loss_mask: 0.1183  loss_rpn_cls: 0.002331  loss_rpn_loc: 0.00689  time: 0.3153  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:21 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 579  total_loss: 0.3983  loss_cls: 0.05354  loss_box_reg: 0.1562  loss_mask: 0.1339  loss_rpn_cls: 0.003609  loss_rpn_loc: 0.01157  time: 0.3162  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:28 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 599  total_loss: 0.3692  loss_cls: 0.04891  loss_box_reg: 0.1739  loss_mask: 0.1205  loss_rpn_cls: 0.001666  loss_rpn_loc: 0.01204  time: 0.3172  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:35 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 619  total_loss: 0.3523  loss_cls: 0.04747  loss_box_reg: 0.1441  loss_mask: 0.1155  loss_rpn_cls: 0.002402  loss_rpn_loc: 0.01769  time: 0.3183  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:42 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 639  total_loss: 0.3266  loss_cls: 0.03722  loss_box_reg: 0.1228  loss_mask: 0.1358  loss_rpn_cls: 0.001373  loss_rpn_loc: 0.0124  time: 0.3190  data_time: 0.0033  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:49 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 659  total_loss: 0.3039  loss_cls: 0.03497  loss_box_reg: 0.1269  loss_mask: 0.09643  loss_rpn_cls: 0.002843  loss_rpn_loc: 0.01491  time: 0.3199  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:01:56 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 679  total_loss: 0.3498  loss_cls: 0.04383  loss_box_reg: 0.1229  loss_mask: 0.1344  loss_rpn_cls: 0.004045  loss_rpn_loc: 0.01415  time: 0.3205  data_time: 0.0033  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:02:03 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 699  total_loss: 0.3407  loss_cls: 0.03544  loss_box_reg: 0.1379  loss_mask: 0.1298  loss_rpn_cls: 0.001385  loss_rpn_loc: 0.01616  time: 0.3213  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:02:09 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 719  total_loss: 0.3344  loss_cls: 0.05067  loss_box_reg: 0.135  loss_mask: 0.1043  loss_rpn_cls: 0.002194  loss_rpn_loc: 0.0152  time: 0.3220  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:02:16 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 739  total_loss: 0.3565  loss_cls: 0.04679  loss_box_reg: 0.1433  loss_mask: 0.09067  loss_rpn_cls: 0.003067  loss_rpn_loc: 0.01352  time: 0.3226  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:02:23 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 759  total_loss: 0.3423  loss_cls: 0.04471  loss_box_reg: 0.1588  loss_mask: 0.1228  loss_rpn_cls: 0.001151  loss_rpn_loc: 0.01107  time: 0.3233  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:02:30 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.3041  loss_cls: 0.03376  loss_box_reg: 0.1382  loss_mask: 0.08206  loss_rpn_cls: 0.002048  loss_rpn_loc: 0.01097  time: 0.3240  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:02:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.3283  loss_cls: 0.03931  loss_box_reg: 0.1163  loss_mask: 0.1143  loss_rpn_cls: 0.003157  loss_rpn_loc: 0.01647  time: 0.3244  data_time: 0.0035  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:02:38 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:18 (0.3244 s / it)\n",
      "\u001b[32m[10/21 07:02:38 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:20 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='94RKY31_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:02:38 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:02:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:02:38 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:02:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:02:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:02:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1097 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 51/126. 0.1130 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:02:50 d2.evaluation.evaluator]: \u001b[0mInference done 90/126. 0.1142 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.435983 (0.127570 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.114585 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/94RKY310/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.213 | 38.902 | 22.563 | 12.153 | 35.727 | 25.456 |\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 34.320 | cushion    | 22.957 | door       | 13.402 |\n",
      "| indoor-plant | 20.281 | sofa       | 38.095 | table      | 4.225  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:02:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:02:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 07:02:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:02:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      "\u001b[32m[10/21 07:02:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.373 | 28.610 | 8.867  | 5.985 | 17.147 | 22.362 |\n",
      "\u001b[32m[10/21 07:02:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 13.183 | cushion    | 19.314 | door       | 11.319 |\n",
      "| indoor-plant | 6.553  | sofa       | 23.867 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='94RKY310_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:02:55 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:02:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:02:55 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:02:55 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:02:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:02:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1190 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 07:03:02 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1247 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 07:03:07 d2.evaluation.evaluator]: \u001b[0mInference done 84/355. 0.1212 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 07:03:12 d2.evaluation.evaluator]: \u001b[0mInference done 124/355. 0.1194 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 164/355. 0.1185 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 07:03:22 d2.evaluation.evaluator]: \u001b[0mInference done 206/355. 0.1172 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 07:03:27 d2.evaluation.evaluator]: \u001b[0mInference done 241/355. 0.1176 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 07:03:32 d2.evaluation.evaluator]: \u001b[0mInference done 277/355. 0.1183 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:03:37 d2.evaluation.evaluator]: \u001b[0mInference done 309/355. 0.1192 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.1193 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.187036 (0.137677 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.119099 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/94RKY310/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.650 | 36.619 | 17.280 | 8.062 | 21.192 | 13.353 |\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.515 | cushion    | 28.407 | door       | 1.300 |\n",
      "| indoor-plant | 30.633 | sofa       | 37.019 | table      | 0.023 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:03:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:03:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "\u001b[32m[10/21 07:03:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:03:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      "\u001b[32m[10/21 07:03:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.347 | 35.392 | 18.021 | 8.406 | 21.147 | 14.665 |\n",
      "\u001b[32m[10/21 07:03:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.231 | cushion    | 38.920 | door       | 2.011 |\n",
      "| indoor-plant | 18.888 | sofa       | 40.036 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='94RKY311_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:03:45 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:03:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:03:45 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:03:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:03:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 16/355. 0.1195 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 07:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1212 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 07:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1191 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 07:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1177 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 07:04:08 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.1172 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 07:04:13 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.1167 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:04:18 d2.evaluation.evaluator]: \u001b[0mInference done 246/355. 0.1177 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 07:04:23 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.1186 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:04:28 d2.evaluation.evaluator]: \u001b[0mInference done 316/355. 0.1189 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 354/355. 0.1187 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.574658 (0.135928 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.118644 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/94RKY310/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.008 | 37.688 | 16.014 | 8.264 | 21.886 | 13.292 |\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.515 | cushion    | 29.669 | door       | 1.870 |\n",
      "| indoor-plant | 29.659 | sofa       | 35.321 | table      | 0.017 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:04:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      "\u001b[32m[10/21 07:04:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.501 | 35.904 | 18.230 | 8.375 | 22.672 | 14.528 |\n",
      "\u001b[32m[10/21 07:04:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.069 | cushion    | 38.635 | door       | 2.726 |\n",
      "| indoor-plant | 17.824 | sofa       | 39.750 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='94RKY312_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:04:35 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:04:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:04:35 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:04:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:04:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 24/355. 0.1241 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 07:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 61/355. 0.1200 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 102/355. 0.1165 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 07:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.1172 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 07:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 183/355. 0.1158 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 07:05:04 d2.evaluation.evaluator]: \u001b[0mInference done 217/355. 0.1170 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.1136 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 298/355. 0.1120 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 07:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 339/355. 0.1112 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.601579 (0.130290 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.110583 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/94RKY310/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.941 | 37.159 | 15.459 | 7.921 | 20.328 | 14.672 |\n",
      "\u001b[32m[10/21 07:05:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.330 | cushion    | 28.662 | door       | 1.916 |\n",
      "| indoor-plant | 31.471 | sofa       | 36.231 | table      | 0.036 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:05:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:05:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 07:05:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:05:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      "\u001b[32m[10/21 07:05:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.631 | 36.212 | 18.612 | 8.297 | 21.159 | 15.712 |\n",
      "\u001b[32m[10/21 07:05:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.143 | cushion    | 38.098 | door       | 3.025 |\n",
      "| indoor-plant | 19.013 | sofa       | 40.507 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [36.61857106958446, 37.687550449544716, 37.159067115523285]}, 'segm': {'AP50': [35.3917073279047, 35.904268028769835, 36.21185492653747]}}\n",
      "dataset_name U1M6D2C\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='U1M6D2C_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/U1M6D2C0\n",
      "output_aug/500/U1M6D2C0\n",
      "\u001b[32m[10/21 07:05:23 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:05:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:05:23 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:05:23 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:05:23 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:05:23 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:05:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:05:23 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:05:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:05:31 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 19  total_loss: 3.119  loss_cls: 1.574  loss_box_reg: 0.6958  loss_mask: 0.6916  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.03308  time: 0.3386  data_time: 0.0158  lr: 9.5905e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:05:37 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 39  total_loss: 2.056  loss_cls: 0.6637  loss_box_reg: 0.6631  loss_mask: 0.6608  loss_rpn_cls: 0.03136  loss_rpn_loc: 0.02601  time: 0.3368  data_time: 0.0035  lr: 0.0001958  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:05:44 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 59  total_loss: 1.775  loss_cls: 0.4924  loss_box_reg: 0.6365  loss_mask: 0.6087  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.02434  time: 0.3374  data_time: 0.0036  lr: 0.00029571  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:05:50 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 79  total_loss: 1.712  loss_cls: 0.4417  loss_box_reg: 0.6416  loss_mask: 0.5275  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.03407  time: 0.3299  data_time: 0.0036  lr: 0.0003956  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:05:57 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 99  total_loss: 1.394  loss_cls: 0.2944  loss_box_reg: 0.6038  loss_mask: 0.3638  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.0412  time: 0.3271  data_time: 0.0037  lr: 0.00049551  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:03 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 119  total_loss: 1.176  loss_cls: 0.239  loss_box_reg: 0.53  loss_mask: 0.2512  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.02307  time: 0.3274  data_time: 0.0036  lr: 0.00059541  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:09 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 139  total_loss: 1.026  loss_cls: 0.1718  loss_box_reg: 0.4692  loss_mask: 0.2352  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.024  time: 0.3205  data_time: 0.0037  lr: 0.00069531  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:16 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 159  total_loss: 0.9338  loss_cls: 0.1651  loss_box_reg: 0.4315  loss_mask: 0.2016  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.02209  time: 0.3236  data_time: 0.0038  lr: 0.00079521  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:22 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 179  total_loss: 0.9257  loss_cls: 0.2081  loss_box_reg: 0.3367  loss_mask: 0.2023  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.02417  time: 0.3253  data_time: 0.0035  lr: 0.0008951  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:29 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 199  total_loss: 0.5759  loss_cls: 0.08605  loss_box_reg: 0.2922  loss_mask: 0.1275  loss_rpn_cls: 0.006975  loss_rpn_loc: 0.01678  time: 0.3266  data_time: 0.0036  lr: 0.000995  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:36 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 219  total_loss: 0.866  loss_cls: 0.1306  loss_box_reg: 0.3922  loss_mask: 0.2058  loss_rpn_cls: 0.007424  loss_rpn_loc: 0.02528  time: 0.3265  data_time: 0.0034  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:42 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 239  total_loss: 0.6804  loss_cls: 0.1206  loss_box_reg: 0.2948  loss_mask: 0.1871  loss_rpn_cls: 0.007014  loss_rpn_loc: 0.02035  time: 0.3261  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:49 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 259  total_loss: 0.6729  loss_cls: 0.09053  loss_box_reg: 0.29  loss_mask: 0.1626  loss_rpn_cls: 0.002063  loss_rpn_loc: 0.01639  time: 0.3262  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:06:54 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 279  total_loss: 0.6138  loss_cls: 0.09406  loss_box_reg: 0.2809  loss_mask: 0.1998  loss_rpn_cls: 0.02529  loss_rpn_loc: 0.01909  time: 0.3231  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:01 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 299  total_loss: 0.6554  loss_cls: 0.0731  loss_box_reg: 0.2546  loss_mask: 0.1732  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.02477  time: 0.3238  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:08 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 319  total_loss: 0.5541  loss_cls: 0.06929  loss_box_reg: 0.2522  loss_mask: 0.1725  loss_rpn_cls: 0.00368  loss_rpn_loc: 0.01422  time: 0.3248  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:15 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 339  total_loss: 0.545  loss_cls: 0.09054  loss_box_reg: 0.2431  loss_mask: 0.1761  loss_rpn_cls: 0.003993  loss_rpn_loc: 0.01751  time: 0.3257  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:21 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 359  total_loss: 0.424  loss_cls: 0.05289  loss_box_reg: 0.1704  loss_mask: 0.1159  loss_rpn_cls: 0.005173  loss_rpn_loc: 0.02879  time: 0.3253  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:27 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 379  total_loss: 0.3912  loss_cls: 0.05043  loss_box_reg: 0.1872  loss_mask: 0.1204  loss_rpn_cls: 0.003189  loss_rpn_loc: 0.01202  time: 0.3248  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:34 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 399  total_loss: 0.4196  loss_cls: 0.0637  loss_box_reg: 0.1853  loss_mask: 0.1131  loss_rpn_cls: 0.002075  loss_rpn_loc: 0.01796  time: 0.3249  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:40 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 419  total_loss: 0.4771  loss_cls: 0.05595  loss_box_reg: 0.2077  loss_mask: 0.1185  loss_rpn_cls: 0.002643  loss_rpn_loc: 0.02073  time: 0.3241  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:45 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 439  total_loss: 0.449  loss_cls: 0.07036  loss_box_reg: 0.2091  loss_mask: 0.126  loss_rpn_cls: 0.005124  loss_rpn_loc: 0.01622  time: 0.3213  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:52 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 459  total_loss: 0.4716  loss_cls: 0.06469  loss_box_reg: 0.1811  loss_mask: 0.1656  loss_rpn_cls: 0.002488  loss_rpn_loc: 0.01741  time: 0.3225  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:07:59 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.4777  loss_cls: 0.05973  loss_box_reg: 0.2292  loss_mask: 0.1559  loss_rpn_cls: 0.003052  loss_rpn_loc: 0.01316  time: 0.3233  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:08:07 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.4983  loss_cls: 0.06788  loss_box_reg: 0.1911  loss_mask: 0.1386  loss_rpn_cls: 0.002219  loss_rpn_loc: 0.01872  time: 0.3245  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:08:07 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:41 (0.3246 s / it)\n",
      "\u001b[32m[10/21 07:08:07 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:42 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='U1M6D2C_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:08:07 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:08:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:08:07 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:08:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:08:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1129 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 48/126. 0.1182 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:08:19 d2.evaluation.evaluator]: \u001b[0mInference done 86/126. 0.1171 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 122/126. 0.1176 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.522706 (0.136551 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.118018 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/U1M6D2C0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.589 | 39.206 | 21.474 | 11.078 | 34.752 | 23.009 |\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 33.303 | cushion    | 21.823 | door       | 13.294 |\n",
      "| indoor-plant | 14.429 | sofa       | 41.335 | table      | 5.353  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.212 | 32.028 | 9.041  | 5.804 | 25.436 | 14.539 |\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 14.890 | cushion    | 24.759 | door       | 11.916 |\n",
      "| indoor-plant | 9.102  | sofa       | 24.605 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='U1M6D2C0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:08:25 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:08:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:08:25 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:08:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:08:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:08:29 d2.evaluation.evaluator]: \u001b[0mInference done 25/355. 0.1218 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 07:08:34 d2.evaluation.evaluator]: \u001b[0mInference done 59/355. 0.1221 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 07:08:39 d2.evaluation.evaluator]: \u001b[0mInference done 96/355. 0.1204 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 07:08:44 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.1191 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.1189 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 07:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.1180 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 07:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.1181 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 07:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.1184 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 310/355. 0.1195 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 345/355. 0.1199 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.230686 (0.143516 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.119885 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:09:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:09:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/U1M6D2C0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:09:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:09:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.907 | 35.489 | 20.763 | 9.874 | 19.458 | 21.471 |\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.927 | cushion    | 34.640 | door       | 0.763 |\n",
      "| indoor-plant | 26.250 | sofa       | 40.944 | table      | 0.917 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.143 | 32.333 | 19.328 | 8.639 | 21.811 | 17.454 |\n",
      "\u001b[32m[10/21 07:09:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.900 | cushion    | 45.583 | door       | 0.604 |\n",
      "| indoor-plant | 20.041 | sofa       | 37.731 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='U1M6D2C1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:09:17 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:09:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:09:17 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:09:18 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:09:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:09:20 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.1264 s / img. ETA=0:00:55\n",
      "\u001b[32m[10/21 07:09:25 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1220 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 07:09:30 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.1229 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 07:09:35 d2.evaluation.evaluator]: \u001b[0mInference done 118/355. 0.1224 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 07:09:40 d2.evaluation.evaluator]: \u001b[0mInference done 154/355. 0.1219 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 07:09:45 d2.evaluation.evaluator]: \u001b[0mInference done 195/355. 0.1203 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 07:09:50 d2.evaluation.evaluator]: \u001b[0mInference done 227/355. 0.1209 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:09:55 d2.evaluation.evaluator]: \u001b[0mInference done 261/355. 0.1212 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:10:00 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1213 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 07:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 328/355. 0.1211 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 07:10:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.889697 (0.145399 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:10:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121065 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:10:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:10:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/U1M6D2C0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.736 | 36.856 | 20.609 | 10.700 | 20.459 | 18.622 |\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.387 | cushion    | 35.906 | door       | 0.677 |\n",
      "| indoor-plant | 24.282 | sofa       | 44.395 | table      | 0.767 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:10:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:10:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:10:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:10:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      "\u001b[32m[10/21 07:10:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.938 | 33.672 | 20.337 | 9.904 | 22.942 | 16.305 |\n",
      "\u001b[32m[10/21 07:10:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.694 | cushion    | 46.891 | door       | 0.632 |\n",
      "| indoor-plant | 18.974 | sofa       | 41.435 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='U1M6D2C2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:10:11 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:10:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:10:11 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:10:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:10:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1234 s / img. ETA=0:00:56\n",
      "\u001b[32m[10/21 07:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 44/355. 0.1231 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 07:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 79/355. 0.1237 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:10:28 d2.evaluation.evaluator]: \u001b[0mInference done 115/355. 0.1241 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 07:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 152/355. 0.1234 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 07:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 191/355. 0.1223 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 07:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.1225 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 258/355. 0.1230 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 07:10:54 d2.evaluation.evaluator]: \u001b[0mInference done 291/355. 0.1229 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 326/355. 0.1229 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.208569 (0.146310 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.122817 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/U1M6D2C0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.343\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.488 | 36.210 | 20.237 | 10.246 | 19.762 | 20.512 |\n",
      "\u001b[32m[10/21 07:11:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.199 | cushion    | 34.880 | door       | 0.770 |\n",
      "| indoor-plant | 27.101 | sofa       | 43.149 | table      | 0.829 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:11:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:11:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:11:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:11:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
      "\u001b[32m[10/21 07:11:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.905 | 34.084 | 20.485 | 10.191 | 22.035 | 17.595 |\n",
      "\u001b[32m[10/21 07:11:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.070 | cushion    | 45.584 | door       | 0.795 |\n",
      "| indoor-plant | 20.511 | sofa       | 41.469 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [35.488986222244066, 36.85565182338665, 36.209581194638886]}, 'segm': {'AP50': [32.33296108500145, 33.671522855603754, 34.08417418658842]}}\n",
      "dataset_name 85YDPQJ\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='85YDPQJ_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/85YDPQJ0\n",
      "output_aug/800/85YDPQJ0\n",
      "\u001b[32m[10/21 07:11:05 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:11:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:11:05 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:11:05 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:11:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:11:05 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:11:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:11:05 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:11:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:11:13 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 19  total_loss: 3.381  loss_cls: 1.915  loss_box_reg: 0.6603  loss_mask: 0.6919  loss_rpn_cls: 0.09775  loss_rpn_loc: 0.02379  time: 0.3576  data_time: 0.0277  lr: 9.5905e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:11:21 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 39  total_loss: 2.136  loss_cls: 0.6382  loss_box_reg: 0.5816  loss_mask: 0.6712  loss_rpn_cls: 0.05452  loss_rpn_loc: 0.03728  time: 0.3567  data_time: 0.0042  lr: 0.00019581  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:11:28 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 59  total_loss: 1.958  loss_cls: 0.5143  loss_box_reg: 0.6724  loss_mask: 0.5912  loss_rpn_cls: 0.04199  loss_rpn_loc: 0.03951  time: 0.3538  data_time: 0.0039  lr: 0.00029571  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:11:35 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 79  total_loss: 1.638  loss_cls: 0.381  loss_box_reg: 0.6668  loss_mask: 0.4888  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.0313  time: 0.3529  data_time: 0.0043  lr: 0.00039561  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:11:42 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 99  total_loss: 1.422  loss_cls: 0.307  loss_box_reg: 0.5682  loss_mask: 0.3859  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.02224  time: 0.3529  data_time: 0.0042  lr: 0.00049551  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:11:49 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 119  total_loss: 1.216  loss_cls: 0.2712  loss_box_reg: 0.5414  loss_mask: 0.2635  loss_rpn_cls: 0.009901  loss_rpn_loc: 0.02004  time: 0.3530  data_time: 0.0041  lr: 0.00059541  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:11:55 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 139  total_loss: 0.9761  loss_cls: 0.2187  loss_box_reg: 0.4975  loss_mask: 0.2533  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.01885  time: 0.3496  data_time: 0.0041  lr: 0.00069531  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:02 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 159  total_loss: 0.9436  loss_cls: 0.1559  loss_box_reg: 0.4037  loss_mask: 0.2054  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.02398  time: 0.3486  data_time: 0.0041  lr: 0.00079521  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:09 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 179  total_loss: 0.8766  loss_cls: 0.1756  loss_box_reg: 0.4584  loss_mask: 0.2227  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.02565  time: 0.3460  data_time: 0.0043  lr: 0.00089511  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:15 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 199  total_loss: 0.754  loss_cls: 0.1309  loss_box_reg: 0.3546  loss_mask: 0.2375  loss_rpn_cls: 0.00797  loss_rpn_loc: 0.02086  time: 0.3425  data_time: 0.0041  lr: 0.000995  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:21 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 219  total_loss: 0.699  loss_cls: 0.0999  loss_box_reg: 0.282  loss_mask: 0.2178  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.03223  time: 0.3412  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:28 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 239  total_loss: 0.7098  loss_cls: 0.09178  loss_box_reg: 0.3556  loss_mask: 0.2021  loss_rpn_cls: 0.004109  loss_rpn_loc: 0.01277  time: 0.3404  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:35 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 259  total_loss: 0.7823  loss_cls: 0.1259  loss_box_reg: 0.3231  loss_mask: 0.2134  loss_rpn_cls: 0.00607  loss_rpn_loc: 0.03371  time: 0.3405  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:41 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 279  total_loss: 0.6544  loss_cls: 0.1057  loss_box_reg: 0.2834  loss_mask: 0.1828  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.03156  time: 0.3386  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:48 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 299  total_loss: 0.6261  loss_cls: 0.1018  loss_box_reg: 0.2642  loss_mask: 0.1881  loss_rpn_cls: 0.003405  loss_rpn_loc: 0.03128  time: 0.3370  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:12:54 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 319  total_loss: 0.6096  loss_cls: 0.09389  loss_box_reg: 0.2821  loss_mask: 0.1771  loss_rpn_cls: 0.009295  loss_rpn_loc: 0.02254  time: 0.3367  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:00 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 339  total_loss: 0.5102  loss_cls: 0.07367  loss_box_reg: 0.2331  loss_mask: 0.13  loss_rpn_cls: 0.005834  loss_rpn_loc: 0.01807  time: 0.3330  data_time: 0.0042  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:06 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 359  total_loss: 0.4767  loss_cls: 0.06812  loss_box_reg: 0.2209  loss_mask: 0.1766  loss_rpn_cls: 0.006262  loss_rpn_loc: 0.01951  time: 0.3319  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:13 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 379  total_loss: 0.5611  loss_cls: 0.06042  loss_box_reg: 0.2273  loss_mask: 0.1301  loss_rpn_cls: 0.003562  loss_rpn_loc: 0.01978  time: 0.3319  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:19 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 399  total_loss: 0.4199  loss_cls: 0.06233  loss_box_reg: 0.1801  loss_mask: 0.1262  loss_rpn_cls: 0.002483  loss_rpn_loc: 0.01157  time: 0.3314  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:26 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 419  total_loss: 0.4937  loss_cls: 0.06093  loss_box_reg: 0.1743  loss_mask: 0.1749  loss_rpn_cls: 0.002419  loss_rpn_loc: 0.01077  time: 0.3315  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:32 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 439  total_loss: 0.4026  loss_cls: 0.06416  loss_box_reg: 0.1653  loss_mask: 0.1304  loss_rpn_cls: 0.003108  loss_rpn_loc: 0.01341  time: 0.3304  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:38 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 459  total_loss: 0.4672  loss_cls: 0.06676  loss_box_reg: 0.2214  loss_mask: 0.1493  loss_rpn_cls: 0.002636  loss_rpn_loc: 0.01516  time: 0.3296  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:45 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 479  total_loss: 0.4097  loss_cls: 0.05174  loss_box_reg: 0.1805  loss_mask: 0.1297  loss_rpn_cls: 0.003123  loss_rpn_loc: 0.01726  time: 0.3295  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:50 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 499  total_loss: 0.4166  loss_cls: 0.04552  loss_box_reg: 0.1493  loss_mask: 0.1081  loss_rpn_cls: 0.002125  loss_rpn_loc: 0.01281  time: 0.3274  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:13:57 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 519  total_loss: 0.43  loss_cls: 0.07632  loss_box_reg: 0.1702  loss_mask: 0.1415  loss_rpn_cls: 0.004254  loss_rpn_loc: 0.01953  time: 0.3269  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:03 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 539  total_loss: 0.3961  loss_cls: 0.05722  loss_box_reg: 0.1762  loss_mask: 0.1132  loss_rpn_cls: 0.0009806  loss_rpn_loc: 0.01159  time: 0.3272  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:10 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 559  total_loss: 0.4078  loss_cls: 0.04986  loss_box_reg: 0.194  loss_mask: 0.1127  loss_rpn_cls: 0.001684  loss_rpn_loc: 0.01314  time: 0.3270  data_time: 0.0042  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:16 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 579  total_loss: 0.4421  loss_cls: 0.05718  loss_box_reg: 0.1654  loss_mask: 0.154  loss_rpn_cls: 0.004479  loss_rpn_loc: 0.01583  time: 0.3272  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:23 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 599  total_loss: 0.4367  loss_cls: 0.05308  loss_box_reg: 0.1632  loss_mask: 0.1531  loss_rpn_cls: 0.02325  loss_rpn_loc: 0.02026  time: 0.3269  data_time: 0.0042  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:29 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 619  total_loss: 0.3554  loss_cls: 0.051  loss_box_reg: 0.1279  loss_mask: 0.1086  loss_rpn_cls: 0.003808  loss_rpn_loc: 0.008316  time: 0.3265  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:36 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 639  total_loss: 0.3089  loss_cls: 0.04764  loss_box_reg: 0.1434  loss_mask: 0.107  loss_rpn_cls: 0.003354  loss_rpn_loc: 0.0159  time: 0.3266  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:40 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 659  total_loss: 0.4073  loss_cls: 0.05956  loss_box_reg: 0.1813  loss_mask: 0.1445  loss_rpn_cls: 0.001274  loss_rpn_loc: 0.01459  time: 0.3239  data_time: 0.0042  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:48 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 679  total_loss: 0.342  loss_cls: 0.04408  loss_box_reg: 0.1549  loss_mask: 0.09678  loss_rpn_cls: 0.00214  loss_rpn_loc: 0.009361  time: 0.3248  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:14:55 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 699  total_loss: 0.3637  loss_cls: 0.04771  loss_box_reg: 0.1529  loss_mask: 0.1383  loss_rpn_cls: 0.001093  loss_rpn_loc: 0.01322  time: 0.3257  data_time: 0.0042  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:15:02 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 719  total_loss: 0.3941  loss_cls: 0.04448  loss_box_reg: 0.1687  loss_mask: 0.1302  loss_rpn_cls: 0.002353  loss_rpn_loc: 0.0214  time: 0.3265  data_time: 0.0042  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:15:09 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 739  total_loss: 0.3785  loss_cls: 0.06536  loss_box_reg: 0.1588  loss_mask: 0.1235  loss_rpn_cls: 0.001995  loss_rpn_loc: 0.01139  time: 0.3274  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:15:16 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 759  total_loss: 0.3273  loss_cls: 0.03999  loss_box_reg: 0.1143  loss_mask: 0.109  loss_rpn_cls: 0.001758  loss_rpn_loc: 0.008712  time: 0.3283  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:15:23 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.3492  loss_cls: 0.05114  loss_box_reg: 0.1618  loss_mask: 0.1198  loss_rpn_cls: 0.001582  loss_rpn_loc: 0.01002  time: 0.3291  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:15:32 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.3373  loss_cls: 0.05356  loss_box_reg: 0.1383  loss_mask: 0.112  loss_rpn_cls: 0.002013  loss_rpn_loc: 0.01645  time: 0.3299  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:15:32 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:23 (0.3299 s / it)\n",
      "\u001b[32m[10/21 07:15:32 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:24 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='85YDPQJ_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:15:32 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:15:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:15:32 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:15:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:15:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:15:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1321 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 07:15:38 d2.evaluation.evaluator]: \u001b[0mInference done 48/126. 0.1209 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:15:44 d2.evaluation.evaluator]: \u001b[0mInference done 85/126. 0.1203 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.evaluator]: \u001b[0mInference done 121/126. 0.1203 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.868031 (0.139405 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.120066 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/85YDPQJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 07:15:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.455 | 40.831 | 24.612 | 12.282 | 36.308 | 23.868 |\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 35.632 | cushion    | 25.444 | door       | 14.481 |\n",
      "| indoor-plant | 16.628 | sofa       | 37.174 | table      | 5.369  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.010 | 32.000 | 10.969 | 6.602 | 23.404 | 20.895 |\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 13.761 | cushion    | 24.561 | door       | 13.393 |\n",
      "| indoor-plant | 9.187  | sofa       | 23.159 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='85YDPQJ0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:15:50 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:15:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:15:50 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:15:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:15:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:15:54 d2.evaluation.evaluator]: \u001b[0mInference done 24/355. 0.1217 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 07:15:59 d2.evaluation.evaluator]: \u001b[0mInference done 57/355. 0.1249 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 07:16:04 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.1209 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 07:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 133/355. 0.1198 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:16:14 d2.evaluation.evaluator]: \u001b[0mInference done 170/355. 0.1200 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 07:16:19 d2.evaluation.evaluator]: \u001b[0mInference done 209/355. 0.1196 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 07:16:24 d2.evaluation.evaluator]: \u001b[0mInference done 241/355. 0.1203 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 07:16:29 d2.evaluation.evaluator]: \u001b[0mInference done 276/355. 0.1204 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:16:34 d2.evaluation.evaluator]: \u001b[0mInference done 307/355. 0.1209 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:16:39 d2.evaluation.evaluator]: \u001b[0mInference done 343/355. 0.1206 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:16:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.510986 (0.144317 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:16:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.120925 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:16:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:16:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/85YDPQJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.021 | 39.290 | 17.292 | 8.408 | 18.254 | 19.184 |\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.156 | cushion    | 34.717 | door       | 1.224 |\n",
      "| indoor-plant | 18.061 | sofa       | 47.792 | table      | 1.177 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:16:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:16:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:16:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:16:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
      "\u001b[32m[10/21 07:16:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.272 | 36.741 | 21.133 | 9.481 | 21.257 | 15.496 |\n",
      "\u001b[32m[10/21 07:16:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.003 | cushion    | 45.384 | door       | 0.860 |\n",
      "| indoor-plant | 19.468 | sofa       | 42.920 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='85YDPQJ1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:16:43 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:16:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:16:43 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:16:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:16:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:16:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1360 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 07:16:50 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1263 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 07:16:55 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.1251 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 07:17:00 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.1247 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 07:17:05 d2.evaluation.evaluator]: \u001b[0mInference done 153/355. 0.1243 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 07:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 192/355. 0.1232 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 07:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.1225 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:17:20 d2.evaluation.evaluator]: \u001b[0mInference done 268/355. 0.1180 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:17:25 d2.evaluation.evaluator]: \u001b[0mInference done 305/355. 0.1161 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 345/355. 0.1149 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:17:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.298914 (0.137997 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:17:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.114449 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:17:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:17:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/85YDPQJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:17:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:17:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.401\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.375 | 40.109 | 17.938 | 9.136 | 19.661 | 17.114 |\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.652 | cushion    | 36.224 | door       | 1.284 |\n",
      "| indoor-plant | 17.681 | sofa       | 47.336 | table      | 1.075 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.580 | 37.593 | 21.480 | 9.542 | 23.182 | 14.461 |\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.646 | cushion    | 45.851 | door       | 1.277 |\n",
      "| indoor-plant | 19.103 | sofa       | 43.601 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='85YDPQJ2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:17:33 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:17:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:17:33 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:17:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:17:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:17:36 d2.evaluation.evaluator]: \u001b[0mInference done 14/355. 0.1099 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 07:17:41 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1071 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 07:17:46 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1101 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 07:17:51 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.1113 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 07:17:56 d2.evaluation.evaluator]: \u001b[0mInference done 170/355. 0.1123 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 07:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 210/355. 0.1107 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 246/355. 0.1113 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 07:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.1110 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:18:16 d2.evaluation.evaluator]: \u001b[0mInference done 314/355. 0.1111 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.1103 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.245247 (0.134986 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.109995 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/85YDPQJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.398\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.353\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.133 | 39.752 | 17.341 | 8.368 | 18.675 | 19.788 |\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.834 | cushion    | 34.718 | door       | 1.445 |\n",
      "| indoor-plant | 18.668 | sofa       | 47.648 | table      | 1.486 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:18:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:18:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/21 07:18:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:18:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      "\u001b[32m[10/21 07:18:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.431 | 37.803 | 20.775 | 9.196 | 21.592 | 16.140 |\n",
      "\u001b[32m[10/21 07:18:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.283 | cushion    | 43.680 | door       | 1.307 |\n",
      "| indoor-plant | 20.092 | sofa       | 44.227 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [39.289798327006444, 40.109191580913695, 39.75167247048767]}, 'segm': {'AP50': [36.74060914702881, 37.593068739321104, 37.80331629725857]}}\n",
      "dataset_name D32A505\n",
      "SOLVER PARAMS (500, 100, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='D32A505_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/D32A5050\n",
      "output_aug/500/D32A5050\n",
      "\u001b[32m[10/21 07:18:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:18:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:18:24 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:18:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:18:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:18:24 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:18:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:18:24 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:18:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:18:31 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 19  total_loss: 2.931  loss_cls: 1.093  loss_box_reg: 0.6355  loss_mask: 0.6881  loss_rpn_cls: 0.08265  loss_rpn_loc: 0.02973  time: 0.3290  data_time: 0.0182  lr: 0.00038162  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:18:38 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 39  total_loss: 1.853  loss_cls: 0.4987  loss_box_reg: 0.6614  loss_mask: 0.5654  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.0319  time: 0.3357  data_time: 0.0041  lr: 0.00078122  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:18:45 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 59  total_loss: 1.408  loss_cls: 0.3582  loss_box_reg: 0.6222  loss_mask: 0.4174  loss_rpn_cls: 0.02225  loss_rpn_loc: 0.02447  time: 0.3339  data_time: 0.0042  lr: 0.0011808  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:18:51 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 79  total_loss: 1.226  loss_cls: 0.2318  loss_box_reg: 0.5799  loss_mask: 0.2889  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.03196  time: 0.3332  data_time: 0.0043  lr: 0.0015804  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:18:58 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 99  total_loss: 1.125  loss_cls: 0.2  loss_box_reg: 0.4982  loss_mask: 0.2837  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.02989  time: 0.3293  data_time: 0.0040  lr: 0.00198  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:04 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 119  total_loss: 0.9744  loss_cls: 0.169  loss_box_reg: 0.44  loss_mask: 0.3132  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.03316  time: 0.3241  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:10 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 139  total_loss: 0.7075  loss_cls: 0.1366  loss_box_reg: 0.3239  loss_mask: 0.1936  loss_rpn_cls: 0.006754  loss_rpn_loc: 0.03234  time: 0.3238  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:15 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 159  total_loss: 0.696  loss_cls: 0.1114  loss_box_reg: 0.2672  loss_mask: 0.1726  loss_rpn_cls: 0.01538  loss_rpn_loc: 0.0319  time: 0.3146  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:21 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 179  total_loss: 0.6304  loss_cls: 0.1014  loss_box_reg: 0.2635  loss_mask: 0.1773  loss_rpn_cls: 0.003416  loss_rpn_loc: 0.01803  time: 0.3138  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:28 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 199  total_loss: 0.5999  loss_cls: 0.08643  loss_box_reg: 0.2746  loss_mask: 0.1648  loss_rpn_cls: 0.008527  loss_rpn_loc: 0.03832  time: 0.3153  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:34 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 219  total_loss: 0.675  loss_cls: 0.1005  loss_box_reg: 0.2528  loss_mask: 0.1763  loss_rpn_cls: 0.003796  loss_rpn_loc: 0.04148  time: 0.3159  data_time: 0.0043  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:41 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 239  total_loss: 0.5725  loss_cls: 0.07415  loss_box_reg: 0.2301  loss_mask: 0.1634  loss_rpn_cls: 0.004384  loss_rpn_loc: 0.03181  time: 0.3178  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:47 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 259  total_loss: 0.5787  loss_cls: 0.06649  loss_box_reg: 0.2434  loss_mask: 0.1596  loss_rpn_cls: 0.005261  loss_rpn_loc: 0.02366  time: 0.3173  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:53 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 279  total_loss: 0.5164  loss_cls: 0.08958  loss_box_reg: 0.1851  loss_mask: 0.1696  loss_rpn_cls: 0.005017  loss_rpn_loc: 0.01916  time: 0.3158  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:19:59 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 299  total_loss: 0.4977  loss_cls: 0.07648  loss_box_reg: 0.2196  loss_mask: 0.1485  loss_rpn_cls: 0.009101  loss_rpn_loc: 0.0126  time: 0.3140  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:05 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 319  total_loss: 0.4828  loss_cls: 0.06828  loss_box_reg: 0.2085  loss_mask: 0.1588  loss_rpn_cls: 0.00398  loss_rpn_loc: 0.01301  time: 0.3139  data_time: 0.0043  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:10 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 339  total_loss: 0.4472  loss_cls: 0.05625  loss_box_reg: 0.213  loss_mask: 0.1413  loss_rpn_cls: 0.00523  loss_rpn_loc: 0.01789  time: 0.3084  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:17 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 359  total_loss: 0.5176  loss_cls: 0.07331  loss_box_reg: 0.2016  loss_mask: 0.1532  loss_rpn_cls: 0.003127  loss_rpn_loc: 0.02271  time: 0.3108  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:24 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 379  total_loss: 0.4138  loss_cls: 0.06323  loss_box_reg: 0.1478  loss_mask: 0.1265  loss_rpn_cls: 0.006754  loss_rpn_loc: 0.02496  time: 0.3128  data_time: 0.0043  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:31 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 399  total_loss: 0.468  loss_cls: 0.07032  loss_box_reg: 0.1991  loss_mask: 0.1392  loss_rpn_cls: 0.003677  loss_rpn_loc: 0.0169  time: 0.3152  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:38 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 419  total_loss: 0.4118  loss_cls: 0.06215  loss_box_reg: 0.1654  loss_mask: 0.1402  loss_rpn_cls: 0.002489  loss_rpn_loc: 0.01819  time: 0.3168  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:45 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 439  total_loss: 0.4059  loss_cls: 0.04856  loss_box_reg: 0.1608  loss_mask: 0.1255  loss_rpn_cls: 0.004619  loss_rpn_loc: 0.01935  time: 0.3185  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:52 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 459  total_loss: 0.3862  loss_cls: 0.05092  loss_box_reg: 0.1543  loss_mask: 0.1284  loss_rpn_cls: 0.005612  loss_rpn_loc: 0.02379  time: 0.3196  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:20:59 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.4471  loss_cls: 0.06315  loss_box_reg: 0.1906  loss_mask: 0.1491  loss_rpn_cls: 0.002116  loss_rpn_loc: 0.01349  time: 0.3214  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:21:07 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.4052  loss_cls: 0.05682  loss_box_reg: 0.1603  loss_mask: 0.1319  loss_rpn_cls: 0.00397  loss_rpn_loc: 0.01403  time: 0.3228  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:21:07 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:40 (0.3229 s / it)\n",
      "\u001b[32m[10/21 07:21:07 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:42 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='D32A505_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:21:07 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:21:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:21:07 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:21:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:21:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1045 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 46/126. 0.1175 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 82/126. 0.1203 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 114/126. 0.1229 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.718508 (0.146434 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.122212 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D32A5050/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.362\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.572 | 38.418 | 20.617 | 9.519 | 35.629 | 22.876 |\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.706 | cushion    | 22.006 | door       | 18.102 |\n",
      "| indoor-plant | 18.300 | sofa       | 33.865 | table      | 4.455  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.855 | 31.779 | 10.520 | 6.469 | 27.239 | 21.297 |\n",
      "\u001b[32m[10/21 07:21:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 12.961 | cushion    | 24.414 | door       | 14.100 |\n",
      "| indoor-plant | 13.773 | sofa       | 23.881 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='D32A5050_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:21:27 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:21:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:21:27 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:21:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:21:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.1251 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 07:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 48/355. 0.1221 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 07:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 82/355. 0.1234 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 116/355. 0.1231 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 07:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 150/355. 0.1227 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 187/355. 0.1222 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 07:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 220/355. 0.1220 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 07:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 249/355. 0.1236 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 07:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.1238 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 311/355. 0.1242 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:22:20 d2.evaluation.evaluator]: \u001b[0mInference done 345/355. 0.1242 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:54.090561 (0.154544 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.124435 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D32A5050/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.914 | 30.768 | 9.639  | 6.565 | 17.114 | 12.129 |\n",
      "\u001b[32m[10/21 07:22:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.892 | cushion    | 24.952 | door       | 1.831 |\n",
      "| indoor-plant | 21.932 | sofa       | 20.647 | table      | 0.228 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:22:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:22:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 07:22:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:22:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.311\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      "\u001b[32m[10/21 07:22:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.805 | 29.326 | 12.503 | 8.312 | 19.598 | 15.114 |\n",
      "\u001b[32m[10/21 07:22:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.534 | cushion    | 38.215 | door       | 1.545 |\n",
      "| indoor-plant | 18.205 | sofa       | 18.330 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='D32A5051_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:22:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:22:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:22:24 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:22:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:22:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:22:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1318 s / img. ETA=0:01:01\n",
      "\u001b[32m[10/21 07:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 44/355. 0.1234 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 07:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 79/355. 0.1229 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 113/355. 0.1235 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 07:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 153/355. 0.1175 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 07:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 195/355. 0.1149 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 07:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 227/355. 0.1148 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 264/355. 0.1124 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 299/355. 0.1110 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 07:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 337/355. 0.1103 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 07:23:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.460276 (0.141315 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:23:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.109837 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:23:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:23:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D32A5050/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:23:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:23:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.327\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.895 | 32.676 | 10.984 | 6.736 | 18.782 | 12.365 |\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.019 | cushion    | 24.240 | door       | 1.921 |\n",
      "| indoor-plant | 22.571 | sofa       | 25.421 | table      | 0.200 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:23:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:23:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
      "\u001b[32m[10/21 07:23:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.304 | 31.260 | 11.952 | 8.002 | 21.227 | 14.107 |\n",
      "\u001b[32m[10/21 07:23:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.723 | cushion    | 35.899 | door       | 1.702 |\n",
      "| indoor-plant | 18.103 | sofa       | 23.396 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='D32A5052_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:23:16 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:23:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:23:16 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:23:16 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:23:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1121 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 07:23:23 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1012 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 88/355. 0.1068 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 07:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 125/355. 0.1089 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 165/355. 0.1088 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 07:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 204/355. 0.1072 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 07:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.1040 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 07:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 279/355. 0.1037 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 312/355. 0.1040 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:24:03 d2.evaluation.evaluator]: \u001b[0mInference done 350/355. 0.1043 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 07:24:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.458848 (0.135597 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:24:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.104249 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:24:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:24:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/D32A5050/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:24:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:24:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:24:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 07:24:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:24:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      "\u001b[32m[10/21 07:24:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.993 | 33.010 | 10.655 | 6.750 | 18.080 | 13.217 |\n",
      "\u001b[32m[10/21 07:24:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.809 | cushion    | 24.647 | door       | 1.715 |\n",
      "| indoor-plant | 23.185 | sofa       | 26.343 | table      | 0.258 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:24:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:24:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.47 seconds.\n",
      "\u001b[32m[10/21 07:24:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:24:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      "\u001b[32m[10/21 07:24:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.662 | 32.112 | 12.752 | 7.948 | 20.729 | 15.445 |\n",
      "\u001b[32m[10/21 07:24:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.267 | cushion    | 36.121 | door       | 1.783 |\n",
      "| indoor-plant | 18.539 | sofa       | 24.262 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [30.768010650452066, 32.675651605422594, 33.00954921042405]}, 'segm': {'AP50': [29.325956483185617, 31.260313841320553, 32.11152181331477]}}\n",
      "dataset_name VO6D4BS\n",
      "SOLVER PARAMS (800, 100, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='VO6D4BS_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/VO6D4BS0\n",
      "output_aug/800/VO6D4BS0\n",
      "\u001b[32m[10/21 07:24:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:24:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:24:07 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:24:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:24:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:24:07 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:24:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:24:07 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:24:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:24:14 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 19  total_loss: 2.965  loss_cls: 1.227  loss_box_reg: 0.6263  loss_mask: 0.6877  loss_rpn_cls: 0.08712  loss_rpn_loc: 0.03834  time: 0.3249  data_time: 0.0186  lr: 0.00038162  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:24:20 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 39  total_loss: 1.897  loss_cls: 0.5456  loss_box_reg: 0.6792  loss_mask: 0.5786  loss_rpn_cls: 0.0374  loss_rpn_loc: 0.02167  time: 0.3188  data_time: 0.0043  lr: 0.00078122  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:24:27 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 59  total_loss: 1.448  loss_cls: 0.2954  loss_box_reg: 0.6465  loss_mask: 0.3399  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.03175  time: 0.3243  data_time: 0.0042  lr: 0.0011808  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:24:32 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 79  total_loss: 1.185  loss_cls: 0.2462  loss_box_reg: 0.5143  loss_mask: 0.2894  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.02676  time: 0.3120  data_time: 0.0040  lr: 0.0015804  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:24:39 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 99  total_loss: 0.8552  loss_cls: 0.1742  loss_box_reg: 0.4503  loss_mask: 0.2331  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.02589  time: 0.3167  data_time: 0.0040  lr: 0.00198  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:24:46 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 119  total_loss: 0.7593  loss_cls: 0.1441  loss_box_reg: 0.4074  loss_mask: 0.2324  loss_rpn_cls: 0.02536  loss_rpn_loc: 0.03083  time: 0.3202  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:24:53 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 139  total_loss: 0.7786  loss_cls: 0.1452  loss_box_reg: 0.3235  loss_mask: 0.2056  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.02983  time: 0.3237  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:24:59 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 159  total_loss: 0.7042  loss_cls: 0.1089  loss_box_reg: 0.3112  loss_mask: 0.2224  loss_rpn_cls: 0.005856  loss_rpn_loc: 0.02538  time: 0.3236  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:06 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 179  total_loss: 0.7225  loss_cls: 0.102  loss_box_reg: 0.2757  loss_mask: 0.1982  loss_rpn_cls: 0.02301  loss_rpn_loc: 0.02739  time: 0.3232  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:12 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 199  total_loss: 0.5385  loss_cls: 0.08348  loss_box_reg: 0.2567  loss_mask: 0.166  loss_rpn_cls: 0.008452  loss_rpn_loc: 0.01858  time: 0.3235  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:18 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 219  total_loss: 0.5198  loss_cls: 0.07181  loss_box_reg: 0.2257  loss_mask: 0.1931  loss_rpn_cls: 0.005447  loss_rpn_loc: 0.02753  time: 0.3181  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:24 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 239  total_loss: 0.5168  loss_cls: 0.0637  loss_box_reg: 0.2369  loss_mask: 0.1809  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.01648  time: 0.3181  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:31 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 259  total_loss: 0.4739  loss_cls: 0.05673  loss_box_reg: 0.2046  loss_mask: 0.1565  loss_rpn_cls: 0.007705  loss_rpn_loc: 0.01985  time: 0.3215  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:38 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 279  total_loss: 0.4623  loss_cls: 0.07203  loss_box_reg: 0.1842  loss_mask: 0.1269  loss_rpn_cls: 0.008167  loss_rpn_loc: 0.01923  time: 0.3240  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:45 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 299  total_loss: 0.4936  loss_cls: 0.06508  loss_box_reg: 0.21  loss_mask: 0.1465  loss_rpn_cls: 0.003452  loss_rpn_loc: 0.01793  time: 0.3263  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:25:53 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 319  total_loss: 0.4245  loss_cls: 0.05926  loss_box_reg: 0.2071  loss_mask: 0.1211  loss_rpn_cls: 0.003926  loss_rpn_loc: 0.01428  time: 0.3283  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:00 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 339  total_loss: 0.3885  loss_cls: 0.03292  loss_box_reg: 0.1916  loss_mask: 0.1032  loss_rpn_cls: 0.003175  loss_rpn_loc: 0.01479  time: 0.3301  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:07 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 359  total_loss: 0.3676  loss_cls: 0.05498  loss_box_reg: 0.1646  loss_mask: 0.1378  loss_rpn_cls: 0.002077  loss_rpn_loc: 0.01887  time: 0.3312  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:14 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 379  total_loss: 0.4585  loss_cls: 0.07851  loss_box_reg: 0.2015  loss_mask: 0.1437  loss_rpn_cls: 0.007119  loss_rpn_loc: 0.01497  time: 0.3325  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:21 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 399  total_loss: 0.4309  loss_cls: 0.06514  loss_box_reg: 0.2188  loss_mask: 0.1321  loss_rpn_cls: 0.006246  loss_rpn_loc: 0.01775  time: 0.3335  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:28 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 419  total_loss: 0.4004  loss_cls: 0.05546  loss_box_reg: 0.1591  loss_mask: 0.1075  loss_rpn_cls: 0.003154  loss_rpn_loc: 0.01466  time: 0.3347  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:35 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 439  total_loss: 0.4113  loss_cls: 0.06125  loss_box_reg: 0.1735  loss_mask: 0.1265  loss_rpn_cls: 0.002679  loss_rpn_loc: 0.02007  time: 0.3357  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:42 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 459  total_loss: 0.4053  loss_cls: 0.03541  loss_box_reg: 0.1575  loss_mask: 0.1133  loss_rpn_cls: 0.006891  loss_rpn_loc: 0.02352  time: 0.3361  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:49 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 479  total_loss: 0.31  loss_cls: 0.02603  loss_box_reg: 0.114  loss_mask: 0.0929  loss_rpn_cls: 0.008074  loss_rpn_loc: 0.03326  time: 0.3369  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:26:56 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 499  total_loss: 0.3392  loss_cls: 0.0274  loss_box_reg: 0.1392  loss_mask: 0.1347  loss_rpn_cls: 0.004795  loss_rpn_loc: 0.01894  time: 0.3374  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:03 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 519  total_loss: 0.3819  loss_cls: 0.04973  loss_box_reg: 0.1634  loss_mask: 0.1152  loss_rpn_cls: 0.00589  loss_rpn_loc: 0.02361  time: 0.3380  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:11 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 539  total_loss: 0.3638  loss_cls: 0.05151  loss_box_reg: 0.1429  loss_mask: 0.09767  loss_rpn_cls: 0.003869  loss_rpn_loc: 0.01338  time: 0.3387  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:18 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 559  total_loss: 0.3771  loss_cls: 0.05201  loss_box_reg: 0.1575  loss_mask: 0.1319  loss_rpn_cls: 0.003193  loss_rpn_loc: 0.01566  time: 0.3393  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:25 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 579  total_loss: 0.368  loss_cls: 0.05198  loss_box_reg: 0.146  loss_mask: 0.1317  loss_rpn_cls: 0.003908  loss_rpn_loc: 0.03053  time: 0.3397  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:32 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 599  total_loss: 0.3908  loss_cls: 0.04624  loss_box_reg: 0.1605  loss_mask: 0.1203  loss_rpn_cls: 0.003114  loss_rpn_loc: 0.01987  time: 0.3401  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:39 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 619  total_loss: 0.316  loss_cls: 0.0381  loss_box_reg: 0.1431  loss_mask: 0.1024  loss_rpn_cls: 0.005148  loss_rpn_loc: 0.02031  time: 0.3406  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:46 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 639  total_loss: 0.4032  loss_cls: 0.05517  loss_box_reg: 0.1556  loss_mask: 0.1091  loss_rpn_cls: 0.002359  loss_rpn_loc: 0.01338  time: 0.3409  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:27:53 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 659  total_loss: 0.35  loss_cls: 0.03772  loss_box_reg: 0.1566  loss_mask: 0.1165  loss_rpn_cls: 0.004602  loss_rpn_loc: 0.01812  time: 0.3414  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:00 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 679  total_loss: 0.3418  loss_cls: 0.04027  loss_box_reg: 0.1499  loss_mask: 0.1139  loss_rpn_cls: 0.00352  loss_rpn_loc: 0.0196  time: 0.3415  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:07 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 699  total_loss: 0.2816  loss_cls: 0.02643  loss_box_reg: 0.1362  loss_mask: 0.09696  loss_rpn_cls: 0.001912  loss_rpn_loc: 0.007894  time: 0.3419  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:14 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 719  total_loss: 0.3324  loss_cls: 0.03543  loss_box_reg: 0.1477  loss_mask: 0.09909  loss_rpn_cls: 0.001087  loss_rpn_loc: 0.008749  time: 0.3422  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:21 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 739  total_loss: 0.3328  loss_cls: 0.04551  loss_box_reg: 0.1253  loss_mask: 0.07598  loss_rpn_cls: 0.004102  loss_rpn_loc: 0.01302  time: 0.3424  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:28 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 759  total_loss: 0.3452  loss_cls: 0.05065  loss_box_reg: 0.1271  loss_mask: 0.1099  loss_rpn_cls: 0.003903  loss_rpn_loc: 0.01861  time: 0.3427  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:35 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.2662  loss_cls: 0.03215  loss_box_reg: 0.12  loss_mask: 0.07874  loss_rpn_cls: 0.002358  loss_rpn_loc: 0.01197  time: 0.3428  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:43 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.3626  loss_cls: 0.04592  loss_box_reg: 0.1586  loss_mask: 0.1177  loss_rpn_cls: 0.002341  loss_rpn_loc: 0.01902  time: 0.3432  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:28:43 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:33 (0.3432 s / it)\n",
      "\u001b[32m[10/21 07:28:43 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:35 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='VO6D4BS_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:28:43 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:28:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:28:43 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:28:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:28:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1160 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 50/126. 0.1174 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 88/126. 0.1177 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 125/126. 0.1190 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.104180 (0.133092 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.119277 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VO6D4BS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448\n",
      "\u001b[32m[10/21 07:29:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.339 | 39.672 | 21.901 | 11.420 | 38.059 | 22.808 |\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 33.132 | cushion    | 25.171 | door       | 14.945 |\n",
      "| indoor-plant | 19.701 | sofa       | 37.015 | table      | 4.071  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.646 | 33.103 | 10.525 | 6.569 | 27.943 | 18.124 |\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 15.888 | cushion    | 23.142 | door       | 15.307 |\n",
      "| indoor-plant | 15.340 | sofa       | 24.200 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='VO6D4BS0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:29:01 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:29:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:29:01 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:29:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:29:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 29/355. 0.1223 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 07:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 65/355. 0.1215 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 103/355. 0.1218 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 07:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 142/355. 0.1203 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 07:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 179/355. 0.1206 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 07:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.1202 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 248/355. 0.1209 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 07:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.1192 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 325/355. 0.1174 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.820145 (0.136629 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.116871 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VO6D4BS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.439 | 37.798 | 26.792 | 10.912 | 21.631 | 16.785 |\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.078 | cushion    | 45.966 | door       | 3.767 |\n",
      "| indoor-plant | 17.354 | sofa       | 51.299 | table      | 0.171 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:29:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:29:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 07:29:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:29:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.369\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
      "\u001b[32m[10/21 07:29:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.786 | 36.934 | 28.202 | 10.683 | 23.707 | 19.644 |\n",
      "\u001b[32m[10/21 07:29:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.094 | cushion    | 57.413 | door       | 3.854 |\n",
      "| indoor-plant | 16.565 | sofa       | 50.793 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='VO6D4BS1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:29:51 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:29:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:29:51 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:29:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:29:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1076 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 07:29:57 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1025 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 07:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.1076 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 07:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.1097 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 07:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.1108 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 07:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.1112 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 249/355. 0.1101 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 286/355. 0.1099 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 07:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.1106 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.586529 (0.130247 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.110639 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VO6D4BS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 07:30:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.711 | 38.883 | 25.316 | 10.669 | 22.159 | 16.499 |\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.024 | cushion    | 46.648 | door       | 4.336 |\n",
      "| indoor-plant | 15.059 | sofa       | 51.997 | table      | 0.204 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.375\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.266\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.959 | 37.463 | 27.503 | 10.997 | 25.076 | 18.057 |\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.832 | cushion    | 57.196 | door       | 4.334 |\n",
      "| indoor-plant | 15.282 | sofa       | 52.106 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='VO6D4BS2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:30:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:30:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:30:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:30:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:30:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0608 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.0997 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 07:30:50 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.1063 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 07:30:55 d2.evaluation.evaluator]: \u001b[0mInference done 133/355. 0.1075 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 07:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.1095 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 07:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.1093 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 07:31:10 d2.evaluation.evaluator]: \u001b[0mInference done 249/355. 0.1094 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:31:15 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.1101 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 07:31:20 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.1104 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:31:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.304819 (0.129442 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:31:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.110648 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:31:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:31:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VO6D4BS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.483 | 38.121 | 25.018 | 10.696 | 21.217 | 17.708 |\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.454 | cushion    | 47.200 | door       | 3.313 |\n",
      "| indoor-plant | 15.911 | sofa       | 51.783 | table      | 0.236 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.615 | 37.361 | 26.722 | 10.798 | 24.201 | 19.056 |\n",
      "\u001b[32m[10/21 07:31:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.467 | cushion    | 57.137 | door       | 3.246 |\n",
      "| indoor-plant | 15.739 | sofa       | 51.100 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [37.79828416220894, 38.88268624382742, 38.121174766032986]}, 'segm': {'AP50': [36.93376187639986, 37.4633627890596, 37.3612104518669]}}\n",
      "dataset_name W1KHJIU\n",
      "SOLVER PARAMS (500, 200, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='W1KHJIU_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/W1KHJIU0\n",
      "output_aug/500/W1KHJIU0\n",
      "\u001b[32m[10/21 07:31:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:31:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:31:26 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:31:26 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:31:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:31:27 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:31:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:31:27 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:31:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:31:34 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 19  total_loss: 3.356  loss_cls: 1.631  loss_box_reg: 0.6861  loss_mask: 0.6916  loss_rpn_cls: 0.1531  loss_rpn_loc: 0.03697  time: 0.3397  data_time: 0.0186  lr: 0.00019181  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:31:41 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 39  total_loss: 2.11  loss_cls: 0.6164  loss_box_reg: 0.6474  loss_mask: 0.6341  loss_rpn_cls: 0.05296  loss_rpn_loc: 0.05402  time: 0.3409  data_time: 0.0038  lr: 0.00039161  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:31:48 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 59  total_loss: 1.622  loss_cls: 0.3996  loss_box_reg: 0.5891  loss_mask: 0.5409  loss_rpn_cls: 0.05783  loss_rpn_loc: 0.04993  time: 0.3427  data_time: 0.0040  lr: 0.00059141  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:31:54 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 79  total_loss: 1.374  loss_cls: 0.2944  loss_box_reg: 0.6037  loss_mask: 0.4058  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.02993  time: 0.3392  data_time: 0.0041  lr: 0.00079121  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:00 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 99  total_loss: 1.172  loss_cls: 0.2574  loss_box_reg: 0.5362  loss_mask: 0.2659  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.03075  time: 0.3337  data_time: 0.0042  lr: 0.00099101  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:07 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 119  total_loss: 0.8633  loss_cls: 0.1632  loss_box_reg: 0.3482  loss_mask: 0.1871  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.02948  time: 0.3302  data_time: 0.0039  lr: 0.0011908  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:13 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 139  total_loss: 0.8901  loss_cls: 0.1391  loss_box_reg: 0.4224  loss_mask: 0.2318  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.02658  time: 0.3298  data_time: 0.0040  lr: 0.0013906  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:18 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 159  total_loss: 0.7432  loss_cls: 0.1362  loss_box_reg: 0.3432  loss_mask: 0.2246  loss_rpn_cls: 0.006493  loss_rpn_loc: 0.02057  time: 0.3196  data_time: 0.0041  lr: 0.0015904  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:25 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 179  total_loss: 0.718  loss_cls: 0.1275  loss_box_reg: 0.333  loss_mask: 0.2093  loss_rpn_cls: 0.004853  loss_rpn_loc: 0.02313  time: 0.3225  data_time: 0.0041  lr: 0.0017902  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:32 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 199  total_loss: 0.6458  loss_cls: 0.0912  loss_box_reg: 0.273  loss_mask: 0.2106  loss_rpn_cls: 0.008797  loss_rpn_loc: 0.03122  time: 0.3248  data_time: 0.0041  lr: 0.00199  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:39 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 219  total_loss: 0.6141  loss_cls: 0.07529  loss_box_reg: 0.2682  loss_mask: 0.2119  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.03548  time: 0.3277  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:46 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 239  total_loss: 0.63  loss_cls: 0.09648  loss_box_reg: 0.2796  loss_mask: 0.1667  loss_rpn_cls: 0.005654  loss_rpn_loc: 0.01755  time: 0.3299  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:32:54 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 259  total_loss: 0.6393  loss_cls: 0.08888  loss_box_reg: 0.245  loss_mask: 0.1604  loss_rpn_cls: 0.005829  loss_rpn_loc: 0.03489  time: 0.3328  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:01 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 279  total_loss: 0.5705  loss_cls: 0.08693  loss_box_reg: 0.2752  loss_mask: 0.1604  loss_rpn_cls: 0.003129  loss_rpn_loc: 0.02025  time: 0.3346  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:08 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 299  total_loss: 0.3293  loss_cls: 0.0551  loss_box_reg: 0.1698  loss_mask: 0.1145  loss_rpn_cls: 0.002811  loss_rpn_loc: 0.005523  time: 0.3352  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:15 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 319  total_loss: 0.3878  loss_cls: 0.05172  loss_box_reg: 0.1661  loss_mask: 0.1473  loss_rpn_cls: 0.003884  loss_rpn_loc: 0.02187  time: 0.3365  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:22 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 339  total_loss: 0.4586  loss_cls: 0.06547  loss_box_reg: 0.1981  loss_mask: 0.1315  loss_rpn_cls: 0.004585  loss_rpn_loc: 0.01677  time: 0.3373  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:29 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 359  total_loss: 0.4343  loss_cls: 0.05701  loss_box_reg: 0.191  loss_mask: 0.1278  loss_rpn_cls: 0.002216  loss_rpn_loc: 0.01749  time: 0.3382  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:36 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 379  total_loss: 0.4903  loss_cls: 0.06828  loss_box_reg: 0.1886  loss_mask: 0.1244  loss_rpn_cls: 0.004279  loss_rpn_loc: 0.02341  time: 0.3393  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:43 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 399  total_loss: 0.4129  loss_cls: 0.05994  loss_box_reg: 0.1632  loss_mask: 0.1123  loss_rpn_cls: 0.001977  loss_rpn_loc: 0.0228  time: 0.3405  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:50 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 419  total_loss: 0.4217  loss_cls: 0.05137  loss_box_reg: 0.1992  loss_mask: 0.1333  loss_rpn_cls: 0.003678  loss_rpn_loc: 0.02015  time: 0.3408  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:33:58 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 439  total_loss: 0.4106  loss_cls: 0.0486  loss_box_reg: 0.1691  loss_mask: 0.1333  loss_rpn_cls: 0.003986  loss_rpn_loc: 0.01658  time: 0.3415  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:34:05 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 459  total_loss: 0.4156  loss_cls: 0.05981  loss_box_reg: 0.1766  loss_mask: 0.1191  loss_rpn_cls: 0.002011  loss_rpn_loc: 0.01493  time: 0.3421  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:34:12 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.3931  loss_cls: 0.0581  loss_box_reg: 0.1798  loss_mask: 0.1104  loss_rpn_cls: 0.002233  loss_rpn_loc: 0.01287  time: 0.3426  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:34:20 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.4543  loss_cls: 0.04952  loss_box_reg: 0.1735  loss_mask: 0.1195  loss_rpn_cls: 0.002128  loss_rpn_loc: 0.02382  time: 0.3434  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:34:20 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:51 (0.3435 s / it)\n",
      "\u001b[32m[10/21 07:34:20 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:52 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='W1KHJIU_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:34:20 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:34:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:34:20 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:34:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:34:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1115 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 46/126. 0.1223 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 84/126. 0.1198 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 118/126. 0.1216 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.928971 (0.139909 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.121383 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W1KHJIU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.594 | 37.159 | 17.723 | 10.819 | 33.538 | 25.062 |\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 30.069 | cushion    | 20.728 | door       | 13.877 |\n",
      "| indoor-plant | 16.299 | sofa       | 30.627 | table      | 5.964  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.400 | 28.294 | 8.671  | 5.446 | 22.966 | 16.338 |\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 12.941 | cushion    | 21.245 | door       | 11.608 |\n",
      "| indoor-plant | 8.754  | sofa       | 19.849 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='W1KHJIU0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:34:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:34:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:34:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:34:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:34:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.1163 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 07:34:47 d2.evaluation.evaluator]: \u001b[0mInference done 56/355. 0.1242 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 07:34:52 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.1235 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 07:34:57 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1218 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:35:02 d2.evaluation.evaluator]: \u001b[0mInference done 169/355. 0.1212 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 07:35:07 d2.evaluation.evaluator]: \u001b[0mInference done 208/355. 0.1203 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 07:35:12 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.1203 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 07:35:17 d2.evaluation.evaluator]: \u001b[0mInference done 276/355. 0.1210 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:35:22 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.1214 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:35:27 d2.evaluation.evaluator]: \u001b[0mInference done 343/355. 0.1216 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:35:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.846637 (0.142419 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:35:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121544 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:35:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:35:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W1KHJIU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:35:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:35:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.221 | 34.364 | 13.517 | 7.954 | 16.996 | 14.217 |\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.429 | cushion    | 31.791 | door       | 0.578 |\n",
      "| indoor-plant | 19.890 | sofa       | 28.361 | table      | 1.275 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.236\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.252 | 30.182 | 17.652 | 9.100 | 17.925 | 14.108 |\n",
      "\u001b[32m[10/21 07:35:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 9.529  | cushion    | 43.952 | door       | 0.193 |\n",
      "| indoor-plant | 13.275 | sofa       | 30.562 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='W1KHJIU1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:35:30 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:35:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:35:31 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:35:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:35:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:35:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1168 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 07:35:38 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1214 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 07:35:43 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.1215 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 07:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 119/355. 0.1214 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 07:35:53 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.1210 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 07:35:58 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.1206 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 07:36:03 d2.evaluation.evaluator]: \u001b[0mInference done 229/355. 0.1207 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 07:36:08 d2.evaluation.evaluator]: \u001b[0mInference done 263/355. 0.1208 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:36:13 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.1213 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 07:36:18 d2.evaluation.evaluator]: \u001b[0mInference done 329/355. 0.1211 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 07:36:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.490175 (0.144258 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:36:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121227 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:36:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:36:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W1KHJIU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:36:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:36:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.357\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.918 | 35.717 | 14.032 | 8.299 | 18.467 | 13.805 |\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 18.098 | cushion    | 32.190 | door       | 0.549 |\n",
      "| indoor-plant | 18.760 | sofa       | 30.875 | table      | 1.033 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.338\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.881 | 31.922 | 18.396 | 9.384 | 19.241 | 13.904 |\n",
      "\u001b[32m[10/21 07:36:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.101 | cushion    | 44.543 | door       | 0.313 |\n",
      "| indoor-plant | 12.222 | sofa       | 33.108 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='W1KHJIU2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:36:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:36:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:36:24 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:36:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:36:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:36:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1141 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 07:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.1065 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.1060 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 07:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1068 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 07:36:46 d2.evaluation.evaluator]: \u001b[0mInference done 178/355. 0.1038 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 07:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 215/355. 0.1030 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 07:36:56 d2.evaluation.evaluator]: \u001b[0mInference done 253/355. 0.1025 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:37:01 d2.evaluation.evaluator]: \u001b[0mInference done 289/355. 0.1026 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 07:37:06 d2.evaluation.evaluator]: \u001b[0mInference done 327/355. 0.1026 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.499758 (0.129999 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.102757 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/W1KHJIU0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 07:37:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.604 | 35.393 | 14.388 | 8.668 | 17.170 | 15.674 |\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.111 | cushion    | 31.406 | door       | 0.510 |\n",
      "| indoor-plant | 20.454 | sofa       | 30.810 | table      | 1.336 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.180\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.341 | 31.012 | 17.830 | 9.647 | 17.972 | 15.338 |\n",
      "\u001b[32m[10/21 07:37:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 10.295 | cushion    | 43.300 | door       | 0.244 |\n",
      "| indoor-plant | 12.155 | sofa       | 32.052 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [34.36424167048707, 35.71733801534091, 35.39346043879173]}, 'segm': {'AP50': [30.181694740040278, 31.922478304495215, 31.011622121340523]}}\n",
      "dataset_name EC4RVYT\n",
      "SOLVER PARAMS (800, 200, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='EC4RVYT_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/EC4RVYT0\n",
      "output_aug/800/EC4RVYT0\n",
      "\u001b[32m[10/21 07:37:12 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:37:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:37:12 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:37:12 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:37:12 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:37:12 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:37:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:37:12 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:37:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:37:19 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 19  total_loss: 3.008  loss_cls: 1.641  loss_box_reg: 0.6024  loss_mask: 0.6898  loss_rpn_cls: 0.1272  loss_rpn_loc: 0.02967  time: 0.3156  data_time: 0.0187  lr: 0.00019181  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:37:25 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 39  total_loss: 2.02  loss_cls: 0.6191  loss_box_reg: 0.6563  loss_mask: 0.6357  loss_rpn_cls: 0.03255  loss_rpn_loc: 0.02427  time: 0.3090  data_time: 0.0041  lr: 0.00039161  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:37:31 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 59  total_loss: 1.499  loss_cls: 0.3785  loss_box_reg: 0.5657  loss_mask: 0.5039  loss_rpn_cls: 0.02715  loss_rpn_loc: 0.03748  time: 0.3043  data_time: 0.0041  lr: 0.00059141  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:37:37 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 79  total_loss: 1.199  loss_cls: 0.2437  loss_box_reg: 0.6054  loss_mask: 0.3685  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.02652  time: 0.2990  data_time: 0.0040  lr: 0.00079121  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:37:44 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 99  total_loss: 1.066  loss_cls: 0.1916  loss_box_reg: 0.4822  loss_mask: 0.2788  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.03059  time: 0.3041  data_time: 0.0042  lr: 0.00099101  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:37:50 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 119  total_loss: 0.865  loss_cls: 0.1273  loss_box_reg: 0.3629  loss_mask: 0.2118  loss_rpn_cls: 0.007259  loss_rpn_loc: 0.021  time: 0.3088  data_time: 0.0038  lr: 0.0011908  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:37:57 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 139  total_loss: 0.9678  loss_cls: 0.198  loss_box_reg: 0.4559  loss_mask: 0.2452  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.02999  time: 0.3133  data_time: 0.0041  lr: 0.0013906  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:03 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 159  total_loss: 0.6415  loss_cls: 0.1084  loss_box_reg: 0.2945  loss_mask: 0.166  loss_rpn_cls: 0.005514  loss_rpn_loc: 0.01359  time: 0.3144  data_time: 0.0041  lr: 0.0015904  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:10 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 179  total_loss: 0.7826  loss_cls: 0.1369  loss_box_reg: 0.3633  loss_mask: 0.2175  loss_rpn_cls: 0.005772  loss_rpn_loc: 0.02502  time: 0.3153  data_time: 0.0041  lr: 0.0017902  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:16 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 199  total_loss: 0.6642  loss_cls: 0.1105  loss_box_reg: 0.3021  loss_mask: 0.1656  loss_rpn_cls: 0.00586  loss_rpn_loc: 0.02317  time: 0.3150  data_time: 0.0039  lr: 0.00199  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:22 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 219  total_loss: 0.7019  loss_cls: 0.08446  loss_box_reg: 0.2683  loss_mask: 0.176  loss_rpn_cls: 0.008608  loss_rpn_loc: 0.02606  time: 0.3139  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:28 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 239  total_loss: 0.5823  loss_cls: 0.05801  loss_box_reg: 0.2143  loss_mask: 0.1553  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.0281  time: 0.3107  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:34 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 259  total_loss: 0.5977  loss_cls: 0.1014  loss_box_reg: 0.2319  loss_mask: 0.182  loss_rpn_cls: 0.007145  loss_rpn_loc: 0.02299  time: 0.3122  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:41 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 279  total_loss: 0.5708  loss_cls: 0.0849  loss_box_reg: 0.2508  loss_mask: 0.1675  loss_rpn_cls: 0.009062  loss_rpn_loc: 0.03467  time: 0.3141  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:48 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 299  total_loss: 0.5269  loss_cls: 0.07536  loss_box_reg: 0.2032  loss_mask: 0.1585  loss_rpn_cls: 0.004719  loss_rpn_loc: 0.01712  time: 0.3159  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:38:54 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 319  total_loss: 0.5333  loss_cls: 0.07729  loss_box_reg: 0.2321  loss_mask: 0.1697  loss_rpn_cls: 0.004175  loss_rpn_loc: 0.02188  time: 0.3159  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:01 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 339  total_loss: 0.4491  loss_cls: 0.05742  loss_box_reg: 0.1699  loss_mask: 0.1524  loss_rpn_cls: 0.002016  loss_rpn_loc: 0.01651  time: 0.3155  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:07 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 359  total_loss: 0.4963  loss_cls: 0.06123  loss_box_reg: 0.1945  loss_mask: 0.1419  loss_rpn_cls: 0.003426  loss_rpn_loc: 0.01941  time: 0.3147  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:13 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 379  total_loss: 0.4328  loss_cls: 0.06222  loss_box_reg: 0.1736  loss_mask: 0.1512  loss_rpn_cls: 0.002867  loss_rpn_loc: 0.01439  time: 0.3151  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:18 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 399  total_loss: 0.4895  loss_cls: 0.05522  loss_box_reg: 0.2102  loss_mask: 0.1274  loss_rpn_cls: 0.00226  loss_rpn_loc: 0.01408  time: 0.3105  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:25 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 419  total_loss: 0.4798  loss_cls: 0.08021  loss_box_reg: 0.1875  loss_mask: 0.1354  loss_rpn_cls: 0.006915  loss_rpn_loc: 0.02481  time: 0.3131  data_time: 0.0043  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:32 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 439  total_loss: 0.4283  loss_cls: 0.05868  loss_box_reg: 0.1888  loss_mask: 0.1191  loss_rpn_cls: 0.005123  loss_rpn_loc: 0.01886  time: 0.3150  data_time: 0.0043  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:39 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 459  total_loss: 0.3843  loss_cls: 0.04315  loss_box_reg: 0.1762  loss_mask: 0.1186  loss_rpn_cls: 0.00136  loss_rpn_loc: 0.01039  time: 0.3169  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:46 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 479  total_loss: 0.4459  loss_cls: 0.05126  loss_box_reg: 0.201  loss_mask: 0.1555  loss_rpn_cls: 0.002501  loss_rpn_loc: 0.0166  time: 0.3187  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:39:53 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 499  total_loss: 0.4772  loss_cls: 0.06038  loss_box_reg: 0.177  loss_mask: 0.1208  loss_rpn_cls: 0.005095  loss_rpn_loc: 0.0229  time: 0.3202  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:00 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 519  total_loss: 0.3912  loss_cls: 0.05269  loss_box_reg: 0.1671  loss_mask: 0.09469  loss_rpn_cls: 0.003547  loss_rpn_loc: 0.02015  time: 0.3213  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:07 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 539  total_loss: 0.3695  loss_cls: 0.0589  loss_box_reg: 0.1597  loss_mask: 0.1305  loss_rpn_cls: 0.002304  loss_rpn_loc: 0.01333  time: 0.3225  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:15 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 559  total_loss: 0.3282  loss_cls: 0.04303  loss_box_reg: 0.1449  loss_mask: 0.1115  loss_rpn_cls: 0.001288  loss_rpn_loc: 0.01296  time: 0.3236  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:21 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 579  total_loss: 0.395  loss_cls: 0.04784  loss_box_reg: 0.1574  loss_mask: 0.1353  loss_rpn_cls: 0.003398  loss_rpn_loc: 0.02141  time: 0.3243  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:29 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 599  total_loss: 0.3822  loss_cls: 0.0531  loss_box_reg: 0.1479  loss_mask: 0.1057  loss_rpn_cls: 0.004622  loss_rpn_loc: 0.02307  time: 0.3254  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:35 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 619  total_loss: 0.2976  loss_cls: 0.03472  loss_box_reg: 0.1266  loss_mask: 0.1075  loss_rpn_cls: 0.006048  loss_rpn_loc: 0.01891  time: 0.3258  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:42 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 639  total_loss: 0.321  loss_cls: 0.04164  loss_box_reg: 0.1365  loss_mask: 0.1169  loss_rpn_cls: 0.002212  loss_rpn_loc: 0.01677  time: 0.3266  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:49 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 659  total_loss: 0.368  loss_cls: 0.03715  loss_box_reg: 0.1569  loss_mask: 0.135  loss_rpn_cls: 0.001849  loss_rpn_loc: 0.01969  time: 0.3272  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:40:56 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 679  total_loss: 0.338  loss_cls: 0.04191  loss_box_reg: 0.1386  loss_mask: 0.1137  loss_rpn_cls: 0.001803  loss_rpn_loc: 0.01439  time: 0.3280  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:41:04 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 699  total_loss: 0.3584  loss_cls: 0.03954  loss_box_reg: 0.1348  loss_mask: 0.1222  loss_rpn_cls: 0.002421  loss_rpn_loc: 0.02011  time: 0.3287  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:41:11 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 719  total_loss: 0.3574  loss_cls: 0.04122  loss_box_reg: 0.1427  loss_mask: 0.1103  loss_rpn_cls: 0.00416  loss_rpn_loc: 0.02297  time: 0.3294  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:41:18 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 739  total_loss: 0.3361  loss_cls: 0.03644  loss_box_reg: 0.1444  loss_mask: 0.119  loss_rpn_cls: 0.002632  loss_rpn_loc: 0.02797  time: 0.3299  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:41:25 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 759  total_loss: 0.317  loss_cls: 0.03954  loss_box_reg: 0.1356  loss_mask: 0.1138  loss_rpn_cls: 0.00194  loss_rpn_loc: 0.0119  time: 0.3305  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:41:32 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.2907  loss_cls: 0.0372  loss_box_reg: 0.1386  loss_mask: 0.09859  loss_rpn_cls: 0.001877  loss_rpn_loc: 0.01652  time: 0.3313  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:41:40 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.367  loss_cls: 0.04158  loss_box_reg: 0.1367  loss_mask: 0.1187  loss_rpn_cls: 0.001543  loss_rpn_loc: 0.01425  time: 0.3319  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:41:40 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:24 (0.3319 s / it)\n",
      "\u001b[32m[10/21 07:41:40 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:26 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='EC4RVYT_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:41:40 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:41:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:41:40 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:41:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:41:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1051 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 52/126. 0.1106 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 93/126. 0.1109 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.942373 (0.123491 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.111234 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EC4RVYT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.486 | 40.042 | 20.830 | 11.311 | 38.009 | 23.518 |\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 33.899 | cushion    | 24.277 | door       | 16.481 |\n",
      "| indoor-plant | 17.020 | sofa       | 31.587 | table      | 5.655  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.108\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.563 | 31.243 | 10.805 | 6.761 | 27.500 | 18.751 |\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 14.830 | cushion    | 23.300 | door       | 14.761 |\n",
      "| indoor-plant | 10.001 | sofa       | 24.485 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='EC4RVYT0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:41:56 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:41:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:41:56 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:41:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:41:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1262 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 07:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1081 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 07:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 96/355. 0.1049 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 07:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 138/355. 0.1048 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 07:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 179/355. 0.1062 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 07:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.1035 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 07:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 263/355. 0.1032 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 303/355. 0.1026 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:42:39 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.1034 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:42:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.999082 (0.122855 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:42:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.103196 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:42:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:42:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EC4RVYT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:42:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:42:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.396\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 20.948 | 39.574 | 18.640 | 9.714 | 21.748 | 17.772 |\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.460 | cushion    | 37.615 | door       | 3.351 |\n",
      "| indoor-plant | 24.782 | sofa       | 44.311 | table      | 0.167 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.374\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.242 | 37.407 | 21.842 | 11.001 | 23.955 | 18.165 |\n",
      "\u001b[32m[10/21 07:42:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.522 | cushion    | 49.169 | door       | 3.812 |\n",
      "| indoor-plant | 21.326 | sofa       | 38.623 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='EC4RVYT1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:42:42 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:42:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:42:42 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:42:42 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:42:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 14/355. 0.0946 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1122 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 07:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 93/355. 0.1112 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 07:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 136/355. 0.1088 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 07:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 185/355. 0.1048 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 07:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 227/355. 0.1033 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 07:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.1032 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 307/355. 0.1026 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 347/355. 0.1036 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.480362 (0.121372 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.103280 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EC4RVYT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.059 | 39.256 | 17.508 | 10.612 | 21.765 | 16.700 |\n",
      "\u001b[32m[10/21 07:43:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.828 | cushion    | 39.185 | door       | 2.751 |\n",
      "| indoor-plant | 23.266 | sofa       | 44.177 | table      | 0.146 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:43:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:43:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 07:43:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:43:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\n",
      "\u001b[32m[10/21 07:43:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.762 | 38.651 | 21.502 | 11.000 | 25.925 | 17.460 |\n",
      "\u001b[32m[10/21 07:43:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.034 | cushion    | 48.731 | door       | 3.345 |\n",
      "| indoor-plant | 20.455 | sofa       | 43.007 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='EC4RVYT2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:43:26 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:43:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:43:26 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:43:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:43:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:43:29 d2.evaluation.evaluator]: \u001b[0mInference done 20/355. 0.1089 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 07:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 58/355. 0.1133 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 07:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 100/355. 0.1114 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 07:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 141/355. 0.1103 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 07:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 191/355. 0.1048 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 07:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.1048 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 07:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.1051 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 304/355. 0.1051 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 07:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.1062 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 07:44:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.286971 (0.126534 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:44:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.106222 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:44:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:44:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EC4RVYT0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:44:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:44:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.298\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.816 | 40.875 | 18.738 | 10.542 | 21.241 | 17.311 |\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.019 | cushion    | 40.052 | door       | 3.721 |\n",
      "| indoor-plant | 24.086 | sofa       | 46.851 | table      | 0.167 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.277\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.273 | 39.229 | 22.721 | 10.968 | 24.322 | 18.380 |\n",
      "\u001b[32m[10/21 07:44:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.865 | cushion    | 49.857 | door       | 4.565 |\n",
      "| indoor-plant | 21.346 | sofa       | 43.003 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [39.57403174910015, 39.25615374975103, 40.87531924791015]}, 'segm': {'AP50': [37.40688571346276, 38.65134908937271, 39.22902435299963]}}\n",
      "dataset_name CSUGT9G\n",
      "SOLVER PARAMS (500, 100, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='CSUGT9G_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/CSUGT9G0\n",
      "output_aug/500/CSUGT9G0\n",
      "\u001b[32m[10/21 07:44:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:44:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:44:13 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:44:13 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:44:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:44:13 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:44:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:44:13 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:44:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:44:20 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 19  total_loss: 2.329  loss_cls: 0.9027  loss_box_reg: 0.5893  loss_mask: 0.6615  loss_rpn_cls: 0.07694  loss_rpn_loc: 0.02184  time: 0.3137  data_time: 0.0177  lr: 0.00095405  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:44:27 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 39  total_loss: 1.629  loss_cls: 0.416  loss_box_reg: 0.5798  loss_mask: 0.4861  loss_rpn_cls: 0.0394  loss_rpn_loc: 0.02157  time: 0.3103  data_time: 0.0040  lr: 0.001953  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:44:33 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 59  total_loss: 1.178  loss_cls: 0.2701  loss_box_reg: 0.4706  loss_mask: 0.2996  loss_rpn_cls: 0.02168  loss_rpn_loc: 0.0283  time: 0.3137  data_time: 0.0040  lr: 0.002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:44:38 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 79  total_loss: 1.074  loss_cls: 0.1684  loss_box_reg: 0.4344  loss_mask: 0.2693  loss_rpn_cls: 0.0175  loss_rpn_loc: 0.02691  time: 0.3007  data_time: 0.0040  lr: 0.0039511  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:44:44 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 99  total_loss: 0.8585  loss_cls: 0.1391  loss_box_reg: 0.2614  loss_mask: 0.2641  loss_rpn_cls: 0.0239  loss_rpn_loc: 0.03927  time: 0.2979  data_time: 0.0042  lr: 0.0049501  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:44:51 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 119  total_loss: 0.8323  loss_cls: 0.1073  loss_box_reg: 0.2957  loss_mask: 0.2621  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.03448  time: 0.3073  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:44:58 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 139  total_loss: 0.7218  loss_cls: 0.08714  loss_box_reg: 0.304  loss_mask: 0.208  loss_rpn_cls: 0.009201  loss_rpn_loc: 0.03484  time: 0.3165  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:06 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 159  total_loss: 0.6161  loss_cls: 0.09138  loss_box_reg: 0.2459  loss_mask: 0.1568  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.04503  time: 0.3218  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:13 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 179  total_loss: 0.5954  loss_cls: 0.08722  loss_box_reg: 0.2516  loss_mask: 0.1986  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.02975  time: 0.3252  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:20 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 199  total_loss: 0.5446  loss_cls: 0.05701  loss_box_reg: 0.2308  loss_mask: 0.1521  loss_rpn_cls: 0.00868  loss_rpn_loc: 0.02478  time: 0.3284  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:27 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 219  total_loss: 0.5107  loss_cls: 0.06265  loss_box_reg: 0.2583  loss_mask: 0.1457  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.02017  time: 0.3309  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:34 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 239  total_loss: 0.5031  loss_cls: 0.06067  loss_box_reg: 0.2335  loss_mask: 0.1544  loss_rpn_cls: 0.007752  loss_rpn_loc: 0.02443  time: 0.3325  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:41 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 259  total_loss: 0.4781  loss_cls: 0.06059  loss_box_reg: 0.2325  loss_mask: 0.1617  loss_rpn_cls: 0.005443  loss_rpn_loc: 0.01652  time: 0.3341  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:48 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 279  total_loss: 0.4429  loss_cls: 0.06058  loss_box_reg: 0.2032  loss_mask: 0.1342  loss_rpn_cls: 0.004437  loss_rpn_loc: 0.02036  time: 0.3359  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:45:55 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 299  total_loss: 0.459  loss_cls: 0.06178  loss_box_reg: 0.1837  loss_mask: 0.1632  loss_rpn_cls: 0.003455  loss_rpn_loc: 0.02531  time: 0.3371  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:02 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 319  total_loss: 0.4911  loss_cls: 0.06924  loss_box_reg: 0.2182  loss_mask: 0.1476  loss_rpn_cls: 0.007501  loss_rpn_loc: 0.02028  time: 0.3383  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:09 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 339  total_loss: 0.4604  loss_cls: 0.05843  loss_box_reg: 0.178  loss_mask: 0.1395  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.02615  time: 0.3391  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:17 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 359  total_loss: 0.3912  loss_cls: 0.05625  loss_box_reg: 0.1873  loss_mask: 0.1118  loss_rpn_cls: 0.002493  loss_rpn_loc: 0.01698  time: 0.3403  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:24 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 379  total_loss: 0.3507  loss_cls: 0.03803  loss_box_reg: 0.1664  loss_mask: 0.1261  loss_rpn_cls: 0.002472  loss_rpn_loc: 0.01163  time: 0.3411  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:31 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 399  total_loss: 0.3787  loss_cls: 0.04723  loss_box_reg: 0.1788  loss_mask: 0.1307  loss_rpn_cls: 0.002339  loss_rpn_loc: 0.01293  time: 0.3424  data_time: 0.0043  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:38 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 419  total_loss: 0.3704  loss_cls: 0.04614  loss_box_reg: 0.1823  loss_mask: 0.1188  loss_rpn_cls: 0.002999  loss_rpn_loc: 0.0184  time: 0.3432  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:45 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 439  total_loss: 0.3961  loss_cls: 0.04563  loss_box_reg: 0.1743  loss_mask: 0.1262  loss_rpn_cls: 0.001863  loss_rpn_loc: 0.01941  time: 0.3437  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:46:53 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 459  total_loss: 0.416  loss_cls: 0.06063  loss_box_reg: 0.168  loss_mask: 0.0923  loss_rpn_cls: 0.00319  loss_rpn_loc: 0.02189  time: 0.3440  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:47:00 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.4362  loss_cls: 0.04812  loss_box_reg: 0.1913  loss_mask: 0.1192  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.02867  time: 0.3444  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:47:08 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.3732  loss_cls: 0.03798  loss_box_reg: 0.159  loss_mask: 0.09419  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.02053  time: 0.3446  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:47:08 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:51 (0.3446 s / it)\n",
      "\u001b[32m[10/21 07:47:08 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:52 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='CSUGT9G_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:47:08 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:47:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:47:08 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:47:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:47:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1123 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 49/126. 0.1181 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 07:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 88/126. 0.1170 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:47:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.034004 (0.132512 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:47:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.116625 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CSUGT9G0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.428\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.664 | 36.262 | 16.047 | 9.301 | 30.573 | 21.108 |\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.678 | cushion    | 19.408 | door       | 15.926 |\n",
      "| indoor-plant | 16.757 | sofa       | 28.935 | table      | 4.276  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.650 | 27.707 | 8.683  | 4.818 | 21.667 | 29.427 |\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 13.868 | cushion    | 16.192 | door       | 15.672 |\n",
      "| indoor-plant | 10.873 | sofa       | 19.297 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='CSUGT9G0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:47:25 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:47:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:47:25 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:47:25 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:47:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0631 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 07:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.0990 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 07:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.1030 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 07:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.1043 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 07:47:47 d2.evaluation.evaluator]: \u001b[0mInference done 177/355. 0.1041 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 07:47:52 d2.evaluation.evaluator]: \u001b[0mInference done 217/355. 0.1058 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 07:47:57 d2.evaluation.evaluator]: \u001b[0mInference done 257/355. 0.1055 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 07:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 295/355. 0.1057 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 07:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 337/355. 0.1049 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 07:48:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.605162 (0.124586 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:48:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.105277 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CSUGT9G0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 16.818 | 33.435 | 15.134 | 13.373 | 20.388 | 7.258 |\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.899 | cushion    | 35.240 | door       | 3.183 |\n",
      "| indoor-plant | 32.260 | sofa       | 17.019 | table      | 0.304 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 07:48:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:48:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
      "\u001b[32m[10/21 07:48:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.154 | 27.150 | 10.133 | 8.957 | 16.151 | 10.830 |\n",
      "\u001b[32m[10/21 07:48:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.959 | cushion    | 35.973 | door       | 3.267 |\n",
      "| indoor-plant | 11.777 | sofa       | 9.949  | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='CSUGT9G1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:48:11 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:48:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:48:11 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:48:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:48:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:48:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0998 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 07:48:18 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1073 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 07:48:23 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.1073 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 07:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 135/355. 0.1043 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 07:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 179/355. 0.1031 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 07:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 219/355. 0.1033 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 07:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 258/355. 0.1028 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 296/355. 0.1023 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 07:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 334/355. 0.1030 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.291817 (0.126548 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.103886 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CSUGT9G0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.216\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.254\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 17.612 | 34.301 | 16.353 | 13.828 | 21.620 | 6.714 |\n",
      "\u001b[32m[10/21 07:48:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.609 | cushion    | 35.961 | door       | 3.678 |\n",
      "| indoor-plant | 30.790 | sofa       | 21.385 | table      | 0.249 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:48:57 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:48:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:48:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:48:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n",
      "\u001b[32m[10/21 07:48:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 12.298 | 27.855 | 10.378 | 8.386 | 17.430 | 9.926 |\n",
      "\u001b[32m[10/21 07:48:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 11.544 | cushion    | 35.472 | door       | 4.015 |\n",
      "| indoor-plant | 11.020 | sofa       | 11.740 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='CSUGT9G2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:48:57 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:48:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:48:57 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:48:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:48:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:48:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0970 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 07:49:04 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1118 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 07:49:09 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.1089 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 07:49:14 d2.evaluation.evaluator]: \u001b[0mInference done 133/355. 0.1027 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 07:49:19 d2.evaluation.evaluator]: \u001b[0mInference done 173/355. 0.1058 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 07:49:24 d2.evaluation.evaluator]: \u001b[0mInference done 213/355. 0.1048 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 07:49:29 d2.evaluation.evaluator]: \u001b[0mInference done 251/355. 0.1046 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 286/355. 0.1044 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 07:49:39 d2.evaluation.evaluator]: \u001b[0mInference done 321/355. 0.1043 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:49:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.967346 (0.131335 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:49:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.105111 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:49:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:49:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CSUGT9G0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:49:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:49:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.361\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 17.808 | 36.078 | 16.483 | 13.293 | 21.277 | 7.301 |\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.760 | cushion    | 33.438 | door       | 3.686 |\n",
      "| indoor-plant | 31.117 | sofa       | 24.505 | table      | 0.343 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.345 | 28.350 | 10.327 | 7.929 | 16.529 | 10.700 |\n",
      "\u001b[32m[10/21 07:49:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.046 | cushion    | 33.245 | door       | 3.993 |\n",
      "| indoor-plant | 12.005 | sofa       | 12.780 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [33.435151368450754, 34.30143977956844, 36.0775242149159]}, 'segm': {'AP50': [27.149927961197378, 27.855335572101698, 28.35024297671135]}}\n",
      "dataset_name 9R6SNFS\n",
      "SOLVER PARAMS (800, 100, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='9R6SNFS_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/9R6SNFS0\n",
      "output_aug/800/9R6SNFS0\n",
      "\u001b[32m[10/21 07:49:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:49:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:49:46 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:49:46 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:49:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:49:46 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:49:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:49:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:49:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:49:54 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 19  total_loss: 2.773  loss_cls: 0.97  loss_box_reg: 0.5996  loss_mask: 0.6782  loss_rpn_cls: 0.09644  loss_rpn_loc: 0.03362  time: 0.3329  data_time: 0.0181  lr: 0.00095405  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:49:59 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 39  total_loss: 1.653  loss_cls: 0.4117  loss_box_reg: 0.5788  loss_mask: 0.5306  loss_rpn_cls: 0.08372  loss_rpn_loc: 0.02615  time: 0.2875  data_time: 0.0043  lr: 0.0019531  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:06 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 59  total_loss: 1.224  loss_cls: 0.2995  loss_box_reg: 0.5519  loss_mask: 0.316  loss_rpn_cls: 0.02305  loss_rpn_loc: 0.0378  time: 0.3103  data_time: 0.0043  lr: 0.002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:13 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 79  total_loss: 1.079  loss_cls: 0.1776  loss_box_reg: 0.4586  loss_mask: 0.3253  loss_rpn_cls: 0.01776  loss_rpn_loc: 0.02724  time: 0.3210  data_time: 0.0040  lr: 0.0039511  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:20 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 99  total_loss: 0.9271  loss_cls: 0.1536  loss_box_reg: 0.3766  loss_mask: 0.2689  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.02946  time: 0.3290  data_time: 0.0042  lr: 0.0049501  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:27 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 119  total_loss: 0.718  loss_cls: 0.1092  loss_box_reg: 0.3379  loss_mask: 0.1843  loss_rpn_cls: 0.01201  loss_rpn_loc: 0.02274  time: 0.3339  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:34 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 139  total_loss: 0.6798  loss_cls: 0.0943  loss_box_reg: 0.2811  loss_mask: 0.1991  loss_rpn_cls: 0.01978  loss_rpn_loc: 0.05154  time: 0.3377  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:42 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 159  total_loss: 0.6861  loss_cls: 0.08647  loss_box_reg: 0.2945  loss_mask: 0.1925  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.05469  time: 0.3400  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:49 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 179  total_loss: 0.5644  loss_cls: 0.07768  loss_box_reg: 0.2502  loss_mask: 0.1453  loss_rpn_cls: 0.03871  loss_rpn_loc: 0.02863  time: 0.3412  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:50:56 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 199  total_loss: 0.6453  loss_cls: 0.09298  loss_box_reg: 0.2726  loss_mask: 0.1453  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.03474  time: 0.3426  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:03 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 219  total_loss: 0.4919  loss_cls: 0.06337  loss_box_reg: 0.2114  loss_mask: 0.1448  loss_rpn_cls: 0.008519  loss_rpn_loc: 0.02597  time: 0.3437  data_time: 0.0043  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:10 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 239  total_loss: 0.5444  loss_cls: 0.07414  loss_box_reg: 0.2158  loss_mask: 0.1653  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.03778  time: 0.3441  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:17 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 259  total_loss: 0.468  loss_cls: 0.05266  loss_box_reg: 0.1926  loss_mask: 0.1356  loss_rpn_cls: 0.01675  loss_rpn_loc: 0.02747  time: 0.3447  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:24 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 279  total_loss: 0.4506  loss_cls: 0.05883  loss_box_reg: 0.1929  loss_mask: 0.1468  loss_rpn_cls: 0.007362  loss_rpn_loc: 0.02774  time: 0.3451  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:31 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 299  total_loss: 0.43  loss_cls: 0.0567  loss_box_reg: 0.1679  loss_mask: 0.1316  loss_rpn_cls: 0.006328  loss_rpn_loc: 0.02271  time: 0.3455  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:38 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 319  total_loss: 0.3945  loss_cls: 0.05166  loss_box_reg: 0.2019  loss_mask: 0.1175  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.01781  time: 0.3460  data_time: 0.0043  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:45 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 339  total_loss: 0.4138  loss_cls: 0.04843  loss_box_reg: 0.1729  loss_mask: 0.1275  loss_rpn_cls: 0.006447  loss_rpn_loc: 0.0136  time: 0.3464  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:52 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 359  total_loss: 0.3581  loss_cls: 0.06172  loss_box_reg: 0.1605  loss_mask: 0.09598  loss_rpn_cls: 0.004103  loss_rpn_loc: 0.01635  time: 0.3467  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:51:59 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 379  total_loss: 0.4575  loss_cls: 0.05407  loss_box_reg: 0.1803  loss_mask: 0.1462  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.01805  time: 0.3473  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:06 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 399  total_loss: 0.4076  loss_cls: 0.04409  loss_box_reg: 0.1782  loss_mask: 0.1299  loss_rpn_cls: 0.008075  loss_rpn_loc: 0.02915  time: 0.3480  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:14 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 419  total_loss: 0.3526  loss_cls: 0.0395  loss_box_reg: 0.1669  loss_mask: 0.1131  loss_rpn_cls: 0.004057  loss_rpn_loc: 0.01555  time: 0.3486  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:21 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 439  total_loss: 0.391  loss_cls: 0.04149  loss_box_reg: 0.1797  loss_mask: 0.1072  loss_rpn_cls: 0.002702  loss_rpn_loc: 0.01348  time: 0.3488  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:28 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 459  total_loss: 0.3719  loss_cls: 0.05681  loss_box_reg: 0.1745  loss_mask: 0.1222  loss_rpn_cls: 0.005988  loss_rpn_loc: 0.0253  time: 0.3490  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:35 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 479  total_loss: 0.3523  loss_cls: 0.03672  loss_box_reg: 0.1581  loss_mask: 0.1105  loss_rpn_cls: 0.002315  loss_rpn_loc: 0.01156  time: 0.3493  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:42 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 499  total_loss: 0.4098  loss_cls: 0.05635  loss_box_reg: 0.2015  loss_mask: 0.09284  loss_rpn_cls: 0.002639  loss_rpn_loc: 0.0209  time: 0.3498  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:50 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 519  total_loss: 0.3935  loss_cls: 0.04119  loss_box_reg: 0.1643  loss_mask: 0.1265  loss_rpn_cls: 0.00489  loss_rpn_loc: 0.01587  time: 0.3504  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:52:57 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 539  total_loss: 0.3826  loss_cls: 0.04634  loss_box_reg: 0.1714  loss_mask: 0.1055  loss_rpn_cls: 0.002767  loss_rpn_loc: 0.01534  time: 0.3508  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:04 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 559  total_loss: 0.3661  loss_cls: 0.04721  loss_box_reg: 0.1645  loss_mask: 0.1198  loss_rpn_cls: 0.004359  loss_rpn_loc: 0.02224  time: 0.3510  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:11 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 579  total_loss: 0.3617  loss_cls: 0.03836  loss_box_reg: 0.1544  loss_mask: 0.1116  loss_rpn_cls: 0.004372  loss_rpn_loc: 0.02723  time: 0.3511  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:18 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 599  total_loss: 0.3373  loss_cls: 0.05119  loss_box_reg: 0.1602  loss_mask: 0.08468  loss_rpn_cls: 0.003137  loss_rpn_loc: 0.01559  time: 0.3513  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:25 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 0.3426  loss_cls: 0.04543  loss_box_reg: 0.166  loss_mask: 0.1053  loss_rpn_cls: 0.002697  loss_rpn_loc: 0.0157  time: 0.3514  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:32 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 0.3415  loss_cls: 0.04824  loss_box_reg: 0.1479  loss_mask: 0.09126  loss_rpn_cls: 0.001643  loss_rpn_loc: 0.01805  time: 0.3518  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:40 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 0.3967  loss_cls: 0.05707  loss_box_reg: 0.1867  loss_mask: 0.1163  loss_rpn_cls: 0.002274  loss_rpn_loc: 0.01878  time: 0.3521  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:47 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 0.4506  loss_cls: 0.05645  loss_box_reg: 0.1548  loss_mask: 0.1231  loss_rpn_cls: 0.004699  loss_rpn_loc: 0.02757  time: 0.3521  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:53:54 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 0.3558  loss_cls: 0.04393  loss_box_reg: 0.1571  loss_mask: 0.1141  loss_rpn_cls: 0.004118  loss_rpn_loc: 0.01679  time: 0.3523  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:54:01 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 0.3643  loss_cls: 0.04069  loss_box_reg: 0.1756  loss_mask: 0.1012  loss_rpn_cls: 0.002889  loss_rpn_loc: 0.01925  time: 0.3525  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:54:08 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.3608  loss_cls: 0.05416  loss_box_reg: 0.1541  loss_mask: 0.08358  loss_rpn_cls: 0.003167  loss_rpn_loc: 0.01692  time: 0.3526  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:54:16 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 0.3442  loss_cls: 0.04036  loss_box_reg: 0.1718  loss_mask: 0.1066  loss_rpn_cls: 0.002664  loss_rpn_loc: 0.02262  time: 0.3529  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:54:23 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.3239  loss_cls: 0.03293  loss_box_reg: 0.1237  loss_mask: 0.08468  loss_rpn_cls: 0.001828  loss_rpn_loc: 0.01698  time: 0.3530  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:54:30 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.337  loss_cls: 0.03529  loss_box_reg: 0.1391  loss_mask: 0.08637  loss_rpn_cls: 0.004038  loss_rpn_loc: 0.02948  time: 0.3523  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:54:30 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:41 (0.3523 s / it)\n",
      "\u001b[32m[10/21 07:54:30 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:42 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='9R6SNFS_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 07:54:30 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 07:54:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:54:30 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:54:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 07:54:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 07:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.0993 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 07:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 53/126. 0.1074 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 07:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 95/126. 0.1065 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.994170 (0.115654 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.103046 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/9R6SNFS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.355\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.024 | 37.273 | 18.610 | 9.288 | 31.282 | 27.176 |\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 22.750 | cushion    | 20.531 | door       | 22.089 |\n",
      "| indoor-plant | 17.502 | sofa       | 26.516 | table      | 4.754  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.778 | 29.293 | 8.487  | 4.378 | 25.348 | 23.044 |\n",
      "\u001b[32m[10/21 07:54:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 12.469 | cushion    | 17.998 | door       | 18.617 |\n",
      "| indoor-plant | 9.299  | sofa       | 18.284 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='9R6SNFS0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 07:54:46 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 07:54:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:54:46 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:54:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 07:54:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1103 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 07:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1151 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 07:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1137 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 07:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.1150 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 07:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.1146 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 07:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.1145 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.1148 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 07:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.1148 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 325/355. 0.1137 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 07:55:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.044625 (0.125842 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:55:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.110322 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/9R6SNFS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 9.042 | 19.711 | 6.683  | 7.513 | 10.573 | 0.797 |\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.023 | cushion    | 21.411 | door       | 1.351 |\n",
      "| indoor-plant | 14.251 | sofa       | 2.851  | table      | 0.366 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.062\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 8.263 | 17.833 | 7.839  | 6.850 | 10.553 | 1.552 |\n",
      "\u001b[32m[10/21 07:55:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.082 | cushion    | 24.214 | door       | 1.542 |\n",
      "| indoor-plant | 10.571 | sofa       | 0.172  | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='9R6SNFS1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 07:55:32 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 07:55:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:55:32 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:55:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 07:55:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1137 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 07:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1127 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 07:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.1137 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 07:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.1132 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 07:55:54 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.1129 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 07:55:59 d2.evaluation.evaluator]: \u001b[0mInference done 210/355. 0.1127 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:56:04 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.1131 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 07:56:09 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.1141 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:56:14 d2.evaluation.evaluator]: \u001b[0mInference done 316/355. 0.1143 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 07:56:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.781334 (0.130804 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:56:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.113274 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:56:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:56:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/9R6SNFS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:56:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:56:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.130\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 9.341 | 20.218 | 7.470  | 7.701 | 10.497 | 1.266 |\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 14.522 | cushion    | 21.596 | door       | 2.543 |\n",
      "| indoor-plant | 13.160 | sofa       | 3.856  | table      | 0.370 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 8.195 | 18.431 | 7.311  | 6.407 | 10.291 | 1.516 |\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.806 | cushion    | 22.864 | door       | 2.989 |\n",
      "| indoor-plant | 10.009 | sofa       | 0.500  | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='9R6SNFS2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 07:56:19 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 07:56:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 07:56:19 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:56:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 07:56:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 07:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1182 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 07:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.1172 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 07:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.1157 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 07:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 129/355. 0.1152 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 07:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.1148 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 07:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 209/355. 0.1141 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 07:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.1146 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 07:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 282/355. 0.1140 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 07:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 321/355. 0.1130 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.671696 (0.130491 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.112761 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/9R6SNFS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.070\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 9.200 | 20.676 | 6.795  | 7.330 | 10.208 | 1.059 |\n",
      "\u001b[32m[10/21 07:57:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 13.429 | cushion    | 22.142 | door       | 1.128 |\n",
      "| indoor-plant | 13.649 | sofa       | 4.506  | table      | 0.346 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 07:57:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 07:57:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 07:57:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 07:57:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.064\n",
      "\u001b[32m[10/21 07:57:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 7.992 | 17.806 | 7.426  | 6.568 | 9.498 | 1.262 |\n",
      "\u001b[32m[10/21 07:57:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 12.331 | cushion    | 24.108 | door       | 1.376 |\n",
      "| indoor-plant | 9.771  | sofa       | 0.369  | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [19.711393557140944, 20.21777095535495, 20.676227958811104]}, 'segm': {'AP50': [17.833211712699963, 18.430768735381275, 17.805781033604347]}}\n",
      "dataset_name A4N09V3\n",
      "SOLVER PARAMS (500, 200, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='A4N09V3_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/A4N09V30\n",
      "output_aug/500/A4N09V30\n",
      "\u001b[32m[10/21 07:57:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 07:57:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 07:57:08 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 07:57:08 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 07:57:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 07:57:08 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 07:57:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 07:57:08 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 07:57:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 07:57:15 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 19  total_loss: 2.589  loss_cls: 1.032  loss_box_reg: 0.6283  loss_mask: 0.6875  loss_rpn_cls: 0.07301  loss_rpn_loc: 0.03736  time: 0.3126  data_time: 0.0166  lr: 0.00047952  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:57:22 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 39  total_loss: 1.721  loss_cls: 0.4355  loss_box_reg: 0.6219  loss_mask: 0.5794  loss_rpn_cls: 0.04237  loss_rpn_loc: 0.02846  time: 0.3333  data_time: 0.0044  lr: 0.00097902  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:57:29 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 59  total_loss: 1.353  loss_cls: 0.2801  loss_box_reg: 0.6101  loss_mask: 0.3995  loss_rpn_cls: 0.01784  loss_rpn_loc: 0.02513  time: 0.3423  data_time: 0.0042  lr: 0.0014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:57:36 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 79  total_loss: 0.7718  loss_cls: 0.1079  loss_box_reg: 0.3623  loss_mask: 0.2287  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.017  time: 0.3456  data_time: 0.0038  lr: 0.001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:57:43 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 99  total_loss: 0.8436  loss_cls: 0.1681  loss_box_reg: 0.3993  loss_mask: 0.2269  loss_rpn_cls: 0.006252  loss_rpn_loc: 0.02521  time: 0.3462  data_time: 0.0037  lr: 0.0024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:57:50 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 119  total_loss: 0.8594  loss_cls: 0.1492  loss_box_reg: 0.3251  loss_mask: 0.22  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.0264  time: 0.3472  data_time: 0.0044  lr: 0.002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:57:57 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 139  total_loss: 0.845  loss_cls: 0.1396  loss_box_reg: 0.3495  loss_mask: 0.2131  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.02675  time: 0.3470  data_time: 0.0040  lr: 0.0034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:04 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 159  total_loss: 0.6506  loss_cls: 0.1121  loss_box_reg: 0.3097  loss_mask: 0.2172  loss_rpn_cls: 0.005171  loss_rpn_loc: 0.01695  time: 0.3473  data_time: 0.0042  lr: 0.003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:11 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 179  total_loss: 0.5862  loss_cls: 0.08679  loss_box_reg: 0.3103  loss_mask: 0.1419  loss_rpn_cls: 0.003625  loss_rpn_loc: 0.01943  time: 0.3477  data_time: 0.0045  lr: 0.0044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:18 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 199  total_loss: 0.7031  loss_cls: 0.1024  loss_box_reg: 0.3038  loss_mask: 0.1544  loss_rpn_cls: 0.003395  loss_rpn_loc: 0.02732  time: 0.3477  data_time: 0.0044  lr: 0.004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:25 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 219  total_loss: 0.6121  loss_cls: 0.08606  loss_box_reg: 0.2654  loss_mask: 0.1621  loss_rpn_cls: 0.006956  loss_rpn_loc: 0.02443  time: 0.3480  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:32 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 239  total_loss: 0.6362  loss_cls: 0.09015  loss_box_reg: 0.2744  loss_mask: 0.1657  loss_rpn_cls: 0.006298  loss_rpn_loc: 0.02695  time: 0.3482  data_time: 0.0044  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:39 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 259  total_loss: 0.6126  loss_cls: 0.07078  loss_box_reg: 0.2462  loss_mask: 0.1511  loss_rpn_cls: 0.02217  loss_rpn_loc: 0.04062  time: 0.3482  data_time: 0.0043  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:46 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 279  total_loss: 0.5693  loss_cls: 0.07349  loss_box_reg: 0.2214  loss_mask: 0.1844  loss_rpn_cls: 0.007609  loss_rpn_loc: 0.02331  time: 0.3488  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:58:53 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 299  total_loss: 0.5451  loss_cls: 0.05375  loss_box_reg: 0.2317  loss_mask: 0.185  loss_rpn_cls: 0.003974  loss_rpn_loc: 0.02313  time: 0.3494  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:00 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 319  total_loss: 0.4409  loss_cls: 0.05267  loss_box_reg: 0.21  loss_mask: 0.1704  loss_rpn_cls: 0.007589  loss_rpn_loc: 0.02189  time: 0.3495  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:07 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 339  total_loss: 0.5102  loss_cls: 0.05822  loss_box_reg: 0.1987  loss_mask: 0.147  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.01749  time: 0.3496  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:14 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 359  total_loss: 0.5064  loss_cls: 0.06003  loss_box_reg: 0.2227  loss_mask: 0.1308  loss_rpn_cls: 0.006361  loss_rpn_loc: 0.02197  time: 0.3500  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:21 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 379  total_loss: 0.4408  loss_cls: 0.07137  loss_box_reg: 0.2124  loss_mask: 0.1397  loss_rpn_cls: 0.006007  loss_rpn_loc: 0.01837  time: 0.3500  data_time: 0.0043  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:29 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 0.3702  loss_cls: 0.04623  loss_box_reg: 0.1709  loss_mask: 0.1079  loss_rpn_cls: 0.004757  loss_rpn_loc: 0.01433  time: 0.3502  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:36 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 0.4076  loss_cls: 0.04488  loss_box_reg: 0.2132  loss_mask: 0.1221  loss_rpn_cls: 0.005934  loss_rpn_loc: 0.02086  time: 0.3501  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:43 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 0.468  loss_cls: 0.06104  loss_box_reg: 0.2009  loss_mask: 0.1405  loss_rpn_cls: 0.00325  loss_rpn_loc: 0.01565  time: 0.3502  data_time: 0.0044  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:50 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 459  total_loss: 0.4076  loss_cls: 0.06689  loss_box_reg: 0.1804  loss_mask: 0.08987  loss_rpn_cls: 0.002077  loss_rpn_loc: 0.01151  time: 0.3504  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 07:59:57 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 479  total_loss: 0.3648  loss_cls: 0.03796  loss_box_reg: 0.1906  loss_mask: 0.1243  loss_rpn_cls: 0.003513  loss_rpn_loc: 0.01436  time: 0.3505  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:00:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.3845  loss_cls: 0.04349  loss_box_reg: 0.1714  loss_mask: 0.1266  loss_rpn_cls: 0.003532  loss_rpn_loc: 0.02476  time: 0.3504  data_time: 0.0044  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:00:05 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:54 (0.3504 s / it)\n",
      "\u001b[32m[10/21 08:00:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:55 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='A4N09V3_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:00:05 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:00:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:00:05 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:00:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:00:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1119 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 47/126. 0.1195 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 84/126. 0.1191 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 08:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 117/126. 0.1220 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.229898 (0.142396 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.122138 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/A4N09V30/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.378\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.167 | 35.413 | 13.750 | 8.641 | 27.741 | 21.963 |\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 23.735 | cushion    | 19.041 | door       | 16.840 |\n",
      "| indoor-plant | 13.307 | sofa       | 26.375 | table      | 3.707  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.126\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.281\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.299\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.028 | 28.555 | 8.521  | 5.773 | 22.599 | 21.441 |\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 13.525 | cushion    | 16.419 | door       | 15.677 |\n",
      "| indoor-plant | 10.790 | sofa       | 21.756 | table      | 0.000  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='A4N09V30_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:00:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:00:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:00:23 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:00:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:00:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 18/355. 0.1294 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 08:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1264 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 08:00:37 d2.evaluation.evaluator]: \u001b[0mInference done 86/355. 0.1264 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 08:00:42 d2.evaluation.evaluator]: \u001b[0mInference done 123/355. 0.1248 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.1238 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 08:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 199/355. 0.1222 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 08:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.1227 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 08:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 262/355. 0.1230 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:01:07 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1234 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.1240 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 355/355. 0.1240 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:01:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:53.047315 (0.151564 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:01:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.123954 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/A4N09V30/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.444 | 31.013 | 17.618 | 7.258 | 18.644 | 13.858 |\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 20.827 | cushion    | 32.101 | door       | 1.091 |\n",
      "| indoor-plant | 13.588 | sofa       | 30.910 | table      | 0.147 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:01:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:01:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 08:01:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:01:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      "\u001b[32m[10/21 08:01:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.341 | 28.849 | 14.852 | 8.595 | 18.970 | 15.479 |\n",
      "\u001b[32m[10/21 08:01:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 19.060 | cushion    | 34.150 | door       | 1.569 |\n",
      "| indoor-plant | 10.890 | sofa       | 26.377 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='A4N09V31_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:01:19 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:01:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:01:19 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:01:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:01:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:01:22 d2.evaluation.evaluator]: \u001b[0mInference done 21/355. 0.1291 s / img. ETA=0:00:54\n",
      "\u001b[32m[10/21 08:01:28 d2.evaluation.evaluator]: \u001b[0mInference done 56/355. 0.1253 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 08:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 100/355. 0.1128 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.1107 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 08:01:43 d2.evaluation.evaluator]: \u001b[0mInference done 181/355. 0.1106 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 08:01:48 d2.evaluation.evaluator]: \u001b[0mInference done 222/355. 0.1078 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 08:01:53 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.1069 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 08:01:58 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1071 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:02:03 d2.evaluation.evaluator]: \u001b[0mInference done 332/355. 0.1063 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.761325 (0.133604 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.106721 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/A4N09V30/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.181\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.141\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.144 | 32.574 | 20.740 | 7.911 | 20.175 | 14.070 |\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.524 | cushion    | 32.733 | door       | 1.478 |\n",
      "| indoor-plant | 12.409 | sofa       | 39.601 | table      | 0.121 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:02:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:02:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.46 seconds.\n",
      "\u001b[32m[10/21 08:02:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:02:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      "\u001b[32m[10/21 08:02:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.886 | 31.837 | 16.188 | 7.821 | 22.113 | 15.009 |\n",
      "\u001b[32m[10/21 08:02:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 19.701 | cushion    | 32.767 | door       | 2.137 |\n",
      "| indoor-plant | 9.811  | sofa       | 36.899 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='A4N09V32_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:02:08 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:02:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:02:08 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:02:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:02:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0929 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 08:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.1057 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 08:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.1104 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 08:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.1087 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 08:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.1053 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 08:02:35 d2.evaluation.evaluator]: \u001b[0mInference done 218/355. 0.1054 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:02:40 d2.evaluation.evaluator]: \u001b[0mInference done 258/355. 0.1043 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.1046 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 08:02:50 d2.evaluation.evaluator]: \u001b[0mInference done 332/355. 0.1052 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 08:02:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.339262 (0.126684 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:02:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.104852 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:02:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:02:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/A4N09V30/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.597 | 32.453 | 19.525 | 7.326 | 20.740 | 14.264 |\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 20.562 | cushion    | 32.767 | door       | 1.601 |\n",
      "| indoor-plant | 12.619 | sofa       | 37.875 | table      | 0.160 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:02:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:02:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 08:02:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:02:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
      "\u001b[32m[10/21 08:02:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.073 | 31.272 | 14.035 | 7.542 | 21.275 | 15.322 |\n",
      "\u001b[32m[10/21 08:02:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.788 | cushion    | 33.709 | door       | 2.115 |\n",
      "| indoor-plant | 9.930  | sofa       | 32.897 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [31.01335997452056, 32.57414304945263, 32.45336008048715]}, 'segm': {'AP50': [28.8485342800494, 31.836576159444206, 31.272081697607167]}}\n",
      "dataset_name MMPSBJ7\n",
      "SOLVER PARAMS (800, 200, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json', name='MMPSBJ7_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/MMPSBJ70\n",
      "output_aug/800/MMPSBJ70\n",
      "\u001b[32m[10/21 08:02:56 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:02:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "76 76\n",
      "\u001b[32m[10/21 08:02:56 d2.data.datasets.coco]: \u001b[0mLoaded 20 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:02:56 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 20 images left.\n",
      "\u001b[32m[10/21 08:02:56 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:02:56 d2.data.common]: \u001b[0mSerializing 20 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:02:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.03 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:02:56 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:02:56 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:03:03 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 19  total_loss: 2.653  loss_cls: 1.048  loss_box_reg: 0.7112  loss_mask: 0.6865  loss_rpn_cls: 0.1482  loss_rpn_loc: 0.05909  time: 0.3429  data_time: 0.0183  lr: 0.00047953  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:09 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 39  total_loss: 1.726  loss_cls: 0.4645  loss_box_reg: 0.6134  loss_mask: 0.5685  loss_rpn_cls: 0.07775  loss_rpn_loc: 0.02978  time: 0.3131  data_time: 0.0041  lr: 0.00097903  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:16 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 59  total_loss: 1.232  loss_cls: 0.2883  loss_box_reg: 0.5835  loss_mask: 0.378  loss_rpn_cls: 0.01969  loss_rpn_loc: 0.02212  time: 0.3219  data_time: 0.0043  lr: 0.0014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:23 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 79  total_loss: 1.09  loss_cls: 0.2167  loss_box_reg: 0.4634  loss_mask: 0.3115  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.0243  time: 0.3285  data_time: 0.0040  lr: 0.001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:30 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 99  total_loss: 0.8289  loss_cls: 0.1507  loss_box_reg: 0.4167  loss_mask: 0.2612  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.02477  time: 0.3335  data_time: 0.0040  lr: 0.0024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:37 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 119  total_loss: 0.8546  loss_cls: 0.12  loss_box_reg: 0.3387  loss_mask: 0.2403  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.06705  time: 0.3341  data_time: 0.0040  lr: 0.002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:43 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 139  total_loss: 0.7063  loss_cls: 0.1035  loss_box_reg: 0.3383  loss_mask: 0.1896  loss_rpn_cls: 0.009428  loss_rpn_loc: 0.02986  time: 0.3321  data_time: 0.0041  lr: 0.0034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:50 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 159  total_loss: 0.7026  loss_cls: 0.1016  loss_box_reg: 0.3266  loss_mask: 0.1921  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.02116  time: 0.3334  data_time: 0.0039  lr: 0.003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:03:55 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 179  total_loss: 0.6874  loss_cls: 0.1229  loss_box_reg: 0.3136  loss_mask: 0.1892  loss_rpn_cls: 0.00686  loss_rpn_loc: 0.02076  time: 0.3238  data_time: 0.0039  lr: 0.0044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:02 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 199  total_loss: 0.5153  loss_cls: 0.07405  loss_box_reg: 0.2593  loss_mask: 0.183  loss_rpn_cls: 0.006433  loss_rpn_loc: 0.02796  time: 0.3271  data_time: 0.0042  lr: 0.004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:09 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 219  total_loss: 0.5571  loss_cls: 0.05675  loss_box_reg: 0.2197  loss_mask: 0.1354  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.01889  time: 0.3291  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:16 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 239  total_loss: 0.5247  loss_cls: 0.07835  loss_box_reg: 0.2029  loss_mask: 0.129  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.03267  time: 0.3304  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:23 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 259  total_loss: 0.5734  loss_cls: 0.07146  loss_box_reg: 0.223  loss_mask: 0.1687  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.03243  time: 0.3322  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:30 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 279  total_loss: 0.5828  loss_cls: 0.05973  loss_box_reg: 0.2345  loss_mask: 0.191  loss_rpn_cls: 0.006461  loss_rpn_loc: 0.02568  time: 0.3343  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:37 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 299  total_loss: 0.6011  loss_cls: 0.07462  loss_box_reg: 0.2493  loss_mask: 0.1956  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.02544  time: 0.3357  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:44 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 319  total_loss: 0.5955  loss_cls: 0.08549  loss_box_reg: 0.2352  loss_mask: 0.1858  loss_rpn_cls: 0.007221  loss_rpn_loc: 0.02234  time: 0.3367  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:52 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 339  total_loss: 0.4994  loss_cls: 0.07334  loss_box_reg: 0.2193  loss_mask: 0.151  loss_rpn_cls: 0.007512  loss_rpn_loc: 0.02022  time: 0.3381  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:04:59 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 359  total_loss: 0.4865  loss_cls: 0.06761  loss_box_reg: 0.2217  loss_mask: 0.1372  loss_rpn_cls: 0.005235  loss_rpn_loc: 0.02573  time: 0.3393  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:06 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 379  total_loss: 0.4364  loss_cls: 0.05841  loss_box_reg: 0.1654  loss_mask: 0.1231  loss_rpn_cls: 0.004794  loss_rpn_loc: 0.02756  time: 0.3405  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:13 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 399  total_loss: 0.4675  loss_cls: 0.062  loss_box_reg: 0.184  loss_mask: 0.1264  loss_rpn_cls: 0.007379  loss_rpn_loc: 0.03831  time: 0.3407  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:20 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 419  total_loss: 0.429  loss_cls: 0.05114  loss_box_reg: 0.2085  loss_mask: 0.1268  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.02636  time: 0.3413  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:27 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 439  total_loss: 0.4193  loss_cls: 0.05132  loss_box_reg: 0.1723  loss_mask: 0.1266  loss_rpn_cls: 0.009739  loss_rpn_loc: 0.03115  time: 0.3421  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:35 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 459  total_loss: 0.4612  loss_cls: 0.04966  loss_box_reg: 0.1751  loss_mask: 0.1439  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.02847  time: 0.3430  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:42 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 479  total_loss: 0.438  loss_cls: 0.05243  loss_box_reg: 0.2052  loss_mask: 0.1193  loss_rpn_cls: 0.007805  loss_rpn_loc: 0.02343  time: 0.3434  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:49 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 499  total_loss: 0.4398  loss_cls: 0.04904  loss_box_reg: 0.1951  loss_mask: 0.1485  loss_rpn_cls: 0.007126  loss_rpn_loc: 0.02609  time: 0.3439  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:05:56 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 519  total_loss: 0.4228  loss_cls: 0.05206  loss_box_reg: 0.1887  loss_mask: 0.1182  loss_rpn_cls: 0.004271  loss_rpn_loc: 0.03002  time: 0.3449  data_time: 0.0043  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:03 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 539  total_loss: 0.3797  loss_cls: 0.05359  loss_box_reg: 0.1633  loss_mask: 0.105  loss_rpn_cls: 0.003594  loss_rpn_loc: 0.02082  time: 0.3456  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:11 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 559  total_loss: 0.3386  loss_cls: 0.03946  loss_box_reg: 0.1409  loss_mask: 0.09578  loss_rpn_cls: 0.007525  loss_rpn_loc: 0.02447  time: 0.3461  data_time: 0.0042  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:18 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 579  total_loss: 0.398  loss_cls: 0.04828  loss_box_reg: 0.1624  loss_mask: 0.1214  loss_rpn_cls: 0.005894  loss_rpn_loc: 0.02729  time: 0.3465  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:25 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 599  total_loss: 0.3558  loss_cls: 0.03996  loss_box_reg: 0.1621  loss_mask: 0.1105  loss_rpn_cls: 0.003283  loss_rpn_loc: 0.01505  time: 0.3470  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:32 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 619  total_loss: 0.3688  loss_cls: 0.0453  loss_box_reg: 0.1628  loss_mask: 0.1183  loss_rpn_cls: 0.003534  loss_rpn_loc: 0.02573  time: 0.3471  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:39 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 639  total_loss: 0.3415  loss_cls: 0.03945  loss_box_reg: 0.1511  loss_mask: 0.09523  loss_rpn_cls: 0.002224  loss_rpn_loc: 0.01193  time: 0.3475  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:45 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 659  total_loss: 0.3429  loss_cls: 0.03342  loss_box_reg: 0.1576  loss_mask: 0.09966  loss_rpn_cls: 0.002301  loss_rpn_loc: 0.01798  time: 0.3464  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:52 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 679  total_loss: 0.3671  loss_cls: 0.04517  loss_box_reg: 0.1732  loss_mask: 0.1231  loss_rpn_cls: 0.002412  loss_rpn_loc: 0.01275  time: 0.3465  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:06:59 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 699  total_loss: 0.4053  loss_cls: 0.04126  loss_box_reg: 0.16  loss_mask: 0.122  loss_rpn_cls: 0.003731  loss_rpn_loc: 0.01839  time: 0.3458  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:07:06 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 719  total_loss: 0.3366  loss_cls: 0.03909  loss_box_reg: 0.1422  loss_mask: 0.1055  loss_rpn_cls: 0.00274  loss_rpn_loc: 0.01754  time: 0.3454  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:07:12 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 739  total_loss: 0.3283  loss_cls: 0.04122  loss_box_reg: 0.1459  loss_mask: 0.09399  loss_rpn_cls: 0.002666  loss_rpn_loc: 0.02438  time: 0.3452  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:07:19 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 759  total_loss: 0.3024  loss_cls: 0.03602  loss_box_reg: 0.1466  loss_mask: 0.1024  loss_rpn_cls: 0.005115  loss_rpn_loc: 0.01669  time: 0.3447  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:07:26 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.3701  loss_cls: 0.04173  loss_box_reg: 0.1564  loss_mask: 0.09232  loss_rpn_cls: 0.003211  loss_rpn_loc: 0.02408  time: 0.3445  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:07:33 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.3816  loss_cls: 0.03862  loss_box_reg: 0.1514  loss_mask: 0.0771  loss_rpn_cls: 0.002911  loss_rpn_loc: 0.01804  time: 0.3439  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:07:33 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:34 (0.3439 s / it)\n",
      "\u001b[32m[10/21 08:07:33 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:35 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='MMPSBJ7_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:07:33 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:07:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:07:33 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:07:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:07:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:07:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.0974 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:07:39 d2.evaluation.evaluator]: \u001b[0mInference done 52/126. 0.1083 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:07:45 d2.evaluation.evaluator]: \u001b[0mInference done 103/126. 0.0981 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.754122 (0.113670 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.101887 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/MMPSBJ70/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.363\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.182\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.488 | 36.295 | 18.173 | 7.845 | 32.887 | 22.890 |\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 24.909 | cushion    | 15.496 | door       | 21.169 |\n",
      "| indoor-plant | 19.038 | sofa       | 30.133 | table      | 6.180  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.132\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.372 | 27.705 | 8.766  | 4.180 | 19.936 | 20.207 |\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 12.230 | cushion    | 15.525 | door       | 18.104 |\n",
      "| indoor-plant | 8.944  | sofa       | 19.327 | table      | 0.099  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='MMPSBJ70_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:07:48 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:07:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:07:48 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:07:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:07:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.0945 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 08:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.1033 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 08:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 93/355. 0.1084 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 08:08:05 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.1096 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 08:08:10 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.1106 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 08:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 215/355. 0.1106 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 08:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 249/355. 0.1115 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.1110 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 332/355. 0.1082 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 08:08:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.413965 (0.126897 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:08:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.108444 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:08:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:08:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/MMPSBJ70/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:08:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:08:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.039 | 31.492 | 9.543  | 5.096 | 17.482 | 10.819 |\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 20.675 | cushion    | 19.145 | door       | 0.654 |\n",
      "| indoor-plant | 18.326 | sofa       | 25.123 | table      | 0.313 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.216\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.381 | 31.030 | 11.505 | 6.207 | 18.686 | 15.444 |\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.536 | cushion    | 30.335 | door       | 0.866 |\n",
      "| indoor-plant | 15.695 | sofa       | 23.853 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='MMPSBJ71_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:08:34 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:08:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:08:34 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:08:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:08:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:08:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1034 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 08:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1052 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 08:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1104 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 08:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.1100 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 08:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.1109 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 08:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.1116 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 08:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.1115 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.1105 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.1064 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 08:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.210275 (0.123458 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:09:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.105885 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/MMPSBJ70/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.682 | 30.873 | 8.473  | 4.983 | 18.441 | 10.093 |\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 22.106 | cushion    | 19.640 | door       | 0.967 |\n",
      "| indoor-plant | 16.887 | sofa       | 22.152 | table      | 0.337 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.191\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 13.726 | 30.746 | 9.793  | 6.076 | 19.074 | 14.767 |\n",
      "\u001b[32m[10/21 08:09:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.227 | cushion    | 31.113 | door       | 1.231 |\n",
      "| indoor-plant | 14.094 | sofa       | 19.688 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='MMPSBJ72_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:09:20 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:09:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:09:20 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:09:20 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:09:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1232 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 08:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1259 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 08:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.1245 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 08:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 120/355. 0.1242 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 08:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.1228 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 08:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 197/355. 0.1225 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 08:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.1219 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 08:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 264/355. 0.1227 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 08:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 298/355. 0.1229 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 334/355. 0.1228 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.498371 (0.141424 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.123006 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/MMPSBJ70/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.223\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.727 | 33.460 | 9.793  | 4.658 | 18.674 | 11.957 |\n",
      "\u001b[32m[10/21 08:10:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 21.004 | cushion    | 19.227 | door       | 0.777 |\n",
      "| indoor-plant | 18.232 | sofa       | 28.778 | table      | 0.342 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:10:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:10:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 08:10:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:10:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.224\n",
      "\u001b[32m[10/21 08:10:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.304 | 33.033 | 9.590  | 5.964 | 19.182 | 16.087 |\n",
      "\u001b[32m[10/21 08:10:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 15.551 | cushion    | 30.221 | door       | 1.044 |\n",
      "| indoor-plant | 15.955 | sofa       | 23.055 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [31.491859398559967, 30.873400832000257, 33.460298042144046]}, 'segm': {'AP50': [31.03031135069159, 30.745977472070813, 33.033241247522064]}}\n",
      "dataset_name UUYVNIH\n",
      "SOLVER PARAMS (500, 100, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='UUYVNIH_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/UUYVNIH0\n",
      "output_aug/500/UUYVNIH0\n",
      "\u001b[32m[10/21 08:10:12 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:10:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:10:12 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:10:12 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:10:12 d2.data.build]: \u001b[0mDistribution of instances among all 6 categories:\n",
      "\u001b[36m|   category   | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:------------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    chair     | 16           |  cushion   | 23           |    door    | 20           |\n",
      "| indoor-plant | 20           |    sofa    | 9            |   table    | 13           |\n",
      "|              |              |            |              |            |              |\n",
      "|    total     | 101          |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/21 08:10:12 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:10:12 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:10:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:10:12 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:10:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:10:20 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 19  total_loss: 3.943  loss_cls: 1.81  loss_box_reg: 0.8665  loss_mask: 0.6916  loss_rpn_cls: 0.4592  loss_rpn_loc: 0.1308  time: 0.3733  data_time: 0.0188  lr: 1.9081e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:10:28 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 39  total_loss: 3.448  loss_cls: 1.511  loss_box_reg: 0.8485  loss_mask: 0.6878  loss_rpn_cls: 0.2114  loss_rpn_loc: 0.2026  time: 0.3723  data_time: 0.0042  lr: 3.9061e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:10:35 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 59  total_loss: 2.894  loss_cls: 1.044  loss_box_reg: 0.9  loss_mask: 0.6799  loss_rpn_cls: 0.08726  loss_rpn_loc: 0.1225  time: 0.3664  data_time: 0.0042  lr: 5.9041e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:10:42 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 79  total_loss: 2.595  loss_cls: 0.8552  loss_box_reg: 0.8775  loss_mask: 0.6686  loss_rpn_cls: 0.06416  loss_rpn_loc: 0.08744  time: 0.3656  data_time: 0.0043  lr: 7.9021e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:10:49 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 99  total_loss: 2.507  loss_cls: 0.7871  loss_box_reg: 0.8666  loss_mask: 0.6543  loss_rpn_cls: 0.06217  loss_rpn_loc: 0.1686  time: 0.3634  data_time: 0.0042  lr: 9.9001e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:10:57 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 119  total_loss: 2.4  loss_cls: 0.7467  loss_box_reg: 0.8468  loss_mask: 0.6333  loss_rpn_cls: 0.06767  loss_rpn_loc: 0.1248  time: 0.3627  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:04 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 2.326  loss_cls: 0.6836  loss_box_reg: 0.8674  loss_mask: 0.6184  loss_rpn_cls: 0.04075  loss_rpn_loc: 0.08875  time: 0.3617  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:11 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 159  total_loss: 2.273  loss_cls: 0.6707  loss_box_reg: 0.8715  loss_mask: 0.6012  loss_rpn_cls: 0.04433  loss_rpn_loc: 0.09367  time: 0.3610  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:18 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 179  total_loss: 2.185  loss_cls: 0.6122  loss_box_reg: 0.8432  loss_mask: 0.5827  loss_rpn_cls: 0.04142  loss_rpn_loc: 0.1155  time: 0.3628  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:26 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 199  total_loss: 2.117  loss_cls: 0.5682  loss_box_reg: 0.8196  loss_mask: 0.564  loss_rpn_cls: 0.03891  loss_rpn_loc: 0.1166  time: 0.3635  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:33 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 219  total_loss: 2.037  loss_cls: 0.5103  loss_box_reg: 0.8326  loss_mask: 0.5506  loss_rpn_cls: 0.03138  loss_rpn_loc: 0.1076  time: 0.3645  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:41 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 239  total_loss: 2.035  loss_cls: 0.5002  loss_box_reg: 0.8601  loss_mask: 0.5308  loss_rpn_cls: 0.03734  loss_rpn_loc: 0.1268  time: 0.3653  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:48 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 259  total_loss: 1.907  loss_cls: 0.4528  loss_box_reg: 0.8305  loss_mask: 0.5065  loss_rpn_cls: 0.03302  loss_rpn_loc: 0.1093  time: 0.3660  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:11:56 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 279  total_loss: 1.856  loss_cls: 0.381  loss_box_reg: 0.8213  loss_mask: 0.476  loss_rpn_cls: 0.0338  loss_rpn_loc: 0.07846  time: 0.3666  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:02 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 299  total_loss: 1.758  loss_cls: 0.3724  loss_box_reg: 0.7979  loss_mask: 0.4717  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.1184  time: 0.3631  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:09 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 319  total_loss: 1.662  loss_cls: 0.3709  loss_box_reg: 0.7914  loss_mask: 0.4336  loss_rpn_cls: 0.01693  loss_rpn_loc: 0.0882  time: 0.3615  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:15 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 339  total_loss: 1.719  loss_cls: 0.3415  loss_box_reg: 0.7873  loss_mask: 0.4183  loss_rpn_cls: 0.02711  loss_rpn_loc: 0.06342  time: 0.3591  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:22 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 359  total_loss: 1.569  loss_cls: 0.2973  loss_box_reg: 0.7651  loss_mask: 0.419  loss_rpn_cls: 0.02728  loss_rpn_loc: 0.08925  time: 0.3573  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:29 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 379  total_loss: 1.569  loss_cls: 0.2746  loss_box_reg: 0.7283  loss_mask: 0.3935  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.09984  time: 0.3561  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:35 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 1.497  loss_cls: 0.2908  loss_box_reg: 0.723  loss_mask: 0.3729  loss_rpn_cls: 0.02394  loss_rpn_loc: 0.08203  time: 0.3551  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:42 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 1.472  loss_cls: 0.2859  loss_box_reg: 0.6915  loss_mask: 0.3531  loss_rpn_cls: 0.01915  loss_rpn_loc: 0.07916  time: 0.3547  data_time: 0.0040  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:49 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 1.397  loss_cls: 0.249  loss_box_reg: 0.6698  loss_mask: 0.3641  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.061  time: 0.3531  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:12:55 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 459  total_loss: 1.32  loss_cls: 0.2383  loss_box_reg: 0.6594  loss_mask: 0.3376  loss_rpn_cls: 0.01066  loss_rpn_loc: 0.08605  time: 0.3514  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:13:01 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 479  total_loss: 1.305  loss_cls: 0.2353  loss_box_reg: 0.6212  loss_mask: 0.3588  loss_rpn_cls: 0.01661  loss_rpn_loc: 0.08862  time: 0.3501  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:13:08 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.23  loss_cls: 0.2117  loss_box_reg: 0.5855  loss_mask: 0.3177  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.06014  time: 0.3471  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:13:08 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:52 (0.3471 s / it)\n",
      "\u001b[32m[10/21 08:13:08 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:54 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='UUYVNIH_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:13:08 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:13:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:13:08 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:13:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:13:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:13:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1161 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 08:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 46/126. 0.1139 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 82/126. 0.1126 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 08:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 116/126. 0.1113 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:17.346721 (0.143361 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.110470 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/UUYVNIH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.538\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 17.678 | 33.976 | 15.234 | 11.130 | 30.504 | 26.603 |\n",
      "\u001b[32m[10/21 08:13:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 17.258 | cushion    | 19.884 | door       | 5.834 |\n",
      "| indoor-plant | 20.459 | sofa       | 37.356 | table      | 5.274 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:13:27 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:13:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/21 08:13:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:13:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      "\u001b[32m[10/21 08:13:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 10.738 | 25.249 | 5.031  | 5.314 | 16.092 | 15.272 |\n",
      "\u001b[32m[10/21 08:13:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.752  | cushion    | 18.362 | door       | 4.429 |\n",
      "| indoor-plant | 15.565 | sofa       | 23.319 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='UUYVNIH0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:13:27 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:13:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:13:27 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:13:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:13:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.1161 s / img. ETA=0:01:01\n",
      "\u001b[32m[10/21 08:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 48/355. 0.1059 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 08:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.1040 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 08:13:45 d2.evaluation.evaluator]: \u001b[0mInference done 122/355. 0.1026 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 08:13:50 d2.evaluation.evaluator]: \u001b[0mInference done 158/355. 0.1036 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 08:13:55 d2.evaluation.evaluator]: \u001b[0mInference done 200/355. 0.1002 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 08:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 231/355. 0.1009 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 08:14:05 d2.evaluation.evaluator]: \u001b[0mInference done 265/355. 0.1008 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 08:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.1017 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.1028 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 351/355. 0.1036 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:14:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:53.410776 (0.152602 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:14:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.103931 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/UUYVNIH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.424 | 33.059 | 23.394 | 12.654 | 22.213 | 18.639 |\n",
      "\u001b[32m[10/21 08:14:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.230  | cushion    | 44.455 | door       | 3.352 |\n",
      "| indoor-plant | 18.717 | sofa       | 51.204 | table      | 2.584 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:14:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:14:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/21 08:14:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:14:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      "\u001b[32m[10/21 08:14:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.214 | 31.012 | 21.891 | 13.324 | 20.643 | 19.032 |\n",
      "\u001b[32m[10/21 08:14:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.216  | cushion    | 55.258 | door       | 3.883 |\n",
      "| indoor-plant | 12.907 | sofa       | 48.022 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='UUYVNIH1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:14:24 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:14:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:14:24 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:14:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:14:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1029 s / img. ETA=0:01:01\n",
      "\u001b[32m[10/21 08:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 42/355. 0.1052 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 08:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 74/355. 0.1069 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 08:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 118/355. 0.0963 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 149/355. 0.1023 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 08:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.1063 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 08:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.1094 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 08:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 234/355. 0.1138 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 08:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 262/355. 0.1161 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 08:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.1192 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 307/355. 0.1217 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:15:22 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.1224 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:15:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:02.235204 (0.177815 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:15:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.124612 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:15:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:15:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/UUYVNIH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:15:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:15:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:15:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 08:15:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:15:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.477\n",
      "\u001b[32m[10/21 08:15:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.935 | 31.965 | 20.443 | 17.128 | 20.282 | 16.280 |\n",
      "\u001b[32m[10/21 08:15:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.388  | cushion    | 42.849 | door       | 3.805 |\n",
      "| indoor-plant | 15.635 | sofa       | 46.089 | table      | 2.842 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:15:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:15:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.56 seconds.\n",
      "\u001b[32m[10/21 08:15:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:15:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.361\n",
      "\u001b[32m[10/21 08:15:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.298 | 29.793 | 21.214 | 16.981 | 18.815 | 17.956 |\n",
      "\u001b[32m[10/21 08:15:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.354  | cushion    | 53.517 | door       | 4.398 |\n",
      "| indoor-plant | 11.526 | sofa       | 44.989 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='UUYVNIH2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:15:29 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:15:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:15:30 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:15:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:15:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1636 s / img. ETA=0:01:20\n",
      "\u001b[32m[10/21 08:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 35/355. 0.1475 s / img. ETA=0:01:08\n",
      "\u001b[32m[10/21 08:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 63/355. 0.1401 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 08:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.1351 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 08:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 126/355. 0.1326 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 08:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.1308 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:16:03 d2.evaluation.evaluator]: \u001b[0mInference done 191/355. 0.1292 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 08:16:08 d2.evaluation.evaluator]: \u001b[0mInference done 215/355. 0.1316 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 08:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.1321 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 08:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 265/355. 0.1337 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.1353 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 08:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 309/355. 0.1371 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.1370 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:16:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.445616 (0.192702 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:16:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:48 (0.138788 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:16:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:16:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/UUYVNIH0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:16:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:16:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:16:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.26 seconds.\n",
      "\u001b[32m[10/21 08:16:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:16:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.403\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514\n",
      "\u001b[32m[10/21 08:16:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.028 | 33.182 | 21.933 | 17.019 | 20.298 | 19.620 |\n",
      "\u001b[32m[10/21 08:16:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.382  | cushion    | 42.764 | door       | 4.297 |\n",
      "| indoor-plant | 18.092 | sofa       | 50.073 | table      | 2.561 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:16:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:16:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.47 seconds.\n",
      "\u001b[32m[10/21 08:16:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:16:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.07 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
      "\u001b[32m[10/21 08:16:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.790 | 30.950 | 21.981 | 16.657 | 19.044 | 21.007 |\n",
      "\u001b[32m[10/21 08:16:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.436  | cushion    | 52.452 | door       | 4.931 |\n",
      "| indoor-plant | 12.374 | sofa       | 47.547 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [33.05890364209264, 31.96463965694497, 33.18190145930247]}, 'segm': {'AP50': [31.011682312552168, 29.793418308223085, 30.949794872625485]}}\n",
      "dataset_name EUUX7ZK\n",
      "SOLVER PARAMS (800, 100, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='EUUX7ZK_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/EUUX7ZK0\n",
      "output_aug/800/EUUX7ZK0\n",
      "\u001b[32m[10/21 08:16:42 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:16:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:16:42 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:16:42 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:16:42 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:16:42 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:16:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:16:42 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:16:42 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:16:50 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 19  total_loss: 4.027  loss_cls: 1.867  loss_box_reg: 0.8607  loss_mask: 0.6912  loss_rpn_cls: 0.4864  loss_rpn_loc: 0.1558  time: 0.3774  data_time: 0.0201  lr: 1.9081e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:16:57 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 39  total_loss: 3.555  loss_cls: 1.557  loss_box_reg: 0.8837  loss_mask: 0.6865  loss_rpn_cls: 0.2063  loss_rpn_loc: 0.1557  time: 0.3766  data_time: 0.0044  lr: 3.9061e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:05 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 59  total_loss: 2.927  loss_cls: 1.079  loss_box_reg: 0.8724  loss_mask: 0.6799  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.1292  time: 0.3762  data_time: 0.0046  lr: 5.9041e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:12 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 79  total_loss: 2.607  loss_cls: 0.8652  loss_box_reg: 0.8718  loss_mask: 0.6676  loss_rpn_cls: 0.07057  loss_rpn_loc: 0.1448  time: 0.3741  data_time: 0.0043  lr: 7.9021e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:20 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 99  total_loss: 2.467  loss_cls: 0.7866  loss_box_reg: 0.8383  loss_mask: 0.6517  loss_rpn_cls: 0.05604  loss_rpn_loc: 0.1255  time: 0.3725  data_time: 0.0042  lr: 9.9001e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:27 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 119  total_loss: 2.437  loss_cls: 0.7526  loss_box_reg: 0.8979  loss_mask: 0.6302  loss_rpn_cls: 0.05866  loss_rpn_loc: 0.1065  time: 0.3732  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:35 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 139  total_loss: 2.356  loss_cls: 0.7201  loss_box_reg: 0.8651  loss_mask: 0.6113  loss_rpn_cls: 0.05392  loss_rpn_loc: 0.1314  time: 0.3726  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:42 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 159  total_loss: 2.298  loss_cls: 0.673  loss_box_reg: 0.8665  loss_mask: 0.5902  loss_rpn_cls: 0.03549  loss_rpn_loc: 0.09869  time: 0.3737  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:50 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 179  total_loss: 2.22  loss_cls: 0.6171  loss_box_reg: 0.8559  loss_mask: 0.5798  loss_rpn_cls: 0.0414  loss_rpn_loc: 0.09175  time: 0.3728  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:17:57 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 199  total_loss: 2.092  loss_cls: 0.5849  loss_box_reg: 0.8511  loss_mask: 0.5599  loss_rpn_cls: 0.0415  loss_rpn_loc: 0.106  time: 0.3731  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:04 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 219  total_loss: 2.106  loss_cls: 0.5807  loss_box_reg: 0.8338  loss_mask: 0.552  loss_rpn_cls: 0.03735  loss_rpn_loc: 0.1219  time: 0.3722  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:12 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 239  total_loss: 2.028  loss_cls: 0.5141  loss_box_reg: 0.8492  loss_mask: 0.526  loss_rpn_cls: 0.03212  loss_rpn_loc: 0.05917  time: 0.3722  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:19 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 259  total_loss: 1.939  loss_cls: 0.4945  loss_box_reg: 0.8278  loss_mask: 0.5037  loss_rpn_cls: 0.03111  loss_rpn_loc: 0.1164  time: 0.3720  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:27 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 279  total_loss: 1.942  loss_cls: 0.4798  loss_box_reg: 0.7825  loss_mask: 0.4865  loss_rpn_cls: 0.03472  loss_rpn_loc: 0.1022  time: 0.3723  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:34 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 299  total_loss: 1.845  loss_cls: 0.4294  loss_box_reg: 0.7943  loss_mask: 0.4693  loss_rpn_cls: 0.03909  loss_rpn_loc: 0.09387  time: 0.3727  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:41 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 319  total_loss: 1.787  loss_cls: 0.3856  loss_box_reg: 0.8038  loss_mask: 0.4466  loss_rpn_cls: 0.04231  loss_rpn_loc: 0.0841  time: 0.3707  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:48 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 339  total_loss: 1.671  loss_cls: 0.3538  loss_box_reg: 0.8004  loss_mask: 0.4245  loss_rpn_cls: 0.0245  loss_rpn_loc: 0.1008  time: 0.3697  data_time: 0.0040  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:18:55 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 359  total_loss: 1.593  loss_cls: 0.3157  loss_box_reg: 0.7759  loss_mask: 0.4204  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.07535  time: 0.3675  data_time: 0.0046  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:02 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 379  total_loss: 1.588  loss_cls: 0.3326  loss_box_reg: 0.7866  loss_mask: 0.3728  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.05762  time: 0.3663  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:09 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 399  total_loss: 1.546  loss_cls: 0.3013  loss_box_reg: 0.7289  loss_mask: 0.3777  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.08715  time: 0.3659  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:16 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 419  total_loss: 1.496  loss_cls: 0.2842  loss_box_reg: 0.7347  loss_mask: 0.3715  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.09306  time: 0.3653  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:23 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 439  total_loss: 1.536  loss_cls: 0.3046  loss_box_reg: 0.6859  loss_mask: 0.3765  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.07283  time: 0.3643  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:30 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 459  total_loss: 1.349  loss_cls: 0.2391  loss_box_reg: 0.6815  loss_mask: 0.3437  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.08524  time: 0.3631  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:37 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 479  total_loss: 1.346  loss_cls: 0.244  loss_box_reg: 0.6578  loss_mask: 0.3383  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.08188  time: 0.3622  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:42 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 499  total_loss: 1.283  loss_cls: 0.2394  loss_box_reg: 0.6192  loss_mask: 0.3532  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.09259  time: 0.3594  data_time: 0.0047  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:49 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 519  total_loss: 1.22  loss_cls: 0.2205  loss_box_reg: 0.5832  loss_mask: 0.3245  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.06945  time: 0.3589  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:19:56 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 539  total_loss: 1.208  loss_cls: 0.2202  loss_box_reg: 0.5846  loss_mask: 0.3465  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.07359  time: 0.3586  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:04 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 559  total_loss: 1.215  loss_cls: 0.2238  loss_box_reg: 0.5611  loss_mask: 0.3448  loss_rpn_cls: 0.02192  loss_rpn_loc: 0.0824  time: 0.3586  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:10 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 579  total_loss: 1.139  loss_cls: 0.2021  loss_box_reg: 0.5177  loss_mask: 0.3199  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.06289  time: 0.3576  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:17 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 599  total_loss: 1.153  loss_cls: 0.2023  loss_box_reg: 0.5105  loss_mask: 0.3228  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.08748  time: 0.3566  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:24 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 1.137  loss_cls: 0.1847  loss_box_reg: 0.4637  loss_mask: 0.3136  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.07329  time: 0.3563  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:29 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 1.13  loss_cls: 0.1978  loss_box_reg: 0.4794  loss_mask: 0.3292  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.08679  time: 0.3542  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:37 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 1.049  loss_cls: 0.1829  loss_box_reg: 0.4544  loss_mask: 0.3156  loss_rpn_cls: 0.008288  loss_rpn_loc: 0.06406  time: 0.3541  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:43 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 1.034  loss_cls: 0.1764  loss_box_reg: 0.4408  loss_mask: 0.3054  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.08436  time: 0.3539  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:51 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 0.9806  loss_cls: 0.1725  loss_box_reg: 0.4347  loss_mask: 0.3103  loss_rpn_cls: 0.00898  loss_rpn_loc: 0.06516  time: 0.3542  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:20:57 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 1.006  loss_cls: 0.176  loss_box_reg: 0.4356  loss_mask: 0.3157  loss_rpn_cls: 0.0109  loss_rpn_loc: 0.06657  time: 0.3536  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:21:04 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.9594  loss_cls: 0.1738  loss_box_reg: 0.4273  loss_mask: 0.2913  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.08345  time: 0.3528  data_time: 0.0045  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:21:11 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 0.8782  loss_cls: 0.163  loss_box_reg: 0.3934  loss_mask: 0.2876  loss_rpn_cls: 0.006231  loss_rpn_loc: 0.06724  time: 0.3525  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:21:16 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.9797  loss_cls: 0.1658  loss_box_reg: 0.4162  loss_mask: 0.3064  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.06119  time: 0.3500  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:21:25 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.9476  loss_cls: 0.151  loss_box_reg: 0.397  loss_mask: 0.3095  loss_rpn_cls: 0.007338  loss_rpn_loc: 0.0621  time: 0.3508  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:21:25 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:39 (0.3508 s / it)\n",
      "\u001b[32m[10/21 08:21:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:41 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='EUUX7ZK_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:21:25 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:21:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:21:25 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:21:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:21:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1076 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 48/126. 0.1176 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 86/126. 0.1166 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 08:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 121/126. 0.1188 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.519303 (0.136523 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.118814 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EUUX7ZK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.367\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.376 | 36.711 | 20.743 | 10.514 | 39.209 | 32.319 |\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 25.103 | cushion    | 23.120 | door       | 9.306 |\n",
      "| indoor-plant | 22.952 | sofa       | 38.572 | table      | 9.205 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 11.862 | 26.640 | 6.682  | 4.805 | 21.011 | 16.433 |\n",
      "\u001b[32m[10/21 08:21:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.641  | cushion    | 20.656 | door       | 8.220 |\n",
      "| indoor-plant | 14.534 | sofa       | 22.123 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='EUUX7ZK0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:21:42 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:21:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:21:43 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:21:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:21:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 23/355. 0.1194 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 08:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 56/355. 0.1205 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 08:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1203 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 08:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 125/355. 0.1211 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.1214 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 08:22:12 d2.evaluation.evaluator]: \u001b[0mInference done 193/355. 0.1220 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 08:22:17 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.1217 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 08:22:22 d2.evaluation.evaluator]: \u001b[0mInference done 262/355. 0.1216 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:22:27 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.1218 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:22:32 d2.evaluation.evaluator]: \u001b[0mInference done 326/355. 0.1222 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:53.401852 (0.152577 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.122595 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EUUX7ZK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.21 seconds.\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.364\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.772 | 36.371 | 26.285 | 13.978 | 27.303 | 21.828 |\n",
      "\u001b[32m[10/21 08:22:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.459  | cushion    | 53.527 | door       | 6.467 |\n",
      "| indoor-plant | 13.758 | sofa       | 63.430 | table      | 3.994 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:22:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:22:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 08:22:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:22:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.339\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387\n",
      "\u001b[32m[10/21 08:22:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.103 | 33.860 | 23.843 | 13.879 | 23.711 | 20.085 |\n",
      "\u001b[32m[10/21 08:22:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.868 | cushion    | 60.431 | door       | 6.897 |\n",
      "| indoor-plant | 9.304 | sofa       | 55.120 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='EUUX7ZK1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:22:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:22:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:22:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:22:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:22:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1360 s / img. ETA=0:00:57\n",
      "\u001b[32m[10/21 08:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1269 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 08:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 80/355. 0.1260 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 08:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.1237 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 152/355. 0.1236 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 08:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 188/355. 0.1232 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 08:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.1227 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 08:23:16 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.1224 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1225 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 330/355. 0.1221 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.718681 (0.144911 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.122354 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EUUX7ZK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.513\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.113 | 36.153 | 25.353 | 11.903 | 26.942 | 21.140 |\n",
      "\u001b[32m[10/21 08:23:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.771  | cushion    | 52.426 | door       | 7.114 |\n",
      "| indoor-plant | 12.603 | sofa       | 60.119 | table      | 4.647 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:23:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:23:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "\u001b[32m[10/21 08:23:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:23:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.326\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n",
      "\u001b[32m[10/21 08:23:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.482 | 32.643 | 23.487 | 11.677 | 23.015 | 19.123 |\n",
      "\u001b[32m[10/21 08:23:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.032 | cushion    | 57.471 | door       | 7.763 |\n",
      "| indoor-plant | 8.795 | sofa       | 53.832 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='EUUX7ZK2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:23:31 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:23:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:23:31 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:23:32 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:23:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1159 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 08:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 44/355. 0.1231 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 08:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 79/355. 0.1236 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 08:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 115/355. 0.1224 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 08:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 150/355. 0.1231 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 08:23:59 d2.evaluation.evaluator]: \u001b[0mInference done 187/355. 0.1230 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 08:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 221/355. 0.1229 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 08:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 255/355. 0.1231 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 08:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.1232 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.1231 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.1233 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.091178 (0.148832 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.123334 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/EUUX7ZK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.365\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.405\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.179 | 36.506 | 25.106 | 11.601 | 26.624 | 22.492 |\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.575  | cushion    | 50.062 | door       | 7.588 |\n",
      "| indoor-plant | 14.300 | sofa       | 61.543 | table      | 4.006 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:24:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:24:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[10/21 08:24:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:24:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.403\n",
      "\u001b[32m[10/21 08:24:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.265 | 33.438 | 23.632 | 11.209 | 23.135 | 20.744 |\n",
      "\u001b[32m[10/21 08:24:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.042 | cushion    | 55.260 | door       | 8.784 |\n",
      "| indoor-plant | 9.227 | sofa       | 53.277 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [36.371031686948406, 36.152807726725094, 36.506198477993784]}, 'segm': {'AP50': [33.85998894187925, 32.64263095879204, 33.43779515836228]}}\n",
      "dataset_name 3AL1DW9\n",
      "SOLVER PARAMS (500, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='3AL1DW9_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/3AL1DW90\n",
      "output_aug/500/3AL1DW90\n",
      "\u001b[32m[10/21 08:24:27 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:24:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:24:27 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:24:27 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:24:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:24:27 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:24:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:24:27 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:24:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:24:35 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 19  total_loss: 3.707  loss_cls: 1.742  loss_box_reg: 0.8668  loss_mask: 0.6943  loss_rpn_cls: 0.3008  loss_rpn_loc: 0.1345  time: 0.3635  data_time: 0.0183  lr: 9.5905e-06  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:24:42 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 39  total_loss: 3.695  loss_cls: 1.599  loss_box_reg: 0.8625  loss_mask: 0.6921  loss_rpn_cls: 0.3867  loss_rpn_loc: 0.186  time: 0.3580  data_time: 0.0045  lr: 1.958e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:24:50 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 59  total_loss: 3.262  loss_cls: 1.322  loss_box_reg: 0.8547  loss_mask: 0.6881  loss_rpn_cls: 0.1504  loss_rpn_loc: 0.1387  time: 0.3681  data_time: 0.0040  lr: 2.9571e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:24:57 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 79  total_loss: 2.849  loss_cls: 1.065  loss_box_reg: 0.8737  loss_mask: 0.6817  loss_rpn_cls: 0.09966  loss_rpn_loc: 0.1566  time: 0.3674  data_time: 0.0039  lr: 3.9561e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:04 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 99  total_loss: 2.647  loss_cls: 0.9035  loss_box_reg: 0.8884  loss_mask: 0.6732  loss_rpn_cls: 0.09326  loss_rpn_loc: 0.08792  time: 0.3639  data_time: 0.0040  lr: 4.955e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:12 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 119  total_loss: 2.518  loss_cls: 0.8334  loss_box_reg: 0.88  loss_mask: 0.6627  loss_rpn_cls: 0.05706  loss_rpn_loc: 0.1072  time: 0.3648  data_time: 0.0039  lr: 5.954e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:18 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 139  total_loss: 2.527  loss_cls: 0.8039  loss_box_reg: 0.8954  loss_mask: 0.6548  loss_rpn_cls: 0.05363  loss_rpn_loc: 0.1326  time: 0.3585  data_time: 0.0039  lr: 6.9531e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:25 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 159  total_loss: 2.435  loss_cls: 0.7436  loss_box_reg: 0.8648  loss_mask: 0.6365  loss_rpn_cls: 0.05438  loss_rpn_loc: 0.1255  time: 0.3569  data_time: 0.0041  lr: 7.952e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:32 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 179  total_loss: 2.401  loss_cls: 0.7144  loss_box_reg: 0.886  loss_mask: 0.6219  loss_rpn_cls: 0.06178  loss_rpn_loc: 0.1231  time: 0.3560  data_time: 0.0038  lr: 8.951e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:38 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 199  total_loss: 2.33  loss_cls: 0.6692  loss_box_reg: 0.8234  loss_mask: 0.6162  loss_rpn_cls: 0.05268  loss_rpn_loc: 0.1189  time: 0.3520  data_time: 0.0047  lr: 9.9501e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:45 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 219  total_loss: 2.233  loss_cls: 0.6489  loss_box_reg: 0.8631  loss_mask: 0.5888  loss_rpn_cls: 0.04659  loss_rpn_loc: 0.1099  time: 0.3506  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:52 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 239  total_loss: 2.105  loss_cls: 0.5936  loss_box_reg: 0.8383  loss_mask: 0.5768  loss_rpn_cls: 0.03271  loss_rpn_loc: 0.06337  time: 0.3497  data_time: 0.0045  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:25:59 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 259  total_loss: 2.094  loss_cls: 0.5512  loss_box_reg: 0.8332  loss_mask: 0.5595  loss_rpn_cls: 0.03627  loss_rpn_loc: 0.1216  time: 0.3487  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:05 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 279  total_loss: 2.059  loss_cls: 0.5494  loss_box_reg: 0.8617  loss_mask: 0.5432  loss_rpn_cls: 0.02755  loss_rpn_loc: 0.1104  time: 0.3468  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:11 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 299  total_loss: 2.007  loss_cls: 0.4733  loss_box_reg: 0.832  loss_mask: 0.5233  loss_rpn_cls: 0.04114  loss_rpn_loc: 0.1164  time: 0.3444  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:18 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 319  total_loss: 1.92  loss_cls: 0.4291  loss_box_reg: 0.8216  loss_mask: 0.4935  loss_rpn_cls: 0.03453  loss_rpn_loc: 0.08375  time: 0.3426  data_time: 0.0040  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:24 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 339  total_loss: 1.807  loss_cls: 0.3969  loss_box_reg: 0.8058  loss_mask: 0.4687  loss_rpn_cls: 0.02548  loss_rpn_loc: 0.06975  time: 0.3408  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:30 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 359  total_loss: 1.712  loss_cls: 0.3713  loss_box_reg: 0.7929  loss_mask: 0.4496  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.07073  time: 0.3403  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:38 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 379  total_loss: 1.757  loss_cls: 0.3632  loss_box_reg: 0.7867  loss_mask: 0.4404  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.06939  time: 0.3411  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:44 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 399  total_loss: 1.68  loss_cls: 0.3111  loss_box_reg: 0.7421  loss_mask: 0.4261  loss_rpn_cls: 0.02281  loss_rpn_loc: 0.1127  time: 0.3410  data_time: 0.0038  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:51 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 419  total_loss: 1.523  loss_cls: 0.3155  loss_box_reg: 0.7505  loss_mask: 0.3994  loss_rpn_cls: 0.02338  loss_rpn_loc: 0.0882  time: 0.3410  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:26:58 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 439  total_loss: 1.555  loss_cls: 0.3154  loss_box_reg: 0.7465  loss_mask: 0.4048  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.09415  time: 0.3402  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:27:04 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 459  total_loss: 1.45  loss_cls: 0.2625  loss_box_reg: 0.7025  loss_mask: 0.3657  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.06987  time: 0.3391  data_time: 0.0036  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:27:11 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 1.458  loss_cls: 0.2703  loss_box_reg: 0.7029  loss_mask: 0.3827  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.06996  time: 0.3391  data_time: 0.0037  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:27:17 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 1.427  loss_cls: 0.2663  loss_box_reg: 0.6951  loss_mask: 0.348  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.07428  time: 0.3370  data_time: 0.0040  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:27:17 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:47 (0.3370 s / it)\n",
      "\u001b[32m[10/21 08:27:17 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:49 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='3AL1DW9_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:27:18 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:27:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:27:18 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:27:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:27:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:27:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1050 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 08:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 47/126. 0.1037 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 80/126. 0.1092 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 08:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 111/126. 0.1109 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.356787 (0.151709 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.109820 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/3AL1DW90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 15.709 | 33.667 | 12.299 | 10.292 | 25.960 | 23.075 |\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 16.956 | cushion    | 19.516 | door       | 7.876 |\n",
      "| indoor-plant | 17.307 | sofa       | 26.154 | table      | 6.444 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:27:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.153\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
      "\u001b[32m[10/21 08:27:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 9.795 | 24.010 | 5.282  | 5.006 | 14.396 | 15.322 |\n",
      "\u001b[32m[10/21 08:27:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.186  | cushion    | 17.610 | door       | 6.908 |\n",
      "| indoor-plant | 15.055 | sofa       | 18.010 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='3AL1DW90_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:27:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:27:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:27:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:27:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:27:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:27:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1245 s / img. ETA=0:01:06\n",
      "\u001b[32m[10/21 08:27:45 d2.evaluation.evaluator]: \u001b[0mInference done 41/355. 0.1096 s / img. ETA=0:00:54\n",
      "\u001b[32m[10/21 08:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 71/355. 0.1109 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 08:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 105/355. 0.1105 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 08:28:00 d2.evaluation.evaluator]: \u001b[0mInference done 140/355. 0.1060 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 167/355. 0.1115 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 08:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.1144 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 08:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 220/355. 0.1183 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 08:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 240/355. 0.1232 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 08:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 266/355. 0.1250 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.1267 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 310/355. 0.1297 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 334/355. 0.1311 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 355/355. 0.1332 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:28:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.702979 (0.193437 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:28:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:46 (0.133225 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/3AL1DW90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.136\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.490\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 15.576 | 29.415 | 14.548 | 12.739 | 20.811 | 13.579 |\n",
      "\u001b[32m[10/21 08:28:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.402  | cushion    | 43.903 | door       | 5.807 |\n",
      "| indoor-plant | 16.008 | sofa       | 21.576 | table      | 5.763 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.36s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:28:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:28:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.55 seconds.\n",
      "\u001b[32m[10/21 08:28:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:28:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
      "\u001b[32m[10/21 08:28:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.723 | 27.046 | 16.755 | 13.696 | 20.053 | 16.552 |\n",
      "\u001b[32m[10/21 08:28:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.178  | cushion    | 55.603 | door       | 6.288 |\n",
      "| indoor-plant | 11.859 | sofa       | 26.407 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='3AL1DW91_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:28:49 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:28:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:28:49 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:28:49 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:28:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:28:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1708 s / img. ETA=0:01:28\n",
      "\u001b[32m[10/21 08:28:57 d2.evaluation.evaluator]: \u001b[0mInference done 31/355. 0.1620 s / img. ETA=0:01:21\n",
      "\u001b[32m[10/21 08:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 54/355. 0.1573 s / img. ETA=0:01:12\n",
      "\u001b[32m[10/21 08:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 74/355. 0.1578 s / img. ETA=0:01:08\n",
      "\u001b[32m[10/21 08:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 103/355. 0.1496 s / img. ETA=0:00:56\n",
      "\u001b[32m[10/21 08:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 126/355. 0.1483 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 08:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 152/355. 0.1466 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 08:29:28 d2.evaluation.evaluator]: \u001b[0mInference done 178/355. 0.1452 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 08:29:33 d2.evaluation.evaluator]: \u001b[0mInference done 204/355. 0.1451 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 08:29:38 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.1456 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 08:29:43 d2.evaluation.evaluator]: \u001b[0mInference done 246/355. 0.1460 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 08:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 270/355. 0.1460 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 08:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.1469 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 08:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 311/355. 0.1480 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:30:04 d2.evaluation.evaluator]: \u001b[0mInference done 333/355. 0.1481 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:30:09 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.1491 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:30:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:18.865772 (0.225331 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:30:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:52 (0.149107 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:30:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:30:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/3AL1DW90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:30:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:30:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:30:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.46 seconds.\n",
      "\u001b[32m[10/21 08:30:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:30:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
      "\u001b[32m[10/21 08:30:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 15.407 | 29.295 | 13.328 | 10.636 | 20.990 | 11.660 |\n",
      "\u001b[32m[10/21 08:30:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.453  | cushion    | 43.436 | door       | 6.179 |\n",
      "| indoor-plant | 15.098 | sofa       | 21.251 | table      | 6.027 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:30:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:30:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.50 seconds.\n",
      "\u001b[32m[10/21 08:30:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:30:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      "\u001b[32m[10/21 08:30:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.233 | 26.107 | 15.599 | 10.269 | 19.481 | 14.192 |\n",
      "\u001b[32m[10/21 08:30:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.181  | cushion    | 55.040 | door       | 6.924 |\n",
      "| indoor-plant | 11.144 | sofa       | 24.107 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='3AL1DW92_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:30:13 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:30:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:30:13 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:30:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:30:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1142 s / img. ETA=0:01:03\n",
      "\u001b[32m[10/21 08:30:20 d2.evaluation.evaluator]: \u001b[0mInference done 37/355. 0.1234 s / img. ETA=0:01:01\n",
      "\u001b[32m[10/21 08:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 67/355. 0.1154 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 08:30:30 d2.evaluation.evaluator]: \u001b[0mInference done 101/355. 0.1106 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 08:30:35 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1108 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 08:30:40 d2.evaluation.evaluator]: \u001b[0mInference done 158/355. 0.1120 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:30:45 d2.evaluation.evaluator]: \u001b[0mInference done 192/355. 0.1110 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 08:30:51 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.1123 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 08:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 244/355. 0.1118 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 08:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 270/355. 0.1123 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 08:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 297/355. 0.1116 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:31:11 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.1122 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 08:31:16 d2.evaluation.evaluator]: \u001b[0mInference done 348/355. 0.1128 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:31:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:03.569527 (0.181627 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:31:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.112751 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/3AL1DW90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.09 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.304\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.131\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.520\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 15.801 | 30.408 | 13.298 | 14.400 | 20.735 | 13.127 |\n",
      "\u001b[32m[10/21 08:31:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.467  | cushion    | 43.132 | door       | 6.945 |\n",
      "| indoor-plant | 16.566 | sofa       | 21.296 | table      | 6.399 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.35s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:31:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:31:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.53 seconds.\n",
      "\u001b[32m[10/21 08:31:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:31:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.08 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399\n",
      "\u001b[32m[10/21 08:31:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 16.728 | 27.619 | 15.914 | 10.087 | 19.476 | 16.404 |\n",
      "\u001b[32m[10/21 08:31:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 0.212  | cushion    | 53.245 | door       | 8.010 |\n",
      "| indoor-plant | 12.275 | sofa       | 26.629 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [29.414511413712034, 29.29545786548592, 30.407507697549157]}, 'segm': {'AP50': [27.04641694900457, 26.107421829681833, 27.618947186226084]}}\n",
      "dataset_name IE7ZPD9\n",
      "SOLVER PARAMS (800, 200, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='IE7ZPD9_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/IE7ZPD90\n",
      "output_aug/800/IE7ZPD90\n",
      "\u001b[32m[10/21 08:31:21 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:31:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:31:21 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:31:21 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:31:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:31:21 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:31:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:31:21 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:31:22 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:31:29 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 19  total_loss: 4.091  loss_cls: 1.931  loss_box_reg: 0.8901  loss_mask: 0.6937  loss_rpn_cls: 0.4135  loss_rpn_loc: 0.1549  time: 0.3251  data_time: 0.0193  lr: 9.5905e-06  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:31:35 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 39  total_loss: 3.771  loss_cls: 1.776  loss_box_reg: 0.9045  loss_mask: 0.6923  loss_rpn_cls: 0.234  loss_rpn_loc: 0.1464  time: 0.3270  data_time: 0.0044  lr: 1.958e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:31:42 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 59  total_loss: 3.323  loss_cls: 1.457  loss_box_reg: 0.8904  loss_mask: 0.6872  loss_rpn_cls: 0.1423  loss_rpn_loc: 0.1732  time: 0.3343  data_time: 0.0043  lr: 2.9571e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:31:48 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 79  total_loss: 2.858  loss_cls: 1.105  loss_box_reg: 0.8614  loss_mask: 0.681  loss_rpn_cls: 0.08991  loss_rpn_loc: 0.1497  time: 0.3228  data_time: 0.0046  lr: 3.9561e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:31:55 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 99  total_loss: 2.665  loss_cls: 0.8991  loss_box_reg: 0.8554  loss_mask: 0.6733  loss_rpn_cls: 0.0813  loss_rpn_loc: 0.133  time: 0.3304  data_time: 0.0043  lr: 4.955e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:02 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 119  total_loss: 2.549  loss_cls: 0.8337  loss_box_reg: 0.8663  loss_mask: 0.6621  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.1371  time: 0.3326  data_time: 0.0044  lr: 5.954e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:09 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 139  total_loss: 2.479  loss_cls: 0.7933  loss_box_reg: 0.8577  loss_mask: 0.6509  loss_rpn_cls: 0.05547  loss_rpn_loc: 0.1325  time: 0.3355  data_time: 0.0041  lr: 6.9531e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:16 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 159  total_loss: 2.435  loss_cls: 0.7695  loss_box_reg: 0.8603  loss_mask: 0.6417  loss_rpn_cls: 0.05207  loss_rpn_loc: 0.1204  time: 0.3350  data_time: 0.0044  lr: 7.9521e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:22 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 179  total_loss: 2.371  loss_cls: 0.7081  loss_box_reg: 0.8477  loss_mask: 0.6255  loss_rpn_cls: 0.05887  loss_rpn_loc: 0.1273  time: 0.3333  data_time: 0.0046  lr: 8.9511e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:29 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 199  total_loss: 2.288  loss_cls: 0.6722  loss_box_reg: 0.8675  loss_mask: 0.6035  loss_rpn_cls: 0.04785  loss_rpn_loc: 0.08841  time: 0.3348  data_time: 0.0044  lr: 9.9501e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:35 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 219  total_loss: 2.222  loss_cls: 0.629  loss_box_reg: 0.8257  loss_mask: 0.5902  loss_rpn_cls: 0.04025  loss_rpn_loc: 0.07911  time: 0.3296  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:42 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 239  total_loss: 2.109  loss_cls: 0.5552  loss_box_reg: 0.8389  loss_mask: 0.5686  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.09779  time: 0.3332  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:50 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 259  total_loss: 2.08  loss_cls: 0.5468  loss_box_reg: 0.8489  loss_mask: 0.5483  loss_rpn_cls: 0.03454  loss_rpn_loc: 0.06652  time: 0.3364  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:32:57 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 279  total_loss: 2.028  loss_cls: 0.5062  loss_box_reg: 0.8113  loss_mask: 0.5381  loss_rpn_cls: 0.04262  loss_rpn_loc: 0.1407  time: 0.3385  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:04 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 299  total_loss: 1.909  loss_cls: 0.4711  loss_box_reg: 0.8251  loss_mask: 0.5008  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.07963  time: 0.3408  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:12 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 319  total_loss: 1.867  loss_cls: 0.4308  loss_box_reg: 0.8123  loss_mask: 0.5006  loss_rpn_cls: 0.03184  loss_rpn_loc: 0.1077  time: 0.3422  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:19 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 339  total_loss: 1.869  loss_cls: 0.4072  loss_box_reg: 0.8028  loss_mask: 0.4667  loss_rpn_cls: 0.03277  loss_rpn_loc: 0.1159  time: 0.3440  data_time: 0.0046  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:26 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 359  total_loss: 1.738  loss_cls: 0.3807  loss_box_reg: 0.7796  loss_mask: 0.4611  loss_rpn_cls: 0.02825  loss_rpn_loc: 0.101  time: 0.3448  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:34 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 379  total_loss: 1.662  loss_cls: 0.3443  loss_box_reg: 0.7913  loss_mask: 0.4193  loss_rpn_cls: 0.01936  loss_rpn_loc: 0.06616  time: 0.3460  data_time: 0.0045  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:41 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 399  total_loss: 1.586  loss_cls: 0.3291  loss_box_reg: 0.748  loss_mask: 0.3963  loss_rpn_cls: 0.01871  loss_rpn_loc: 0.04982  time: 0.3473  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:49 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 419  total_loss: 1.564  loss_cls: 0.3118  loss_box_reg: 0.7646  loss_mask: 0.3871  loss_rpn_cls: 0.02521  loss_rpn_loc: 0.09002  time: 0.3485  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:33:56 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 439  total_loss: 1.537  loss_cls: 0.3027  loss_box_reg: 0.7318  loss_mask: 0.3936  loss_rpn_cls: 0.02015  loss_rpn_loc: 0.08442  time: 0.3495  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:04 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 459  total_loss: 1.452  loss_cls: 0.262  loss_box_reg: 0.7167  loss_mask: 0.3623  loss_rpn_cls: 0.01786  loss_rpn_loc: 0.08132  time: 0.3506  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:11 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 479  total_loss: 1.42  loss_cls: 0.2577  loss_box_reg: 0.6624  loss_mask: 0.3588  loss_rpn_cls: 0.01827  loss_rpn_loc: 0.1173  time: 0.3517  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:18 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 499  total_loss: 1.366  loss_cls: 0.2281  loss_box_reg: 0.6325  loss_mask: 0.3738  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.05305  time: 0.3523  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:26 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 519  total_loss: 1.331  loss_cls: 0.2355  loss_box_reg: 0.6372  loss_mask: 0.3404  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.05585  time: 0.3531  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:33 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 539  total_loss: 1.263  loss_cls: 0.2297  loss_box_reg: 0.6208  loss_mask: 0.34  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.09457  time: 0.3537  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:41 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 559  total_loss: 1.261  loss_cls: 0.2411  loss_box_reg: 0.5683  loss_mask: 0.3355  loss_rpn_cls: 0.02476  loss_rpn_loc: 0.08067  time: 0.3540  data_time: 0.0046  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:48 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 579  total_loss: 1.183  loss_cls: 0.2103  loss_box_reg: 0.5303  loss_mask: 0.3316  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.09117  time: 0.3544  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:34:55 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 599  total_loss: 1.144  loss_cls: 0.2056  loss_box_reg: 0.5665  loss_mask: 0.3317  loss_rpn_cls: 0.01091  loss_rpn_loc: 0.04563  time: 0.3546  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:02 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 1.169  loss_cls: 0.2148  loss_box_reg: 0.5167  loss_mask: 0.3599  loss_rpn_cls: 0.01864  loss_rpn_loc: 0.09023  time: 0.3546  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:10 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 1.084  loss_cls: 0.2024  loss_box_reg: 0.4749  loss_mask: 0.309  loss_rpn_cls: 0.009341  loss_rpn_loc: 0.07205  time: 0.3552  data_time: 0.0046  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:17 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 1.027  loss_cls: 0.1837  loss_box_reg: 0.4751  loss_mask: 0.3152  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.05432  time: 0.3557  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:24 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 1.072  loss_cls: 0.2032  loss_box_reg: 0.4752  loss_mask: 0.3155  loss_rpn_cls: 0.0105  loss_rpn_loc: 0.05577  time: 0.3549  data_time: 0.0042  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:31 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 1.046  loss_cls: 0.1927  loss_box_reg: 0.4485  loss_mask: 0.3078  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.0708  time: 0.3549  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:38 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 1.002  loss_cls: 0.1654  loss_box_reg: 0.4357  loss_mask: 0.3015  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.06663  time: 0.3545  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:45 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.9814  loss_cls: 0.1786  loss_box_reg: 0.4305  loss_mask: 0.3036  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.08179  time: 0.3547  data_time: 0.0044  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:52 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 1.031  loss_cls: 0.1846  loss_box_reg: 0.4115  loss_mask: 0.3053  loss_rpn_cls: 0.00943  loss_rpn_loc: 0.07629  time: 0.3548  data_time: 0.0041  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:35:59 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.9378  loss_cls: 0.1805  loss_box_reg: 0.3973  loss_mask: 0.2988  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.06154  time: 0.3552  data_time: 0.0040  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:36:08 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.9577  loss_cls: 0.1654  loss_box_reg: 0.4192  loss_mask: 0.2891  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.06041  time: 0.3552  data_time: 0.0043  lr: 0.0001  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:36:08 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:43 (0.3552 s / it)\n",
      "\u001b[32m[10/21 08:36:08 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:44 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='IE7ZPD9_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:36:08 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:36:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:36:08 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:36:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:36:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1159 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 08:36:14 d2.evaluation.evaluator]: \u001b[0mInference done 49/126. 0.1116 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:36:19 d2.evaluation.evaluator]: \u001b[0mInference done 90/126. 0.1053 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.331835 (0.126709 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.103262 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IE7ZPD90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.317\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.501 | 39.347 | 22.542 | 13.420 | 40.987 | 30.047 |\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 26.829 | cushion    | 25.214 | door       | 8.147 |\n",
      "| indoor-plant | 23.142 | sofa       | 44.628 | table      | 7.045 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 12.205 | 28.986 | 6.547  | 5.865 | 21.691 | 15.980 |\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 6.306  | cushion    | 21.424 | door       | 6.826 |\n",
      "| indoor-plant | 13.944 | sofa       | 24.730 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='IE7ZPD90_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:36:24 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:36:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:36:24 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:36:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:36:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1072 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 08:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 47/355. 0.1069 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 08:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 89/355. 0.1020 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 08:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 126/355. 0.1035 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 08:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 163/355. 0.1030 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 08:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 201/355. 0.1042 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 08:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 236/355. 0.1044 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 279/355. 0.1017 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 311/355. 0.1022 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 08:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 348/355. 0.1022 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:37:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.123853 (0.137497 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:37:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.102572 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IE7ZPD90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.582 | 34.032 | 24.708 | 14.689 | 26.178 | 22.944 |\n",
      "\u001b[32m[10/21 08:37:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.917  | cushion    | 54.907 | door       | 5.180 |\n",
      "| indoor-plant | 11.977 | sofa       | 57.543 | table      | 2.970 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:37:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:37:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.35 seconds.\n",
      "\u001b[32m[10/21 08:37:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:37:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.206\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.384\n",
      "\u001b[32m[10/21 08:37:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.632 | 31.205 | 22.393 | 13.971 | 21.886 | 20.832 |\n",
      "\u001b[32m[10/21 08:37:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.622 | cushion    | 59.316 | door       | 5.532 |\n",
      "| indoor-plant | 6.944 | sofa       | 50.378 | table      | 0.000 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='IE7ZPD91_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:37:15 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:37:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:37:15 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:37:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:37:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 15/355. 0.0875 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 08:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 55/355. 0.0977 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 08:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 94/355. 0.1025 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 08:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 128/355. 0.1057 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 08:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.1036 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 08:37:43 d2.evaluation.evaluator]: \u001b[0mInference done 218/355. 0.1001 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 08:37:48 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.1038 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:37:53 d2.evaluation.evaluator]: \u001b[0mInference done 282/355. 0.1061 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:37:58 d2.evaluation.evaluator]: \u001b[0mInference done 312/355. 0.1086 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 08:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.1107 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.866485 (0.139619 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.111528 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IE7ZPD90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.365 | 32.887 | 23.330 | 14.029 | 25.086 | 21.419 |\n",
      "\u001b[32m[10/21 08:38:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.487  | cushion    | 53.983 | door       | 5.859 |\n",
      "| indoor-plant | 10.027 | sofa       | 51.360 | table      | 3.475 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:38:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:38:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[10/21 08:38:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:38:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.06 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.189\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
      "\u001b[32m[10/21 08:38:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.624 | 29.599 | 21.830 | 12.581 | 21.048 | 18.711 |\n",
      "\u001b[32m[10/21 08:38:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.743 | cushion    | 57.888 | door       | 6.132 |\n",
      "| indoor-plant | 6.460 | sofa       | 45.523 | table      | 0.001 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='IE7ZPD92_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:38:07 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:38:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:38:07 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:38:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:38:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1293 s / img. ETA=0:00:59\n",
      "\u001b[32m[10/21 08:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 44/355. 0.1219 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 08:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 78/355. 0.1237 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 08:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 111/355. 0.1234 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 08:38:29 d2.evaluation.evaluator]: \u001b[0mInference done 146/355. 0.1235 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 08:38:34 d2.evaluation.evaluator]: \u001b[0mInference done 182/355. 0.1239 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 08:38:39 d2.evaluation.evaluator]: \u001b[0mInference done 214/355. 0.1240 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 08:38:44 d2.evaluation.evaluator]: \u001b[0mInference done 247/355. 0.1239 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 279/355. 0.1240 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:38:54 d2.evaluation.evaluator]: \u001b[0mInference done 306/355. 0.1248 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 08:38:59 d2.evaluation.evaluator]: \u001b[0mInference done 338/355. 0.1250 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:55.101714 (0.157433 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:44 (0.125822 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/IE7ZPD90/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.239\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.161 | 34.629 | 23.903 | 13.537 | 25.406 | 23.533 |\n",
      "\u001b[32m[10/21 08:39:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.176  | cushion    | 53.382 | door       | 6.574 |\n",
      "| indoor-plant | 11.983 | sofa       | 54.674 | table      | 3.176 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:39:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:39:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.51 seconds.\n",
      "\u001b[32m[10/21 08:39:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:39:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
      "\u001b[32m[10/21 08:39:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 19.998 | 31.281 | 21.990 | 12.217 | 20.942 | 20.903 |\n",
      "\u001b[32m[10/21 08:39:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP    | category   | AP     | category   | AP    |\n",
      "|:-------------|:------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.802 | cushion    | 56.861 | door       | 7.199 |\n",
      "| indoor-plant | 7.092 | sofa       | 47.036 | table      | 0.000 |\n",
      "all results {'bbox': {'AP50': [34.031756006768994, 32.88655795351001, 34.628631209304054]}, 'segm': {'AP50': [31.204942489512348, 29.598793359959092, 31.281178095613825]}}\n",
      "dataset_name RKJ05JL\n",
      "SOLVER PARAMS (500, 100, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='RKJ05JL_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/RKJ05JL0\n",
      "output_aug/500/RKJ05JL0\n",
      "\u001b[32m[10/21 08:39:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:39:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:39:06 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:39:06 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:39:06 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:39:06 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:39:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:39:06 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:39:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:39:14 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 19  total_loss: 4.057  loss_cls: 2.08  loss_box_reg: 0.8587  loss_mask: 0.6919  loss_rpn_cls: 0.3269  loss_rpn_loc: 0.1845  time: 0.3881  data_time: 0.0179  lr: 9.5405e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:39:21 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 39  total_loss: 2.741  loss_cls: 0.9678  loss_box_reg: 0.8832  loss_mask: 0.6734  loss_rpn_cls: 0.08065  loss_rpn_loc: 0.1434  time: 0.3813  data_time: 0.0040  lr: 0.0001953  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:39:29 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 59  total_loss: 2.497  loss_cls: 0.8047  loss_box_reg: 0.8753  loss_mask: 0.6345  loss_rpn_cls: 0.06775  loss_rpn_loc: 0.1125  time: 0.3763  data_time: 0.0041  lr: 0.0002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:39:36 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 79  total_loss: 2.339  loss_cls: 0.6922  loss_box_reg: 0.8833  loss_mask: 0.5974  loss_rpn_cls: 0.05513  loss_rpn_loc: 0.1272  time: 0.3724  data_time: 0.0039  lr: 0.0003951  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:39:43 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 99  total_loss: 1.98  loss_cls: 0.5511  loss_box_reg: 0.843  loss_mask: 0.5198  loss_rpn_cls: 0.02971  loss_rpn_loc: 0.0873  time: 0.3691  data_time: 0.0040  lr: 0.000495  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:39:50 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 119  total_loss: 1.809  loss_cls: 0.4438  loss_box_reg: 0.7965  loss_mask: 0.4509  loss_rpn_cls: 0.02799  loss_rpn_loc: 0.09316  time: 0.3675  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:39:57 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 139  total_loss: 1.65  loss_cls: 0.3341  loss_box_reg: 0.7729  loss_mask: 0.3886  loss_rpn_cls: 0.01813  loss_rpn_loc: 0.09402  time: 0.3658  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:05 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 159  total_loss: 1.396  loss_cls: 0.2615  loss_box_reg: 0.6939  loss_mask: 0.336  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.08978  time: 0.3654  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:12 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 179  total_loss: 1.276  loss_cls: 0.2251  loss_box_reg: 0.6002  loss_mask: 0.3358  loss_rpn_cls: 0.02477  loss_rpn_loc: 0.09499  time: 0.3653  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:19 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 199  total_loss: 1.153  loss_cls: 0.2003  loss_box_reg: 0.5366  loss_mask: 0.3198  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.0588  time: 0.3650  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:26 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 219  total_loss: 1.044  loss_cls: 0.164  loss_box_reg: 0.4963  loss_mask: 0.3075  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.08103  time: 0.3644  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:34 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 239  total_loss: 0.923  loss_cls: 0.1649  loss_box_reg: 0.4426  loss_mask: 0.2654  loss_rpn_cls: 0.006943  loss_rpn_loc: 0.07353  time: 0.3638  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:41 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 259  total_loss: 0.9512  loss_cls: 0.155  loss_box_reg: 0.4105  loss_mask: 0.2794  loss_rpn_cls: 0.009951  loss_rpn_loc: 0.08129  time: 0.3632  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:48 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 279  total_loss: 0.9144  loss_cls: 0.1661  loss_box_reg: 0.3914  loss_mask: 0.2819  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.0683  time: 0.3630  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:40:55 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 299  total_loss: 0.8691  loss_cls: 0.1599  loss_box_reg: 0.3632  loss_mask: 0.2572  loss_rpn_cls: 0.008241  loss_rpn_loc: 0.08394  time: 0.3627  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:02 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 319  total_loss: 0.8781  loss_cls: 0.1401  loss_box_reg: 0.3641  loss_mask: 0.2617  loss_rpn_cls: 0.005338  loss_rpn_loc: 0.06073  time: 0.3625  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:10 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 339  total_loss: 0.7263  loss_cls: 0.1277  loss_box_reg: 0.3252  loss_mask: 0.2326  loss_rpn_cls: 0.005545  loss_rpn_loc: 0.04716  time: 0.3621  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:17 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 359  total_loss: 0.8732  loss_cls: 0.1425  loss_box_reg: 0.3628  loss_mask: 0.2431  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.08687  time: 0.3622  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:24 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 379  total_loss: 0.7216  loss_cls: 0.1243  loss_box_reg: 0.3141  loss_mask: 0.215  loss_rpn_cls: 0.008431  loss_rpn_loc: 0.06445  time: 0.3616  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:31 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 0.7212  loss_cls: 0.1306  loss_box_reg: 0.2874  loss_mask: 0.2355  loss_rpn_cls: 0.005425  loss_rpn_loc: 0.06653  time: 0.3615  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:38 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 0.6689  loss_cls: 0.1123  loss_box_reg: 0.2885  loss_mask: 0.2231  loss_rpn_cls: 0.006118  loss_rpn_loc: 0.05511  time: 0.3618  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:46 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 0.6486  loss_cls: 0.1123  loss_box_reg: 0.2542  loss_mask: 0.2252  loss_rpn_cls: 0.004983  loss_rpn_loc: 0.05245  time: 0.3617  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:53 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 459  total_loss: 0.7203  loss_cls: 0.1206  loss_box_reg: 0.3001  loss_mask: 0.2282  loss_rpn_cls: 0.006974  loss_rpn_loc: 0.06056  time: 0.3616  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:41:59 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 479  total_loss: 0.7612  loss_cls: 0.119  loss_box_reg: 0.3052  loss_mask: 0.2445  loss_rpn_cls: 0.006169  loss_rpn_loc: 0.07174  time: 0.3604  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:42:08 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.6495  loss_cls: 0.115  loss_box_reg: 0.2956  loss_mask: 0.1925  loss_rpn_cls: 0.008936  loss_rpn_loc: 0.05836  time: 0.3602  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:42:08 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:59 (0.3602 s / it)\n",
      "\u001b[32m[10/21 08:42:08 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:00 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='RKJ05JL_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:42:08 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:42:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:42:08 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:42:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:42:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:42:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1166 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:42:14 d2.evaluation.evaluator]: \u001b[0mInference done 55/126. 0.1056 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 97/126. 0.1081 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.312737 (0.118287 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.107479 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/RKJ05JL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.432 | 39.350 | 25.188 | 12.798 | 45.098 | 27.822 |\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 27.540 | cushion    | 27.264 | door       | 10.361 |\n",
      "| indoor-plant | 24.556 | sofa       | 39.872 | table      | 11.001 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.297\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.609 | 33.765 | 14.536 | 6.605 | 30.918 | 22.163 |\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 10.851 | cushion    | 26.330 | door       | 10.484 |\n",
      "| indoor-plant | 15.272 | sofa       | 28.078 | table      | 2.639  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='RKJ05JL0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:42:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:42:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:42:23 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:42:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:42:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:42:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0941 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 08:42:30 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.1010 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 08:42:35 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.1044 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 08:42:40 d2.evaluation.evaluator]: \u001b[0mInference done 136/355. 0.1067 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 08:42:45 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.1082 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 08:42:50 d2.evaluation.evaluator]: \u001b[0mInference done 219/355. 0.1084 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:42:55 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.1084 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 305/355. 0.1065 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 08:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.1065 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:43:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.366119 (0.121046 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:43:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.106333 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:43:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:43:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/RKJ05JL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:43:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:43:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.385\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.280\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.453\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.873 | 38.465 | 27.017 | 13.729 | 27.962 | 22.630 |\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.515  | cushion    | 56.502 | door       | 3.968 |\n",
      "| indoor-plant | 20.346 | sofa       | 60.399 | table      | 6.508 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.933 | 34.254 | 24.852 | 14.212 | 23.316 | 19.227 |\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.008  | cushion    | 62.626 | door       | 4.664 |\n",
      "| indoor-plant | 15.453 | sofa       | 53.732 | table      | 0.117 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='RKJ05JL1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:43:07 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:43:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:43:07 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:43:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:43:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.1038 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 08:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 63/355. 0.1053 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 08:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 105/355. 0.1072 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 08:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 144/355. 0.1095 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 08:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 185/355. 0.1103 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 08:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 227/355. 0.1099 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 08:43:40 d2.evaluation.evaluator]: \u001b[0mInference done 271/355. 0.1080 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:43:45 d2.evaluation.evaluator]: \u001b[0mInference done 314/355. 0.1074 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:43:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.424167 (0.121212 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:43:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.107017 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/RKJ05JL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.383\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.511 | 38.305 | 27.051 | 12.450 | 28.634 | 21.937 |\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.018  | cushion    | 54.092 | door       | 5.010 |\n",
      "| indoor-plant | 19.502 | sofa       | 59.269 | table      | 7.173 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.234\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.028 | 33.631 | 23.384 | 11.927 | 23.026 | 18.971 |\n",
      "\u001b[32m[10/21 08:43:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.338  | cushion    | 58.912 | door       | 6.022 |\n",
      "| indoor-plant | 14.455 | sofa       | 51.337 | table      | 0.105 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='RKJ05JL2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:43:52 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:43:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:43:52 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:43:52 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:43:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1024 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 08:43:58 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1094 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 08:44:03 d2.evaluation.evaluator]: \u001b[0mInference done 93/355. 0.1073 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 08:44:08 d2.evaluation.evaluator]: \u001b[0mInference done 133/355. 0.1090 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 08:44:13 d2.evaluation.evaluator]: \u001b[0mInference done 175/355. 0.1091 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 08:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 218/355. 0.1085 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:44:23 d2.evaluation.evaluator]: \u001b[0mInference done 260/355. 0.1080 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 314/355. 0.1029 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 353/355. 0.1041 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.455571 (0.118444 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.104162 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/RKJ05JL0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.251\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.471\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.140 | 39.717 | 26.830 | 12.274 | 28.898 | 23.417 |\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.720  | cushion    | 53.465 | door       | 4.547 |\n",
      "| indoor-plant | 22.380 | sofa       | 61.814 | table      | 6.913 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:44:34 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:44:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 08:44:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:44:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.346\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n",
      "\u001b[32m[10/21 08:44:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.334 | 34.585 | 24.627 | 13.198 | 23.112 | 20.162 |\n",
      "\u001b[32m[10/21 08:44:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.302  | cushion    | 58.171 | door       | 5.918 |\n",
      "| indoor-plant | 15.350 | sofa       | 53.193 | table      | 0.070 |\n",
      "all results {'bbox': {'AP50': [38.46509321369757, 38.30520042712733, 39.71745797139239]}, 'segm': {'AP50': [34.25422726201451, 33.63059423250116, 34.585165911788366]}}\n",
      "dataset_name LVD0KYB\n",
      "SOLVER PARAMS (800, 100, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='LVD0KYB_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/LVD0KYB0\n",
      "output_aug/800/LVD0KYB0\n",
      "\u001b[32m[10/21 08:44:36 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:44:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:44:36 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:44:36 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:44:36 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:44:36 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:44:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:44:36 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:44:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:44:43 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 19  total_loss: 3.834  loss_cls: 1.842  loss_box_reg: 0.874  loss_mask: 0.6912  loss_rpn_cls: 0.2564  loss_rpn_loc: 0.1736  time: 0.3393  data_time: 0.0163  lr: 9.5405e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:44:50 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 39  total_loss: 2.745  loss_cls: 0.8973  loss_box_reg: 0.859  loss_mask: 0.6734  loss_rpn_cls: 0.08052  loss_rpn_loc: 0.1394  time: 0.3495  data_time: 0.0038  lr: 0.00019531  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:44:57 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 59  total_loss: 2.492  loss_cls: 0.7512  loss_box_reg: 0.8724  loss_mask: 0.6354  loss_rpn_cls: 0.07216  loss_rpn_loc: 0.1297  time: 0.3495  data_time: 0.0037  lr: 0.0002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:05 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 79  total_loss: 2.293  loss_cls: 0.6677  loss_box_reg: 0.8864  loss_mask: 0.5947  loss_rpn_cls: 0.05174  loss_rpn_loc: 0.112  time: 0.3524  data_time: 0.0038  lr: 0.00039511  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:12 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 99  total_loss: 2.098  loss_cls: 0.5287  loss_box_reg: 0.8408  loss_mask: 0.535  loss_rpn_cls: 0.0359  loss_rpn_loc: 0.1443  time: 0.3532  data_time: 0.0036  lr: 0.000495  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:19 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 119  total_loss: 1.724  loss_cls: 0.4097  loss_box_reg: 0.8177  loss_mask: 0.4382  loss_rpn_cls: 0.02356  loss_rpn_loc: 0.05592  time: 0.3523  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:26 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 139  total_loss: 1.559  loss_cls: 0.2952  loss_box_reg: 0.7528  loss_mask: 0.3819  loss_rpn_cls: 0.02053  loss_rpn_loc: 0.07887  time: 0.3516  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:33 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 159  total_loss: 1.369  loss_cls: 0.2474  loss_box_reg: 0.6678  loss_mask: 0.3496  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.09945  time: 0.3517  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:40 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 179  total_loss: 1.229  loss_cls: 0.191  loss_box_reg: 0.585  loss_mask: 0.3172  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.08504  time: 0.3524  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:47 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 199  total_loss: 1.156  loss_cls: 0.1993  loss_box_reg: 0.5036  loss_mask: 0.3122  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.08132  time: 0.3530  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:45:54 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 219  total_loss: 1.009  loss_cls: 0.1739  loss_box_reg: 0.4492  loss_mask: 0.3027  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.0631  time: 0.3539  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:02 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 239  total_loss: 0.9692  loss_cls: 0.1816  loss_box_reg: 0.449  loss_mask: 0.2725  loss_rpn_cls: 0.015  loss_rpn_loc: 0.07654  time: 0.3544  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:09 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 259  total_loss: 0.9601  loss_cls: 0.1671  loss_box_reg: 0.3978  loss_mask: 0.2837  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.09919  time: 0.3559  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:16 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 279  total_loss: 0.885  loss_cls: 0.1588  loss_box_reg: 0.3793  loss_mask: 0.2726  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.08698  time: 0.3562  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:23 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 299  total_loss: 0.8043  loss_cls: 0.1514  loss_box_reg: 0.3527  loss_mask: 0.2478  loss_rpn_cls: 0.008183  loss_rpn_loc: 0.06327  time: 0.3560  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:31 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 319  total_loss: 0.8003  loss_cls: 0.149  loss_box_reg: 0.3673  loss_mask: 0.2363  loss_rpn_cls: 0.008569  loss_rpn_loc: 0.05955  time: 0.3562  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:37 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 339  total_loss: 0.7914  loss_cls: 0.1211  loss_box_reg: 0.3323  loss_mask: 0.2353  loss_rpn_cls: 0.008695  loss_rpn_loc: 0.07328  time: 0.3557  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:45 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 359  total_loss: 0.7351  loss_cls: 0.1219  loss_box_reg: 0.3071  loss_mask: 0.257  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.04742  time: 0.3555  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:52 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 379  total_loss: 0.7009  loss_cls: 0.1273  loss_box_reg: 0.2959  loss_mask: 0.2128  loss_rpn_cls: 0.008817  loss_rpn_loc: 0.05848  time: 0.3551  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:46:59 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 399  total_loss: 0.7834  loss_cls: 0.1314  loss_box_reg: 0.3319  loss_mask: 0.2413  loss_rpn_cls: 0.005397  loss_rpn_loc: 0.06118  time: 0.3549  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:06 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 419  total_loss: 0.7437  loss_cls: 0.1084  loss_box_reg: 0.2766  loss_mask: 0.233  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.07252  time: 0.3549  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:13 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 439  total_loss: 0.7353  loss_cls: 0.1252  loss_box_reg: 0.3054  loss_mask: 0.2195  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.04506  time: 0.3548  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:20 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 459  total_loss: 0.6981  loss_cls: 0.117  loss_box_reg: 0.3138  loss_mask: 0.2257  loss_rpn_cls: 0.008549  loss_rpn_loc: 0.06149  time: 0.3551  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:27 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 479  total_loss: 0.6718  loss_cls: 0.09925  loss_box_reg: 0.2806  loss_mask: 0.2153  loss_rpn_cls: 0.00503  loss_rpn_loc: 0.06388  time: 0.3551  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:34 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 499  total_loss: 0.6263  loss_cls: 0.09477  loss_box_reg: 0.2566  loss_mask: 0.2057  loss_rpn_cls: 0.008957  loss_rpn_loc: 0.05862  time: 0.3554  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:42 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 519  total_loss: 0.6659  loss_cls: 0.1083  loss_box_reg: 0.2862  loss_mask: 0.2266  loss_rpn_cls: 0.004692  loss_rpn_loc: 0.04227  time: 0.3559  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:49 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 539  total_loss: 0.6311  loss_cls: 0.1083  loss_box_reg: 0.2724  loss_mask: 0.2012  loss_rpn_cls: 0.006651  loss_rpn_loc: 0.05687  time: 0.3560  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:47:57 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 559  total_loss: 0.6094  loss_cls: 0.1026  loss_box_reg: 0.2593  loss_mask: 0.1966  loss_rpn_cls: 0.005367  loss_rpn_loc: 0.06346  time: 0.3572  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:04 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 579  total_loss: 0.6169  loss_cls: 0.08785  loss_box_reg: 0.245  loss_mask: 0.2012  loss_rpn_cls: 0.004829  loss_rpn_loc: 0.04236  time: 0.3571  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:11 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 599  total_loss: 0.6007  loss_cls: 0.09203  loss_box_reg: 0.2626  loss_mask: 0.1952  loss_rpn_cls: 0.007002  loss_rpn_loc: 0.05418  time: 0.3571  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:18 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 0.675  loss_cls: 0.1014  loss_box_reg: 0.2753  loss_mask: 0.2231  loss_rpn_cls: 0.009031  loss_rpn_loc: 0.06692  time: 0.3569  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:25 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 0.5617  loss_cls: 0.08563  loss_box_reg: 0.2277  loss_mask: 0.1861  loss_rpn_cls: 0.00332  loss_rpn_loc: 0.04404  time: 0.3567  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:32 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 0.6055  loss_cls: 0.1034  loss_box_reg: 0.2482  loss_mask: 0.1973  loss_rpn_cls: 0.005492  loss_rpn_loc: 0.05953  time: 0.3565  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:39 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 0.6087  loss_cls: 0.1084  loss_box_reg: 0.243  loss_mask: 0.1882  loss_rpn_cls: 0.005298  loss_rpn_loc: 0.04982  time: 0.3565  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:46 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 0.5764  loss_cls: 0.09414  loss_box_reg: 0.2159  loss_mask: 0.2052  loss_rpn_cls: 0.003898  loss_rpn_loc: 0.03906  time: 0.3564  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:48:53 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 0.5841  loss_cls: 0.09451  loss_box_reg: 0.2428  loss_mask: 0.1971  loss_rpn_cls: 0.005057  loss_rpn_loc: 0.04351  time: 0.3564  data_time: 0.0035  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:49:00 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.5613  loss_cls: 0.07596  loss_box_reg: 0.2456  loss_mask: 0.1891  loss_rpn_cls: 0.002782  loss_rpn_loc: 0.0431  time: 0.3564  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:49:07 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 0.5626  loss_cls: 0.09519  loss_box_reg: 0.2222  loss_mask: 0.182  loss_rpn_cls: 0.00338  loss_rpn_loc: 0.04246  time: 0.3555  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:49:14 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.5407  loss_cls: 0.08063  loss_box_reg: 0.2122  loss_mask: 0.1867  loss_rpn_cls: 0.004316  loss_rpn_loc: 0.04081  time: 0.3555  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:49:22 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5737  loss_cls: 0.08067  loss_box_reg: 0.2222  loss_mask: 0.18  loss_rpn_cls: 0.002746  loss_rpn_loc: 0.04575  time: 0.3547  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:49:22 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:43 (0.3548 s / it)\n",
      "\u001b[32m[10/21 08:49:22 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:44 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='LVD0KYB_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:49:22 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:49:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:49:22 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:49:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:49:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1127 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 52/126. 0.1130 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 95/126. 0.1104 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.705778 (0.121535 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.111228 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/LVD0KYB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.591 | 42.072 | 27.244 | 12.873 | 45.711 | 37.745 |\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 28.907 | cushion    | 32.448 | door       | 16.198 |\n",
      "| indoor-plant | 27.136 | sofa       | 37.363 | table      | 11.492 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.331\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.855 | 34.228 | 14.152 | 7.357 | 32.508 | 24.045 |\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 10.427 | cushion    | 28.415 | door       | 12.885 |\n",
      "| indoor-plant | 20.929 | sofa       | 26.046 | table      | 2.429  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='LVD0KYB0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:49:37 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:49:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:49:37 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:49:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:49:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:49:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1041 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 08:49:44 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.1042 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 08:49:49 d2.evaluation.evaluator]: \u001b[0mInference done 93/355. 0.1086 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 08:49:54 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.1098 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 08:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 177/355. 0.1091 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 08:50:04 d2.evaluation.evaluator]: \u001b[0mInference done 225/355. 0.1059 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 08:50:09 d2.evaluation.evaluator]: \u001b[0mInference done 266/355. 0.1065 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.1064 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 08:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 348/355. 0.1069 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 08:50:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.201118 (0.120575 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:50:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.106902 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:50:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:50:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/LVD0KYB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.438\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.413\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.060 | 43.809 | 30.600 | 15.896 | 31.255 | 23.539 |\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.605  | cushion    | 68.401 | door       | 4.793 |\n",
      "| indoor-plant | 24.141 | sofa       | 64.416 | table      | 4.005 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.390\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.359\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.610 | 39.019 | 27.471 | 15.247 | 27.309 | 19.941 |\n",
      "\u001b[32m[10/21 08:50:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.497  | cushion    | 71.756 | door       | 5.606 |\n",
      "| indoor-plant | 18.808 | sofa       | 55.797 | table      | 0.198 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='LVD0KYB1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:50:21 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:50:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:50:22 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:50:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:50:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 24/355. 0.1056 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 08:50:30 d2.evaluation.evaluator]: \u001b[0mInference done 65/355. 0.1088 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 08:50:35 d2.evaluation.evaluator]: \u001b[0mInference done 106/355. 0.1107 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 08:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 146/355. 0.1115 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 08:50:45 d2.evaluation.evaluator]: \u001b[0mInference done 187/355. 0.1115 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 08:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 234/355. 0.1077 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 08:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 275/355. 0.1083 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 317/355. 0.1080 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.343726 (0.120982 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.107849 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/LVD0KYB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.440\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.846 | 44.011 | 31.076 | 12.801 | 31.928 | 23.276 |\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.465  | cushion    | 67.724 | door       | 6.253 |\n",
      "| indoor-plant | 23.040 | sofa       | 62.107 | table      | 4.484 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:51:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:51:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 08:51:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:51:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.388\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n",
      "\u001b[32m[10/21 08:51:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.336 | 38.772 | 27.357 | 12.013 | 27.840 | 19.185 |\n",
      "\u001b[32m[10/21 08:51:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.829  | cushion    | 70.549 | door       | 7.260 |\n",
      "| indoor-plant | 18.127 | sofa       | 54.109 | table      | 0.144 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='LVD0KYB2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:51:06 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:51:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:51:06 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:51:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:51:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0987 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 08:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1072 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 08:51:17 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.1111 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 08:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.1123 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 08:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 173/355. 0.1121 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 08:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.1049 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 08:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 266/355. 0.1066 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 08:51:43 d2.evaluation.evaluator]: \u001b[0mInference done 303/355. 0.1083 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 08:51:48 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.1091 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.305963 (0.123731 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.109496 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/LVD0KYB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.907 | 44.670 | 30.850 | 12.932 | 31.240 | 24.286 |\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.930  | cushion    | 67.018 | door       | 5.794 |\n",
      "| indoor-plant | 25.459 | sofa       | 61.888 | table      | 4.355 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:51:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:51:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 08:51:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:51:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.371\n",
      "\u001b[32m[10/21 08:51:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.992 | 39.697 | 26.384 | 11.728 | 27.141 | 20.490 |\n",
      "\u001b[32m[10/21 08:51:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.802  | cushion    | 68.708 | door       | 6.838 |\n",
      "| indoor-plant | 19.648 | sofa       | 52.728 | table      | 0.229 |\n",
      "all results {'bbox': {'AP50': [43.80948777156179, 44.0112996825793, 44.67035626631854]}, 'segm': {'AP50': [39.0194123073261, 38.77194657219114, 39.696963088982635]}}\n",
      "dataset_name CFS655A\n",
      "SOLVER PARAMS (500, 200, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='CFS655A_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/CFS655A0\n",
      "output_aug/500/CFS655A0\n",
      "\u001b[32m[10/21 08:51:52 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:51:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:51:52 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:51:52 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:51:52 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:51:52 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:51:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:51:52 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:51:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:52:00 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 19  total_loss: 4.01  loss_cls: 1.997  loss_box_reg: 0.8967  loss_mask: 0.6946  loss_rpn_cls: 0.3652  loss_rpn_loc: 0.1922  time: 0.3648  data_time: 0.0162  lr: 4.7952e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:07 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 39  total_loss: 3.155  loss_cls: 1.301  loss_box_reg: 0.8582  loss_mask: 0.685  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.1268  time: 0.3604  data_time: 0.0039  lr: 9.7902e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:14 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 59  total_loss: 2.582  loss_cls: 0.8608  loss_box_reg: 0.8746  loss_mask: 0.6656  loss_rpn_cls: 0.07602  loss_rpn_loc: 0.1329  time: 0.3567  data_time: 0.0039  lr: 0.00014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:21 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 79  total_loss: 2.481  loss_cls: 0.7549  loss_box_reg: 0.8789  loss_mask: 0.6395  loss_rpn_cls: 0.06464  loss_rpn_loc: 0.1202  time: 0.3567  data_time: 0.0038  lr: 0.0001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:28 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 99  total_loss: 2.302  loss_cls: 0.6835  loss_box_reg: 0.8578  loss_mask: 0.6094  loss_rpn_cls: 0.04707  loss_rpn_loc: 0.1047  time: 0.3568  data_time: 0.0038  lr: 0.00024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:35 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 119  total_loss: 2.127  loss_cls: 0.5868  loss_box_reg: 0.8589  loss_mask: 0.5558  loss_rpn_cls: 0.0308  loss_rpn_loc: 0.1135  time: 0.3567  data_time: 0.0038  lr: 0.0002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:43 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 139  total_loss: 1.949  loss_cls: 0.5109  loss_box_reg: 0.8211  loss_mask: 0.5061  loss_rpn_cls: 0.03926  loss_rpn_loc: 0.1186  time: 0.3572  data_time: 0.0039  lr: 0.00034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:50 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 159  total_loss: 1.781  loss_cls: 0.3923  loss_box_reg: 0.7916  loss_mask: 0.445  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.08937  time: 0.3567  data_time: 0.0037  lr: 0.0003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:52:57 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 179  total_loss: 1.607  loss_cls: 0.3232  loss_box_reg: 0.7533  loss_mask: 0.3841  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.0709  time: 0.3566  data_time: 0.0038  lr: 0.00044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:04 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 199  total_loss: 1.347  loss_cls: 0.2239  loss_box_reg: 0.6719  loss_mask: 0.3321  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.06027  time: 0.3567  data_time: 0.0038  lr: 0.0004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:11 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 219  total_loss: 1.204  loss_cls: 0.2114  loss_box_reg: 0.5816  loss_mask: 0.349  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.1042  time: 0.3569  data_time: 0.0036  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:18 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 239  total_loss: 1.122  loss_cls: 0.1969  loss_box_reg: 0.5159  loss_mask: 0.3086  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.07823  time: 0.3570  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:25 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 259  total_loss: 1.136  loss_cls: 0.2032  loss_box_reg: 0.4841  loss_mask: 0.3155  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.1017  time: 0.3565  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:33 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 279  total_loss: 1.054  loss_cls: 0.1859  loss_box_reg: 0.452  loss_mask: 0.3146  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.07353  time: 0.3570  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:40 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 299  total_loss: 0.8936  loss_cls: 0.1626  loss_box_reg: 0.3846  loss_mask: 0.2748  loss_rpn_cls: 0.009245  loss_rpn_loc: 0.08122  time: 0.3565  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:47 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 319  total_loss: 0.8983  loss_cls: 0.1457  loss_box_reg: 0.3958  loss_mask: 0.2834  loss_rpn_cls: 0.009444  loss_rpn_loc: 0.06128  time: 0.3565  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:53:54 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 339  total_loss: 0.9651  loss_cls: 0.1619  loss_box_reg: 0.4009  loss_mask: 0.2844  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.09514  time: 0.3574  data_time: 0.0037  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:02 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 359  total_loss: 0.818  loss_cls: 0.1339  loss_box_reg: 0.3396  loss_mask: 0.2566  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.05301  time: 0.3588  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:10 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 379  total_loss: 0.7393  loss_cls: 0.1301  loss_box_reg: 0.3361  loss_mask: 0.2372  loss_rpn_cls: 0.009821  loss_rpn_loc: 0.05099  time: 0.3605  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:18 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 0.8188  loss_cls: 0.1327  loss_box_reg: 0.3339  loss_mask: 0.2527  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.08105  time: 0.3621  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:24 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 0.7727  loss_cls: 0.117  loss_box_reg: 0.3035  loss_mask: 0.2394  loss_rpn_cls: 0.00944  loss_rpn_loc: 0.0627  time: 0.3607  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:31 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 0.7552  loss_cls: 0.1227  loss_box_reg: 0.3295  loss_mask: 0.2511  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.08749  time: 0.3596  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:37 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 459  total_loss: 0.6579  loss_cls: 0.1058  loss_box_reg: 0.2653  loss_mask: 0.2268  loss_rpn_cls: 0.008648  loss_rpn_loc: 0.07383  time: 0.3580  data_time: 0.0039  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:44 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 479  total_loss: 0.746  loss_cls: 0.1296  loss_box_reg: 0.3242  loss_mask: 0.227  loss_rpn_cls: 0.006905  loss_rpn_loc: 0.05564  time: 0.3566  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.7372  loss_cls: 0.1063  loss_box_reg: 0.2919  loss_mask: 0.2295  loss_rpn_cls: 0.008753  loss_rpn_loc: 0.07041  time: 0.3558  data_time: 0.0038  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:54:52 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:57 (0.3558 s / it)\n",
      "\u001b[32m[10/21 08:54:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:58 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='CFS655A_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 08:54:52 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 08:54:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:54:52 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:54:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 08:54:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 08:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1129 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 08:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 52/126. 0.1124 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 08:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 94/126. 0.1110 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.826219 (0.122531 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.110113 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CFS655A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.421\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.902 | 42.120 | 26.426 | 13.179 | 47.550 | 30.378 |\n",
      "\u001b[32m[10/21 08:55:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 28.949 | cushion    | 28.801 | door       | 12.624 |\n",
      "| indoor-plant | 25.994 | sofa       | 42.607 | table      | 10.437 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:55:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:55:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 08:55:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:55:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
      "\u001b[32m[10/21 08:55:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.631 | 34.203 | 13.220 | 8.330 | 31.679 | 23.425 |\n",
      "\u001b[32m[10/21 08:55:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 11.829 | cushion    | 25.419 | door       | 12.082 |\n",
      "| indoor-plant | 18.617 | sofa       | 29.913 | table      | 1.927  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='CFS655A0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 08:55:08 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 08:55:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:55:08 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:55:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 08:55:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1119 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 08:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1043 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 08:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 93/355. 0.1061 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 08:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 143/355. 0.0992 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 08:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 184/355. 0.1020 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 08:55:35 d2.evaluation.evaluator]: \u001b[0mInference done 224/355. 0.1031 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 08:55:40 d2.evaluation.evaluator]: \u001b[0mInference done 262/355. 0.1043 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 300/355. 0.1052 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 08:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 340/355. 0.1052 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.339956 (0.123828 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.105740 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CFS655A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.172\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.855 | 43.408 | 30.862 | 17.244 | 31.579 | 23.460 |\n",
      "\u001b[32m[10/21 08:55:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.311  | cushion    | 65.655 | door       | 4.117 |\n",
      "| indoor-plant | 22.831 | sofa       | 63.097 | table      | 7.116 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:55:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:55:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 08:55:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:55:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.396\n",
      "\u001b[32m[10/21 08:55:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.215 | 38.682 | 26.134 | 14.959 | 25.718 | 22.622 |\n",
      "\u001b[32m[10/21 08:55:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.069  | cushion    | 67.622 | door       | 5.100 |\n",
      "| indoor-plant | 17.672 | sofa       | 57.696 | table      | 0.130 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='CFS655A1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 08:55:53 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 08:55:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:55:53 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:55:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 08:55:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1116 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 08:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.1064 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 08:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1090 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 08:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 139/355. 0.1023 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 08:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.1047 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 08:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 222/355. 0.1043 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 08:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 261/355. 0.1051 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 08:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 302/355. 0.1049 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 08:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 341/355. 0.1061 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 08:56:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.369394 (0.123913 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:56:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.106576 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:56:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:56:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CFS655A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:56:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:56:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.183 | 43.699 | 30.636 | 14.943 | 31.757 | 21.255 |\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.066  | cushion    | 64.096 | door       | 5.148 |\n",
      "| indoor-plant | 21.568 | sofa       | 59.897 | table      | 7.321 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.849 | 38.379 | 26.752 | 12.519 | 26.113 | 20.765 |\n",
      "\u001b[32m[10/21 08:56:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.373  | cushion    | 65.503 | door       | 6.357 |\n",
      "| indoor-plant | 16.807 | sofa       | 56.937 | table      | 0.118 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='CFS655A2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 08:56:39 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 08:56:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 08:56:39 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:56:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 08:56:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 08:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.1167 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 08:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.1104 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 08:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 92/355. 0.1108 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 08:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 145/355. 0.0997 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 08:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 188/355. 0.1017 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 08:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 222/355. 0.1052 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 08:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 258/355. 0.1076 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 08:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 292/355. 0.1099 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 08:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 328/355. 0.1111 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.563389 (0.130181 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.111815 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/CFS655A0/coco_instances_results.json\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.470\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.838 | 44.531 | 31.322 | 15.795 | 31.823 | 23.117 |\n",
      "\u001b[32m[10/21 08:57:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.866  | cushion    | 64.349 | door       | 4.800 |\n",
      "| indoor-plant | 23.712 | sofa       | 61.870 | table      | 7.430 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 08:57:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 08:57:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.45 seconds.\n",
      "\u001b[32m[10/21 08:57:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 08:57:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.391\n",
      "\u001b[32m[10/21 08:57:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.652 | 39.202 | 26.831 | 13.833 | 25.731 | 22.104 |\n",
      "\u001b[32m[10/21 08:57:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.742  | cushion    | 65.079 | door       | 6.022 |\n",
      "| indoor-plant | 17.316 | sofa       | 55.694 | table      | 0.061 |\n",
      "all results {'bbox': {'AP50': [43.407891677600354, 43.69866344227519, 44.53054006030527]}, 'segm': {'AP50': [38.68179071965353, 38.3787595044664, 39.20183723739344]}}\n",
      "dataset_name VJAEGJ4\n",
      "SOLVER PARAMS (800, 200, 0.0005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='VJAEGJ4_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/VJAEGJ40\n",
      "output_aug/800/VJAEGJ40\n",
      "\u001b[32m[10/21 08:57:27 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 08:57:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 08:57:27 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 08:57:27 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 08:57:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 08:57:27 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 08:57:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 08:57:27 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 08:57:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 08:57:36 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 19  total_loss: 3.842  loss_cls: 1.801  loss_box_reg: 0.862  loss_mask: 0.6904  loss_rpn_cls: 0.2949  loss_rpn_loc: 0.1535  time: 0.3746  data_time: 0.0204  lr: 4.7953e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:57:43 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 39  total_loss: 3.107  loss_cls: 1.165  loss_box_reg: 0.8936  loss_mask: 0.6816  loss_rpn_cls: 0.1299  loss_rpn_loc: 0.1612  time: 0.3711  data_time: 0.0043  lr: 9.7903e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:57:50 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 59  total_loss: 2.51  loss_cls: 0.8178  loss_box_reg: 0.8663  loss_mask: 0.6623  loss_rpn_cls: 0.05401  loss_rpn_loc: 0.08651  time: 0.3718  data_time: 0.0043  lr: 0.00014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:57:58 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 79  total_loss: 2.41  loss_cls: 0.7404  loss_box_reg: 0.8738  loss_mask: 0.6392  loss_rpn_cls: 0.05742  loss_rpn_loc: 0.1209  time: 0.3709  data_time: 0.0044  lr: 0.0001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:05 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 99  total_loss: 2.241  loss_cls: 0.6431  loss_box_reg: 0.8492  loss_mask: 0.5932  loss_rpn_cls: 0.0463  loss_rpn_loc: 0.07628  time: 0.3685  data_time: 0.0043  lr: 0.00024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:12 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 119  total_loss: 2.09  loss_cls: 0.5537  loss_box_reg: 0.8607  loss_mask: 0.5582  loss_rpn_cls: 0.03553  loss_rpn_loc: 0.08749  time: 0.3656  data_time: 0.0043  lr: 0.0002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:19 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 139  total_loss: 1.962  loss_cls: 0.4706  loss_box_reg: 0.8369  loss_mask: 0.5004  loss_rpn_cls: 0.02667  loss_rpn_loc: 0.1013  time: 0.3638  data_time: 0.0042  lr: 0.00034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:27 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 159  total_loss: 1.626  loss_cls: 0.3335  loss_box_reg: 0.7862  loss_mask: 0.424  loss_rpn_cls: 0.02273  loss_rpn_loc: 0.07306  time: 0.3652  data_time: 0.0043  lr: 0.0003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:34 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 179  total_loss: 1.565  loss_cls: 0.3036  loss_box_reg: 0.7546  loss_mask: 0.3962  loss_rpn_cls: 0.02486  loss_rpn_loc: 0.1069  time: 0.3653  data_time: 0.0049  lr: 0.00044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:41 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 199  total_loss: 1.35  loss_cls: 0.2448  loss_box_reg: 0.658  loss_mask: 0.3377  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.07607  time: 0.3661  data_time: 0.0043  lr: 0.0004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:49 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 219  total_loss: 1.301  loss_cls: 0.2284  loss_box_reg: 0.6032  loss_mask: 0.3331  loss_rpn_cls: 0.01711  loss_rpn_loc: 0.1164  time: 0.3665  data_time: 0.0042  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:58:56 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 239  total_loss: 1.115  loss_cls: 0.2087  loss_box_reg: 0.5398  loss_mask: 0.3072  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.07919  time: 0.3667  data_time: 0.0044  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:04 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 259  total_loss: 1.098  loss_cls: 0.1929  loss_box_reg: 0.4841  loss_mask: 0.2965  loss_rpn_cls: 0.01021  loss_rpn_loc: 0.09312  time: 0.3669  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:11 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 279  total_loss: 0.9592  loss_cls: 0.1687  loss_box_reg: 0.4242  loss_mask: 0.2819  loss_rpn_cls: 0.008057  loss_rpn_loc: 0.07995  time: 0.3672  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:19 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 299  total_loss: 0.959  loss_cls: 0.1683  loss_box_reg: 0.4383  loss_mask: 0.2873  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.07073  time: 0.3676  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:26 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 319  total_loss: 0.888  loss_cls: 0.1504  loss_box_reg: 0.3878  loss_mask: 0.2727  loss_rpn_cls: 0.008521  loss_rpn_loc: 0.05501  time: 0.3679  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:34 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 339  total_loss: 0.8136  loss_cls: 0.1283  loss_box_reg: 0.3487  loss_mask: 0.2447  loss_rpn_cls: 0.009525  loss_rpn_loc: 0.06483  time: 0.3686  data_time: 0.0045  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:41 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 359  total_loss: 0.7952  loss_cls: 0.1395  loss_box_reg: 0.3612  loss_mask: 0.2537  loss_rpn_cls: 0.03321  loss_rpn_loc: 0.08639  time: 0.3672  data_time: 0.0044  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:47 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 379  total_loss: 0.7482  loss_cls: 0.1165  loss_box_reg: 0.3135  loss_mask: 0.2456  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.0526  time: 0.3657  data_time: 0.0042  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 08:59:54 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 399  total_loss: 0.7893  loss_cls: 0.1322  loss_box_reg: 0.3198  loss_mask: 0.2449  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.05798  time: 0.3645  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:01 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 419  total_loss: 0.7139  loss_cls: 0.1275  loss_box_reg: 0.2901  loss_mask: 0.2292  loss_rpn_cls: 0.004818  loss_rpn_loc: 0.04901  time: 0.3628  data_time: 0.0042  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:08 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 439  total_loss: 0.7593  loss_cls: 0.1068  loss_box_reg: 0.3054  loss_mask: 0.2212  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.06346  time: 0.3619  data_time: 0.0044  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:14 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 459  total_loss: 0.6792  loss_cls: 0.1116  loss_box_reg: 0.2927  loss_mask: 0.2147  loss_rpn_cls: 0.007858  loss_rpn_loc: 0.05646  time: 0.3611  data_time: 0.0042  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:22 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 479  total_loss: 0.7881  loss_cls: 0.1236  loss_box_reg: 0.3283  loss_mask: 0.2459  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.0801  time: 0.3609  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:28 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 499  total_loss: 0.7291  loss_cls: 0.1106  loss_box_reg: 0.3393  loss_mask: 0.2321  loss_rpn_cls: 0.007147  loss_rpn_loc: 0.03887  time: 0.3595  data_time: 0.0045  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:35 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 519  total_loss: 0.6267  loss_cls: 0.112  loss_box_reg: 0.2538  loss_mask: 0.207  loss_rpn_cls: 0.005735  loss_rpn_loc: 0.0566  time: 0.3579  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:41 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 539  total_loss: 0.6556  loss_cls: 0.1055  loss_box_reg: 0.2693  loss_mask: 0.2213  loss_rpn_cls: 0.003131  loss_rpn_loc: 0.04736  time: 0.3570  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:47 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 559  total_loss: 0.7077  loss_cls: 0.1096  loss_box_reg: 0.2692  loss_mask: 0.2235  loss_rpn_cls: 0.008184  loss_rpn_loc: 0.06995  time: 0.3544  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:00:54 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 579  total_loss: 0.684  loss_cls: 0.1166  loss_box_reg: 0.2719  loss_mask: 0.2119  loss_rpn_cls: 0.003743  loss_rpn_loc: 0.0492  time: 0.3542  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:01 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 599  total_loss: 0.5986  loss_cls: 0.1015  loss_box_reg: 0.2493  loss_mask: 0.2046  loss_rpn_cls: 0.007533  loss_rpn_loc: 0.06202  time: 0.3539  data_time: 0.0045  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:08 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 0.5857  loss_cls: 0.09852  loss_box_reg: 0.2496  loss_mask: 0.1953  loss_rpn_cls: 0.007596  loss_rpn_loc: 0.03575  time: 0.3540  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:14 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 0.6425  loss_cls: 0.09597  loss_box_reg: 0.2637  loss_mask: 0.2134  loss_rpn_cls: 0.007008  loss_rpn_loc: 0.06487  time: 0.3529  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:21 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 0.6532  loss_cls: 0.1056  loss_box_reg: 0.2558  loss_mask: 0.2259  loss_rpn_cls: 0.00989  loss_rpn_loc: 0.07417  time: 0.3521  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:28 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 0.5784  loss_cls: 0.08629  loss_box_reg: 0.2319  loss_mask: 0.189  loss_rpn_cls: 0.004388  loss_rpn_loc: 0.04884  time: 0.3518  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:33 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 0.6291  loss_cls: 0.09141  loss_box_reg: 0.2645  loss_mask: 0.2126  loss_rpn_cls: 0.005807  loss_rpn_loc: 0.06763  time: 0.3499  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:40 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 0.5275  loss_cls: 0.08248  loss_box_reg: 0.2258  loss_mask: 0.1853  loss_rpn_cls: 0.00523  loss_rpn_loc: 0.06227  time: 0.3495  data_time: 0.0042  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:47 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.5953  loss_cls: 0.08959  loss_box_reg: 0.2459  loss_mask: 0.2119  loss_rpn_cls: 0.00292  loss_rpn_loc: 0.05785  time: 0.3495  data_time: 0.0043  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:01:54 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 0.5598  loss_cls: 0.09226  loss_box_reg: 0.2397  loss_mask: 0.2034  loss_rpn_cls: 0.006508  loss_rpn_loc: 0.05741  time: 0.3495  data_time: 0.0042  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:02:01 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.5846  loss_cls: 0.09563  loss_box_reg: 0.2324  loss_mask: 0.193  loss_rpn_cls: 0.004326  loss_rpn_loc: 0.04152  time: 0.3491  data_time: 0.0041  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:02:08 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5991  loss_cls: 0.09047  loss_box_reg: 0.2604  loss_mask: 0.1928  loss_rpn_cls: 0.004532  loss_rpn_loc: 0.04895  time: 0.3483  data_time: 0.0040  lr: 0.0005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:02:08 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:37 (0.3483 s / it)\n",
      "\u001b[32m[10/21 09:02:08 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='VJAEGJ4_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:02:08 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:02:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:02:08 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:02:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:02:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:02:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1013 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 09:02:15 d2.evaluation.evaluator]: \u001b[0mInference done 54/126. 0.1049 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 100/126. 0.1015 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:12.801528 (0.105798 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:11 (0.092417 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VJAEGJ40/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.444\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.137 | 42.895 | 27.716 | 15.591 | 48.880 | 29.410 |\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 29.574 | cushion    | 31.314 | door       | 12.057 |\n",
      "| indoor-plant | 28.340 | sofa       | 43.966 | table      | 11.574 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.869 | 34.287 | 14.132 | 7.347 | 32.772 | 25.210 |\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 9.964  | cushion    | 28.338 | door       | 10.983 |\n",
      "| indoor-plant | 20.052 | sofa       | 29.251 | table      | 2.624  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='VJAEGJ40_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:02:22 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:02:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:02:22 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:02:22 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:02:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 17/355. 0.1200 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 09:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1192 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 09:02:35 d2.evaluation.evaluator]: \u001b[0mInference done 88/355. 0.1199 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 09:02:40 d2.evaluation.evaluator]: \u001b[0mInference done 125/355. 0.1199 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 09:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 161/355. 0.1209 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 09:02:50 d2.evaluation.evaluator]: \u001b[0mInference done 200/355. 0.1204 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 235/355. 0.1208 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:03:01 d2.evaluation.evaluator]: \u001b[0mInference done 272/355. 0.1206 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 306/355. 0.1207 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 09:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.1207 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.769859 (0.142200 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.120738 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VJAEGJ40/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 09:03:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.436\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.605 | 43.612 | 31.760 | 16.508 | 31.222 | 26.336 |\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.414  | cushion    | 66.481 | door       | 6.750 |\n",
      "| indoor-plant | 25.382 | sofa       | 66.344 | table      | 4.258 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.40 seconds.\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.385\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.557 | 38.481 | 26.252 | 15.470 | 25.941 | 19.523 |\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.332  | cushion    | 70.913 | door       | 7.117 |\n",
      "| indoor-plant | 16.464 | sofa       | 51.487 | table      | 0.029 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='VJAEGJ41_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:03:14 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:03:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:03:14 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:03:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:03:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:03:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1241 s / img. ETA=0:00:50\n",
      "\u001b[32m[10/21 09:03:21 d2.evaluation.evaluator]: \u001b[0mInference done 47/355. 0.1223 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 09:03:26 d2.evaluation.evaluator]: \u001b[0mInference done 82/355. 0.1223 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 09:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 118/355. 0.1215 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 09:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 153/355. 0.1219 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 191/355. 0.1213 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 225/355. 0.1217 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 09:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.1220 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 293/355. 0.1219 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 328/355. 0.1219 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.607008 (0.144591 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121562 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VJAEGJ40/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.546\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.481 | 44.134 | 31.973 | 16.607 | 31.470 | 26.347 |\n",
      "\u001b[32m[10/21 09:04:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.103  | cushion    | 65.906 | door       | 8.739 |\n",
      "| indoor-plant | 24.969 | sofa       | 63.602 | table      | 4.570 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:04:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:04:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 09:04:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:04:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.380\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n",
      "\u001b[32m[10/21 09:04:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.296 | 38.040 | 26.730 | 15.342 | 25.699 | 19.417 |\n",
      "\u001b[32m[10/21 09:04:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.707  | cushion    | 69.741 | door       | 9.160 |\n",
      "| indoor-plant | 14.781 | sofa       | 50.354 | table      | 0.032 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='VJAEGJ42_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:04:07 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:04:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:04:07 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:04:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:04:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1211 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 09:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1216 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 09:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 81/355. 0.1213 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 09:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 117/355. 0.1210 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 152/355. 0.1224 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 09:04:34 d2.evaluation.evaluator]: \u001b[0mInference done 192/355. 0.1210 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 09:04:39 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.1213 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 09:04:44 d2.evaluation.evaluator]: \u001b[0mInference done 261/355. 0.1213 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:04:49 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.1218 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 330/355. 0.1214 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:04:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:50.345747 (0.143845 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:04:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121842 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/VJAEGJ40/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.544\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.729 | 44.651 | 31.530 | 16.357 | 31.270 | 26.239 |\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.546  | cushion    | 66.504 | door       | 7.303 |\n",
      "| indoor-plant | 27.401 | sofa       | 64.081 | table      | 4.540 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 09:04:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:05:00 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.355\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363\n",
      "\u001b[32m[10/21 09:05:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.845 | 38.673 | 25.922 | 15.242 | 24.937 | 19.642 |\n",
      "\u001b[32m[10/21 09:05:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.726  | cushion    | 69.642 | door       | 7.669 |\n",
      "| indoor-plant | 15.882 | sofa       | 48.131 | table      | 0.020 |\n",
      "all results {'bbox': {'AP50': [43.61192974683669, 44.133664003198916, 44.65079843795146]}, 'segm': {'AP50': [38.48142519131186, 38.04025224148974, 38.67279981806461]}}\n",
      "dataset_name SDL06LD\n",
      "SOLVER PARAMS (500, 100, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='SDL06LD_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/SDL06LD0\n",
      "output_aug/500/SDL06LD0\n",
      "\u001b[32m[10/21 09:05:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:05:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:05:01 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:05:01 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:05:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:05:01 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:05:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:05:01 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:05:01 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:05:09 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 19  total_loss: 3.653  loss_cls: 1.821  loss_box_reg: 0.8941  loss_mask: 0.689  loss_rpn_cls: 0.1694  loss_rpn_loc: 0.09801  time: 0.3541  data_time: 0.0170  lr: 0.00019081  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:05:16 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 39  total_loss: 2.606  loss_cls: 0.859  loss_box_reg: 0.8762  loss_mask: 0.6588  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.09418  time: 0.3623  data_time: 0.0040  lr: 0.00039061  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:05:24 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 59  total_loss: 2.293  loss_cls: 0.6731  loss_box_reg: 0.8582  loss_mask: 0.5945  loss_rpn_cls: 0.04769  loss_rpn_loc: 0.1116  time: 0.3719  data_time: 0.0040  lr: 0.00059041  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:05:31 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 79  total_loss: 1.999  loss_cls: 0.5166  loss_box_reg: 0.8352  loss_mask: 0.5001  loss_rpn_cls: 0.0314  loss_rpn_loc: 0.09804  time: 0.3741  data_time: 0.0039  lr: 0.00079021  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:05:39 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 99  total_loss: 1.682  loss_cls: 0.3752  loss_box_reg: 0.7904  loss_mask: 0.3929  loss_rpn_cls: 0.0261  loss_rpn_loc: 0.1136  time: 0.3728  data_time: 0.0038  lr: 0.00099001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:05:46 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 119  total_loss: 1.334  loss_cls: 0.2309  loss_box_reg: 0.6543  loss_mask: 0.3299  loss_rpn_cls: 0.03072  loss_rpn_loc: 0.08942  time: 0.3711  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:05:53 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 1.208  loss_cls: 0.2073  loss_box_reg: 0.5638  loss_mask: 0.3105  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.1105  time: 0.3708  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:01 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 159  total_loss: 1.089  loss_cls: 0.1937  loss_box_reg: 0.4814  loss_mask: 0.3123  loss_rpn_cls: 0.01631  loss_rpn_loc: 0.09914  time: 0.3694  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:08 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 179  total_loss: 0.8993  loss_cls: 0.1641  loss_box_reg: 0.4244  loss_mask: 0.2556  loss_rpn_cls: 0.008268  loss_rpn_loc: 0.06407  time: 0.3688  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:15 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 199  total_loss: 0.8601  loss_cls: 0.1558  loss_box_reg: 0.37  loss_mask: 0.2497  loss_rpn_cls: 0.01066  loss_rpn_loc: 0.07529  time: 0.3679  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:22 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 219  total_loss: 0.7802  loss_cls: 0.126  loss_box_reg: 0.3695  loss_mask: 0.2462  loss_rpn_cls: 0.00648  loss_rpn_loc: 0.05638  time: 0.3671  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:29 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 239  total_loss: 0.8199  loss_cls: 0.1452  loss_box_reg: 0.3377  loss_mask: 0.2481  loss_rpn_cls: 0.008209  loss_rpn_loc: 0.07297  time: 0.3659  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:36 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 259  total_loss: 0.7718  loss_cls: 0.1242  loss_box_reg: 0.3139  loss_mask: 0.2388  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.08845  time: 0.3628  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:43 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 279  total_loss: 0.7079  loss_cls: 0.1117  loss_box_reg: 0.2924  loss_mask: 0.2366  loss_rpn_cls: 0.01049  loss_rpn_loc: 0.06335  time: 0.3615  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:49 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 299  total_loss: 0.6834  loss_cls: 0.112  loss_box_reg: 0.2904  loss_mask: 0.2075  loss_rpn_cls: 0.006627  loss_rpn_loc: 0.06695  time: 0.3581  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:06:55 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 319  total_loss: 0.6851  loss_cls: 0.1085  loss_box_reg: 0.2858  loss_mask: 0.2029  loss_rpn_cls: 0.00567  loss_rpn_loc: 0.06253  time: 0.3551  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:02 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 339  total_loss: 0.6769  loss_cls: 0.1091  loss_box_reg: 0.2641  loss_mask: 0.2117  loss_rpn_cls: 0.006485  loss_rpn_loc: 0.08354  time: 0.3534  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:08 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 359  total_loss: 0.7289  loss_cls: 0.1055  loss_box_reg: 0.3077  loss_mask: 0.2304  loss_rpn_cls: 0.004432  loss_rpn_loc: 0.06618  time: 0.3518  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:15 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 379  total_loss: 0.6428  loss_cls: 0.107  loss_box_reg: 0.2928  loss_mask: 0.2039  loss_rpn_cls: 0.007092  loss_rpn_loc: 0.05925  time: 0.3503  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:22 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 0.637  loss_cls: 0.09848  loss_box_reg: 0.2701  loss_mask: 0.2008  loss_rpn_cls: 0.004462  loss_rpn_loc: 0.04814  time: 0.3496  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:28 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 0.6812  loss_cls: 0.1048  loss_box_reg: 0.2577  loss_mask: 0.2146  loss_rpn_cls: 0.009676  loss_rpn_loc: 0.07716  time: 0.3481  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:34 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 0.6593  loss_cls: 0.108  loss_box_reg: 0.245  loss_mask: 0.1841  loss_rpn_cls: 0.009491  loss_rpn_loc: 0.08298  time: 0.3463  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:41 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 459  total_loss: 0.566  loss_cls: 0.08795  loss_box_reg: 0.2362  loss_mask: 0.1921  loss_rpn_cls: 0.007174  loss_rpn_loc: 0.06114  time: 0.3452  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:46 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.6443  loss_cls: 0.09102  loss_box_reg: 0.254  loss_mask: 0.2002  loss_rpn_cls: 0.006209  loss_rpn_loc: 0.06403  time: 0.3418  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:53 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5853  loss_cls: 0.09659  loss_box_reg: 0.2457  loss_mask: 0.183  loss_rpn_cls: 0.005771  loss_rpn_loc: 0.0495  time: 0.3413  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:07:53 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:49 (0.3413 s / it)\n",
      "\u001b[32m[10/21 09:07:53 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:51 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='SDL06LD_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:07:53 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:07:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:07:53 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:07:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:07:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1102 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 53/126. 0.1097 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:08:05 d2.evaluation.evaluator]: \u001b[0mInference done 96/126. 0.1085 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.378794 (0.118833 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.108322 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SDL06LD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.462\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.266\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.539\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.648 | 41.009 | 27.515 | 11.766 | 46.242 | 26.615 |\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.569 | cushion    | 33.258 | door       | 17.298 |\n",
      "| indoor-plant | 26.335 | sofa       | 34.074 | table      | 11.351 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.249 | 32.217 | 12.167 | 7.402 | 31.354 | 27.503 |\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 8.472  | cushion    | 30.320 | door       | 10.600 |\n",
      "| indoor-plant | 20.353 | sofa       | 24.102 | table      | 3.650  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='SDL06LD0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:08:09 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:08:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:08:09 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:08:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:08:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1166 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 09:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1129 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 09:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.1063 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 09:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 139/355. 0.1047 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 09:08:31 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.1066 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:08:36 d2.evaluation.evaluator]: \u001b[0mInference done 233/355. 0.1004 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 272/355. 0.1019 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 311/355. 0.1030 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 09:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 352/355. 0.1035 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.774333 (0.119355 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:36 (0.103363 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SDL06LD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.517 | 43.020 | 30.944 | 17.650 | 29.289 | 29.607 |\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.901  | cushion    | 70.151 | door       | 2.486 |\n",
      "| indoor-plant | 25.955 | sofa       | 63.066 | table      | 5.540 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.185 | 37.197 | 27.726 | 15.061 | 24.502 | 20.052 |\n",
      "\u001b[32m[10/21 09:08:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.787  | cushion    | 71.614 | door       | 3.088 |\n",
      "| indoor-plant | 15.403 | sofa       | 59.026 | table      | 0.189 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='SDL06LD1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:08:53 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:08:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:08:53 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:08:53 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:08:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 29/355. 0.1038 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 09:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 71/355. 0.1057 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 118/355. 0.1021 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 09:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 165/355. 0.1005 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.1000 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 09:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 255/355. 0.1001 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 310/355. 0.0955 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 348/355. 0.0981 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.154295 (0.111869 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.098349 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SDL06LD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.437\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.552\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.713 | 43.672 | 31.873 | 16.821 | 30.525 | 29.523 |\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.379  | cushion    | 69.232 | door       | 2.740 |\n",
      "| indoor-plant | 25.671 | sofa       | 64.631 | table      | 5.625 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.674 | 37.566 | 27.936 | 12.707 | 24.977 | 19.143 |\n",
      "\u001b[32m[10/21 09:09:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.171  | cushion    | 70.375 | door       | 3.606 |\n",
      "| indoor-plant | 14.057 | sofa       | 57.680 | table      | 0.153 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='SDL06LD2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:09:34 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:09:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:09:34 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:09:34 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:09:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 21/355. 0.1184 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 09:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 58/355. 0.1197 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 09:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 97/355. 0.1181 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:09:52 d2.evaluation.evaluator]: \u001b[0mInference done 136/355. 0.1173 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 09:09:57 d2.evaluation.evaluator]: \u001b[0mInference done 178/355. 0.1160 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:10:02 d2.evaluation.evaluator]: \u001b[0mInference done 214/355. 0.1171 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 09:10:07 d2.evaluation.evaluator]: \u001b[0mInference done 251/355. 0.1170 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:10:12 d2.evaluation.evaluator]: \u001b[0mInference done 286/355. 0.1176 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:10:17 d2.evaluation.evaluator]: \u001b[0mInference done 323/355. 0.1176 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:47.441994 (0.135549 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.117848 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/SDL06LD0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.443\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.539\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.778 | 44.321 | 31.335 | 19.418 | 30.274 | 29.588 |\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.023  | cushion    | 68.606 | door       | 2.687 |\n",
      "| indoor-plant | 27.700 | sofa       | 63.497 | table      | 6.153 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:10:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:10:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 09:10:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:10:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.240\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.351\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[10/21 09:10:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.367 | 37.881 | 27.037 | 13.183 | 23.987 | 19.666 |\n",
      "\u001b[32m[10/21 09:10:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.943  | cushion    | 68.749 | door       | 3.529 |\n",
      "| indoor-plant | 15.036 | sofa       | 56.830 | table      | 0.112 |\n",
      "all results {'bbox': {'AP50': [43.01966889049649, 43.67228408004969, 44.32095046115843]}, 'segm': {'AP50': [37.19731416053761, 37.56636089505828, 37.88126328617529]}}\n",
      "dataset_name A4JSYJB\n",
      "SOLVER PARAMS (800, 100, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='A4JSYJB_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/A4JSYJB0\n",
      "output_aug/800/A4JSYJB0\n",
      "\u001b[32m[10/21 09:10:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:10:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:10:24 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:10:24 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:10:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:10:24 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:10:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:10:24 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:10:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:10:31 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 19  total_loss: 3.533  loss_cls: 1.704  loss_box_reg: 0.8557  loss_mask: 0.6902  loss_rpn_cls: 0.2178  loss_rpn_loc: 0.189  time: 0.3484  data_time: 0.0164  lr: 0.00019081  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:10:39 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 39  total_loss: 2.54  loss_cls: 0.84  loss_box_reg: 0.8506  loss_mask: 0.6563  loss_rpn_cls: 0.05493  loss_rpn_loc: 0.09846  time: 0.3543  data_time: 0.0038  lr: 0.00039061  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:10:46 d2.utils.events]: \u001b[0m eta: 0:04:19  iter: 59  total_loss: 2.28  loss_cls: 0.6618  loss_box_reg: 0.8772  loss_mask: 0.6008  loss_rpn_cls: 0.05004  loss_rpn_loc: 0.1292  time: 0.3530  data_time: 0.0039  lr: 0.00059041  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:10:53 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 79  total_loss: 1.983  loss_cls: 0.5069  loss_box_reg: 0.8269  loss_mask: 0.4996  loss_rpn_cls: 0.03685  loss_rpn_loc: 0.08511  time: 0.3510  data_time: 0.0038  lr: 0.00079021  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:00 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 99  total_loss: 1.671  loss_cls: 0.3174  loss_box_reg: 0.7864  loss_mask: 0.4195  loss_rpn_cls: 0.02456  loss_rpn_loc: 0.09894  time: 0.3529  data_time: 0.0038  lr: 0.00099001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:07 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 119  total_loss: 1.299  loss_cls: 0.2118  loss_box_reg: 0.6541  loss_mask: 0.3264  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.07561  time: 0.3533  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:14 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 139  total_loss: 1.204  loss_cls: 0.2216  loss_box_reg: 0.533  loss_mask: 0.3104  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.131  time: 0.3543  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:21 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 159  total_loss: 1.01  loss_cls: 0.1758  loss_box_reg: 0.4478  loss_mask: 0.2896  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.09782  time: 0.3539  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:28 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 179  total_loss: 0.9386  loss_cls: 0.1633  loss_box_reg: 0.442  loss_mask: 0.2702  loss_rpn_cls: 0.00908  loss_rpn_loc: 0.07121  time: 0.3539  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:35 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 199  total_loss: 0.973  loss_cls: 0.1618  loss_box_reg: 0.4318  loss_mask: 0.2469  loss_rpn_cls: 0.01684  loss_rpn_loc: 0.09812  time: 0.3546  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:43 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 219  total_loss: 0.8268  loss_cls: 0.1431  loss_box_reg: 0.3558  loss_mask: 0.2297  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.07556  time: 0.3543  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:50 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 239  total_loss: 0.8146  loss_cls: 0.1325  loss_box_reg: 0.3255  loss_mask: 0.2247  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.07987  time: 0.3541  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:11:57 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 259  total_loss: 0.8227  loss_cls: 0.1162  loss_box_reg: 0.3239  loss_mask: 0.2483  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.09952  time: 0.3545  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:04 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 279  total_loss: 0.79  loss_cls: 0.1168  loss_box_reg: 0.3478  loss_mask: 0.2451  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.07877  time: 0.3541  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:11 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 299  total_loss: 0.7498  loss_cls: 0.131  loss_box_reg: 0.3219  loss_mask: 0.2099  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.09088  time: 0.3541  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:18 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 319  total_loss: 0.7091  loss_cls: 0.1176  loss_box_reg: 0.3103  loss_mask: 0.2126  loss_rpn_cls: 0.00691  loss_rpn_loc: 0.06579  time: 0.3541  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:25 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 339  total_loss: 0.6603  loss_cls: 0.1151  loss_box_reg: 0.2725  loss_mask: 0.2231  loss_rpn_cls: 0.008978  loss_rpn_loc: 0.05911  time: 0.3537  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:32 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 359  total_loss: 0.6627  loss_cls: 0.1178  loss_box_reg: 0.2858  loss_mask: 0.2007  loss_rpn_cls: 0.007496  loss_rpn_loc: 0.0634  time: 0.3541  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:39 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 379  total_loss: 0.6441  loss_cls: 0.1005  loss_box_reg: 0.2781  loss_mask: 0.209  loss_rpn_cls: 0.003089  loss_rpn_loc: 0.04414  time: 0.3543  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:46 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 399  total_loss: 0.6374  loss_cls: 0.1015  loss_box_reg: 0.2679  loss_mask: 0.2006  loss_rpn_cls: 0.005889  loss_rpn_loc: 0.07363  time: 0.3542  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:12:54 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 419  total_loss: 0.5874  loss_cls: 0.08691  loss_box_reg: 0.2603  loss_mask: 0.1845  loss_rpn_cls: 0.003411  loss_rpn_loc: 0.0576  time: 0.3546  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:01 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 439  total_loss: 0.6133  loss_cls: 0.09172  loss_box_reg: 0.269  loss_mask: 0.1988  loss_rpn_cls: 0.005881  loss_rpn_loc: 0.07025  time: 0.3545  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:08 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 459  total_loss: 0.6503  loss_cls: 0.09375  loss_box_reg: 0.2552  loss_mask: 0.1902  loss_rpn_cls: 0.007172  loss_rpn_loc: 0.07015  time: 0.3547  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:15 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 479  total_loss: 0.573  loss_cls: 0.08799  loss_box_reg: 0.2357  loss_mask: 0.192  loss_rpn_cls: 0.009928  loss_rpn_loc: 0.05323  time: 0.3545  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:22 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 499  total_loss: 0.6055  loss_cls: 0.09212  loss_box_reg: 0.2619  loss_mask: 0.1865  loss_rpn_cls: 0.005636  loss_rpn_loc: 0.05426  time: 0.3547  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:29 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 519  total_loss: 0.5663  loss_cls: 0.1036  loss_box_reg: 0.2589  loss_mask: 0.1852  loss_rpn_cls: 0.003891  loss_rpn_loc: 0.05533  time: 0.3545  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:36 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 539  total_loss: 0.5753  loss_cls: 0.09467  loss_box_reg: 0.2382  loss_mask: 0.1803  loss_rpn_cls: 0.005791  loss_rpn_loc: 0.05242  time: 0.3545  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:43 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 559  total_loss: 0.5678  loss_cls: 0.08232  loss_box_reg: 0.2432  loss_mask: 0.1745  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.05777  time: 0.3546  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:50 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 579  total_loss: 0.5483  loss_cls: 0.07339  loss_box_reg: 0.2382  loss_mask: 0.1729  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.03612  time: 0.3547  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:13:57 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 599  total_loss: 0.6512  loss_cls: 0.08989  loss_box_reg: 0.2472  loss_mask: 0.196  loss_rpn_cls: 0.007516  loss_rpn_loc: 0.05185  time: 0.3537  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:04 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 0.5524  loss_cls: 0.07622  loss_box_reg: 0.229  loss_mask: 0.1578  loss_rpn_cls: 0.005037  loss_rpn_loc: 0.04734  time: 0.3534  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:11 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 0.5553  loss_cls: 0.07944  loss_box_reg: 0.2372  loss_mask: 0.1742  loss_rpn_cls: 0.006459  loss_rpn_loc: 0.06779  time: 0.3532  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:17 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 0.5323  loss_cls: 0.07497  loss_box_reg: 0.215  loss_mask: 0.172  loss_rpn_cls: 0.00856  loss_rpn_loc: 0.06256  time: 0.3515  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:24 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 0.5732  loss_cls: 0.0792  loss_box_reg: 0.2386  loss_mask: 0.1791  loss_rpn_cls: 0.004394  loss_rpn_loc: 0.05876  time: 0.3510  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:31 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 0.5597  loss_cls: 0.08073  loss_box_reg: 0.2274  loss_mask: 0.1626  loss_rpn_cls: 0.005421  loss_rpn_loc: 0.06879  time: 0.3510  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:37 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 0.5466  loss_cls: 0.07213  loss_box_reg: 0.2344  loss_mask: 0.1782  loss_rpn_cls: 0.00685  loss_rpn_loc: 0.05505  time: 0.3507  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:44 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.4922  loss_cls: 0.07975  loss_box_reg: 0.2083  loss_mask: 0.1727  loss_rpn_cls: 0.004428  loss_rpn_loc: 0.05305  time: 0.3498  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:50 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 0.5329  loss_cls: 0.07412  loss_box_reg: 0.2311  loss_mask: 0.1606  loss_rpn_cls: 0.002495  loss_rpn_loc: 0.04618  time: 0.3490  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:14:57 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.5108  loss_cls: 0.07261  loss_box_reg: 0.2072  loss_mask: 0.1537  loss_rpn_cls: 0.005325  loss_rpn_loc: 0.04757  time: 0.3485  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:15:03 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5079  loss_cls: 0.07932  loss_box_reg: 0.2154  loss_mask: 0.1704  loss_rpn_cls: 0.002666  loss_rpn_loc: 0.0567  time: 0.3468  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:15:03 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:36 (0.3468 s / it)\n",
      "\u001b[32m[10/21 09:15:03 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='A4JSYJB_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:15:03 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:15:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:15:03 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:15:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:15:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1025 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 09:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 52/126. 0.1106 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 94/126. 0.1109 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.871638 (0.122906 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.111686 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/A4JSYJB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.512\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.595 | 40.857 | 26.198 | 12.380 | 47.951 | 31.630 |\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.306 | cushion    | 29.852 | door       | 14.601 |\n",
      "| indoor-plant | 28.171 | sofa       | 37.849 | table      | 11.790 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.063 | 34.001 | 11.876 | 7.530 | 31.751 | 26.250 |\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 10.160 | cushion    | 26.629 | door       | 10.010 |\n",
      "| indoor-plant | 20.111 | sofa       | 25.014 | table      | 4.453  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='A4JSYJB0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:15:19 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:15:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:15:19 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:15:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:15:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:15:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1029 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 09:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1016 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 09:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1075 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 09:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1090 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.1090 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 217/355. 0.1062 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 257/355. 0.1061 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 09:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 297/355. 0.1058 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 09:16:01 d2.evaluation.evaluator]: \u001b[0mInference done 337/355. 0.1060 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.596292 (0.124561 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.105843 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/A4JSYJB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.436\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.479\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.278 | 43.612 | 34.226 | 16.878 | 33.111 | 24.321 |\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.090  | cushion    | 68.452 | door       | 3.519 |\n",
      "| indoor-plant | 33.037 | sofa       | 68.389 | table      | 5.178 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:16:04 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:16:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.29 seconds.\n",
      "\u001b[32m[10/21 09:16:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:16:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.386\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.156\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.360\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318\n",
      "\u001b[32m[10/21 09:16:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.824 | 38.565 | 25.243 | 15.553 | 26.490 | 16.566 |\n",
      "\u001b[32m[10/21 09:16:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 1.665  | cushion    | 71.870 | door       | 3.811 |\n",
      "| indoor-plant | 22.417 | sofa       | 49.073 | table      | 0.107 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='A4JSYJB1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:16:05 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:16:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:16:05 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:16:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:16:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:16:06 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.0898 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 09:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.1013 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 09:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 91/355. 0.1070 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 09:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1077 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.1082 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 215/355. 0.1067 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 09:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.1042 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 294/355. 0.1059 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 09:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 332/355. 0.1069 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 09:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.583161 (0.127380 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.107743 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:16:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:16:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/A4JSYJB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:16:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:16:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.436\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.167 | 43.614 | 34.433 | 21.898 | 33.451 | 24.545 |\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.624  | cushion    | 68.808 | door       | 4.320 |\n",
      "| indoor-plant | 32.793 | sofa       | 66.486 | table      | 4.969 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.383\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.788 | 38.270 | 25.746 | 20.667 | 25.983 | 17.212 |\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.268  | cushion    | 70.563 | door       | 4.629 |\n",
      "| indoor-plant | 21.814 | sofa       | 49.338 | table      | 0.115 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='A4JSYJB2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:16:51 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:16:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:16:51 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:16:51 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:16:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1287 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 09:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1252 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 09:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 84/355. 0.1213 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 09:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 122/355. 0.1201 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 09:17:13 d2.evaluation.evaluator]: \u001b[0mInference done 160/355. 0.1201 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 09:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 199/355. 0.1194 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 234/355. 0.1197 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.1202 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:17:34 d2.evaluation.evaluator]: \u001b[0mInference done 304/355. 0.1202 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 09:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 340/355. 0.1205 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.821962 (0.139491 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.120474 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/A4JSYJB0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.343\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.469\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.714 | 44.971 | 34.312 | 18.279 | 33.418 | 24.269 |\n",
      "\u001b[32m[10/21 09:17:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.497  | cushion    | 69.454 | door       | 4.015 |\n",
      "| indoor-plant | 34.865 | sofa       | 67.165 | table      | 5.287 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:17:42 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:17:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 09:17:42 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:17:42 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
      "\u001b[32m[10/21 09:17:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.687 | 39.442 | 25.411 | 15.654 | 25.405 | 16.717 |\n",
      "\u001b[32m[10/21 09:17:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.150  | cushion    | 71.172 | door       | 4.469 |\n",
      "| indoor-plant | 22.934 | sofa       | 47.159 | table      | 0.238 |\n",
      "all results {'bbox': {'AP50': [43.612488057287955, 43.61420808348453, 44.97115594670933]}, 'segm': {'AP50': [38.56544736670411, 38.269895404406014, 39.44214896440831]}}\n",
      "dataset_name 8AFH5WS\n",
      "SOLVER PARAMS (500, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='8AFH5WS_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/8AFH5WS0\n",
      "output_aug/500/8AFH5WS0\n",
      "\u001b[32m[10/21 09:17:43 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:17:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:17:43 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:17:43 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:17:43 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:17:43 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:17:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:17:43 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:17:43 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:17:51 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 19  total_loss: 3.716  loss_cls: 1.697  loss_box_reg: 0.8647  loss_mask: 0.6917  loss_rpn_cls: 0.3181  loss_rpn_loc: 0.1663  time: 0.3560  data_time: 0.0217  lr: 9.5905e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:17:58 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 39  total_loss: 2.723  loss_cls: 0.8865  loss_box_reg: 0.8849  loss_mask: 0.6751  loss_rpn_cls: 0.06871  loss_rpn_loc: 0.1475  time: 0.3593  data_time: 0.0037  lr: 0.0001958  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:06 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 59  total_loss: 2.54  loss_cls: 0.7653  loss_box_reg: 0.8938  loss_mask: 0.6445  loss_rpn_cls: 0.05837  loss_rpn_loc: 0.1422  time: 0.3599  data_time: 0.0038  lr: 0.00029571  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:13 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 79  total_loss: 2.311  loss_cls: 0.6645  loss_box_reg: 0.8882  loss_mask: 0.6035  loss_rpn_cls: 0.04718  loss_rpn_loc: 0.1361  time: 0.3593  data_time: 0.0037  lr: 0.0003956  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:20 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 99  total_loss: 2.028  loss_cls: 0.5226  loss_box_reg: 0.8414  loss_mask: 0.5144  loss_rpn_cls: 0.03344  loss_rpn_loc: 0.0788  time: 0.3570  data_time: 0.0038  lr: 0.00049551  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:27 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 119  total_loss: 1.783  loss_cls: 0.3984  loss_box_reg: 0.8234  loss_mask: 0.4681  loss_rpn_cls: 0.02504  loss_rpn_loc: 0.09511  time: 0.3569  data_time: 0.0038  lr: 0.00059541  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:34 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 139  total_loss: 1.488  loss_cls: 0.288  loss_box_reg: 0.7617  loss_mask: 0.3613  loss_rpn_cls: 0.02092  loss_rpn_loc: 0.07182  time: 0.3560  data_time: 0.0038  lr: 0.00069531  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:41 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 159  total_loss: 1.388  loss_cls: 0.2528  loss_box_reg: 0.6451  loss_mask: 0.3512  loss_rpn_cls: 0.01896  loss_rpn_loc: 0.1186  time: 0.3574  data_time: 0.0039  lr: 0.00079521  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:48 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 179  total_loss: 1.275  loss_cls: 0.2078  loss_box_reg: 0.5559  loss_mask: 0.3154  loss_rpn_cls: 0.04823  loss_rpn_loc: 0.1082  time: 0.3565  data_time: 0.0037  lr: 0.0008951  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:18:55 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 199  total_loss: 1.114  loss_cls: 0.1943  loss_box_reg: 0.5017  loss_mask: 0.3034  loss_rpn_cls: 0.01673  loss_rpn_loc: 0.09786  time: 0.3567  data_time: 0.0036  lr: 0.000995  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:03 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 219  total_loss: 0.969  loss_cls: 0.18  loss_box_reg: 0.4372  loss_mask: 0.269  loss_rpn_cls: 0.009793  loss_rpn_loc: 0.06374  time: 0.3570  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:10 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 239  total_loss: 0.8759  loss_cls: 0.1611  loss_box_reg: 0.3973  loss_mask: 0.2468  loss_rpn_cls: 0.008363  loss_rpn_loc: 0.08139  time: 0.3579  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:17 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 259  total_loss: 0.8604  loss_cls: 0.1594  loss_box_reg: 0.3723  loss_mask: 0.2608  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.06756  time: 0.3565  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:24 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 279  total_loss: 0.8059  loss_cls: 0.1509  loss_box_reg: 0.3568  loss_mask: 0.2266  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.07183  time: 0.3568  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:30 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 299  total_loss: 0.7583  loss_cls: 0.1184  loss_box_reg: 0.3267  loss_mask: 0.2333  loss_rpn_cls: 0.007933  loss_rpn_loc: 0.07079  time: 0.3547  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:38 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 319  total_loss: 0.7051  loss_cls: 0.1191  loss_box_reg: 0.3088  loss_mask: 0.2254  loss_rpn_cls: 0.007845  loss_rpn_loc: 0.05331  time: 0.3545  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:45 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 339  total_loss: 0.7823  loss_cls: 0.1261  loss_box_reg: 0.3297  loss_mask: 0.2219  loss_rpn_cls: 0.005871  loss_rpn_loc: 0.06916  time: 0.3544  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:52 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 359  total_loss: 0.7515  loss_cls: 0.1194  loss_box_reg: 0.3334  loss_mask: 0.2264  loss_rpn_cls: 0.004427  loss_rpn_loc: 0.08146  time: 0.3544  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:19:59 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 379  total_loss: 0.6658  loss_cls: 0.1105  loss_box_reg: 0.2908  loss_mask: 0.2134  loss_rpn_cls: 0.005667  loss_rpn_loc: 0.06306  time: 0.3542  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:20:06 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 0.6845  loss_cls: 0.1179  loss_box_reg: 0.3008  loss_mask: 0.2111  loss_rpn_cls: 0.01989  loss_rpn_loc: 0.06019  time: 0.3539  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:20:13 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 0.6402  loss_cls: 0.1074  loss_box_reg: 0.2878  loss_mask: 0.1881  loss_rpn_cls: 0.008418  loss_rpn_loc: 0.05171  time: 0.3538  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:20:19 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 0.6581  loss_cls: 0.09698  loss_box_reg: 0.2977  loss_mask: 0.2018  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.04321  time: 0.3516  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:20:26 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 459  total_loss: 0.6356  loss_cls: 0.1126  loss_box_reg: 0.256  loss_mask: 0.2012  loss_rpn_cls: 0.006999  loss_rpn_loc: 0.06488  time: 0.3516  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:20:33 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 479  total_loss: 0.624  loss_cls: 0.09768  loss_box_reg: 0.2501  loss_mask: 0.1947  loss_rpn_cls: 0.004748  loss_rpn_loc: 0.08266  time: 0.3520  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:20:41 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5881  loss_cls: 0.09103  loss_box_reg: 0.2645  loss_mask: 0.1922  loss_rpn_cls: 0.005539  loss_rpn_loc: 0.0734  time: 0.3519  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:20:41 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:55 (0.3519 s / it)\n",
      "\u001b[32m[10/21 09:20:41 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:56 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='8AFH5WS_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:20:41 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:20:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:20:41 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:20:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:20:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1124 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 52/126. 0.1129 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 94/126. 0.1121 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.704052 (0.121521 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:13 (0.110119 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/8AFH5WS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.427\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.568\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.028 | 42.655 | 27.364 | 12.616 | 49.521 | 30.266 |\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 29.383 | cushion    | 31.660 | door       | 17.776 |\n",
      "| indoor-plant | 25.470 | sofa       | 41.352 | table      | 10.526 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.323 | 34.188 | 13.293 | 6.911 | 31.403 | 23.448 |\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 9.598  | cushion    | 26.795 | door       | 11.767 |\n",
      "| indoor-plant | 19.266 | sofa       | 28.445 | table      | 2.067  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='8AFH5WS0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:20:57 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:20:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:20:57 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:20:57 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:20:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1004 s / img. ETA=0:00:43\n",
      "\u001b[32m[10/21 09:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.1006 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 09:21:08 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.1012 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 09:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 138/355. 0.1012 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 09:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 181/355. 0.1013 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 09:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 223/355. 0.1016 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 09:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 264/355. 0.1016 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 09:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 307/355. 0.1002 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 09:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 351/355. 0.0998 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:21:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:41.844274 (0.119555 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:21:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.099489 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/8AFH5WS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.448\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.924 | 44.800 | 33.011 | 16.133 | 33.118 | 25.952 |\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.590  | cushion    | 66.723 | door       | 4.856 |\n",
      "| indoor-plant | 27.459 | sofa       | 65.363 | table      | 5.553 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:21:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.395\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
      "\u001b[32m[10/21 09:21:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.319 | 39.514 | 28.405 | 15.782 | 27.038 | 21.828 |\n",
      "\u001b[32m[10/21 09:21:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.251  | cushion    | 71.694 | door       | 5.610 |\n",
      "| indoor-plant | 19.153 | sofa       | 59.119 | table      | 0.086 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='8AFH5WS1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:21:41 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:21:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:21:41 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:21:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:21:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 26/355. 0.1141 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 09:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 63/355. 0.1165 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 09:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 101/355. 0.1167 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.1182 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 09:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 174/355. 0.1187 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 09:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 211/355. 0.1189 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 09:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.1194 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 09:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.1196 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 09:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 316/355. 0.1196 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 352/355. 0.1196 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.966690 (0.139905 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.119693 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/8AFH5WS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:22:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.456\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.037 | 45.580 | 33.801 | 19.558 | 33.585 | 25.490 |\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.299  | cushion    | 65.662 | door       | 6.477 |\n",
      "| indoor-plant | 27.485 | sofa       | 64.331 | table      | 5.967 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.404\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.630 | 40.393 | 26.935 | 19.587 | 26.947 | 20.270 |\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.573  | cushion    | 70.908 | door       | 7.521 |\n",
      "| indoor-plant | 17.917 | sofa       | 54.786 | table      | 0.072 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='8AFH5WS2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:22:31 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:22:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:22:31 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:22:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:22:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.1244 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 09:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 58/355. 0.1207 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 09:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.1213 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 09:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 132/355. 0.1209 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 09:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 167/355. 0.1220 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 09:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 204/355. 0.1216 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 239/355. 0.1214 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 274/355. 0.1214 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 308/355. 0.1214 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 09:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.1215 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.688936 (0.141968 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121303 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/8AFH5WS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.299\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.471\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.938 | 47.142 | 34.426 | 19.823 | 34.511 | 26.005 |\n",
      "\u001b[32m[10/21 09:23:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.264  | cushion    | 67.333 | door       | 6.011 |\n",
      "| indoor-plant | 29.494 | sofa       | 66.413 | table      | 6.114 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:23:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:23:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 09:23:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:23:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.420\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\n",
      "\u001b[32m[10/21 09:23:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.921 | 41.952 | 27.344 | 19.638 | 26.865 | 21.327 |\n",
      "\u001b[32m[10/21 09:23:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.891  | cushion    | 71.549 | door       | 6.985 |\n",
      "| indoor-plant | 19.192 | sofa       | 54.828 | table      | 0.078 |\n",
      "all results {'bbox': {'AP50': [44.79976235828226, 45.579689677240694, 47.14187392292784]}, 'segm': {'AP50': [39.51389537995617, 40.39289912633098, 41.95188855104245]}}\n",
      "dataset_name 6036UIK\n",
      "SOLVER PARAMS (800, 200, 0.001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='6036UIK_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/6036UIK0\n",
      "output_aug/800/6036UIK0\n",
      "\u001b[32m[10/21 09:23:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:23:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:23:24 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:23:24 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:23:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:23:24 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:23:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:23:24 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:23:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:23:32 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 19  total_loss: 3.691  loss_cls: 1.723  loss_box_reg: 0.882  loss_mask: 0.6909  loss_rpn_cls: 0.3509  loss_rpn_loc: 0.1533  time: 0.3612  data_time: 0.0168  lr: 9.5905e-05  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:23:39 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 39  total_loss: 2.779  loss_cls: 0.9072  loss_box_reg: 0.8962  loss_mask: 0.6754  loss_rpn_cls: 0.08809  loss_rpn_loc: 0.1292  time: 0.3602  data_time: 0.0039  lr: 0.00019581  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:23:46 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 59  total_loss: 2.428  loss_cls: 0.7369  loss_box_reg: 0.8768  loss_mask: 0.6414  loss_rpn_cls: 0.05876  loss_rpn_loc: 0.1289  time: 0.3597  data_time: 0.0041  lr: 0.00029571  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:23:54 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 79  total_loss: 2.255  loss_cls: 0.6076  loss_box_reg: 0.8392  loss_mask: 0.592  loss_rpn_cls: 0.03994  loss_rpn_loc: 0.08911  time: 0.3614  data_time: 0.0040  lr: 0.00039561  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:01 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 99  total_loss: 2.006  loss_cls: 0.4972  loss_box_reg: 0.8475  loss_mask: 0.5206  loss_rpn_cls: 0.03131  loss_rpn_loc: 0.09742  time: 0.3584  data_time: 0.0039  lr: 0.00049551  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:08 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 119  total_loss: 1.702  loss_cls: 0.3605  loss_box_reg: 0.8092  loss_mask: 0.4332  loss_rpn_cls: 0.02362  loss_rpn_loc: 0.1023  time: 0.3589  data_time: 0.0039  lr: 0.00059541  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:15 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 139  total_loss: 1.535  loss_cls: 0.269  loss_box_reg: 0.7438  loss_mask: 0.384  loss_rpn_cls: 0.02211  loss_rpn_loc: 0.1092  time: 0.3587  data_time: 0.0038  lr: 0.00069531  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:22 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 159  total_loss: 1.292  loss_cls: 0.2292  loss_box_reg: 0.6141  loss_mask: 0.3317  loss_rpn_cls: 0.03944  loss_rpn_loc: 0.1062  time: 0.3551  data_time: 0.0041  lr: 0.00079521  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:29 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 179  total_loss: 1.147  loss_cls: 0.1858  loss_box_reg: 0.5642  loss_mask: 0.2967  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.0652  time: 0.3543  data_time: 0.0040  lr: 0.00089511  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:35 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 199  total_loss: 1.014  loss_cls: 0.171  loss_box_reg: 0.4833  loss_mask: 0.2831  loss_rpn_cls: 0.011  loss_rpn_loc: 0.06364  time: 0.3499  data_time: 0.0038  lr: 0.000995  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:41 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 219  total_loss: 1.01  loss_cls: 0.1707  loss_box_reg: 0.4566  loss_mask: 0.2582  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.0946  time: 0.3471  data_time: 0.0036  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:48 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 239  total_loss: 0.9625  loss_cls: 0.178  loss_box_reg: 0.4035  loss_mask: 0.2495  loss_rpn_cls: 0.009264  loss_rpn_loc: 0.08588  time: 0.3476  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:24:55 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 259  total_loss: 0.8717  loss_cls: 0.1458  loss_box_reg: 0.3697  loss_mask: 0.2602  loss_rpn_cls: 0.00981  loss_rpn_loc: 0.06858  time: 0.3463  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:02 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 279  total_loss: 0.8569  loss_cls: 0.157  loss_box_reg: 0.3487  loss_mask: 0.2315  loss_rpn_cls: 0.007669  loss_rpn_loc: 0.08414  time: 0.3460  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:08 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 299  total_loss: 0.8302  loss_cls: 0.1381  loss_box_reg: 0.343  loss_mask: 0.2299  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.08474  time: 0.3444  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:15 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 319  total_loss: 0.7193  loss_cls: 0.1067  loss_box_reg: 0.3159  loss_mask: 0.227  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.0625  time: 0.3428  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:21 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 339  total_loss: 0.728  loss_cls: 0.1249  loss_box_reg: 0.3008  loss_mask: 0.2125  loss_rpn_cls: 0.00606  loss_rpn_loc: 0.06899  time: 0.3421  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:27 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 359  total_loss: 0.7661  loss_cls: 0.1142  loss_box_reg: 0.3173  loss_mask: 0.2113  loss_rpn_cls: 0.008386  loss_rpn_loc: 0.06903  time: 0.3386  data_time: 0.0041  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:34 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 379  total_loss: 0.716  loss_cls: 0.128  loss_box_reg: 0.2833  loss_mask: 0.216  loss_rpn_cls: 0.004569  loss_rpn_loc: 0.07546  time: 0.3384  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:40 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 399  total_loss: 0.6866  loss_cls: 0.1124  loss_box_reg: 0.2928  loss_mask: 0.2106  loss_rpn_cls: 0.006728  loss_rpn_loc: 0.05478  time: 0.3386  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:47 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 419  total_loss: 0.6297  loss_cls: 0.1125  loss_box_reg: 0.2794  loss_mask: 0.2012  loss_rpn_cls: 0.006246  loss_rpn_loc: 0.05664  time: 0.3380  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:25:54 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 439  total_loss: 0.6287  loss_cls: 0.112  loss_box_reg: 0.2696  loss_mask: 0.1895  loss_rpn_cls: 0.005974  loss_rpn_loc: 0.0663  time: 0.3377  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:00 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 459  total_loss: 0.6421  loss_cls: 0.09975  loss_box_reg: 0.267  loss_mask: 0.1965  loss_rpn_cls: 0.008273  loss_rpn_loc: 0.07968  time: 0.3366  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:06 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 479  total_loss: 0.6314  loss_cls: 0.1067  loss_box_reg: 0.2683  loss_mask: 0.1881  loss_rpn_cls: 0.005874  loss_rpn_loc: 0.06636  time: 0.3359  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:13 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 499  total_loss: 0.6559  loss_cls: 0.1021  loss_box_reg: 0.2828  loss_mask: 0.1772  loss_rpn_cls: 0.006293  loss_rpn_loc: 0.06698  time: 0.3358  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:18 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 519  total_loss: 0.5677  loss_cls: 0.1013  loss_box_reg: 0.2487  loss_mask: 0.1839  loss_rpn_cls: 0.005851  loss_rpn_loc: 0.06337  time: 0.3334  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:25 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 539  total_loss: 0.6584  loss_cls: 0.1085  loss_box_reg: 0.2753  loss_mask: 0.2  loss_rpn_cls: 0.00668  loss_rpn_loc: 0.06045  time: 0.3331  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:32 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 559  total_loss: 0.6356  loss_cls: 0.1021  loss_box_reg: 0.2901  loss_mask: 0.1849  loss_rpn_cls: 0.006402  loss_rpn_loc: 0.05531  time: 0.3337  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:38 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 579  total_loss: 0.6093  loss_cls: 0.09253  loss_box_reg: 0.2518  loss_mask: 0.1894  loss_rpn_cls: 0.005224  loss_rpn_loc: 0.05849  time: 0.3334  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:45 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 599  total_loss: 0.6059  loss_cls: 0.09884  loss_box_reg: 0.2477  loss_mask: 0.2078  loss_rpn_cls: 0.002619  loss_rpn_loc: 0.0628  time: 0.3335  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:52 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 619  total_loss: 0.604  loss_cls: 0.09004  loss_box_reg: 0.2435  loss_mask: 0.174  loss_rpn_cls: 0.004837  loss_rpn_loc: 0.06184  time: 0.3331  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:26:58 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 639  total_loss: 0.4986  loss_cls: 0.07889  loss_box_reg: 0.2121  loss_mask: 0.1617  loss_rpn_cls: 0.003733  loss_rpn_loc: 0.05336  time: 0.3326  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:04 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 659  total_loss: 0.533  loss_cls: 0.08443  loss_box_reg: 0.214  loss_mask: 0.166  loss_rpn_cls: 0.003856  loss_rpn_loc: 0.05301  time: 0.3323  data_time: 0.0037  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:10 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 679  total_loss: 0.5609  loss_cls: 0.08493  loss_box_reg: 0.241  loss_mask: 0.1706  loss_rpn_cls: 0.003357  loss_rpn_loc: 0.04237  time: 0.3313  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:16 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 699  total_loss: 0.5256  loss_cls: 0.07326  loss_box_reg: 0.2185  loss_mask: 0.1761  loss_rpn_cls: 0.002952  loss_rpn_loc: 0.0466  time: 0.3302  data_time: 0.0038  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:24 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 719  total_loss: 0.5362  loss_cls: 0.08949  loss_box_reg: 0.2181  loss_mask: 0.1663  loss_rpn_cls: 0.003509  loss_rpn_loc: 0.04725  time: 0.3316  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:31 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 739  total_loss: 0.5391  loss_cls: 0.08861  loss_box_reg: 0.2223  loss_mask: 0.1741  loss_rpn_cls: 0.003502  loss_rpn_loc: 0.04759  time: 0.3327  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:39 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 759  total_loss: 0.5462  loss_cls: 0.07769  loss_box_reg: 0.2325  loss_mask: 0.1655  loss_rpn_cls: 0.00898  loss_rpn_loc: 0.07502  time: 0.3344  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:47 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.5098  loss_cls: 0.08455  loss_box_reg: 0.2157  loss_mask: 0.174  loss_rpn_cls: 0.004121  loss_rpn_loc: 0.04964  time: 0.3358  data_time: 0.0040  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:55 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5048  loss_cls: 0.07329  loss_box_reg: 0.2262  loss_mask: 0.1627  loss_rpn_cls: 0.005044  loss_rpn_loc: 0.05351  time: 0.3365  data_time: 0.0039  lr: 0.001  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:27:55 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:28 (0.3366 s / it)\n",
      "\u001b[32m[10/21 09:27:55 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:29 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='6036UIK_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:27:56 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:27:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:27:56 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:27:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:27:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1096 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 50/126. 0.1158 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 90/126. 0.1154 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.486285 (0.127986 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.116335 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6036UIK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.435\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.471\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.687 | 43.471 | 28.959 | 12.770 | 47.140 | 33.480 |\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 27.677 | cushion    | 29.617 | door       | 19.862 |\n",
      "| indoor-plant | 30.053 | sofa       | 37.115 | table      | 9.795  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.362\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.375\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 17.364 | 36.202 | 13.195 | 7.195 | 33.317 | 28.564 |\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 10.679 | cushion    | 27.671 | door       | 14.920 |\n",
      "| indoor-plant | 21.237 | sofa       | 26.774 | table      | 2.899  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='6036UIK0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:28:12 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:28:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:28:12 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:28:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:28:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1297 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 09:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1283 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 09:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 82/355. 0.1252 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 09:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.1235 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 09:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.1228 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 09:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 199/355. 0.1219 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 235/355. 0.1220 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 270/355. 0.1224 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:28:54 d2.evaluation.evaluator]: \u001b[0mInference done 306/355. 0.1222 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 09:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.1219 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 09:29:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.226376 (0.137790 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:29:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121908 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:29:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:29:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6036UIK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:29:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:29:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.282\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.445\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.517\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.780 | 47.593 | 32.170 | 17.351 | 32.878 | 28.177 |\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.657  | cushion    | 67.289 | door       | 4.871 |\n",
      "| indoor-plant | 31.121 | sofa       | 65.195 | table      | 5.547 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.197\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.358\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.615 | 40.161 | 26.540 | 15.367 | 27.431 | 20.857 |\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.466  | cushion    | 73.075 | door       | 4.986 |\n",
      "| indoor-plant | 22.244 | sofa       | 50.811 | table      | 0.110 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='6036UIK1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:29:02 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:29:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:29:02 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:29:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:29:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 14/355. 0.1204 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 09:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 48/355. 0.1247 s / img. ETA=0:00:44\n",
      "\u001b[32m[10/21 09:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 84/355. 0.1249 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 09:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.1235 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 09:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.1242 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 195/355. 0.1234 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 09:29:35 d2.evaluation.evaluator]: \u001b[0mInference done 229/355. 0.1234 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 09:29:40 d2.evaluation.evaluator]: \u001b[0mInference done 263/355. 0.1237 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 297/355. 0.1240 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 335/355. 0.1233 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.867555 (0.142479 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.123132 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6036UIK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 09:29:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.488\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.264\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.161 | 48.822 | 32.268 | 17.287 | 33.998 | 28.492 |\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.360  | cushion    | 67.003 | door       | 7.102 |\n",
      "| indoor-plant | 30.693 | sofa       | 65.482 | table      | 5.324 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.269\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.342\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.875 | 40.991 | 26.897 | 13.657 | 28.529 | 20.016 |\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.898  | cushion    | 73.008 | door       | 6.921 |\n",
      "| indoor-plant | 21.581 | sofa       | 50.739 | table      | 0.106 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='6036UIK2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:29:54 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:29:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:29:54 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:29:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:29:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:29:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1268 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 09:30:01 d2.evaluation.evaluator]: \u001b[0mInference done 45/355. 0.1241 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 09:30:06 d2.evaluation.evaluator]: \u001b[0mInference done 80/355. 0.1254 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 09:30:11 d2.evaluation.evaluator]: \u001b[0mInference done 116/355. 0.1252 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:30:16 d2.evaluation.evaluator]: \u001b[0mInference done 153/355. 0.1244 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:30:21 d2.evaluation.evaluator]: \u001b[0mInference done 192/355. 0.1235 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 09:30:27 d2.evaluation.evaluator]: \u001b[0mInference done 226/355. 0.1232 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 09:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 261/355. 0.1235 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:30:37 d2.evaluation.evaluator]: \u001b[0mInference done 295/355. 0.1235 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:30:42 d2.evaluation.evaluator]: \u001b[0mInference done 332/355. 0.1230 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:30:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.987465 (0.142821 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:30:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.122778 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:30:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:30:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/6036UIK0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:30:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:30:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.497\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.331\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.804 | 49.712 | 33.062 | 21.142 | 34.202 | 28.638 |\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.149  | cushion    | 67.039 | door       | 7.459 |\n",
      "| indoor-plant | 33.679 | sofa       | 65.892 | table      | 5.606 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.616 | 41.572 | 26.115 | 14.321 | 27.289 | 20.805 |\n",
      "\u001b[32m[10/21 09:30:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.990  | cushion    | 72.454 | door       | 7.365 |\n",
      "| indoor-plant | 22.900 | sofa       | 47.867 | table      | 0.121 |\n",
      "all results {'bbox': {'AP50': [47.59282655876705, 48.82216120759694, 49.71219330510394]}, 'segm': {'AP50': [40.16111793743666, 40.99128146617376, 41.57191606825926]}}\n",
      "dataset_name 7AR5I5Z\n",
      "SOLVER PARAMS (500, 100, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='7AR5I5Z_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/7AR5I5Z0\n",
      "output_aug/500/7AR5I5Z0\n",
      "\u001b[32m[10/21 09:30:47 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:30:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:30:47 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:30:47 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:30:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:30:47 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:30:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:30:47 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:30:48 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:30:56 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 19  total_loss: 3.38  loss_cls: 1.516  loss_box_reg: 0.8676  loss_mask: 0.6863  loss_rpn_cls: 0.198  loss_rpn_loc: 0.1543  time: 0.3840  data_time: 0.0165  lr: 0.00038162  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:04 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 39  total_loss: 2.467  loss_cls: 0.7893  loss_box_reg: 0.8465  loss_mask: 0.6334  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1003  time: 0.3868  data_time: 0.0038  lr: 0.00078122  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:11 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 59  total_loss: 2.181  loss_cls: 0.5797  loss_box_reg: 0.8697  loss_mask: 0.5197  loss_rpn_cls: 0.0437  loss_rpn_loc: 0.1058  time: 0.3783  data_time: 0.0038  lr: 0.0011808  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:18 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 79  total_loss: 1.639  loss_cls: 0.3265  loss_box_reg: 0.7764  loss_mask: 0.387  loss_rpn_cls: 0.02432  loss_rpn_loc: 0.08678  time: 0.3717  data_time: 0.0037  lr: 0.0015804  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:25 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 99  total_loss: 1.292  loss_cls: 0.2243  loss_box_reg: 0.6242  loss_mask: 0.3347  loss_rpn_cls: 0.02425  loss_rpn_loc: 0.1126  time: 0.3637  data_time: 0.0037  lr: 0.00198  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:32 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 119  total_loss: 1.127  loss_cls: 0.2143  loss_box_reg: 0.5534  loss_mask: 0.2818  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.07853  time: 0.3628  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:38 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 139  total_loss: 1.05  loss_cls: 0.1588  loss_box_reg: 0.4561  loss_mask: 0.2849  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.1028  time: 0.3583  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:46 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 159  total_loss: 1.022  loss_cls: 0.178  loss_box_reg: 0.374  loss_mask: 0.2578  loss_rpn_cls: 0.03686  loss_rpn_loc: 0.1189  time: 0.3582  data_time: 0.0036  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:31:53 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 179  total_loss: 0.966  loss_cls: 0.1488  loss_box_reg: 0.3834  loss_mask: 0.2469  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.1217  time: 0.3573  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:00 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 199  total_loss: 0.8997  loss_cls: 0.141  loss_box_reg: 0.4108  loss_mask: 0.2371  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.1079  time: 0.3578  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:07 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 219  total_loss: 0.7478  loss_cls: 0.1227  loss_box_reg: 0.3361  loss_mask: 0.2215  loss_rpn_cls: 0.009192  loss_rpn_loc: 0.09017  time: 0.3575  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:14 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 239  total_loss: 0.8143  loss_cls: 0.1193  loss_box_reg: 0.3634  loss_mask: 0.2198  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.08968  time: 0.3575  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:20 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 259  total_loss: 0.7741  loss_cls: 0.1279  loss_box_reg: 0.3363  loss_mask: 0.2041  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.05989  time: 0.3541  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:27 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 279  total_loss: 0.6957  loss_cls: 0.1209  loss_box_reg: 0.3075  loss_mask: 0.1991  loss_rpn_cls: 0.008861  loss_rpn_loc: 0.07531  time: 0.3539  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:35 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 299  total_loss: 0.6418  loss_cls: 0.1028  loss_box_reg: 0.288  loss_mask: 0.1827  loss_rpn_cls: 0.009414  loss_rpn_loc: 0.05769  time: 0.3542  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:42 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 319  total_loss: 0.6165  loss_cls: 0.1028  loss_box_reg: 0.2764  loss_mask: 0.1831  loss_rpn_cls: 0.003672  loss_rpn_loc: 0.06441  time: 0.3546  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:49 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 339  total_loss: 0.5699  loss_cls: 0.09444  loss_box_reg: 0.2613  loss_mask: 0.1748  loss_rpn_cls: 0.004664  loss_rpn_loc: 0.05659  time: 0.3542  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:32:56 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 359  total_loss: 0.6332  loss_cls: 0.08842  loss_box_reg: 0.2697  loss_mask: 0.1881  loss_rpn_cls: 0.007548  loss_rpn_loc: 0.06678  time: 0.3541  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:02 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 379  total_loss: 0.6729  loss_cls: 0.09362  loss_box_reg: 0.2807  loss_mask: 0.1955  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.09666  time: 0.3520  data_time: 0.0042  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:09 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 0.6369  loss_cls: 0.09651  loss_box_reg: 0.269  loss_mask: 0.1687  loss_rpn_cls: 0.006536  loss_rpn_loc: 0.064  time: 0.3518  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:16 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 0.6251  loss_cls: 0.09099  loss_box_reg: 0.2705  loss_mask: 0.1779  loss_rpn_cls: 0.005578  loss_rpn_loc: 0.04483  time: 0.3521  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:24 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 0.6296  loss_cls: 0.0907  loss_box_reg: 0.2745  loss_mask: 0.1788  loss_rpn_cls: 0.005382  loss_rpn_loc: 0.05947  time: 0.3530  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:31 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 459  total_loss: 0.5623  loss_cls: 0.09161  loss_box_reg: 0.2532  loss_mask: 0.148  loss_rpn_cls: 0.00489  loss_rpn_loc: 0.05396  time: 0.3530  data_time: 0.0036  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:38 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 479  total_loss: 0.5661  loss_cls: 0.09  loss_box_reg: 0.2414  loss_mask: 0.1777  loss_rpn_cls: 0.005679  loss_rpn_loc: 0.07176  time: 0.3528  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:45 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5336  loss_cls: 0.08493  loss_box_reg: 0.2194  loss_mask: 0.1605  loss_rpn_cls: 0.005695  loss_rpn_loc: 0.07461  time: 0.3521  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:33:45 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:55 (0.3521 s / it)\n",
      "\u001b[32m[10/21 09:33:45 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:56 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='7AR5I5Z_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:33:46 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:33:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:33:46 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:33:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:33:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:33:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.0966 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:33:52 d2.evaluation.evaluator]: \u001b[0mInference done 51/126. 0.1122 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:33:57 d2.evaluation.evaluator]: \u001b[0mInference done 91/126. 0.1152 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.332554 (0.126715 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.115703 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/7AR5I5Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.490\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.422 | 42.288 | 28.142 | 12.264 | 48.978 | 27.411 |\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 28.055 | cushion    | 31.383 | door       | 17.768 |\n",
      "| indoor-plant | 29.929 | sofa       | 35.056 | table      | 10.343 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:34:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:34:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:34:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:34:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n",
      "\u001b[32m[10/21 09:34:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.879 | 31.232 | 10.929 | 6.613 | 29.890 | 24.633 |\n",
      "\u001b[32m[10/21 09:34:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.975  | cushion    | 28.218 | door       | 9.329 |\n",
      "| indoor-plant | 15.812 | sofa       | 25.606 | table      | 2.335 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='7AR5I5Z0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:34:02 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:34:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:34:02 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:34:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:34:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:34:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1245 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 09:34:09 d2.evaluation.evaluator]: \u001b[0mInference done 50/355. 0.1191 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 09:34:14 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.1171 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:34:19 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1162 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:34:24 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.1155 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:34:29 d2.evaluation.evaluator]: \u001b[0mInference done 213/355. 0.1152 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 09:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.1159 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 289/355. 0.1158 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 331/355. 0.1149 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.484932 (0.127100 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.114997 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/7AR5I5Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.466\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.155 | 42.634 | 33.220 | 16.638 | 33.334 | 23.358 |\n",
      "\u001b[32m[10/21 09:34:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.930  | cushion    | 69.817 | door       | 2.382 |\n",
      "| indoor-plant | 28.665 | sofa       | 64.422 | table      | 5.717 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:34:48 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:34:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 09:34:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:34:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.162\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n",
      "\u001b[32m[10/21 09:34:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.484 | 37.896 | 25.537 | 14.723 | 25.592 | 16.176 |\n",
      "\u001b[32m[10/21 09:34:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.169  | cushion    | 73.130 | door       | 2.825 |\n",
      "| indoor-plant | 14.709 | sofa       | 48.034 | table      | 0.038 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='7AR5I5Z1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:34:48 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:34:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:34:48 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:34:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:34:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1286 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 09:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 48/355. 0.1221 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 09:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.1196 s / img. ETA=0:00:36\n",
      "\u001b[32m[10/21 09:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 126/355. 0.1195 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 09:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 166/355. 0.1185 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 09:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 207/355. 0.1172 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 09:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.1179 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 09:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 278/355. 0.1183 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 09:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.1185 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 09:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 354/355. 0.1182 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.711507 (0.133461 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.118289 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/7AR5I5Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.431\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.259 | 43.030 | 33.447 | 14.547 | 34.396 | 23.355 |\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.867  | cushion    | 70.248 | door       | 3.118 |\n",
      "| indoor-plant | 27.858 | sofa       | 63.862 | table      | 5.599 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.472 | 38.427 | 25.547 | 12.042 | 25.550 | 17.396 |\n",
      "\u001b[32m[10/21 09:35:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.750  | cushion    | 72.429 | door       | 3.541 |\n",
      "| indoor-plant | 13.636 | sofa       | 48.442 | table      | 0.032 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='7AR5I5Z2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:35:37 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:35:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:35:37 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:35:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:35:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 29/355. 0.1146 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 09:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 68/355. 0.1172 s / img. ETA=0:00:37\n",
      "\u001b[32m[10/21 09:35:51 d2.evaluation.evaluator]: \u001b[0mInference done 109/355. 0.1166 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 09:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 150/355. 0.1157 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 09:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 193/355. 0.1149 s / img. ETA=0:00:20\n",
      "\u001b[32m[10/21 09:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 229/355. 0.1157 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 268/355. 0.1158 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 305/355. 0.1163 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 09:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.1160 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 09:36:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.069178 (0.128769 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:36:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.116346 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/7AR5I5Z0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.428\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.102 | 43.944 | 32.897 | 15.153 | 33.933 | 23.303 |\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.574  | cushion    | 69.466 | door       | 2.492 |\n",
      "| indoor-plant | 28.956 | sofa       | 63.401 | table      | 5.723 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.38 seconds.\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.113 | 39.103 | 25.717 | 12.040 | 25.223 | 16.593 |\n",
      "\u001b[32m[10/21 09:36:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.762  | cushion    | 71.497 | door       | 3.214 |\n",
      "| indoor-plant | 14.010 | sofa       | 47.170 | table      | 0.027 |\n",
      "all results {'bbox': {'AP50': [42.634443423467594, 43.02972439195453, 43.94414061918089]}, 'segm': {'AP50': [37.895845177542796, 38.42726858606648, 39.10286273086674]}}\n",
      "dataset_name P1SPGEJ\n",
      "SOLVER PARAMS (800, 100, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='P1SPGEJ_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/P1SPGEJ0\n",
      "output_aug/800/P1SPGEJ0\n",
      "\u001b[32m[10/21 09:36:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:36:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:36:25 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:36:25 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:36:25 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:36:25 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:36:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:36:25 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:36:25 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:36:33 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 19  total_loss: 3.522  loss_cls: 1.523  loss_box_reg: 0.8722  loss_mask: 0.6902  loss_rpn_cls: 0.1289  loss_rpn_loc: 0.1228  time: 0.3718  data_time: 0.0175  lr: 0.00038162  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:36:40 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 39  total_loss: 2.485  loss_cls: 0.7616  loss_box_reg: 0.87  loss_mask: 0.6323  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.09253  time: 0.3659  data_time: 0.0040  lr: 0.00078122  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:36:47 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 59  total_loss: 2.103  loss_cls: 0.5826  loss_box_reg: 0.8414  loss_mask: 0.5356  loss_rpn_cls: 0.03589  loss_rpn_loc: 0.1244  time: 0.3639  data_time: 0.0039  lr: 0.0011808  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:36:54 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 79  total_loss: 1.678  loss_cls: 0.3736  loss_box_reg: 0.7866  loss_mask: 0.3958  loss_rpn_cls: 0.02651  loss_rpn_loc: 0.1067  time: 0.3629  data_time: 0.0039  lr: 0.0015804  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:01 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 99  total_loss: 1.341  loss_cls: 0.2519  loss_box_reg: 0.6161  loss_mask: 0.3312  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.1034  time: 0.3620  data_time: 0.0039  lr: 0.00198  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:09 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 119  total_loss: 1.116  loss_cls: 0.1814  loss_box_reg: 0.5011  loss_mask: 0.2801  loss_rpn_cls: 0.01443  loss_rpn_loc: 0.1109  time: 0.3610  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:16 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 139  total_loss: 1.046  loss_cls: 0.185  loss_box_reg: 0.4975  loss_mask: 0.2569  loss_rpn_cls: 0.02862  loss_rpn_loc: 0.09984  time: 0.3609  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:23 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 159  total_loss: 0.9491  loss_cls: 0.1722  loss_box_reg: 0.429  loss_mask: 0.23  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.08536  time: 0.3605  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:30 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 179  total_loss: 0.811  loss_cls: 0.1403  loss_box_reg: 0.3938  loss_mask: 0.2174  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.07061  time: 0.3596  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:37 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 199  total_loss: 0.7538  loss_cls: 0.1192  loss_box_reg: 0.3431  loss_mask: 0.2224  loss_rpn_cls: 0.006816  loss_rpn_loc: 0.04688  time: 0.3598  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:44 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 219  total_loss: 0.7672  loss_cls: 0.1275  loss_box_reg: 0.3083  loss_mask: 0.2267  loss_rpn_cls: 0.006507  loss_rpn_loc: 0.06852  time: 0.3595  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:52 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 239  total_loss: 0.7656  loss_cls: 0.136  loss_box_reg: 0.336  loss_mask: 0.2168  loss_rpn_cls: 0.006713  loss_rpn_loc: 0.07393  time: 0.3602  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:37:59 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 259  total_loss: 0.7025  loss_cls: 0.09679  loss_box_reg: 0.3333  loss_mask: 0.1976  loss_rpn_cls: 0.006791  loss_rpn_loc: 0.06845  time: 0.3603  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:06 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 279  total_loss: 0.6774  loss_cls: 0.1055  loss_box_reg: 0.3109  loss_mask: 0.1956  loss_rpn_cls: 0.006501  loss_rpn_loc: 0.07735  time: 0.3592  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:13 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 299  total_loss: 0.628  loss_cls: 0.1016  loss_box_reg: 0.2912  loss_mask: 0.1864  loss_rpn_cls: 0.007049  loss_rpn_loc: 0.06992  time: 0.3587  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:20 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 319  total_loss: 0.6228  loss_cls: 0.0941  loss_box_reg: 0.2875  loss_mask: 0.1739  loss_rpn_cls: 0.01066  loss_rpn_loc: 0.07375  time: 0.3586  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:27 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 339  total_loss: 0.6705  loss_cls: 0.09798  loss_box_reg: 0.2776  loss_mask: 0.2022  loss_rpn_cls: 0.005869  loss_rpn_loc: 0.07302  time: 0.3564  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:34 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 359  total_loss: 0.6467  loss_cls: 0.09034  loss_box_reg: 0.2827  loss_mask: 0.1666  loss_rpn_cls: 0.005017  loss_rpn_loc: 0.07083  time: 0.3564  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:41 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 379  total_loss: 0.5638  loss_cls: 0.09494  loss_box_reg: 0.2528  loss_mask: 0.1619  loss_rpn_cls: 0.004934  loss_rpn_loc: 0.05326  time: 0.3557  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:48 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 399  total_loss: 0.5685  loss_cls: 0.08738  loss_box_reg: 0.255  loss_mask: 0.1696  loss_rpn_cls: 0.005218  loss_rpn_loc: 0.05421  time: 0.3558  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:38:54 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 419  total_loss: 0.5617  loss_cls: 0.08548  loss_box_reg: 0.2504  loss_mask: 0.1603  loss_rpn_cls: 0.003788  loss_rpn_loc: 0.04228  time: 0.3546  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:01 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 439  total_loss: 0.5596  loss_cls: 0.09074  loss_box_reg: 0.2556  loss_mask: 0.1727  loss_rpn_cls: 0.004348  loss_rpn_loc: 0.06543  time: 0.3541  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:07 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 459  total_loss: 0.571  loss_cls: 0.08257  loss_box_reg: 0.2444  loss_mask: 0.1677  loss_rpn_cls: 0.006291  loss_rpn_loc: 0.07305  time: 0.3521  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:15 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 479  total_loss: 0.5621  loss_cls: 0.08707  loss_box_reg: 0.2501  loss_mask: 0.1608  loss_rpn_cls: 0.005502  loss_rpn_loc: 0.04952  time: 0.3526  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:22 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 499  total_loss: 0.5891  loss_cls: 0.07733  loss_box_reg: 0.2346  loss_mask: 0.1693  loss_rpn_cls: 0.005378  loss_rpn_loc: 0.07033  time: 0.3527  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:29 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 519  total_loss: 0.5779  loss_cls: 0.07851  loss_box_reg: 0.2545  loss_mask: 0.1754  loss_rpn_cls: 0.005137  loss_rpn_loc: 0.0685  time: 0.3530  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:36 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 539  total_loss: 0.5823  loss_cls: 0.07313  loss_box_reg: 0.2436  loss_mask: 0.1636  loss_rpn_cls: 0.002982  loss_rpn_loc: 0.04051  time: 0.3525  data_time: 0.0035  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:43 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 559  total_loss: 0.527  loss_cls: 0.0637  loss_box_reg: 0.223  loss_mask: 0.1574  loss_rpn_cls: 0.004374  loss_rpn_loc: 0.05224  time: 0.3523  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:50 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 579  total_loss: 0.531  loss_cls: 0.07107  loss_box_reg: 0.2309  loss_mask: 0.1614  loss_rpn_cls: 0.003182  loss_rpn_loc: 0.06395  time: 0.3522  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:39:56 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 599  total_loss: 0.5458  loss_cls: 0.08986  loss_box_reg: 0.2231  loss_mask: 0.1612  loss_rpn_cls: 0.00344  loss_rpn_loc: 0.04816  time: 0.3502  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:03 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 0.5105  loss_cls: 0.07988  loss_box_reg: 0.2189  loss_mask: 0.1506  loss_rpn_cls: 0.002167  loss_rpn_loc: 0.04323  time: 0.3505  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:10 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 0.515  loss_cls: 0.07634  loss_box_reg: 0.2311  loss_mask: 0.165  loss_rpn_cls: 0.004583  loss_rpn_loc: 0.06161  time: 0.3504  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:17 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 0.5312  loss_cls: 0.08236  loss_box_reg: 0.2276  loss_mask: 0.1603  loss_rpn_cls: 0.00475  loss_rpn_loc: 0.0652  time: 0.3505  data_time: 0.0036  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:24 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 0.5477  loss_cls: 0.08218  loss_box_reg: 0.2594  loss_mask: 0.1622  loss_rpn_cls: 0.002728  loss_rpn_loc: 0.04919  time: 0.3501  data_time: 0.0036  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:30 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 0.5546  loss_cls: 0.08729  loss_box_reg: 0.2501  loss_mask: 0.1527  loss_rpn_cls: 0.005322  loss_rpn_loc: 0.06357  time: 0.3499  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:37 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 0.4792  loss_cls: 0.07905  loss_box_reg: 0.2099  loss_mask: 0.1342  loss_rpn_cls: 0.005008  loss_rpn_loc: 0.04436  time: 0.3490  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:43 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.492  loss_cls: 0.07357  loss_box_reg: 0.2199  loss_mask: 0.1559  loss_rpn_cls: 0.005399  loss_rpn_loc: 0.05786  time: 0.3477  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:50 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 0.5305  loss_cls: 0.0806  loss_box_reg: 0.2324  loss_mask: 0.1538  loss_rpn_cls: 0.003214  loss_rpn_loc: 0.05847  time: 0.3481  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:40:57 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.5219  loss_cls: 0.06803  loss_box_reg: 0.2197  loss_mask: 0.1595  loss_rpn_cls: 0.003355  loss_rpn_loc: 0.05781  time: 0.3483  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:41:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5525  loss_cls: 0.08218  loss_box_reg: 0.2283  loss_mask: 0.1587  loss_rpn_cls: 0.008164  loss_rpn_loc: 0.07746  time: 0.3486  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:41:05 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:38 (0.3487 s / it)\n",
      "\u001b[32m[10/21 09:41:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='P1SPGEJ_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:41:05 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:41:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:41:05 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:41:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:41:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1101 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 49/126. 0.1151 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 09:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 87/126. 0.1175 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 09:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 123/126. 0.1193 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:16.450014 (0.135951 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.119334 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/P1SPGEJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.428\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.480\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.316\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.577\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.496\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.834 | 42.768 | 27.846 | 12.042 | 47.969 | 31.566 |\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 27.761 | cushion    | 30.949 | door       | 22.981 |\n",
      "| indoor-plant | 21.171 | sofa       | 34.892 | table      | 11.251 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.128\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.416\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.700 | 31.666 | 12.790 | 6.371 | 33.169 | 27.919 |\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 7.419  | cushion    | 29.404 | door       | 13.348 |\n",
      "| indoor-plant | 14.776 | sofa       | 26.315 | table      | 2.937  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='P1SPGEJ0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:41:23 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:41:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:41:23 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:41:23 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:41:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 27/355. 0.1238 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 09:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 63/355. 0.1220 s / img. ETA=0:00:42\n",
      "\u001b[32m[10/21 09:41:38 d2.evaluation.evaluator]: \u001b[0mInference done 101/355. 0.1204 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 09:41:43 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.1211 s / img. ETA=0:00:30\n",
      "\u001b[32m[10/21 09:41:48 d2.evaluation.evaluator]: \u001b[0mInference done 172/355. 0.1218 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 09:41:53 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.1206 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 09:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 246/355. 0.1208 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 09:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 281/355. 0.1210 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 09:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.1212 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 09:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 351/355. 0.1214 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.665158 (0.141900 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121414 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/P1SPGEJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.05 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.339\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.237\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.463\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.509\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.495\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.715 | 47.040 | 30.615 | 18.753 | 33.890 | 24.187 |\n",
      "\u001b[32m[10/21 09:42:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.751  | cushion    | 71.900 | door       | 5.124 |\n",
      "| indoor-plant | 36.393 | sofa       | 48.914 | table      | 5.211 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:42:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:42:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 09:42:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:42:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.395\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.135\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.394\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "\u001b[32m[10/21 09:42:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.637 | 39.469 | 25.854 | 13.539 | 27.736 | 19.309 |\n",
      "\u001b[32m[10/21 09:42:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.246  | cushion    | 73.193 | door       | 5.547 |\n",
      "| indoor-plant | 20.770 | sofa       | 44.874 | table      | 0.189 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='P1SPGEJ1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:42:15 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:42:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:42:15 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:42:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:42:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 19/355. 0.1220 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 09:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 53/355. 0.1228 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 09:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 88/355. 0.1229 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 09:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 125/355. 0.1214 s / img. ETA=0:00:33\n",
      "\u001b[32m[10/21 09:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 159/355. 0.1219 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 198/355. 0.1214 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 09:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 231/355. 0.1213 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 09:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 264/355. 0.1218 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:42:59 d2.evaluation.evaluator]: \u001b[0mInference done 297/355. 0.1214 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 333/355. 0.1214 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:43:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:51.273319 (0.146495 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:43:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121207 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:43:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:43:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/P1SPGEJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:43:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:43:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.520\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.823 | 48.253 | 33.004 | 22.161 | 37.016 | 25.049 |\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.489  | cushion    | 72.083 | door       | 6.553 |\n",
      "| indoor-plant | 36.005 | sofa       | 53.562 | table      | 5.248 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.32 seconds.\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.315\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.736 | 40.000 | 25.398 | 15.877 | 29.014 | 18.813 |\n",
      "\u001b[32m[10/21 09:43:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.819  | cushion    | 72.538 | door       | 6.713 |\n",
      "| indoor-plant | 19.831 | sofa       | 45.371 | table      | 0.144 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='P1SPGEJ2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:43:09 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:43:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:43:09 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:43:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:43:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1154 s / img. ETA=0:00:52\n",
      "\u001b[32m[10/21 09:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 52/355. 0.0975 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 09:43:21 d2.evaluation.evaluator]: \u001b[0mInference done 94/355. 0.0987 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 09:43:26 d2.evaluation.evaluator]: \u001b[0mInference done 134/355. 0.0989 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 09:43:31 d2.evaluation.evaluator]: \u001b[0mInference done 176/355. 0.1003 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 09:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 215/355. 0.0999 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 09:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 251/355. 0.1002 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 290/355. 0.0995 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 330/355. 0.0997 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:43:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.974184 (0.128498 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:43:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.100328 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/P1SPGEJ0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.491\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.225\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.519\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.491\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 30.458 | 49.116 | 33.437 | 22.481 | 36.571 | 24.513 |\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.166  | cushion    | 72.649 | door       | 6.573 |\n",
      "| indoor-plant | 38.399 | sofa       | 54.603 | table      | 5.360 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:43:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:43:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.33 seconds.\n",
      "\u001b[32m[10/21 09:43:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:43:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.330\n",
      "\u001b[32m[10/21 09:43:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.820 | 41.648 | 24.947 | 19.452 | 28.415 | 18.604 |\n",
      "\u001b[32m[10/21 09:43:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.669  | cushion    | 72.730 | door       | 6.866 |\n",
      "| indoor-plant | 22.134 | sofa       | 43.189 | table      | 0.332 |\n",
      "all results {'bbox': {'AP50': [47.04045259279418, 48.2532833525687, 49.11645057365871]}, 'segm': {'AP50': [39.46880344584591, 40.000083903133174, 41.6484593923343]}}\n",
      "dataset_name QIQY0L8\n",
      "SOLVER PARAMS (500, 200, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='QIQY0L8_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/QIQY0L80\n",
      "output_aug/500/QIQY0L80\n",
      "\u001b[32m[10/21 09:43:57 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:43:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:43:57 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:43:57 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:43:57 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:43:57 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:43:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:43:57 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:43:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:44:04 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 19  total_loss: 3.55  loss_cls: 1.626  loss_box_reg: 0.8606  loss_mask: 0.6896  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.1818  time: 0.3226  data_time: 0.0161  lr: 0.00019181  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:10 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 39  total_loss: 2.573  loss_cls: 0.8231  loss_box_reg: 0.885  loss_mask: 0.656  loss_rpn_cls: 0.07093  loss_rpn_loc: 0.1243  time: 0.3240  data_time: 0.0039  lr: 0.00039161  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:17 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 59  total_loss: 2.3  loss_cls: 0.6893  loss_box_reg: 0.8583  loss_mask: 0.5997  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.1406  time: 0.3210  data_time: 0.0037  lr: 0.00059141  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:24 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 79  total_loss: 1.976  loss_cls: 0.4907  loss_box_reg: 0.8481  loss_mask: 0.4906  loss_rpn_cls: 0.02312  loss_rpn_loc: 0.05758  time: 0.3281  data_time: 0.0038  lr: 0.00079121  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:31 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 99  total_loss: 1.579  loss_cls: 0.31  loss_box_reg: 0.7527  loss_mask: 0.4144  loss_rpn_cls: 0.03321  loss_rpn_loc: 0.1241  time: 0.3327  data_time: 0.0038  lr: 0.00099101  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:37 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 119  total_loss: 1.327  loss_cls: 0.228  loss_box_reg: 0.6341  loss_mask: 0.3493  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.1023  time: 0.3346  data_time: 0.0039  lr: 0.0011908  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:44 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 139  total_loss: 1.281  loss_cls: 0.2186  loss_box_reg: 0.536  loss_mask: 0.3118  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.1224  time: 0.3313  data_time: 0.0038  lr: 0.0013906  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:50 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 159  total_loss: 1.012  loss_cls: 0.1896  loss_box_reg: 0.4643  loss_mask: 0.2814  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.07553  time: 0.3288  data_time: 0.0035  lr: 0.0015904  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:44:57 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 179  total_loss: 0.9916  loss_cls: 0.1918  loss_box_reg: 0.4202  loss_mask: 0.2678  loss_rpn_cls: 0.02155  loss_rpn_loc: 0.08261  time: 0.3315  data_time: 0.0037  lr: 0.0017902  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:03 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 199  total_loss: 0.934  loss_cls: 0.1702  loss_box_reg: 0.4272  loss_mask: 0.253  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.09077  time: 0.3272  data_time: 0.0039  lr: 0.00199  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:10 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 219  total_loss: 0.8336  loss_cls: 0.1492  loss_box_reg: 0.369  loss_mask: 0.2249  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.09155  time: 0.3289  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:17 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 239  total_loss: 0.7857  loss_cls: 0.156  loss_box_reg: 0.3371  loss_mask: 0.2168  loss_rpn_cls: 0.005942  loss_rpn_loc: 0.06708  time: 0.3306  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:24 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 259  total_loss: 0.81  loss_cls: 0.1394  loss_box_reg: 0.3754  loss_mask: 0.2408  loss_rpn_cls: 0.007621  loss_rpn_loc: 0.06395  time: 0.3324  data_time: 0.0036  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:30 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 279  total_loss: 0.684  loss_cls: 0.1171  loss_box_reg: 0.3108  loss_mask: 0.2183  loss_rpn_cls: 0.007258  loss_rpn_loc: 0.07541  time: 0.3310  data_time: 0.0036  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:36 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 299  total_loss: 0.7543  loss_cls: 0.1184  loss_box_reg: 0.3274  loss_mask: 0.21  loss_rpn_cls: 0.009745  loss_rpn_loc: 0.07085  time: 0.3297  data_time: 0.0036  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:43 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 319  total_loss: 0.7372  loss_cls: 0.1281  loss_box_reg: 0.333  loss_mask: 0.2143  loss_rpn_cls: 0.007381  loss_rpn_loc: 0.08085  time: 0.3302  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:49 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 339  total_loss: 0.6672  loss_cls: 0.1097  loss_box_reg: 0.287  loss_mask: 0.1911  loss_rpn_cls: 0.006611  loss_rpn_loc: 0.06318  time: 0.3268  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:45:56 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 359  total_loss: 0.6234  loss_cls: 0.09983  loss_box_reg: 0.2819  loss_mask: 0.1885  loss_rpn_cls: 0.006237  loss_rpn_loc: 0.06173  time: 0.3292  data_time: 0.0043  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:04 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 379  total_loss: 0.6706  loss_cls: 0.1089  loss_box_reg: 0.291  loss_mask: 0.1853  loss_rpn_cls: 0.005259  loss_rpn_loc: 0.06388  time: 0.3323  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:12 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 399  total_loss: 0.6201  loss_cls: 0.0912  loss_box_reg: 0.2768  loss_mask: 0.1693  loss_rpn_cls: 0.005181  loss_rpn_loc: 0.04894  time: 0.3353  data_time: 0.0041  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:19 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 419  total_loss: 0.6013  loss_cls: 0.107  loss_box_reg: 0.3012  loss_mask: 0.1551  loss_rpn_cls: 0.003464  loss_rpn_loc: 0.06958  time: 0.3366  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:26 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 439  total_loss: 0.6471  loss_cls: 0.09558  loss_box_reg: 0.3098  loss_mask: 0.1683  loss_rpn_cls: 0.003782  loss_rpn_loc: 0.08484  time: 0.3380  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:33 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 459  total_loss: 0.5911  loss_cls: 0.0867  loss_box_reg: 0.2724  loss_mask: 0.1752  loss_rpn_cls: 0.004251  loss_rpn_loc: 0.04221  time: 0.3391  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:41 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 479  total_loss: 0.6298  loss_cls: 0.09399  loss_box_reg: 0.2746  loss_mask: 0.19  loss_rpn_cls: 0.005674  loss_rpn_loc: 0.08698  time: 0.3401  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5583  loss_cls: 0.0952  loss_box_reg: 0.2446  loss_mask: 0.1662  loss_rpn_cls: 0.007748  loss_rpn_loc: 0.06513  time: 0.3410  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:46:49 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:49 (0.3410 s / it)\n",
      "\u001b[32m[10/21 09:46:49 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:50 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='QIQY0L8_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:46:49 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:46:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:46:49 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:46:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:46:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1074 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 09:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 50/126. 0.1153 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 90/126. 0.1160 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.785570 (0.130459 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.117372 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/QIQY0L80/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 09:47:05 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.249\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.414\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.923 | 41.400 | 27.076 | 14.104 | 48.640 | 24.662 |\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 28.753 | cushion    | 30.377 | door       | 14.606 |\n",
      "| indoor-plant | 27.549 | sofa       | 38.958 | table      | 9.292  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 15.664 | 33.961 | 10.301 | 6.941 | 31.060 | 26.095 |\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 10.921 | cushion    | 26.288 | door       | 10.606 |\n",
      "| indoor-plant | 19.622 | sofa       | 23.263 | table      | 3.282  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='QIQY0L80_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:47:06 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:47:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:47:06 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:47:06 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:47:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1225 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 09:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 48/355. 0.1196 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 09:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.1153 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 131/355. 0.1140 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 171/355. 0.1137 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 212/355. 0.1139 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 09:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 248/355. 0.1151 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 285/355. 0.1158 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 322/355. 0.1164 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:47:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.797433 (0.130850 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:47:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.116684 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/QIQY0L80/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.424\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.451\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.792 | 42.366 | 31.595 | 16.995 | 33.376 | 19.769 |\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.702  | cushion    | 74.156 | door       | 3.129 |\n",
      "| indoor-plant | 21.592 | sofa       | 57.898 | table      | 6.272 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.204 | 37.747 | 27.393 | 15.832 | 26.081 | 19.073 |\n",
      "\u001b[32m[10/21 09:47:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.751  | cushion    | 75.684 | door       | 3.895 |\n",
      "| indoor-plant | 12.058 | sofa       | 56.712 | table      | 0.123 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='QIQY0L81_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:47:54 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:47:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:47:54 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:47:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:47:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1203 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 09:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.1180 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 09:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 90/355. 0.1153 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.1149 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 169/355. 0.1155 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 210/355. 0.1154 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 09:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 246/355. 0.1161 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 09:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 288/355. 0.1142 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 331/355. 0.1128 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.204832 (0.126300 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.111887 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/QIQY0L80/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.422\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.434\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.480\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.757 | 42.159 | 31.993 | 15.845 | 33.612 | 19.776 |\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.315  | cushion    | 73.482 | door       | 3.928 |\n",
      "| indoor-plant | 21.292 | sofa       | 57.390 | table      | 6.138 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:48:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:48:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 09:48:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:48:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.138\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
      "\u001b[32m[10/21 09:48:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.466 | 37.587 | 26.765 | 13.818 | 24.956 | 19.344 |\n",
      "\u001b[32m[10/21 09:48:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.162  | cushion    | 73.894 | door       | 4.806 |\n",
      "| indoor-plant | 10.729 | sofa       | 54.072 | table      | 0.131 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='QIQY0L82_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:48:40 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:48:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:48:40 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:48:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:48:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1028 s / img. ETA=0:00:41\n",
      "\u001b[32m[10/21 09:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 54/355. 0.1020 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 09:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 95/355. 0.1079 s / img. ETA=0:00:31\n",
      "\u001b[32m[10/21 09:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.1079 s / img. ETA=0:00:26\n",
      "\u001b[32m[10/21 09:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 179/355. 0.1086 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 220/355. 0.1083 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.1088 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 297/355. 0.1095 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 09:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.1099 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 09:49:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.833229 (0.125238 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:49:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.109567 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:49:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:49:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/QIQY0L80/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:49:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:49:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.438\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.224\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.712 | 43.864 | 32.262 | 17.432 | 34.168 | 20.604 |\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.089  | cushion    | 74.237 | door       | 3.554 |\n",
      "| indoor-plant | 25.560 | sofa       | 58.867 | table      | 5.967 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.393\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.188\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.372\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.782 | 39.275 | 27.046 | 15.672 | 25.757 | 18.771 |\n",
      "\u001b[32m[10/21 09:49:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.050  | cushion    | 73.964 | door       | 4.741 |\n",
      "| indoor-plant | 12.803 | sofa       | 54.062 | table      | 0.073 |\n",
      "all results {'bbox': {'AP50': [42.36576773352795, 42.15943213843818, 43.863670949095535]}, 'segm': {'AP50': [37.74687191876034, 37.58724295546522, 39.27470824234679]}}\n",
      "dataset_name B5WZET7\n",
      "SOLVER PARAMS (800, 200, 0.002)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='B5WZET7_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/B5WZET70\n",
      "output_aug/800/B5WZET70\n",
      "\u001b[32m[10/21 09:49:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:49:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:49:26 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:49:26 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:49:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:49:26 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:49:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:49:26 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:49:26 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:49:33 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 19  total_loss: 3.652  loss_cls: 1.67  loss_box_reg: 0.8931  loss_mask: 0.6896  loss_rpn_cls: 0.1902  loss_rpn_loc: 0.1288  time: 0.3073  data_time: 0.0157  lr: 0.00019181  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:49:40 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 39  total_loss: 2.499  loss_cls: 0.8259  loss_box_reg: 0.8918  loss_mask: 0.6544  loss_rpn_cls: 0.06524  loss_rpn_loc: 0.1532  time: 0.3283  data_time: 0.0037  lr: 0.00039161  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:49:47 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 59  total_loss: 2.286  loss_cls: 0.6644  loss_box_reg: 0.8861  loss_mask: 0.5936  loss_rpn_cls: 0.04228  loss_rpn_loc: 0.1204  time: 0.3360  data_time: 0.0036  lr: 0.00059141  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:49:53 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 79  total_loss: 1.93  loss_cls: 0.4686  loss_box_reg: 0.8489  loss_mask: 0.497  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.07728  time: 0.3375  data_time: 0.0038  lr: 0.00079121  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:00 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 99  total_loss: 1.65  loss_cls: 0.331  loss_box_reg: 0.7795  loss_mask: 0.4142  loss_rpn_cls: 0.0194  loss_rpn_loc: 0.1178  time: 0.3343  data_time: 0.0038  lr: 0.00099101  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:07 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 119  total_loss: 1.333  loss_cls: 0.2406  loss_box_reg: 0.6391  loss_mask: 0.311  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.08482  time: 0.3338  data_time: 0.0037  lr: 0.0011908  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:13 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 139  total_loss: 1.19  loss_cls: 0.1843  loss_box_reg: 0.5638  loss_mask: 0.3176  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.08965  time: 0.3332  data_time: 0.0037  lr: 0.0013906  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:19 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 159  total_loss: 1.016  loss_cls: 0.1722  loss_box_reg: 0.4921  loss_mask: 0.2764  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.07947  time: 0.3299  data_time: 0.0038  lr: 0.0015904  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:26 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 179  total_loss: 1.022  loss_cls: 0.1522  loss_box_reg: 0.4525  loss_mask: 0.2609  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.06424  time: 0.3330  data_time: 0.0040  lr: 0.0017902  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:34 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 199  total_loss: 0.9369  loss_cls: 0.1578  loss_box_reg: 0.4135  loss_mask: 0.2568  loss_rpn_cls: 0.009414  loss_rpn_loc: 0.1039  time: 0.3353  data_time: 0.0041  lr: 0.00199  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:40 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 219  total_loss: 0.83  loss_cls: 0.1525  loss_box_reg: 0.3818  loss_mask: 0.2366  loss_rpn_cls: 0.008066  loss_rpn_loc: 0.07405  time: 0.3347  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:47 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 239  total_loss: 0.8544  loss_cls: 0.1234  loss_box_reg: 0.3492  loss_mask: 0.2259  loss_rpn_cls: 0.006942  loss_rpn_loc: 0.1191  time: 0.3334  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:50:53 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 259  total_loss: 0.7701  loss_cls: 0.1233  loss_box_reg: 0.35  loss_mask: 0.2423  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.06316  time: 0.3328  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:00 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 279  total_loss: 0.7131  loss_cls: 0.1166  loss_box_reg: 0.3312  loss_mask: 0.21  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.06055  time: 0.3329  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:05 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 299  total_loss: 0.7811  loss_cls: 0.1093  loss_box_reg: 0.3097  loss_mask: 0.2194  loss_rpn_cls: 0.02233  loss_rpn_loc: 0.1072  time: 0.3287  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:12 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 319  total_loss: 0.7478  loss_cls: 0.1003  loss_box_reg: 0.3082  loss_mask: 0.2134  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.1044  time: 0.3309  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:20 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 339  total_loss: 0.8155  loss_cls: 0.1416  loss_box_reg: 0.3303  loss_mask: 0.217  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.1071  time: 0.3327  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:27 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 359  total_loss: 0.6747  loss_cls: 0.1174  loss_box_reg: 0.297  loss_mask: 0.2018  loss_rpn_cls: 0.009497  loss_rpn_loc: 0.0793  time: 0.3344  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:34 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 379  total_loss: 0.6028  loss_cls: 0.1057  loss_box_reg: 0.2804  loss_mask: 0.1852  loss_rpn_cls: 0.006785  loss_rpn_loc: 0.0444  time: 0.3359  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:41 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 399  total_loss: 0.6109  loss_cls: 0.09425  loss_box_reg: 0.2626  loss_mask: 0.1859  loss_rpn_cls: 0.007209  loss_rpn_loc: 0.06499  time: 0.3370  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:48 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 419  total_loss: 0.618  loss_cls: 0.0977  loss_box_reg: 0.2705  loss_mask: 0.1867  loss_rpn_cls: 0.004875  loss_rpn_loc: 0.03936  time: 0.3378  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:51:56 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 439  total_loss: 0.6259  loss_cls: 0.1018  loss_box_reg: 0.2658  loss_mask: 0.1826  loss_rpn_cls: 0.00469  loss_rpn_loc: 0.07462  time: 0.3388  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:03 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 459  total_loss: 0.6365  loss_cls: 0.09598  loss_box_reg: 0.2719  loss_mask: 0.1851  loss_rpn_cls: 0.006079  loss_rpn_loc: 0.07102  time: 0.3400  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:10 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 479  total_loss: 0.6351  loss_cls: 0.0989  loss_box_reg: 0.2778  loss_mask: 0.1754  loss_rpn_cls: 0.006583  loss_rpn_loc: 0.0728  time: 0.3409  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:18 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 499  total_loss: 0.6489  loss_cls: 0.1022  loss_box_reg: 0.266  loss_mask: 0.182  loss_rpn_cls: 0.00962  loss_rpn_loc: 0.06547  time: 0.3418  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:25 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 519  total_loss: 0.5928  loss_cls: 0.09581  loss_box_reg: 0.2509  loss_mask: 0.1686  loss_rpn_cls: 0.004462  loss_rpn_loc: 0.07015  time: 0.3428  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:32 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 539  total_loss: 0.5936  loss_cls: 0.08486  loss_box_reg: 0.2406  loss_mask: 0.1662  loss_rpn_cls: 0.006027  loss_rpn_loc: 0.07468  time: 0.3434  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:39 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 559  total_loss: 0.5856  loss_cls: 0.08335  loss_box_reg: 0.2408  loss_mask: 0.1694  loss_rpn_cls: 0.004024  loss_rpn_loc: 0.07464  time: 0.3440  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:47 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 579  total_loss: 0.5619  loss_cls: 0.08815  loss_box_reg: 0.2335  loss_mask: 0.1599  loss_rpn_cls: 0.008472  loss_rpn_loc: 0.04625  time: 0.3445  data_time: 0.0040  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:52:54 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 599  total_loss: 0.5843  loss_cls: 0.08899  loss_box_reg: 0.2482  loss_mask: 0.1721  loss_rpn_cls: 0.004314  loss_rpn_loc: 0.06033  time: 0.3450  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:01 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 619  total_loss: 0.5106  loss_cls: 0.07807  loss_box_reg: 0.2268  loss_mask: 0.1515  loss_rpn_cls: 0.004709  loss_rpn_loc: 0.05089  time: 0.3457  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:08 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 639  total_loss: 0.5457  loss_cls: 0.08789  loss_box_reg: 0.2208  loss_mask: 0.1682  loss_rpn_cls: 0.006957  loss_rpn_loc: 0.04509  time: 0.3462  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:16 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 659  total_loss: 0.5119  loss_cls: 0.08694  loss_box_reg: 0.2258  loss_mask: 0.1559  loss_rpn_cls: 0.004543  loss_rpn_loc: 0.04532  time: 0.3468  data_time: 0.0035  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:23 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 679  total_loss: 0.5224  loss_cls: 0.07058  loss_box_reg: 0.2294  loss_mask: 0.1551  loss_rpn_cls: 0.003375  loss_rpn_loc: 0.05606  time: 0.3473  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:30 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 699  total_loss: 0.5274  loss_cls: 0.07627  loss_box_reg: 0.2328  loss_mask: 0.158  loss_rpn_cls: 0.002812  loss_rpn_loc: 0.05328  time: 0.3476  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:37 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 719  total_loss: 0.5567  loss_cls: 0.08178  loss_box_reg: 0.2165  loss_mask: 0.1509  loss_rpn_cls: 0.004797  loss_rpn_loc: 0.06945  time: 0.3477  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:44 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 739  total_loss: 0.4816  loss_cls: 0.06898  loss_box_reg: 0.2109  loss_mask: 0.139  loss_rpn_cls: 0.006604  loss_rpn_loc: 0.05432  time: 0.3481  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:52 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 759  total_loss: 0.512  loss_cls: 0.06883  loss_box_reg: 0.2182  loss_mask: 0.1563  loss_rpn_cls: 0.006865  loss_rpn_loc: 0.04917  time: 0.3486  data_time: 0.0038  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:53:59 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 779  total_loss: 0.5005  loss_cls: 0.07926  loss_box_reg: 0.2006  loss_mask: 0.1489  loss_rpn_cls: 0.006986  loss_rpn_loc: 0.06357  time: 0.3487  data_time: 0.0039  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:54:07 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.5252  loss_cls: 0.08428  loss_box_reg: 0.2135  loss_mask: 0.1508  loss_rpn_cls: 0.00421  loss_rpn_loc: 0.05241  time: 0.3490  data_time: 0.0037  lr: 0.002  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:54:07 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:04:38 (0.3490 s / it)\n",
      "\u001b[32m[10/21 09:54:07 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:39 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='B5WZET7_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:54:07 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:54:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:54:07 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:54:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:54:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:54:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1060 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 09:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 49/126. 0.1181 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:54:19 d2.evaluation.evaluator]: \u001b[0mInference done 90/126. 0.1164 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.721043 (0.129926 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.117367 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:54:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:54:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/B5WZET70/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:54:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:54:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.256\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.419\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.472\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.556\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.440\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.569 | 41.917 | 28.478 | 12.114 | 47.249 | 27.377 |\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 26.481 | cushion    | 32.022 | door       | 22.464 |\n",
      "| indoor-plant | 26.369 | sofa       | 35.186 | table      | 10.894 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.338\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.139\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.379\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 16.051 | 33.760 | 13.940 | 6.850 | 32.925 | 28.044 |\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 6.899  | cushion    | 27.908 | door       | 15.196 |\n",
      "| indoor-plant | 20.320 | sofa       | 22.999 | table      | 2.984  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='B5WZET70_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:54:24 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:54:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:54:24 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:54:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:54:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1204 s / img. ETA=0:00:47\n",
      "\u001b[32m[10/21 09:54:30 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.1185 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 09:54:36 d2.evaluation.evaluator]: \u001b[0mInference done 89/355. 0.1179 s / img. ETA=0:00:34\n",
      "\u001b[32m[10/21 09:54:41 d2.evaluation.evaluator]: \u001b[0mInference done 129/355. 0.1170 s / img. ETA=0:00:29\n",
      "\u001b[32m[10/21 09:54:46 d2.evaluation.evaluator]: \u001b[0mInference done 170/355. 0.1164 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 09:54:51 d2.evaluation.evaluator]: \u001b[0mInference done 213/355. 0.1150 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 09:54:56 d2.evaluation.evaluator]: \u001b[0mInference done 250/355. 0.1158 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 287/355. 0.1163 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 09:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 325/355. 0.1166 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.349277 (0.129569 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.116911 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/B5WZET70/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.438\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.446\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.179 | 43.785 | 32.763 | 17.632 | 29.486 | 28.577 |\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.884  | cushion    | 71.767 | door       | 4.914 |\n",
      "| indoor-plant | 31.146 | sofa       | 61.128 | table      | 3.233 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:55:10 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:55:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 09:55:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:55:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.220\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.361\n",
      "\u001b[32m[10/21 09:55:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.547 | 39.400 | 26.999 | 15.496 | 27.264 | 21.973 |\n",
      "\u001b[32m[10/21 09:55:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.310  | cushion    | 73.912 | door       | 4.736 |\n",
      "| indoor-plant | 21.239 | sofa       | 50.941 | table      | 0.144 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='B5WZET71_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 09:55:11 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 09:55:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:55:11 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:55:11 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 09:55:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:55:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1204 s / img. ETA=0:00:48\n",
      "\u001b[32m[10/21 09:55:18 d2.evaluation.evaluator]: \u001b[0mInference done 49/355. 0.1183 s / img. ETA=0:00:40\n",
      "\u001b[32m[10/21 09:55:23 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.1186 s / img. ETA=0:00:35\n",
      "\u001b[32m[10/21 09:55:28 d2.evaluation.evaluator]: \u001b[0mInference done 130/355. 0.1138 s / img. ETA=0:00:28\n",
      "\u001b[32m[10/21 09:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 173/355. 0.1117 s / img. ETA=0:00:22\n",
      "\u001b[32m[10/21 09:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 216/355. 0.1109 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 09:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 259/355. 0.1087 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 09:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 298/355. 0.1087 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 09:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 339/355. 0.1091 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.309608 (0.123742 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.108545 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/B5WZET70/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.447\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.251\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.534\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.639 | 44.739 | 32.763 | 16.235 | 31.076 | 29.382 |\n",
      "\u001b[32m[10/21 09:55:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.265  | cushion    | 72.233 | door       | 5.526 |\n",
      "| indoor-plant | 30.927 | sofa       | 62.420 | table      | 3.461 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:55:56 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:55:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "\u001b[32m[10/21 09:55:56 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:55:56 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.400\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.149\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.280\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n",
      "\u001b[32m[10/21 09:55:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.930 | 40.020 | 28.120 | 14.864 | 28.019 | 21.197 |\n",
      "\u001b[32m[10/21 09:55:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.831  | cushion    | 74.273 | door       | 5.480 |\n",
      "| indoor-plant | 20.900 | sofa       | 52.012 | table      | 0.084 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='B5WZET72_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 09:55:56 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 09:55:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:55:56 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:55:56 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 09:55:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 16/355. 0.0971 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 09:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 55/355. 0.1105 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 09:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 97/355. 0.1098 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 09:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 137/355. 0.1115 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 09:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 180/355. 0.1105 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 09:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 221/355. 0.1095 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 09:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 266/355. 0.1066 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 09:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 306/355. 0.1063 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 09:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 348/355. 0.1064 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.694101 (0.121983 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:37 (0.106073 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/B5WZET70/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.15 seconds.\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.450\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 29.800 | 44.980 | 32.440 | 20.341 | 30.581 | 29.317 |\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.363  | cushion    | 72.677 | door       | 5.002 |\n",
      "| indoor-plant | 32.804 | sofa       | 61.329 | table      | 3.625 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:56:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.197\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.210\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      "\u001b[32m[10/21 09:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 25.836 | 40.946 | 27.478 | 19.744 | 27.244 | 21.740 |\n",
      "\u001b[32m[10/21 09:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.766  | cushion    | 73.552 | door       | 5.178 |\n",
      "| indoor-plant | 22.189 | sofa       | 51.237 | table      | 0.092 |\n",
      "all results {'bbox': {'AP50': [43.78489079863089, 44.73885504922054, 44.97953563845831]}, 'segm': {'AP50': [39.4004093894964, 40.0197143865933, 40.946174685617784]}}\n",
      "dataset_name MQRT7YF\n",
      "SOLVER PARAMS (500, 100, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='MQRT7YF_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/MQRT7YF0\n",
      "output_aug/500/MQRT7YF0\n",
      "\u001b[32m[10/21 09:56:42 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 09:56:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 09:56:42 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 09:56:42 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 09:56:42 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 09:56:42 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:56:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 09:56:42 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 09:56:42 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 09:56:49 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 19  total_loss: 2.904  loss_cls: 1.142  loss_box_reg: 0.8618  loss_mask: 0.6803  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.134  time: 0.3429  data_time: 0.0158  lr: 0.00095405  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:56:56 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 39  total_loss: 2.341  loss_cls: 0.6917  loss_box_reg: 0.9038  loss_mask: 0.5862  loss_rpn_cls: 0.05059  loss_rpn_loc: 0.1099  time: 0.3354  data_time: 0.0037  lr: 0.001953  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:02 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 59  total_loss: 1.74  loss_cls: 0.4158  loss_box_reg: 0.7756  loss_mask: 0.4212  loss_rpn_cls: 0.02625  loss_rpn_loc: 0.1049  time: 0.3358  data_time: 0.0038  lr: 0.002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:09 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 79  total_loss: 1.277  loss_cls: 0.2332  loss_box_reg: 0.5828  loss_mask: 0.2916  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.1102  time: 0.3381  data_time: 0.0039  lr: 0.0039511  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:15 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 99  total_loss: 1.176  loss_cls: 0.1951  loss_box_reg: 0.5086  loss_mask: 0.2681  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.1583  time: 0.3308  data_time: 0.0039  lr: 0.0049501  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:22 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 119  total_loss: 1.074  loss_cls: 0.2146  loss_box_reg: 0.4676  loss_mask: 0.2739  loss_rpn_cls: 0.02471  loss_rpn_loc: 0.1245  time: 0.3353  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:29 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 139  total_loss: 0.9778  loss_cls: 0.1532  loss_box_reg: 0.4196  loss_mask: 0.2438  loss_rpn_cls: 0.03023  loss_rpn_loc: 0.1314  time: 0.3374  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:36 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 159  total_loss: 0.8481  loss_cls: 0.1278  loss_box_reg: 0.3902  loss_mask: 0.2269  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.09613  time: 0.3392  data_time: 0.0036  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:43 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 179  total_loss: 0.7862  loss_cls: 0.1443  loss_box_reg: 0.3792  loss_mask: 0.2059  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.07433  time: 0.3377  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:50 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 199  total_loss: 0.8272  loss_cls: 0.1226  loss_box_reg: 0.3565  loss_mask: 0.2059  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.1172  time: 0.3369  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:57:57 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 219  total_loss: 0.8398  loss_cls: 0.1145  loss_box_reg: 0.3508  loss_mask: 0.2115  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.09589  time: 0.3379  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:02 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 239  total_loss: 0.7231  loss_cls: 0.1215  loss_box_reg: 0.3148  loss_mask: 0.201  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.1001  time: 0.3312  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:09 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 259  total_loss: 0.7088  loss_cls: 0.1102  loss_box_reg: 0.3215  loss_mask: 0.1865  loss_rpn_cls: 0.00993  loss_rpn_loc: 0.07943  time: 0.3339  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:16 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 279  total_loss: 0.6904  loss_cls: 0.1002  loss_box_reg: 0.3343  loss_mask: 0.1733  loss_rpn_cls: 0.00721  loss_rpn_loc: 0.1145  time: 0.3362  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:24 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 299  total_loss: 0.6947  loss_cls: 0.103  loss_box_reg: 0.3272  loss_mask: 0.1736  loss_rpn_cls: 0.008769  loss_rpn_loc: 0.07405  time: 0.3382  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:31 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 319  total_loss: 0.6238  loss_cls: 0.08342  loss_box_reg: 0.2895  loss_mask: 0.1553  loss_rpn_cls: 0.01047  loss_rpn_loc: 0.05624  time: 0.3401  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:39 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 339  total_loss: 0.6753  loss_cls: 0.1024  loss_box_reg: 0.3099  loss_mask: 0.1694  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.1003  time: 0.3419  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:46 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 359  total_loss: 0.6081  loss_cls: 0.09963  loss_box_reg: 0.286  loss_mask: 0.151  loss_rpn_cls: 0.008386  loss_rpn_loc: 0.07513  time: 0.3433  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:58:53 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 379  total_loss: 0.6929  loss_cls: 0.1049  loss_box_reg: 0.3098  loss_mask: 0.1575  loss_rpn_cls: 0.006664  loss_rpn_loc: 0.08813  time: 0.3445  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:59:01 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 399  total_loss: 0.6175  loss_cls: 0.0966  loss_box_reg: 0.2872  loss_mask: 0.1599  loss_rpn_cls: 0.009604  loss_rpn_loc: 0.08043  time: 0.3458  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:59:08 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 419  total_loss: 0.677  loss_cls: 0.09057  loss_box_reg: 0.2876  loss_mask: 0.164  loss_rpn_cls: 0.05285  loss_rpn_loc: 0.09305  time: 0.3465  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:59:15 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 439  total_loss: 0.6163  loss_cls: 0.07671  loss_box_reg: 0.294  loss_mask: 0.169  loss_rpn_cls: 0.0174  loss_rpn_loc: 0.07796  time: 0.3471  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:59:22 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 459  total_loss: 0.6488  loss_cls: 0.1029  loss_box_reg: 0.2746  loss_mask: 0.1676  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.08343  time: 0.3477  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:59:30 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 479  total_loss: 0.6459  loss_cls: 0.07755  loss_box_reg: 0.2644  loss_mask: 0.169  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.09617  time: 0.3486  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:59:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.6148  loss_cls: 0.0896  loss_box_reg: 0.2844  loss_mask: 0.1524  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.08173  time: 0.3490  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 09:59:38 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:02:53 (0.3490 s / it)\n",
      "\u001b[32m[10/21 09:59:38 d2.engine.hooks]: \u001b[0mTotal training time: 0:02:55 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='MQRT7YF_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 09:59:38 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 09:59:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:59:38 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:59:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 09:59:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 09:59:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1099 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 09:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 51/126. 0.1163 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 09:59:49 d2.evaluation.evaluator]: \u001b[0mInference done 91/126. 0.1162 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:15.401283 (0.127283 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:14 (0.116122 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MQRT7YF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.391\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.417\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.214\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.478\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.058 | 39.066 | 22.805 | 12.031 | 41.653 | 21.426 |\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 24.877 | cushion    | 32.849 | door       | 16.020 |\n",
      "| indoor-plant | 28.646 | sofa       | 22.923 | table      | 7.032  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.391\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.372\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.540 | 28.943 | 12.315 | 6.736 | 32.525 | 27.103 |\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.967  | cushion    | 27.950 | door       | 9.850 |\n",
      "| indoor-plant | 22.501 | sofa       | 19.206 | table      | 2.766 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='MQRT7YF0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 09:59:54 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 09:59:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 09:59:54 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 09:59:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 09:59:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 09:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1183 s / img. ETA=0:00:49\n",
      "\u001b[32m[10/21 10:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1229 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 10:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 82/355. 0.1235 s / img. ETA=0:00:39\n",
      "\u001b[32m[10/21 10:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.1214 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 10:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.1218 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 10:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.1214 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 10:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 233/355. 0.1211 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 10:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.1213 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 10:00:37 d2.evaluation.evaluator]: \u001b[0mInference done 304/355. 0.1214 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 10:00:42 d2.evaluation.evaluator]: \u001b[0mInference done 342/355. 0.1210 s / img. ETA=0:00:01\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.664630 (0.139042 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.121213 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MQRT7YF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.434\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.286\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.449\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.460\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.695 | 43.402 | 30.260 | 13.049 | 28.603 | 21.239 |\n",
      "\u001b[32m[10/21 10:00:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.287  | cushion    | 66.082 | door       | 4.720 |\n",
      "| indoor-plant | 20.139 | sofa       | 59.278 | table      | 5.665 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:00:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:00:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[10/21 10:00:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:00:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.303\n",
      "\u001b[32m[10/21 10:00:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.725 | 39.217 | 21.239 | 11.906 | 22.773 | 15.729 |\n",
      "\u001b[32m[10/21 10:00:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.240  | cushion    | 72.134 | door       | 6.520 |\n",
      "| indoor-plant | 15.957 | sofa       | 32.294 | table      | 0.204 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='MQRT7YF1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 10:00:45 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 10:00:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:00:45 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:00:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 10:00:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:00:47 d2.evaluation.evaluator]: \u001b[0mInference done 12/355. 0.1302 s / img. ETA=0:00:54\n",
      "\u001b[32m[10/21 10:00:52 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1265 s / img. ETA=0:00:46\n",
      "\u001b[32m[10/21 10:00:57 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.1230 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 10:01:02 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.1216 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 10:01:07 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.1221 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 10:01:12 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.1211 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 10:01:17 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.1221 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 10:01:23 d2.evaluation.evaluator]: \u001b[0mInference done 265/355. 0.1224 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 10:01:28 d2.evaluation.evaluator]: \u001b[0mInference done 299/355. 0.1225 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 10:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 336/355. 0.1225 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 10:01:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:49.424871 (0.141214 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:01:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.122521 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MQRT7YF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.274\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.244\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.422\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.425 | 44.144 | 31.595 | 13.687 | 30.485 | 20.274 |\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.013  | cushion    | 67.710 | door       | 5.047 |\n",
      "| indoor-plant | 19.150 | sofa       | 61.217 | table      | 6.415 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.39 seconds.\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.397\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.027 | 39.721 | 21.331 | 12.140 | 23.094 | 14.845 |\n",
      "\u001b[32m[10/21 10:01:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.500  | cushion    | 72.655 | door       | 7.113 |\n",
      "| indoor-plant | 14.524 | sofa       | 34.235 | table      | 0.134 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='MQRT7YF2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 10:01:37 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 10:01:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:01:37 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:01:37 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 10:01:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.1276 s / img. ETA=0:00:51\n",
      "\u001b[32m[10/21 10:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 46/355. 0.1242 s / img. ETA=0:00:45\n",
      "\u001b[32m[10/21 10:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 83/355. 0.1230 s / img. ETA=0:00:38\n",
      "\u001b[32m[10/21 10:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 121/355. 0.1218 s / img. ETA=0:00:32\n",
      "\u001b[32m[10/21 10:01:59 d2.evaluation.evaluator]: \u001b[0mInference done 157/355. 0.1219 s / img. ETA=0:00:27\n",
      "\u001b[32m[10/21 10:02:04 d2.evaluation.evaluator]: \u001b[0mInference done 196/355. 0.1210 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 10:02:09 d2.evaluation.evaluator]: \u001b[0mInference done 231/355. 0.1212 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 10:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 273/355. 0.1179 s / img. ETA=0:00:11\n",
      "\u001b[32m[10/21 10:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 314/355. 0.1159 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.533527 (0.132953 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.114742 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/MQRT7YF0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.17 seconds.\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.449\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.318\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.425\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.457 | 44.929 | 31.798 | 13.652 | 30.064 | 21.235 |\n",
      "\u001b[32m[10/21 10:02:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.408  | cushion    | 67.974 | door       | 4.674 |\n",
      "| indoor-plant | 21.747 | sofa       | 59.479 | table      | 6.462 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:02:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:02:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 10:02:25 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:02:25 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.04 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.321\n",
      "\u001b[32m[10/21 10:02:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.761 | 40.195 | 20.684 | 11.928 | 23.021 | 15.175 |\n",
      "\u001b[32m[10/21 10:02:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.868  | cushion    | 73.116 | door       | 6.260 |\n",
      "| indoor-plant | 16.497 | sofa       | 30.655 | table      | 0.169 |\n",
      "all results {'bbox': {'AP50': [43.401802594062346, 44.144454903267764, 44.928741562343475]}, 'segm': {'AP50': [39.21685144454949, 39.72096525730583, 40.19473600494596]}}\n",
      "dataset_name BCBNFIS\n",
      "SOLVER PARAMS (800, 100, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='BCBNFIS_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/BCBNFIS0\n",
      "output_aug/800/BCBNFIS0\n",
      "\u001b[32m[10/21 10:02:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 10:02:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 10:02:26 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 10:02:26 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 10:02:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 10:02:26 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:02:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 10:02:26 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 10:02:26 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 10:02:34 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 19  total_loss: 2.858  loss_cls: 1.152  loss_box_reg: 0.8827  loss_mask: 0.6821  loss_rpn_cls: 0.09583  loss_rpn_loc: 0.07364  time: 0.3617  data_time: 0.0213  lr: 0.00095405  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:02:41 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 39  total_loss: 2.26  loss_cls: 0.643  loss_box_reg: 0.8649  loss_mask: 0.5515  loss_rpn_cls: 0.06309  loss_rpn_loc: 0.1398  time: 0.3584  data_time: 0.0038  lr: 0.0019531  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:02:48 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 59  total_loss: 1.657  loss_cls: 0.3624  loss_box_reg: 0.784  loss_mask: 0.4  loss_rpn_cls: 0.02423  loss_rpn_loc: 0.06895  time: 0.3611  data_time: 0.0039  lr: 0.002952  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:02:55 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 79  total_loss: 1.449  loss_cls: 0.2363  loss_box_reg: 0.6289  loss_mask: 0.3145  loss_rpn_cls: 0.02176  loss_rpn_loc: 0.1421  time: 0.3590  data_time: 0.0039  lr: 0.0039511  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:02 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 99  total_loss: 1.083  loss_cls: 0.1827  loss_box_reg: 0.486  loss_mask: 0.2717  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.136  time: 0.3540  data_time: 0.0037  lr: 0.0049501  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:09 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 119  total_loss: 1.03  loss_cls: 0.1749  loss_box_reg: 0.4685  loss_mask: 0.2326  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.1222  time: 0.3537  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:16 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 139  total_loss: 0.9258  loss_cls: 0.1489  loss_box_reg: 0.4337  loss_mask: 0.2244  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.1092  time: 0.3493  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:23 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 159  total_loss: 0.7954  loss_cls: 0.1546  loss_box_reg: 0.3773  loss_mask: 0.202  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.1065  time: 0.3506  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:30 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 179  total_loss: 0.9349  loss_cls: 0.1409  loss_box_reg: 0.3773  loss_mask: 0.2313  loss_rpn_cls: 0.02879  loss_rpn_loc: 0.117  time: 0.3514  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:37 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 199  total_loss: 0.7315  loss_cls: 0.09472  loss_box_reg: 0.3469  loss_mask: 0.1957  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.08719  time: 0.3515  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:44 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 219  total_loss: 0.7696  loss_cls: 0.09852  loss_box_reg: 0.3127  loss_mask: 0.2077  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.1122  time: 0.3510  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:51 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 239  total_loss: 0.704  loss_cls: 0.1132  loss_box_reg: 0.3462  loss_mask: 0.194  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.07534  time: 0.3507  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:03:57 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 259  total_loss: 0.6675  loss_cls: 0.09712  loss_box_reg: 0.3014  loss_mask: 0.1779  loss_rpn_cls: 0.01656  loss_rpn_loc: 0.08462  time: 0.3474  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:04 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 279  total_loss: 0.6591  loss_cls: 0.08723  loss_box_reg: 0.3013  loss_mask: 0.1694  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.0619  time: 0.3486  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:12 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 299  total_loss: 0.6539  loss_cls: 0.1063  loss_box_reg: 0.2899  loss_mask: 0.1774  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.09862  time: 0.3497  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:19 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 319  total_loss: 0.6623  loss_cls: 0.1063  loss_box_reg: 0.2898  loss_mask: 0.1742  loss_rpn_cls: 0.008168  loss_rpn_loc: 0.08216  time: 0.3507  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:26 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 339  total_loss: 0.5933  loss_cls: 0.08053  loss_box_reg: 0.2375  loss_mask: 0.1701  loss_rpn_cls: 0.008221  loss_rpn_loc: 0.07988  time: 0.3504  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:33 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 359  total_loss: 0.5831  loss_cls: 0.08874  loss_box_reg: 0.2742  loss_mask: 0.1563  loss_rpn_cls: 0.007357  loss_rpn_loc: 0.07466  time: 0.3498  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:39 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 379  total_loss: 0.6302  loss_cls: 0.1051  loss_box_reg: 0.2814  loss_mask: 0.1638  loss_rpn_cls: 0.005783  loss_rpn_loc: 0.07486  time: 0.3480  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:44 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 399  total_loss: 0.6328  loss_cls: 0.09074  loss_box_reg: 0.2964  loss_mask: 0.1593  loss_rpn_cls: 0.007333  loss_rpn_loc: 0.07921  time: 0.3418  data_time: 0.0136  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:48 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 419  total_loss: 0.5717  loss_cls: 0.07882  loss_box_reg: 0.2791  loss_mask: 0.164  loss_rpn_cls: 0.009512  loss_rpn_loc: 0.0817  time: 0.3360  data_time: 0.0050  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:52 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 439  total_loss: 0.5911  loss_cls: 0.09813  loss_box_reg: 0.2558  loss_mask: 0.1407  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.08557  time: 0.3303  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:04:56 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 459  total_loss: 0.64  loss_cls: 0.08333  loss_box_reg: 0.2651  loss_mask: 0.1469  loss_rpn_cls: 0.00683  loss_rpn_loc: 0.09673  time: 0.3248  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:00 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 479  total_loss: 0.5556  loss_cls: 0.07365  loss_box_reg: 0.2819  loss_mask: 0.148  loss_rpn_cls: 0.01081  loss_rpn_loc: 0.0495  time: 0.3196  data_time: 0.0036  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:04 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 499  total_loss: 0.549  loss_cls: 0.07034  loss_box_reg: 0.2419  loss_mask: 0.1523  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.06983  time: 0.3149  data_time: 0.0035  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:08 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 519  total_loss: 0.5311  loss_cls: 0.08192  loss_box_reg: 0.2583  loss_mask: 0.1382  loss_rpn_cls: 0.005587  loss_rpn_loc: 0.04797  time: 0.3105  data_time: 0.0036  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:12 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 539  total_loss: 0.5544  loss_cls: 0.07065  loss_box_reg: 0.2472  loss_mask: 0.1358  loss_rpn_cls: 0.006199  loss_rpn_loc: 0.06626  time: 0.3064  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:16 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 559  total_loss: 0.5579  loss_cls: 0.07443  loss_box_reg: 0.253  loss_mask: 0.1458  loss_rpn_cls: 0.005996  loss_rpn_loc: 0.06805  time: 0.3026  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:20 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 579  total_loss: 0.531  loss_cls: 0.07497  loss_box_reg: 0.2552  loss_mask: 0.1217  loss_rpn_cls: 0.008546  loss_rpn_loc: 0.06479  time: 0.2991  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:24 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 599  total_loss: 0.5106  loss_cls: 0.08059  loss_box_reg: 0.2454  loss_mask: 0.1362  loss_rpn_cls: 0.006126  loss_rpn_loc: 0.0583  time: 0.2958  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:28 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 619  total_loss: 0.5135  loss_cls: 0.07772  loss_box_reg: 0.2302  loss_mask: 0.1381  loss_rpn_cls: 0.004827  loss_rpn_loc: 0.07604  time: 0.2927  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:32 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 639  total_loss: 0.5218  loss_cls: 0.08335  loss_box_reg: 0.2405  loss_mask: 0.1454  loss_rpn_cls: 0.007648  loss_rpn_loc: 0.08033  time: 0.2898  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:36 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 659  total_loss: 0.5636  loss_cls: 0.07929  loss_box_reg: 0.2275  loss_mask: 0.1419  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.09438  time: 0.2871  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:41 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 679  total_loss: 0.5356  loss_cls: 0.0865  loss_box_reg: 0.2268  loss_mask: 0.1333  loss_rpn_cls: 0.009278  loss_rpn_loc: 0.07229  time: 0.2847  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:45 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 699  total_loss: 0.4886  loss_cls: 0.06963  loss_box_reg: 0.233  loss_mask: 0.1311  loss_rpn_cls: 0.007124  loss_rpn_loc: 0.05998  time: 0.2823  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:49 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 719  total_loss: 0.519  loss_cls: 0.06938  loss_box_reg: 0.2121  loss_mask: 0.1465  loss_rpn_cls: 0.00818  loss_rpn_loc: 0.07474  time: 0.2800  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:53 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 739  total_loss: 0.525  loss_cls: 0.08312  loss_box_reg: 0.2492  loss_mask: 0.1255  loss_rpn_cls: 0.006163  loss_rpn_loc: 0.06313  time: 0.2779  data_time: 0.0039  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:05:57 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 759  total_loss: 0.5096  loss_cls: 0.06773  loss_box_reg: 0.2461  loss_mask: 0.1293  loss_rpn_cls: 0.004729  loss_rpn_loc: 0.06525  time: 0.2758  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:06:01 d2.utils.events]: \u001b[0m eta: 0:00:04  iter: 779  total_loss: 0.541  loss_cls: 0.07181  loss_box_reg: 0.2481  loss_mask: 0.1302  loss_rpn_cls: 0.00508  loss_rpn_loc: 0.0778  time: 0.2738  data_time: 0.0036  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:06:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4691  loss_cls: 0.07192  loss_box_reg: 0.2161  loss_mask: 0.1331  loss_rpn_cls: 0.005488  loss_rpn_loc: 0.0672  time: 0.2719  data_time: 0.0036  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:06:06 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:03:36 (0.2719 s / it)\n",
      "\u001b[32m[10/21 10:06:06 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:38 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='BCBNFIS_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 10:06:06 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 10:06:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:06:06 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:06:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 10:06:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 10:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.0564 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 10:06:11 d2.evaluation.evaluator]: \u001b[0mInference done 90/126. 0.0564 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.807109 (0.064522 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.056786 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BCBNFIS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.347\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.457\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 22.342 | 34.674 | 25.340 | 9.909 | 45.686 | 25.042 |\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 25.034 | cushion    | 31.910 | door       | 15.261 |\n",
      "| indoor-plant | 21.612 | sofa       | 30.442 | table      | 9.791  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.292\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.418 | 28.386 | 12.107 | 5.288 | 32.286 | 29.207 |\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 8.519  | cushion    | 28.708 | door       | 10.787 |\n",
      "| indoor-plant | 11.602 | sofa       | 23.139 | table      | 3.753  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='BCBNFIS0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 10:06:14 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 10:06:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:06:14 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:06:14 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 10:06:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 31/355. 0.0559 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 10:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 111/355. 0.0564 s / img. ETA=0:00:15\n",
      "\u001b[32m[10/21 10:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 191/355. 0.0566 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 10:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 267/355. 0.0566 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.evaluator]: \u001b[0mInference done 346/355. 0.0566 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.470774 (0.064202 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.056614 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BCBNFIS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.12 seconds.\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.412\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.440\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.335\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.510 | 41.155 | 32.064 | 16.740 | 29.123 | 19.358 |\n",
      "\u001b[32m[10/21 10:06:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 6.444  | cushion    | 66.288 | door       | 3.492 |\n",
      "| indoor-plant | 24.473 | sofa       | 58.959 | table      | 5.401 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:06:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:06:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 10:06:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:06:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.220\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.141\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.167\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      "\u001b[32m[10/21 10:06:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.985 | 37.733 | 22.557 | 14.108 | 20.521 | 16.752 |\n",
      "\u001b[32m[10/21 10:06:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.076  | cushion    | 68.356 | door       | 3.679 |\n",
      "| indoor-plant | 10.831 | sofa       | 44.919 | table      | 0.047 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='BCBNFIS1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 10:06:38 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 10:06:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:06:38 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:06:38 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 10:06:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:06:42 d2.evaluation.evaluator]: \u001b[0mInference done 51/355. 0.0586 s / img. ETA=0:00:21\n",
      "\u001b[32m[10/21 10:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 129/355. 0.0581 s / img. ETA=0:00:14\n",
      "\u001b[32m[10/21 10:06:52 d2.evaluation.evaluator]: \u001b[0mInference done 208/355. 0.0577 s / img. ETA=0:00:09\n",
      "\u001b[32m[10/21 10:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 280/355. 0.0577 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.211146 (0.066318 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057740 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BCBNFIS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.283\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.333\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.276 | 42.316 | 33.347 | 14.328 | 30.823 | 18.374 |\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.461  | cushion    | 66.933 | door       | 4.507 |\n",
      "| indoor-plant | 25.101 | sofa       | 60.083 | table      | 5.573 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.173\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.272 | 37.727 | 24.433 | 11.395 | 20.977 | 16.413 |\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.318  | cushion    | 68.011 | door       | 4.843 |\n",
      "| indoor-plant | 10.358 | sofa       | 46.075 | table      | 0.030 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='BCBNFIS2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 10:07:02 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 10:07:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:07:02 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:07:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 10:07:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/355. 0.0584 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 10:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.0572 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 10:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 165/355. 0.0572 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 10:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 239/355. 0.0572 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 10:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 313/355. 0.0573 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:23.230381 (0.066373 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057216 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/BCBNFIS0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.288\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 28.759 | 43.252 | 33.507 | 14.373 | 30.456 | 20.665 |\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 6.959  | cushion    | 68.701 | door       | 4.089 |\n",
      "| indoor-plant | 26.338 | sofa       | 60.256 | table      | 6.210 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:07:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:07:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
      "\u001b[32m[10/21 10:07:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:07:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.221\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.169\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.305\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.264\n",
      "\u001b[32m[10/21 10:07:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 22.128 | 38.743 | 23.713 | 11.450 | 21.320 | 16.894 |\n",
      "\u001b[32m[10/21 10:07:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.422  | cushion    | 69.654 | door       | 4.265 |\n",
      "| indoor-plant | 11.002 | sofa       | 43.405 | table      | 0.021 |\n",
      "all results {'bbox': {'AP50': [41.15481044883792, 42.31631990744412, 43.251955263405485]}, 'segm': {'AP50': [37.73261050118831, 37.726987467116246, 38.74298255814039]}}\n",
      "dataset_name TGED1SV\n",
      "SOLVER PARAMS (500, 200, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='TGED1SV_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/TGED1SV0\n",
      "output_aug/500/TGED1SV0\n",
      "\u001b[32m[10/21 10:07:28 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 10:07:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 10:07:28 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 10:07:28 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 10:07:28 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 10:07:28 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:07:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 10:07:28 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 10:07:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 10:07:33 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 19  total_loss: 3.353  loss_cls: 1.494  loss_box_reg: 0.8729  loss_mask: 0.6847  loss_rpn_cls: 0.1375  loss_rpn_loc: 0.0997  time: 0.2064  data_time: 0.0213  lr: 0.00047952  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:07:37 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 39  total_loss: 2.475  loss_cls: 0.7312  loss_box_reg: 0.8795  loss_mask: 0.6152  loss_rpn_cls: 0.09707  loss_rpn_loc: 0.1743  time: 0.2058  data_time: 0.0040  lr: 0.00097902  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:07:41 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 59  total_loss: 2.027  loss_cls: 0.5508  loss_box_reg: 0.8532  loss_mask: 0.4905  loss_rpn_cls: 0.02798  loss_rpn_loc: 0.1044  time: 0.2077  data_time: 0.0039  lr: 0.0014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:07:45 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 79  total_loss: 1.478  loss_cls: 0.2663  loss_box_reg: 0.7352  loss_mask: 0.3597  loss_rpn_cls: 0.01993  loss_rpn_loc: 0.09537  time: 0.2079  data_time: 0.0039  lr: 0.001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:07:49 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 99  total_loss: 1.268  loss_cls: 0.2546  loss_box_reg: 0.5776  loss_mask: 0.2964  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.1008  time: 0.2069  data_time: 0.0040  lr: 0.0024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:07:53 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 119  total_loss: 1.102  loss_cls: 0.1944  loss_box_reg: 0.5103  loss_mask: 0.2769  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.101  time: 0.2062  data_time: 0.0039  lr: 0.002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:07:57 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 139  total_loss: 0.9611  loss_cls: 0.153  loss_box_reg: 0.4613  loss_mask: 0.2593  loss_rpn_cls: 0.006286  loss_rpn_loc: 0.0822  time: 0.2068  data_time: 0.0041  lr: 0.0034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:02 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 159  total_loss: 0.8559  loss_cls: 0.1646  loss_box_reg: 0.3835  loss_mask: 0.224  loss_rpn_cls: 0.009793  loss_rpn_loc: 0.07137  time: 0.2070  data_time: 0.0039  lr: 0.003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:06 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 179  total_loss: 0.9383  loss_cls: 0.1753  loss_box_reg: 0.3991  loss_mask: 0.2197  loss_rpn_cls: 0.008886  loss_rpn_loc: 0.1069  time: 0.2063  data_time: 0.0037  lr: 0.0044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:10 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 199  total_loss: 0.887  loss_cls: 0.1527  loss_box_reg: 0.4294  loss_mask: 0.2027  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.08936  time: 0.2059  data_time: 0.0041  lr: 0.004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:14 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 219  total_loss: 0.8581  loss_cls: 0.1381  loss_box_reg: 0.4033  loss_mask: 0.201  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.1203  time: 0.2058  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:18 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 239  total_loss: 0.8562  loss_cls: 0.1332  loss_box_reg: 0.3861  loss_mask: 0.1924  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.09934  time: 0.2064  data_time: 0.0041  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:22 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 259  total_loss: 0.8184  loss_cls: 0.1313  loss_box_reg: 0.3531  loss_mask: 0.1859  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.09494  time: 0.2068  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:27 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 279  total_loss: 0.7941  loss_cls: 0.1208  loss_box_reg: 0.3679  loss_mask: 0.1843  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.09188  time: 0.2074  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:31 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 299  total_loss: 0.7569  loss_cls: 0.1194  loss_box_reg: 0.3549  loss_mask: 0.1632  loss_rpn_cls: 0.007982  loss_rpn_loc: 0.08389  time: 0.2071  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:35 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 319  total_loss: 0.6885  loss_cls: 0.1065  loss_box_reg: 0.3314  loss_mask: 0.1665  loss_rpn_cls: 0.008812  loss_rpn_loc: 0.07861  time: 0.2066  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:39 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 339  total_loss: 0.6728  loss_cls: 0.1051  loss_box_reg: 0.2884  loss_mask: 0.1784  loss_rpn_cls: 0.006471  loss_rpn_loc: 0.08543  time: 0.2062  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:43 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 359  total_loss: 0.6892  loss_cls: 0.1078  loss_box_reg: 0.3243  loss_mask: 0.1769  loss_rpn_cls: 0.007382  loss_rpn_loc: 0.0812  time: 0.2059  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:47 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 379  total_loss: 0.6654  loss_cls: 0.1205  loss_box_reg: 0.3105  loss_mask: 0.1617  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.0636  time: 0.2055  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:51 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 399  total_loss: 0.6098  loss_cls: 0.09872  loss_box_reg: 0.2765  loss_mask: 0.1565  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.08126  time: 0.2056  data_time: 0.0040  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:55 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 419  total_loss: 0.5979  loss_cls: 0.08353  loss_box_reg: 0.2732  loss_mask: 0.1593  loss_rpn_cls: 0.009345  loss_rpn_loc: 0.08669  time: 0.2053  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:08:59 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 439  total_loss: 0.6381  loss_cls: 0.09298  loss_box_reg: 0.2883  loss_mask: 0.1478  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.1101  time: 0.2050  data_time: 0.0038  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:09:03 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 459  total_loss: 0.5491  loss_cls: 0.08074  loss_box_reg: 0.2708  loss_mask: 0.1485  loss_rpn_cls: 0.006552  loss_rpn_loc: 0.0518  time: 0.2048  data_time: 0.0036  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:09:07 d2.utils.events]: \u001b[0m eta: 0:00:04  iter: 479  total_loss: 0.5873  loss_cls: 0.09197  loss_box_reg: 0.2759  loss_mask: 0.1538  loss_rpn_cls: 0.007492  loss_rpn_loc: 0.06264  time: 0.2045  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:09:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.5628  loss_cls: 0.08137  loss_box_reg: 0.2712  loss_mask: 0.143  loss_rpn_cls: 0.006281  loss_rpn_loc: 0.05823  time: 0.2044  data_time: 0.0037  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:09:12 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:01:41 (0.2044 s / it)\n",
      "\u001b[32m[10/21 10:09:12 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:42 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='TGED1SV_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 10:09:12 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 10:09:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:09:12 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:09:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 10:09:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 10:09:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.0558 s / img. ETA=0:00:06\n",
      "\u001b[32m[10/21 10:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 86/126. 0.0571 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.289162 (0.068505 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.057304 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TGED1SV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.05 seconds.\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.239\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.168\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.524\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 21.440 | 39.166 | 21.213 | 10.628 | 43.288 | 23.852 |\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 27.562 | cushion    | 29.608 | door       | 14.314 |\n",
      "| indoor-plant | 22.489 | sofa       | 25.055 | table      | 9.615  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.032 | 29.423 | 11.634 | 5.994 | 31.443 | 24.210 |\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 5.523  | cushion    | 30.494 | door       | 11.975 |\n",
      "| indoor-plant | 14.683 | sofa       | 17.163 | table      | 4.351  |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='TGED1SV0_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 10:09:21 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 10:09:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:09:21 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:09:21 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 10:09:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 22/355. 0.0586 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 10:09:28 d2.evaluation.evaluator]: \u001b[0mInference done 94/355. 0.0587 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 10:09:33 d2.evaluation.evaluator]: \u001b[0mInference done 169/355. 0.0578 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 10:09:38 d2.evaluation.evaluator]: \u001b[0mInference done 245/355. 0.0573 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 10:09:43 d2.evaluation.evaluator]: \u001b[0mInference done 315/355. 0.0572 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.188241 (0.069109 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:20 (0.057162 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TGED1SV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.236\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.451\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.395\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.195 | 41.555 | 31.511 | 16.081 | 28.905 | 20.459 |\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 3.847  | cushion    | 61.397 | door       | 9.110 |\n",
      "| indoor-plant | 27.492 | sofa       | 52.950 | table      | 2.376 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.23 seconds.\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.377\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.168\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.143\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.212\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.139\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.323 | 37.681 | 16.803 | 14.323 | 21.184 | 10.345 |\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.232  | cushion    | 68.163 | door       | 9.269 |\n",
      "| indoor-plant | 10.917 | sofa       | 19.125 | table      | 0.233 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='TGED1SV1_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 10:09:46 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 10:09:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:09:46 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:09:46 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 10:09:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:09:48 d2.evaluation.evaluator]: \u001b[0mInference done 18/355. 0.0566 s / img. ETA=0:00:24\n",
      "\u001b[32m[10/21 10:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 94/355. 0.0559 s / img. ETA=0:00:17\n",
      "\u001b[32m[10/21 10:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 169/355. 0.0561 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 10:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 242/355. 0.0562 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 10:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 310/355. 0.0563 s / img. ETA=0:00:03\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.182779 (0.069094 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.056260 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TGED1SV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.425\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.295\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.213 | 42.549 | 29.540 | 13.365 | 29.139 | 19.775 |\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 4.538  | cushion    | 61.075 | door       | 10.303 |\n",
      "| indoor-plant | 26.951 | sofa       | 51.580 | table      | 2.829  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:10:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:10:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.30 seconds.\n",
      "\u001b[32m[10/21 10:10:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:10:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.187\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.379\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.232\n",
      "\u001b[32m[10/21 10:10:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.671 | 37.905 | 17.315 | 12.298 | 21.392 | 11.262 |\n",
      "\u001b[32m[10/21 10:10:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.541  | cushion    | 68.284 | door       | 9.860 |\n",
      "| indoor-plant | 10.444 | sofa       | 20.565 | table      | 0.333 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='TGED1SV2_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 10:10:12 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 10:10:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:10:12 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:10:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 10:10:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:10:13 d2.evaluation.evaluator]: \u001b[0mInference done 13/355. 0.0567 s / img. ETA=0:00:25\n",
      "\u001b[32m[10/21 10:10:18 d2.evaluation.evaluator]: \u001b[0mInference done 87/355. 0.0556 s / img. ETA=0:00:18\n",
      "\u001b[32m[10/21 10:10:23 d2.evaluation.evaluator]: \u001b[0mInference done 158/355. 0.0563 s / img. ETA=0:00:13\n",
      "\u001b[32m[10/21 10:10:28 d2.evaluation.evaluator]: \u001b[0mInference done 230/355. 0.0562 s / img. ETA=0:00:08\n",
      "\u001b[32m[10/21 10:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 295/355. 0.0564 s / img. ETA=0:00:04\n",
      "\u001b[32m[10/21 10:10:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:24.959433 (0.071313 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:10:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.056249 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:10:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:10:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/500/TGED1SV0/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:10:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:10:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.14 seconds.\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.198\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.233\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.223 | 43.006 | 30.222 | 14.562 | 28.893 | 19.798 |\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 4.042  | cushion    | 61.258 | door       | 9.535 |\n",
      "| indoor-plant | 28.984 | sofa       | 51.105 | table      | 2.414 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.183\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.174\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.130\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.137\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.336\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.241\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 18.311 | 38.740 | 17.443 | 12.960 | 21.089 | 10.842 |\n",
      "\u001b[32m[10/21 10:10:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 2.633  | cushion    | 67.918 | door       | 9.247 |\n",
      "| indoor-plant | 11.225 | sofa       | 18.653 | table      | 0.192 |\n",
      "all results {'bbox': {'AP50': [41.55508264064968, 42.54861584238003, 43.00580947539067]}, 'segm': {'AP50': [37.680545024302674, 37.90469176705036, 38.739856333702136]}}\n",
      "dataset_name JDTL5V5\n",
      "SOLVER PARAMS (800, 200, 0.005)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/activeonly/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json', name='JDTL5V5_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/800/JDTL5V50\n",
      "output_aug/800/JDTL5V50\n",
      "\u001b[32m[10/21 10:10:39 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 10:10:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n",
      "101 101\n",
      "\u001b[32m[10/21 10:10:39 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from /checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/activeonly/pred_label_gt5p2/coco_train.json\n",
      "\u001b[32m[10/21 10:10:39 d2.data.build]: \u001b[0mRemoved 2 images with no usable annotations. 14 images left.\n",
      "\u001b[32m[10/21 10:10:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/21 10:10:39 d2.data.common]: \u001b[0mSerializing 14 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:10:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.06 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/21 10:10:39 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (6, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/21 10:10:39 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/21 10:10:43 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 19  total_loss: 3.287  loss_cls: 1.52  loss_box_reg: 0.8921  loss_mask: 0.687  loss_rpn_cls: 0.1241  loss_rpn_loc: 0.1632  time: 0.2003  data_time: 0.0147  lr: 0.00047953  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:10:47 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 39  total_loss: 2.43  loss_cls: 0.7724  loss_box_reg: 0.8843  loss_mask: 0.6231  loss_rpn_cls: 0.07181  loss_rpn_loc: 0.1096  time: 0.2013  data_time: 0.0034  lr: 0.00097903  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:10:51 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 59  total_loss: 2.151  loss_cls: 0.5464  loss_box_reg: 0.8306  loss_mask: 0.5325  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.1419  time: 0.2009  data_time: 0.0033  lr: 0.0014785  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:10:55 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 79  total_loss: 1.533  loss_cls: 0.3462  loss_box_reg: 0.7467  loss_mask: 0.3418  loss_rpn_cls: 0.0172  loss_rpn_loc: 0.08276  time: 0.2006  data_time: 0.0032  lr: 0.001978  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:10:59 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 99  total_loss: 1.271  loss_cls: 0.2187  loss_box_reg: 0.5942  loss_mask: 0.2889  loss_rpn_cls: 0.02349  loss_rpn_loc: 0.1361  time: 0.2002  data_time: 0.0034  lr: 0.0024775  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:03 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 119  total_loss: 1.13  loss_cls: 0.179  loss_box_reg: 0.5061  loss_mask: 0.274  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.08616  time: 0.2005  data_time: 0.0033  lr: 0.002977  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:07 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 139  total_loss: 0.9834  loss_cls: 0.1802  loss_box_reg: 0.4436  loss_mask: 0.2713  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.09061  time: 0.2007  data_time: 0.0033  lr: 0.0034765  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:12 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 159  total_loss: 0.9553  loss_cls: 0.1876  loss_box_reg: 0.4279  loss_mask: 0.2453  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.09552  time: 0.2008  data_time: 0.0033  lr: 0.003976  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:16 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 179  total_loss: 0.9143  loss_cls: 0.168  loss_box_reg: 0.407  loss_mask: 0.232  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.1042  time: 0.2007  data_time: 0.0034  lr: 0.0044755  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:20 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 199  total_loss: 0.8943  loss_cls: 0.1519  loss_box_reg: 0.4185  loss_mask: 0.2354  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.1161  time: 0.2008  data_time: 0.0032  lr: 0.004975  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:24 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 219  total_loss: 0.8817  loss_cls: 0.1449  loss_box_reg: 0.3805  loss_mask: 0.2239  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.0992  time: 0.2007  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:28 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 239  total_loss: 0.8967  loss_cls: 0.1295  loss_box_reg: 0.3871  loss_mask: 0.2168  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.1126  time: 0.2007  data_time: 0.0032  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:32 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 259  total_loss: 0.8217  loss_cls: 0.1291  loss_box_reg: 0.3537  loss_mask: 0.2067  loss_rpn_cls: 0.01768  loss_rpn_loc: 0.1221  time: 0.2005  data_time: 0.0033  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:36 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 279  total_loss: 0.8192  loss_cls: 0.1143  loss_box_reg: 0.3392  loss_mask: 0.1788  loss_rpn_cls: 0.008642  loss_rpn_loc: 0.1015  time: 0.2006  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:40 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 299  total_loss: 0.7292  loss_cls: 0.1183  loss_box_reg: 0.3354  loss_mask: 0.1815  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.09168  time: 0.2005  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:44 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 319  total_loss: 0.682  loss_cls: 0.1004  loss_box_reg: 0.2987  loss_mask: 0.1558  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.06703  time: 0.2006  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:48 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 339  total_loss: 0.7339  loss_cls: 0.1111  loss_box_reg: 0.3369  loss_mask: 0.1803  loss_rpn_cls: 0.0194  loss_rpn_loc: 0.08949  time: 0.2010  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:11:54 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 359  total_loss: 0.7082  loss_cls: 0.1063  loss_box_reg: 0.2845  loss_mask: 0.1551  loss_rpn_cls: 0.009972  loss_rpn_loc: 0.1024  time: 0.2066  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:01 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 379  total_loss: 0.743  loss_cls: 0.122  loss_box_reg: 0.2981  loss_mask: 0.1813  loss_rpn_cls: 0.046  loss_rpn_loc: 0.1059  time: 0.2142  data_time: 0.0033  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:08 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 399  total_loss: 0.7282  loss_cls: 0.09818  loss_box_reg: 0.3091  loss_mask: 0.1827  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.08512  time: 0.2210  data_time: 0.0033  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:15 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 419  total_loss: 0.6768  loss_cls: 0.1067  loss_box_reg: 0.3173  loss_mask: 0.1744  loss_rpn_cls: 0.006789  loss_rpn_loc: 0.08999  time: 0.2270  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:22 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 439  total_loss: 0.601  loss_cls: 0.1002  loss_box_reg: 0.2587  loss_mask: 0.1512  loss_rpn_cls: 0.008466  loss_rpn_loc: 0.06925  time: 0.2329  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:29 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 459  total_loss: 0.6457  loss_cls: 0.1019  loss_box_reg: 0.2934  loss_mask: 0.1688  loss_rpn_cls: 0.008646  loss_rpn_loc: 0.08781  time: 0.2381  data_time: 0.0032  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:36 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 479  total_loss: 0.5632  loss_cls: 0.08457  loss_box_reg: 0.2529  loss_mask: 0.15  loss_rpn_cls: 0.007091  loss_rpn_loc: 0.06933  time: 0.2428  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:43 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 499  total_loss: 0.657  loss_cls: 0.09154  loss_box_reg: 0.2757  loss_mask: 0.1719  loss_rpn_cls: 0.008442  loss_rpn_loc: 0.1008  time: 0.2473  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:50 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 519  total_loss: 0.5543  loss_cls: 0.0852  loss_box_reg: 0.2494  loss_mask: 0.143  loss_rpn_cls: 0.005531  loss_rpn_loc: 0.08911  time: 0.2512  data_time: 0.0033  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:12:57 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 539  total_loss: 0.6198  loss_cls: 0.09355  loss_box_reg: 0.2858  loss_mask: 0.1495  loss_rpn_cls: 0.008679  loss_rpn_loc: 0.08199  time: 0.2551  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:04 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 559  total_loss: 0.6067  loss_cls: 0.09202  loss_box_reg: 0.2756  loss_mask: 0.1583  loss_rpn_cls: 0.005418  loss_rpn_loc: 0.05863  time: 0.2583  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:11 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 579  total_loss: 0.5992  loss_cls: 0.09545  loss_box_reg: 0.2873  loss_mask: 0.1435  loss_rpn_cls: 0.00575  loss_rpn_loc: 0.07534  time: 0.2616  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:18 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 599  total_loss: 0.5656  loss_cls: 0.07805  loss_box_reg: 0.2548  loss_mask: 0.1463  loss_rpn_cls: 0.009153  loss_rpn_loc: 0.05717  time: 0.2644  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:25 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 619  total_loss: 0.5551  loss_cls: 0.08556  loss_box_reg: 0.2637  loss_mask: 0.1409  loss_rpn_cls: 0.007336  loss_rpn_loc: 0.06776  time: 0.2671  data_time: 0.0035  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:32 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 639  total_loss: 0.5707  loss_cls: 0.09075  loss_box_reg: 0.2463  loss_mask: 0.1528  loss_rpn_cls: 0.00818  loss_rpn_loc: 0.08001  time: 0.2696  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:39 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 659  total_loss: 0.5327  loss_cls: 0.06943  loss_box_reg: 0.2394  loss_mask: 0.1464  loss_rpn_cls: 0.004436  loss_rpn_loc: 0.05237  time: 0.2723  data_time: 0.0035  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:46 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 679  total_loss: 0.5483  loss_cls: 0.08492  loss_box_reg: 0.2386  loss_mask: 0.1409  loss_rpn_cls: 0.004545  loss_rpn_loc: 0.06991  time: 0.2748  data_time: 0.0036  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:13:53 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 699  total_loss: 0.6006  loss_cls: 0.09927  loss_box_reg: 0.2543  loss_mask: 0.1509  loss_rpn_cls: 0.004927  loss_rpn_loc: 0.09649  time: 0.2769  data_time: 0.0035  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:14:00 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 719  total_loss: 0.4836  loss_cls: 0.07437  loss_box_reg: 0.2303  loss_mask: 0.1193  loss_rpn_cls: 0.004965  loss_rpn_loc: 0.05469  time: 0.2788  data_time: 0.0032  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:14:07 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 739  total_loss: 0.5613  loss_cls: 0.07974  loss_box_reg: 0.2411  loss_mask: 0.1415  loss_rpn_cls: 0.005353  loss_rpn_loc: 0.06787  time: 0.2809  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:14:14 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 759  total_loss: 0.5121  loss_cls: 0.08382  loss_box_reg: 0.2283  loss_mask: 0.132  loss_rpn_cls: 0.004177  loss_rpn_loc: 0.05989  time: 0.2827  data_time: 0.0033  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:14:21 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 779  total_loss: 0.5078  loss_cls: 0.08828  loss_box_reg: 0.2164  loss_mask: 0.1405  loss_rpn_cls: 0.006798  loss_rpn_loc: 0.0744  time: 0.2845  data_time: 0.0032  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:14:29 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 799  total_loss: 0.4934  loss_cls: 0.0762  loss_box_reg: 0.2407  loss_mask: 0.1316  loss_rpn_cls: 0.005259  loss_rpn_loc: 0.05208  time: 0.2862  data_time: 0.0034  lr: 0.005  max_mem: 3290M\n",
      "\u001b[32m[10/21 10:14:29 d2.engine.hooks]: \u001b[0mOverall training speed: 798 iterations in 0:03:48 (0.2862 s / it)\n",
      "\u001b[32m[10/21 10:14:29 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:49 (0:00:01 on hooks)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/rgb', json_file='/checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json', name='JDTL5V5_val0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "586 586\n",
      "\u001b[32m[10/21 10:14:29 d2.data.datasets.coco]: \u001b[0mLoaded 126 images in COCO format from /checkpoint/apratik/data/data/apartment_0/default/no_noise/mul_traj_200/83/seg/coco_train.json\n",
      "\u001b[32m[10/21 10:14:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:14:29 d2.data.common]: \u001b[0mSerializing 126 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:14:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.35 MiB\n",
      "\u001b[32m[10/21 10:14:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 126 images\n",
      "\u001b[32m[10/21 10:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/126. 0.1058 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 10:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 56/126. 0.1076 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 10:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 101/126. 0.1067 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:13.205181 (0.109134 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:12 (0.102594 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/JDTL5V50/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.365\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.384\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.763 | 36.532 | 21.713 | 10.747 | 43.338 | 26.212 |\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| chair        | 27.159 | cushion    | 30.942 | door       | 13.165 |\n",
      "| indoor-plant | 15.842 | sofa       | 29.503 | table      | 7.964  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.145\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.275\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 14.481 | 27.519 | 12.934 | 6.009 | 32.273 | 28.571 |\n",
      "\u001b[32m[10/21 10:14:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.504  | cushion    | 30.866 | door       | 9.391 |\n",
      "| indoor-plant | 10.889 | sofa       | 24.169 | table      | 3.070 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json', name='JDTL5V50_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1832 1832\n",
      "\u001b[32m[10/21 10:14:43 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n0.json\n",
      "\u001b[32m[10/21 10:14:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:14:44 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:14:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.24 MiB\n",
      "\u001b[32m[10/21 10:14:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 30/355. 0.0585 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 10:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 109/355. 0.0574 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 10:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 192/355. 0.0564 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 10:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 269/355. 0.0563 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.evaluator]: \u001b[0mInference done 350/355. 0.0559 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.229674 (0.063513 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.055944 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/JDTL5V50/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.040 | 40.781 | 30.417 | 16.898 | 27.594 | 19.323 |\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 7.763  | cushion    | 62.667 | door       | 1.432 |\n",
      "| indoor-plant | 18.641 | sofa       | 62.181 | table      | 3.559 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:15:06 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:15:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[10/21 10:15:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:15:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.389\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.254\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.261\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.321\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "\u001b[32m[10/21 10:15:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.271 | 38.898 | 25.435 | 14.188 | 26.069 | 17.200 |\n",
      "\u001b[32m[10/21 10:15:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.171  | cushion    | 69.188 | door       | 1.555 |\n",
      "| indoor-plant | 17.804 | sofa       | 51.351 | table      | 0.554 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json', name='JDTL5V51_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1808 1808\n",
      "\u001b[32m[10/21 10:15:07 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n1.json\n",
      "\u001b[32m[10/21 10:15:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:15:07 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:15:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.23 MiB\n",
      "\u001b[32m[10/21 10:15:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:15:11 d2.evaluation.evaluator]: \u001b[0mInference done 60/355. 0.0562 s / img. ETA=0:00:19\n",
      "\u001b[32m[10/21 10:15:16 d2.evaluation.evaluator]: \u001b[0mInference done 145/355. 0.0552 s / img. ETA=0:00:12\n",
      "\u001b[32m[10/21 10:15:21 d2.evaluation.evaluator]: \u001b[0mInference done 228/355. 0.0551 s / img. ETA=0:00:07\n",
      "\u001b[32m[10/21 10:15:26 d2.evaluation.evaluator]: \u001b[0mInference done 307/355. 0.0552 s / img. ETA=0:00:02\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:21.471695 (0.061348 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.054975 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/JDTL5V50/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.11 seconds.\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.291\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.208\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.437\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 26.963 | 42.319 | 31.676 | 16.414 | 29.118 | 18.379 |\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.910  | cushion    | 63.701 | door       | 1.860 |\n",
      "| indoor-plant | 18.541 | sofa       | 64.461 | table      | 4.307 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.392\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.353\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.764 | 39.205 | 27.047 | 15.504 | 26.014 | 17.123 |\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.786  | cushion    | 69.858 | door       | 2.048 |\n",
      "| indoor-plant | 16.735 | sofa       | 53.738 | table      | 0.417 |\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/ActiveVision/active_vision/replica_random_exploration_data/frl_apartment_1/rgb', json_file='/checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json', name='JDTL5V52_test0', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "1972 1972\n",
      "\u001b[32m[10/21 10:15:29 d2.data.datasets.coco]: \u001b[0mLoaded 355 images in COCO format from /checkpoint/apratik/finals/jsons/active_vision/frlapt1_20n2.json\n",
      "\u001b[32m[10/21 10:15:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/21 10:15:29 d2.data.common]: \u001b[0mSerializing 355 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/21 10:15:29 d2.data.common]: \u001b[0mSerialized dataset takes 1.31 MiB\n",
      "\u001b[32m[10/21 10:15:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 355 images\n",
      "\u001b[32m[10/21 10:15:31 d2.evaluation.evaluator]: \u001b[0mInference done 21/355. 0.0573 s / img. ETA=0:00:23\n",
      "\u001b[32m[10/21 10:15:36 d2.evaluation.evaluator]: \u001b[0mInference done 102/355. 0.0559 s / img. ETA=0:00:16\n",
      "\u001b[32m[10/21 10:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 186/355. 0.0555 s / img. ETA=0:00:10\n",
      "\u001b[32m[10/21 10:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 262/355. 0.0558 s / img. ETA=0:00:05\n",
      "\u001b[32m[10/21 10:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 344/355. 0.0555 s / img. ETA=0:00:00\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:22.013279 (0.062895 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:19 (0.055478 s / img per device, on 1 devices)\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to output_aug/800/JDTL5V50/coco_instances_results.json\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.11 seconds.\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.423\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.429\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 27.044 | 42.306 | 31.444 | 19.557 | 28.899 | 19.581 |\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 8.009  | cushion    | 64.102 | door       | 1.486 |\n",
      "| indoor-plant | 20.462 | sofa       | 64.078 | table      | 4.124 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.20 seconds.\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.402\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.265\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.244\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.569 | 40.206 | 26.548 | 18.565 | 26.554 | 16.636 |\n",
      "\u001b[32m[10/21 10:15:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| chair        | 5.447  | cushion    | 69.636 | door       | 1.620 |\n",
      "| indoor-plant | 18.103 | sofa       | 52.200 | table      | 0.408 |\n",
      "all results {'bbox': {'AP50': [40.78075554827112, 42.31878509308257, 42.30558342470192]}, 'segm': {'AP50': [38.8982032135991, 39.20492986638102, 40.20554149000578]}}\n",
      "dataset_name 915DD68\n",
      "SOLVER PARAMS (500, 100, 0.0001)\n",
      "classes Metadata(evaluator_type='coco', image_root='/checkpoint/apratik/data_devfair0187/apartment_0/straightline/no_noise/1633991019/1/default/rgb', json_file='/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p4/coco_train.json', name='915DD68_train', thing_classes=['chair', 'cushion', 'door', 'indoor-plant', 'sofa', 'table'])\n",
      "recreating output_aug/500/915DD680\n",
      "output_aug/500/915DD680\n",
      "\u001b[32m[10/21 10:15:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=7, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/21 10:15:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomCrop(crop_type='absolute', crop_size=(640, 640)), RandomBrightness(intensity_min=0.9, intensity_max=1.1)]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p4/coco_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3c058bd343b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-684278b7248b>\u001b[0m in \u001b[0;36m_runner\u001b[0;34m(trajs, gt, ps)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0moutdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'pred_label_gt{gt}p{p}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"*.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                         \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-97b0a3aceed1>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(out_dir, img_dir_train, n, traj, x, gt, p)\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_uppercase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'dataset_name {dataset_name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0mres_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation_results.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-97b0a3aceed1>\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, train_json, img_dir_train, dataset_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# self.vis()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-97b0a3aceed1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#DefaultTrainer(cfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# For training, wrap with DDP. But don't need this for inference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-97b0a3aceed1>\u001b[0m in \u001b[0;36mbuild_train_loader\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomBrightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         ])\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_detection_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCOCOTrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_called_with_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                     \u001b[0mexplicit_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_args_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0morig_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mexplicit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36m_get_args_from_config\u001b[0;34m(from_config_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_arg_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mextra_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_config_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;31m# forward the other arguments to __init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36m_train_loader_from_config\u001b[0;34m(cfg, mapper, dataset, sampler)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKEYPOINT_ON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mproposal_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROPOSAL_FILES_TRAIN\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOAD_PROPOSALS\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36mget_detection_dataset_dicts\u001b[0;34m(names, filter_empty, min_keypoints, proposal_files)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is empty!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/data/build.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mdataset_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is empty!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 )\n\u001b[1;32m     57\u001b[0m             ) from e\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mload_coco_json\u001b[0;34m(json_file, image_root, dataset_name, extra_annotation_keys)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredirect_stdout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mcoco_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading {} takes {:.2f} seconds.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/locobot_env/lib/python3.7/site-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading annotations into memory...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             assert type(dataset) == dict, 'annotation file format {} not supported'.format(\n\u001b[1;32m     82\u001b[0m                 type(dataset))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/checkpoint/apratik/jobs/active_vision/pipeline/apartment_0/straightline/no_noise/14-10-2021/19:17:17/1/default/pred_label_gt5p4/coco_train.json'"
     ]
    }
   ],
   "source": [
    "_runner([1,3,6,10,13], 5, [2,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc838dac-4db0-4a76-bb13-9b7536e2a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loco",
   "language": "python",
   "name": "loco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
